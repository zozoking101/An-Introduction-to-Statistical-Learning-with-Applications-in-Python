{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d02f63a",
   "metadata": {},
   "source": [
    "### Linear Model Selection and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee38c5e2",
   "metadata": {},
   "source": [
    "In the regression setting, the standard linear model\n",
    "Y = 0+ 1X1+···+ pXp+\n",
    "(6.1)\n",
    "is commonly used to describe the relationship between a response Y and\n",
    "a set of variables X1,X2,...,Xp. We have seen in Chapter 3 that one\n",
    "typically fits this model using least squares.\n",
    "In the chapters that follow, we consider some approaches for extending\n",
    "the linear model framework. In Chapter 7 we generalize (6.1) in order to\n",
    "accommodate non-linear, but still additive, relationships, while in Chap\n",
    "ters 8 and 10 we consider even more general non-linear models. However,\n",
    "the linear model has distinct advantages in terms of inference and, on real\n",
    "world problems, is often surprisingly competitive in relation to non-linear\n",
    "methods. Hence, before moving to the non-linear world, we discuss in this\n",
    "chapter some ways in which the simple linear model can be improved, by re\n",
    "placing plain least squares fitting with some alternative fitting procedures.\n",
    "Why might we want to use another fitting procedure instead of least\n",
    "squares? As we will see, alternative fitting procedures can yield better pre\n",
    "diction accuracy and model interpretability.\n",
    "\n",
    "• Prediction Accuracy: Provided that the true relationship between the\n",
    "response and the predictors is approximately linear, the least squares\n",
    "estimates will have low bias. If n \n",
    "p—that is, if n, the number of\n",
    "observations, is much larger than p, the number of variables—then the\n",
    "least squares estimates tend to also have low variance, and hence will\n",
    "perform well on test observations. However, if n is not much larger\n",
    "than p, then there can be a lot of variability in the least squares fit,\n",
    "resulting in overfitting and consequently poor predictions on future\n",
    "observations not used in model training. And if p>n, then there is no\n",
    "longer a unique least squares coefficient estimate: there are infinitely many solutions. Each of these least squares solutions gives zero error\n",
    "on the training data, but typically very poor test set performance\n",
    "due to extremely high variance.1 By constraining or shrinking the\n",
    "estimated coefficients, we can often substantially reduce the variance\n",
    "at the cost of a negligible increase in bias. This can lead to substantial\n",
    "improvements in the accuracy with which we can predict the response\n",
    "for observations not used in model training.\n",
    "\n",
    "• Model Interpretability: It is often the case that some or many of the\n",
    "variables used in a multiple regression model are in fact not associ\n",
    "ated with the response. Including such irrelevant variables leads to\n",
    "unnecessary complexity in the resulting model. By removing these\n",
    "variables—that is, by setting the corresponding coefficient estimates\n",
    "to zero—we can obtain a model that is more easily interpreted. Now\n",
    "least squares is extremely unlikely to yield any coefficient estimates\n",
    "that are exactly zero. In this chapter, we see some approaches for au\n",
    "tomatically performing feature selection or variable selection—that is, feature\n",
    "for excluding irrelevant variables from a multiple regression model.\n",
    "\n",
    "There are many alternatives, both classical and modern, to using least\n",
    "squares to fit (6.1). In this chapter, we discuss three important classes of\n",
    "methods.\n",
    "\n",
    "• Subset Selection. This approach involves identifying a subset of the p\n",
    "predictors that we believe to be related to the response. We then fit\n",
    "a model using least squares on the reduced set of variables.\n",
    "\n",
    "• Shrinkage. This approach involves fitting a model involving all p pre\n",
    "dictors. However, the estimated coefficients are shrunken towards zero\n",
    "relative to the least squares estimates. This shrinkage (also known as\n",
    "regularization) has the effect of reducing variance. Depending on what\n",
    "type of shrinkage is performed, some of the coefficients may be esti\n",
    "mated to be exactly zero. Hence, shrinkage methods can also perform\n",
    "variable selection.\n",
    "\n",
    "• Dimension Reduction. This approach involves projecting the p predic\n",
    "tors into an M-dimensional subspace, where M<p.This is achieved\n",
    "by computing M different linear combinations, or projections, of the\n",
    "variables. Then these M projections are used as predictors to fit a\n",
    "linear regression model by least squares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96fdead",
   "metadata": {},
   "source": [
    "#### Subset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9d046b",
   "metadata": {},
   "source": [
    "##### Best Subset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaac9018",
   "metadata": {},
   "source": [
    "To perform *best subset selection*, we fit a separate least squares regression for each of the models of the p predictors. That is, we fit all p models that contain exactly one predictor, all $ \\binom{p}{2} $ models that contain exactly two predictors, and so on. We look at all of the resulting models, with the goal of identifying the one that is the best.\n",
    "\n",
    "The problem of selecting the best model from among the $ 2^p $ possibilities considered by best subset selection is then usually broken up into two stages, as described in Algorithm 6.1.\n",
    "\n",
    "##### **Algorithm 6.1** *Best subset selection*\n",
    "\n",
    "1. Let $ M_0 $ denote the null model, which contains no predictors. This model simply predicts the sample mean for each observation.\n",
    "\n",
    "2. For $ k = 1, 2, \\ldots, p $:\n",
    "\n",
    "   (a) Fit all $ \\binom{p}{k} $ models that contain exactly k predictors.\n",
    "   \n",
    "   (b) Pick the best among these models, and call it $ M_k $. Here “best” is defined as having the smallest RSS, or equivalently $ R^2 $.\n",
    "\n",
    "3. Select a single best model from among $ M_0, \\ldots, M_p $ using the prediction error on a validation set, $ C_p $ (AIC), BIC, or adjusted $ R^2 $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a33b0f1",
   "metadata": {},
   "source": [
    "In Algorithm 6.1, Step 2 identifies the best model (on the training data)\n",
    "for each subset size, in order to reduce the problem from one of 2p possible\n",
    "models to one of p +1possible models. In Figure 6.1, these models form\n",
    "the lower frontier depicted in red.\n",
    "Now in order to select a single best model, we must simply choose among\n",
    "these p +1options. This task must be performed with care, because the\n",
    "RSS of these p +1models decreases monotonically, and the R2 increases\n",
    "monotonically, as the number of features included in the models increases.\n",
    "Therefore, if we use these statistics to select the best model, then we will\n",
    "always end up with a model involving all of the variables. The problem is\n",
    "that a low RSS or a high R2 indicates a model with a low training error,\n",
    "whereas we wish to choose a model that has a low test error. (As shown in\n",
    "Chapter 2 in Figures 2.9–2.11, training error tends to be quite a bit smaller\n",
    "than test error, and a low training error by no means guarantees a low test\n",
    "error.) Therefore, in Step 3, we use the error on a validation set, Cp, BIC, or\n",
    "adjusted R2 in order to select among M0,M1,...,Mp. If cross-validation\n",
    "is used to select the best model, then Step 2 is repeated on each training\n",
    "fold, and the validation errors are averaged to select the best value of k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cd273c",
   "metadata": {},
   "source": [
    "Then the model Mk fit on the full training set is delivered for the chosen\n",
    "k. These approaches are discussed in Section 6.1.3.\n",
    "An application of best subset selection is shown in Figure 6.1. Each\n",
    "plotted point corresponds to a least squares regression model fit using a\n",
    "different subset of the 10 predictors in the Credit data set, discussed in\n",
    "Chapter 3. Here the variable region is a three-level qualitative variable,\n",
    "and so is represented by two dummy variables, which are selected sepa\n",
    "rately in this case. Hence, there are a total of 11 possible variables which\n",
    "can be included in the model. We have plotted the RSS and R2 statistics\n",
    "for each model, as a function of the number of variables. The red curves\n",
    "connect the best models for each model size, according to RSS or R2. The\n",
    "f\n",
    "igure shows that, as expected, these quantities improve as the number of\n",
    "variables increases; however, from the three-variable model on, there is little\n",
    "improvement in RSS and R2 as a result of including additional predictors.\n",
    "Although we have presented best subset selection here for least squares\n",
    "regression, the same ideas apply to other types of models, such as logistic\n",
    "regression. In the case of logistic regression, instead of ordering models by\n",
    "RSS in Step 2 of Algorithm 6.1, we instead use the deviance, a measure deviance\n",
    "that plays the role of RSS for a broader class of models. The deviance is\n",
    "negative two times the maximized log-likelihood; the smaller the deviance,\n",
    "the better the fit.\n",
    "While best subset selection is a simple and conceptually appealing ap\n",
    "proach, it suffers from computational limitations. The number of possible\n",
    "models that must be considered grows rapidly as p increases. In general,\n",
    "there are 2p models that involve subsets of p predictors. So if p = 10,\n",
    "then there are approximately 1,000 possible models to be considered, and if\n",
    "p =20,then there are over one million possibilities! Consequently, best sub\n",
    "set selection becomes computationally infeasible for values of p greater than around 40, even with extremely fast modern computers. There are compu\n",
    "tational shortcuts—so called branch-and-bound techniques—for eliminat\n",
    "ing some choices, but these have their limitations as p gets large. They also\n",
    "only work for least squares linear regression. We present computationally\n",
    "efficient alternatives to best subset selection next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097842b",
   "metadata": {},
   "source": [
    "##### **Algorithm 6.2** *Forward stepwise selection*\n",
    "\n",
    "1. Let $ M_0 $ denote the null model, which contains no predictors.\n",
    "\n",
    "2. For $ k = 0, \\ldots, p - 1 $:\n",
    "\n",
    "   - (a) Consider all $ p - k $ models that augment the predictors in $ M_k $ with one additional predictor.\n",
    "   \n",
    "   - (b) Choose the best among these $ p - k $ models, and call it $ M_{k+1} $. Here best is defined as having the smallest RSS or highest $ R^2 $.\n",
    "\n",
    "3. Select a single best model from among $ M_0, \\ldots, M_p $ using the prediction error on a validation set, $ C_p $ (AIC), BIC, or adjusted $ R^2 $. Or use the cross-validation method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f255d",
   "metadata": {},
   "source": [
    "##### Stepwise Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc158be",
   "metadata": {},
   "source": [
    "For computational reasons, best subset selection cannot be applied with\n",
    "very large p. Best subset selection may also suffer from statistical problems\n",
    "when p is large. The larger the search space, the higher the chance of finding\n",
    "models that look good on the training data, even though they might not\n",
    "have any predictive power on future data. Thus an enormous search space\n",
    "can lead to overfitting and high variance of the coefficient estimates.\n",
    "For both of these reasons, stepwise methods, which explore a far more\n",
    "restricted set of models, are attractive alternatives to best subset selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679aab05",
   "metadata": {},
   "source": [
    "Forward Stepwise Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36191d1",
   "metadata": {},
   "source": [
    "*Forward stepwise selection* is a computationally efficient alternative to best subset selection. While the best subset selection procedure considers all\n",
    "2p possible models containing subsets of the p predictors, forward step\n",
    "wise considers a much smaller set of models. Forward stepwise selection\n",
    "begins with a model containing no predictors, and then adds predictors\n",
    "to the model, one-at-a-time, until all of the predictors are in the model.\n",
    "In particular, at each step the variable that gives the greatest additional\n",
    "improvement to the fit is added to the model. More formally, the forward\n",
    "stepwise selection procedure is given in Algorithm 6.2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a161f3",
   "metadata": {},
   "source": [
    "## 6. Linear Model Selection and Regularization\n",
    "\n",
    "Unlike best subset selection, which involved fitting $ 2^p $ models, forward stepwise selection involves fitting one null model, along with $ p - k $ models in the $ k $-th iteration, for $ k = 0, \\ldots, p - 1 $. This amounts to a total of $ 1 + \\sum_{i=0}^{p-1} (p - i) = 1 + p(p + 1)/2 $ models. This is a substantial difference: when $p$ = 20, best subset selection requires fitting $ 1,048,576 $ models, whereas forward stepwise selection requires fitting only $ 21 $ models. \n",
    "\n",
    "In step 2(b) of Algorithm 6.2, we identify the best model from those available, which augment $ M_k $ with one additional predictor. We do this by simply choosing the model with the lowest RSS or the highest $ R^2 $. In this case, we must identify the best model from a set of models with different numbers of variables. This is more challenging, and is discussed in Section 6.1.3.\n",
    "\n",
    "Forward stepwise selection's computational advantage over best subset selection is clear. Though forward stepwise seems to work well in practice, it is important to keep in mind that it is fundamentally a greedy algorithm. In a data set with $ p $ predictors, the best possible model will include predictors $ X_2 $ and $ X_1 $. However, forward stepwise selection is still unable to find the best possible model among $ M_1, M_2, $ and those available with $ X_1 $ together with an additional variable.\n",
    "\n",
    "As shown in Section 6.1.3, the forward stepwise selection on the Credit data set illustrates this phenomenon. Both forward stepwise selection and best subset selection favored models that included the predictors rating and income, whereas the best subset selection also included the variable student.\n",
    "\n",
    "In high-dimensional settings where $ p $ is greater than $ n $, forward stepwise selection can still be applied even when subset selection cannot. If $ p $ is greater than $ n $, each time an additional variable is included, only the subset of $ M_0, \\ldots, M_k $ can be constructed, which avoids overfitting, as each submodel is fit using least squares, which does not yield a unique solution if $ p > n $.\n",
    "\n",
    "\n",
    "\n",
    "| # Variables | Best subset                      | Forward stepwise                  |\n",
    "|-------------|----------------------------------|-----------------------------------|\n",
    "| One         | `rating`                           | `rating`                            |\n",
    "| Two         | `rating`, `income`                   | `rating`, `income`                    |\n",
    "| Three       | `rating`, `income`, `student`              | `rating`, `income`, `student`               |\n",
    "| Four        | `cards`, `income`, `student`, `limit` | `rating`, `income`, `student`, `limit` |\n",
    "\n",
    "The first four selected models for best subset selection and forward stepwise selection on the Credit data set. The first three models are identical but the fourth models differ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d33c838",
   "metadata": {},
   "source": [
    "Backward Stepwise Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4bc443",
   "metadata": {},
   "source": [
    "Like forward stepwise selection, backward stepwise selection provides an efficient alternative to best subset selection. However, unlike forward step\n",
    "wise selection, it begins with the full least squares model containing all p\n",
    "predictors, and then iteratively removes the least useful predictor, one-at\n",
    "a-time. Details are given in Algorithm 6.3.\n",
    "\n",
    "\n",
    "Like forward stepwise selection, the backward selection approach searches\n",
    "through only 1+p(p+1)/2 models, and so can be applied in settings where\n",
    "p is too large to apply best subset selection.3 Also like forward stepwise\n",
    "selection, backward stepwise selection is not guaranteed to yield the best\n",
    "model containing a subset of the p predictors.\n",
    "Backward selection requires that the number of samples n is larger than\n",
    "the number of variables p (so that the full model can be fit). In contrast,\n",
    "forward stepwise can be used even when n<p, and so is the only viable\n",
    "subset method when p is very large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2df46a",
   "metadata": {},
   "source": [
    "Hybrid Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a7e4e",
   "metadata": {},
   "source": [
    "The best subset, forward stepwise, and backward stepwise selection ap\n",
    "proaches generally give similar but not identical models. As another al\n",
    "ternative, hybrid versions of forward and backward stepwise selection are\n",
    "available, in which variables are added to the model sequentially, in analogy\n",
    "to forward selection. However, after adding each new variable, the method\n",
    "may also remove any variables that no longer provide an improvement in\n",
    "the model fit. Such an approach attempts to more closely mimic best sub\n",
    "set selection while retaining the computational advantages of forward and\n",
    "backward stepwise selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b066da3",
   "metadata": {},
   "source": [
    "##### Choosing the Optimal Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df32254",
   "metadata": {},
   "source": [
    "Best subset selection, forward selection, and backward selection result in\n",
    "the creation of a set of models, each of which contains a subset of the p predictors. To apply these methods, we need a way to determine which of\n",
    "these models is best. As we discussed in Section 6.1.1, the model containing\n",
    "all of the predictors will always have the smallest RSS and the largest R2,\n",
    "since these quantities are related to the training error. Instead, we wish to\n",
    "choose a model with a low test error. As is evident here, and as we show\n",
    "in Chapter 2, the training error can be a poor estimate of the test error.\n",
    "Therefore, RSS and R2 are not suitable for selecting the best model among\n",
    "a collection of models with different numbers of predictors.\n",
    "In order to select the best model with respect to test error, we need to\n",
    "estimate this test error. There are two common approaches:\n",
    "\n",
    "1. We can indirectly estimate test error by making an adjustment to the\n",
    "training error to account for the bias due to overfitting.\n",
    "\n",
    "\n",
    "2. We can directly estimate the test error, using either a validation set\n",
    "approach or a cross-validation approach, as discussed in Chapter 5.\n",
    "\n",
    "We consider both of these approaches below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5f37cc",
   "metadata": {},
   "source": [
    "We show in Chapter 2 that the training set $ R^2 $ is generally an under-estimate of the test MSE. (Recall that MSE = RSS/n.) In training RSS, but when we fit a model to the training data using least squares, we (not the test RSS) is as small as possible, this can sometimes misestimate the regression coefficients in a model. Thus, we need to choose from among a set of models with different variables.\n",
    "\n",
    "However, a number of techniques for adjusting the training error can lead to a set of models with different variables. We introduce the following metrics for model selection criteria: \n",
    "\n",
    "- **Akaike information criterion (AIC)**, \n",
    "- **Bayesian information criterion (BIC)**, and \n",
    "- **Adjusted $ R^2 $**. \n",
    "\n",
    "Figure 6.2 gives a comparison of the best model selection criteria and selects the best subset on the Credit data set.\n",
    "\n",
    "For a fitted least squares model containing $ p $ predictors, the $ C_p $ estimate of test MSE is computed using the equation:\n",
    "\n",
    "$$\n",
    "C_p = \\frac{(RSS + 2d\\hat{\\sigma}^2)}{n}\n",
    "$$\n",
    "\n",
    "where $ \\hat{\\sigma}^2 $ is an estimate of the variance of the error $ \\epsilon $ associated with the regression model in (6.1). Typically $ d $ is chosen to be $ p $ or the number of parameters in the model. The $ C_p $ statistic adds a penalty term involving $ d $ in order to adjust for the number of predictors  in the model increases; this is intended to adjust for the corresponding decrease in training RSS. Based on the scope of this book, one can show that if $ \\hat{\\sigma}^2 $ in (6.2), then $ C_p $ is an unbiased estimate of test MSE. As a consequence, the $ C_p $ statistic tends to take a larger value in the model selected with the lowest $ C_p $ value. In Figure 6.2, C_p selects the six-variable model containing the predictors income, lint, age, and risk.\n",
    "\n",
    "The AIC criterion is defined as follows:\n",
    "$$\n",
    "AIC = \\frac{1}{n} (RSS + 2d\\hat{\\sigma}^2)\n",
    "$$\n",
    "where, for simplicity, we have omitted irrelevant constants. Here for least squares models, AIC and $ C_p $ are proportional to each other, as shown in Figure 6.2.\n",
    "\n",
    "BIC is derived from a Bayesian point of view; it ends up looking similar to $ C_p $ and $ AIC $ for the least squares model but with a different penalty term:\n",
    "$$\n",
    "BIC = \\frac{1}{n} (RSS + \\log(n)d\\hat{\\sigma}^2)\n",
    "$$\n",
    "Like $ C_p $, the BIC also penalizes a more complex model for a loss in precision, and generally we select the model with the lowest BIC. Notice that the BIC penalty includes the $ 2d\\ \\log(n) $ term, where $ n $ is the number of observations. Since $ \\log n > 2 $ for any $ n > 7 $, the BIC statistic generally places a heavier penalty on models with many variables, and hence reveals in the selection of smaller models than $ C_p $. In Figure 6.2, we see that the direct task decider is a single model that contains only the four predictors income, lint, age, and assertion. In this case the chosen model does not appear to make much difference in accuracy between the four-variable and six-variable models.\n",
    "\n",
    "The adjusted $ R^2 $ statistic is another popular approach for selecting among a set of models that contain different numbers of variables. Recall from Chapter 3 that the adjusted $ R^2 $ is defined as follows, where $ RSS = \\sum(y_i - \\hat{y})^2 $ is the total sum of squared response. Since $ RSS $ increases as more variables are added to the model, the $ R^2 $ measure becomes biased toward a larger selected model of variables, the adjusted $ R^2 $ is calculated as\n",
    "\n",
    "$$\n",
    "\\text{Adjusted } R^2 = 1 - \\frac{RSS/(n - d - 1)}{TSS/(n - 1)}\n",
    "$$\n",
    "\n",
    "Unlike $ C_p $ and BIC, for which a small value indicates a model with a low extent error, a large value of adjusted $ R^2 $ indicates a model with a small test error. Additionally, the adjusted $ R^2 $ is equivalent to how much variability is explained by the model. Consequently, the adjusted $ R^2 $ may increase or decrease depending on the fits of new variables added, and one must be cautious of the laws of diminishing returns when adding additional predictors. \n",
    "\n",
    "Nonetheless, the adjusted $ R^2 $ provides a more robust measure than $ C_p $ and BIC in model selection, owing to the fact that the adjusted $ R^2 $ accounts for degrees of freedom in models where fewer predictor variables yield higher estimates; hence, $ AIC $ and BIC can be less robust than the adjusted $ R^2 $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c8d92",
   "metadata": {},
   "source": [
    "Validation and Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856f8235",
   "metadata": {},
   "source": [
    "\n",
    "As an alternative to the approaches just discussed, we can directly esti\n",
    "mate the test error using the validation set and cross-validation methods\n",
    "discussed in Chapter 5. We can compute the validation set error or the\n",
    "cross-validation error for each model under consideration, and then select the model for which the resulting estimated test error is smallest. This pro\n",
    "cedure has an advantage relative to AIC, BIC, Cp, and adjusted R2, in that\n",
    "it provides a direct estimate of the test error, and makes fewer assumptions\n",
    "about the true underlying model. It can also be used in a wider range of\n",
    "model selection tasks, even in cases where it is hard to pinpoint the model\n",
    "degrees of freedom (e.g. the number of predictors in the model) or hard\n",
    "to estimate the error variance 2. Note that when cross-validation is used,\n",
    "the sequence of models Mk in Algorithms 6.1–6.3 is determined separately\n",
    "for each training fold, and the validation errors are averaged over all folds\n",
    "for each model size k. This means, for example with best-subset regression,\n",
    "that Mk, the best subset of size k, can differ across the folds. Once the\n",
    "best size k is chosen, we find the best model of that size on the full data\n",
    "set.\n",
    "In the past, performing cross-validation was computationally prohibitive\n",
    "for many problems with large p and/or large n, and so AIC, BIC, Cp,\n",
    "and adjusted R2 were more attractive approaches for choosing among a\n",
    "set of models. However, nowadays with fast computers, the computations\n",
    "required to perform cross-validation are hardly ever an issue. Thus, cross\n",
    "validation is a very attractive approach for selecting from among a number\n",
    "of models under consideration.\n",
    "Figure 6.3 displays, as a function of d, the BIC, validation set errors, and\n",
    "cross-validation errors on the Credit data, for the best d-variable model.\n",
    "The validation errors were calculated by randomly selecting three-quarters\n",
    "of the observations as the training set, and the remainder as the valida\n",
    "tion set. The cross-validation errors were computed using k = 10 folds.\n",
    "In this case, the validation and cross-validation methods both result in a\n",
    "six-variable model. However, all three approaches suggest that the four-,\n",
    "f\n",
    "ive-, and six-variable models are roughly equivalent in terms of their test\n",
    "errors.\n",
    "In fact, the estimated test error curves displayed in the center and right\n",
    "hand panels of Figure 6.3 are quite flat. While a three-variable model clearly\n",
    "has lower estimated test error than a two-variable model, the estimated test\n",
    "errors of the 3- to 11-variable models are quite similar. Furthermore, if we repeated the validation set approach using a different split of the data into\n",
    "a training set and a validation set, or if we repeated cross-validation using\n",
    "a different set of cross-validation folds, thentheprecisemodelwiththe\n",
    "lowest estimatedtest errorwouldsurelychange. Inthis setting,we can\n",
    "select amodel using theone-standard-error rule.Wefirst calculate the \n",
    "standarderrorof theestimatedtestMSEfor eachmodel size, andthen\n",
    "selectthesmallestmodel forwhichtheestimatedtesterror iswithinone\n",
    "standarderrorofthelowestpointonthecurve.Therationalehereisthat\n",
    "ifasetofmodelsappeartobemoreor lessequallygood, thenwemight\n",
    "aswell choose the simplestmodel—that is, themodelwiththe smallest\n",
    "number of predictors. Inthis case, applying theone-standard-error rule\n",
    "tothevalidationsetorcross-validationapproachleadstoselectionof the\n",
    "three-variablemodel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3c8f6a",
   "metadata": {},
   "source": [
    "#### Shrinkage Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d169a73",
   "metadata": {},
   "source": [
    "The subset selection methods described in Section 6.1 involve using least squares to fit a linear model that contains as many predictors. As an alternative, we can find a model containing all predictors and then calibrate or regularize the coefficient estimates, or equivalently, shrink the estimates toward zero. It may not be immediately obvious why such a constraint should improve the fit, but it turns out that shrinking the coefficients can significantly reduce their variance. The two best-known techniques for shrinking the coefficient estimates towards zero are ridge regression and the lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a861857a",
   "metadata": {},
   "source": [
    "##### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cf6e54",
   "metadata": {},
   "source": [
    "Recall from Chapter 3 that the least squares fitting procedure for $ \\beta_0, \\beta_1, \\ldots, \\beta_p $ using the values that minimize\n",
    "\n",
    "$$\n",
    "RSS = \\sum (y_i - \\beta_0 - \\beta_1 x_{1i} - \\ldots - \\beta_p x_{pi})^2\n",
    "$$\n",
    "\n",
    "Ridge regression is simply a variation of this, where the estimator is determined by minimizing a slightly different quantity. In particular, the ridge regression coefficient estimates $ \\hat{\\beta}_P $ are those that minimize\n",
    "\n",
    "$$\n",
    "RSS + \\lambda \\sum_{j=1}^p \\beta_j^2\n",
    "$$\n",
    "\n",
    "where $ \\lambda > 0 $ is a tuning parameter, to be determined separately. Expressing $ \\lambda $ trades off too much variance in estimates; ridge regression seeks coefficient estimates that fit the data well, by making them smaller. The second term, $ \\lambda \\sum_{j=1}^p \\beta_j^2 $, penalizes large values of the coefficients, thus shrinking the estimates of $ \\beta_j $ towards zero. The tuning parameter $ \\lambda $ serves to control the relative impact of these two terms on the regression coefficient esti\n",
    "mates. When =0, the penalty term has no effect, and ridge regression\n",
    "will produce the least squares estimates. However, as \n",
    ", the impact of\n",
    "the shrinkage penalty grows, and the ridge regression coefficient estimates\n",
    "will approach zero. Unlike least squares, which generates only one set of co\n",
    "efficient estimates, ridge regression will produce a different set of coefficient\n",
    "estimates, ˆR, for each value of . Selecting a good value for is critical;\n",
    "we defer this discussion to Section 6.2.3, where we use cross-validation.\n",
    "Note that in (6.5), the shrinkage penalty is applied to 1,..., p, but\n",
    "not to the intercept 0. We want to shrink the estimated association of\n",
    "each variable with the response; however, we do not want to shrink the\n",
    "intercept, which is simply a measure of the mean value of the response\n",
    "when xi1 = xi2 = ...= xip =0. If we assume that the variables—that is,\n",
    "the columns of the data matrix X—have been centered to have mean zero\n",
    "before ridge regression is performed, then the estimated intercept will take\n",
    "the form ˆ0 =¯y= n\n",
    "i=1yi/n.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9bd596",
   "metadata": {},
   "source": [
    "An Application to the Credit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3690562a",
   "metadata": {},
   "source": [
    "In Figure 6.4, the ridge regression coefficient estimates for the Credit data\n",
    "set are displayed. In the left-hand panel, each curve corresponds to the\n",
    "ridge regression coefficient estimate for one of the ten variables, plotted\n",
    "as a function of . For example, the black solid line represents the ridge\n",
    "regression estimate for the income coefficient, as is varied. At the extreme\n",
    "left-hand side of the plot, is essentially zero, and so the corresponding\n",
    "ridge coefficient estimates are the same as the usual least squares esti\n",
    "mates. But as increases, the ridge coefficient estimates shrink towards\n",
    "zero. When is extremely large, then all of the ridge coefficient estimates\n",
    "are basically zero; this corresponds to the null model that contains no predictors. In this plot, the income, limit, rating, and student variables are\n",
    "displayed in distinct colors, since these variables tend to have by far the\n",
    "largest coefficient estimates. While the ridge coefficient estimates tend to\n",
    "decrease in aggregate as increases, individual coefficients, such as rating\n",
    "and income, may occasionally increase as increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7ff260",
   "metadata": {},
   "source": [
    "The right-hand panel of Figure 6.4 displays the same ridge coefficient estimates as the left-hand panel, but instead of displaying on the x-axis, we now display $\\hat{R}^2/\\hat{2}$, where $\\hat{}$ denotes the vector of least squares coefficient estimates. The notation $\\|\\cdot\\|_2$ denotes the 2 norm (pronounced “ell 2”) of a vector, and is defined as $\\|\\beta\\|_2 = \\sqrt{\\sum_{j=1}^{p} \\beta_j^2}$. It measures the distance of $\\beta$ from zero. As $\\lambda$ increases, the 2 norm of $\\hat{R}$ will always decrease, and so will $\\hat{R}^2/\\hat{2}$. The latter quantity ranges from 1 (when $\\lambda=0$, in which case the ridge regression coefficient estimate is the same as the least squares estimate, and so their 2 norms are the same) to 0 (when $\\lambda = \\infty$, in which case the ridge regression coefficient estimate is a vector of zeros, with 2 norm equal to zero). Therefore, we can think of the x-axis in the right-hand panel of Figure 6.4 as the amount that the ridge regression coefficient estimates have been shrunken towards zero; a small value indicates that they have been shrunken very close to zero.\n",
    "\n",
    "The standard least squares coefficient estimates discussed in Chapter 3 are scale equivariant: multiplying $X_j$ by a constant $c$ simply leads to a scaling of the least squares coefficient estimates by a factor of $1/c$. In other words, regardless of how the jth predictor is scaled, $X_j \\hat{\\beta}_j$ will remain the same. In contrast, the ridge regression coefficient estimates can change substantially when multiplying a given predictor by a constant. For instance, consider the income variable, which is measured in dollars. One could reasonably have measured income in thousands of dollars, which would result in a reduction in the observed values of income by a factor of 1,000. Now due to the sum of squared coefficients term in the ridge regression formulation (6.5), such a change in scale will not simply cause the ridge regression coefficient estimate for income to change by a factor of 1,000. In other words, $X_j \\hat{R}_j$ will depend not only on the value of $\\lambda$, but also on the scaling of the jth predictor. In fact, the value of $X_j \\hat{R}_j$ may even depend on the scaling of the other predictors! Therefore, it is best to apply ridge regression after standardizing the predictors, using the formula\n",
    "\n",
    "$$\n",
    "\\tilde{x}_{ij} = \\frac{x_{ij}}{1 / n \\sum_{i=1}^n (x_{ij} - \\bar{x}_j)^2}\n",
    "$$\n",
    "\n",
    "so that they are all on the same scale. In (6.6), the denominator is the estimated standard deviation of the jth predictor. Consequently, all of the standardized predictors will have a standard deviation of one. As a result, the final fit will not depend on the scale on which the predictors are measured. In Figure 6.4, the y-axis displays the standardized ridge regression coefficient estimates—that is, the coefficient estimates that result from performing ridge regression using standardized predictors.\n",
    "\n",
    "Why Does Ridge Regression Improve Over Least Squares?\n",
    "\n",
    "Ridge regression’s advantage over least squares is rooted in the bias-variance trade-off. As $\\lambda$ increases, the flexibility of the ridge regression fit decreases, leading to decreased variance but increased bias. This is illustrated in the left-hand panel of Figure 6.5, using a simulated data set containing $p = 45$ predictors and $n = 50$ observations. The green curve in the left-hand panel of Figure 6.5 displays the variance of the ridge regression predictions as a function of $\\lambda$. At the least squares coefficient estimates, which correspond to ridge regression with $\\lambda = 0$, the variance is high but there is no bias. But as $\\lambda$ increases, the shrinkage of the ridge coefficient estimates leads to a substantial reduction in the variance of the predictions, at the expense of a slight increase in bias. Recall that the least mean squared error (MSE), plotted in bias-variance bias, is closely related to the variance plus the squared bias. For values of $\\lambda$ that are not too small, the variance generally remains very low, as shown in the figure, plotted in black. However, as $\\lambda$ increases from 0 to 10. Beyond this point, the decrease in variance is no longer sufficient to offset the increased bias, and the MSE can begin to be significantly underestimated, resulting in a large increase in the bias. \n",
    "\n",
    "The minimum MSE is achieved at and around the value of $\\lambda$ that results in the smallest MSE associated with the least squares fit, when using the same hyperparameter that will yield the best fit for any model designed for use with $\\lambda$. However, for an inflexible estimator, the MSE is considerably higher.\n",
    "\n",
    "In general, as the number of observations increases, the ridge regression estimates become more stable against the errors in the left-hand curve; however, the fitted values may still have high variance. This means that while ridge regression can improve the fitted values' stability by controlling their variance, the coefficients of the variables in the model may be increasingly biased.\n",
    "\n",
    "In Figure 6.5, the least squares estimates continue to outperform ridge regression predictions, even when $\\lambda > 0$, because the least squares estimation can still perform well by trading off a small increase in bias for a large decrease in variance. Hence, ridge regression works best in situations\n",
    "where the least squares estimates have high variance.\n",
    "Ridge regression also has substantial computational advantages over best\n",
    "subset selection, which requires searching through $2^p$ models. As we dis\n",
    "cussed previously, even for moderate values of $p$, such a search can be\n",
    "computationally infeasible. In contrast, for any fixed value of $\\lambda$, ridge re\n",
    "gression only fits a single model, and the model-fitting procedure can be\n",
    "performed quite quickly. In fact, one can show that the computations re\n",
    "quired to solve (6.5), simultaneously for all values of $\\lambda$, are almost identical\n",
    "to those for fitting a model using least squares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ade56",
   "metadata": {},
   "source": [
    "#### The Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21238e86",
   "metadata": {},
   "source": [
    "Ridge regression does have one obvious disadvantage. Unlike best subset,\n",
    "forward stepwise, and backward stepwise selection, which will generally\n",
    "select models that involve just a subset of the variables, ridge regression\n",
    "will include all $p$ predictors in the final model. The penalty \n",
    "$$\n",
    "\\sum_{j=1}^{p} \\beta_j^2\n",
    "$$ \n",
    "in (6.5) will shrink all of the coefficients towards zero, but it will not set any of them\n",
    "exactly to zero (unless $\\lambda = \\infty$). This may not be a problem for prediction\n",
    "accuracy, but it can create a challenge in model interpretation in settings in\n",
    "which the number of variables $p$ is quite large. For example, in the Credit\n",
    "data set, it appears that the most important variables are income, limit,\n",
    "rating, and student. So we might wish to build a model including just\n",
    "these predictors. However, ridge regression will always generate a model\n",
    "involving all ten predictors. Increasing the value of $\\lambda$ will tend to reduce\n",
    "the magnitudes of the coefficients, but will not result in exclusion of any of\n",
    "the variables.\n",
    "\n",
    "The lasso is a relatively recent alternative to ridge regression that over-\n",
    "comes this disadvantage. The lasso coefficients, $\\hat{\\beta}_L$, minimize the quantity\n",
    "$$\n",
    "\\sum_{i=1}^{n} \\left( y_i - \\sum_{j=1}^{p} \\beta_j x_{ij} \\right)^2 + \\lambda \\sum_{j=1}^{p} | \\beta_j | = \\text{RSS} + \\lambda \\sum_{j=1}^{p} | \\beta_j |.\n",
    "$$\n",
    "Comparing (6.7) to (6.5), we see that the lasso and ridge regression have\n",
    "similar formulations. The only difference is that the $\\beta_j^2$ term in the ridge\n",
    "regression penalty (6.5) has been replaced by $|\\beta_j|$ in the lasso penalty (6.7).\n",
    "In statistical parlance, the lasso uses an $L_1$ (pronounced “ell 1”) penalty\n",
    "instead of an $L_2$ penalty. The $L_1$ norm of a coefficient vector is given by\n",
    "$$\n",
    "||\\beta||_1 = \\sum_{j=1}^{p} | \\beta_j |.\n",
    "$$\n",
    "\n",
    "As with ridge regression, the lasso shrinks the coefficient estimates to\n",
    "wards zero. However, in the case of the lasso, the $L_1$ penalty has the effect\n",
    "of forcing some of the coefficient estimates to be exactly equal to zero when\n",
    "the tuning parameter is sufficiently large. Hence, much like best subset se\n",
    "lection, the lasso performs variable selection. As a result, models generated\n",
    "from the lasso are generally much easier to interpret than those produced\n",
    "by ridge regression. We say that the lasso yields sparse models—that is,\n",
    "models that involve only a subset of the variables. As in ridge regression,\n",
    "selecting a good value of $\\lambda$ for the lasso is critical; we defer this discussion\n",
    "to Section 6.2.3, where we use cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc1b249",
   "metadata": {},
   "source": [
    "As an example, consider the coefficient plots in Figure 6.6, which are gen\n",
    "erated from applying the lasso to the Credit dataset. When $\\lambda = 0$, then\n",
    "the lasso simply gives the least squares fit, and when $\\lambda$ becomes sufficiently\n",
    "large, the lasso gives the null model in which all coefficient estimates equal\n",
    "zero. However, in between these two extremes, the ridge regression and\n",
    "lasso models are quite different from each other. Moving from left to right\n",
    "in the right-hand panel of Figure 6.6, we observe that at first the lasso re\n",
    "sults in a model that contains only the rating predictor. Then student and\n",
    "limit enter the model almost simultaneously, shortly followed by income.\n",
    "Eventually, the remaining variables enter the model. Hence, depending on\n",
    "the value of $\\lambda$, the lasso can produce a model involving any number of vari\n",
    "ables. In contrast, ridge regression will always include all of the variables in\n",
    "the model, although the magnitude of the coefficient estimates will depend\n",
    "on $\\lambda$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6683a9",
   "metadata": {},
   "source": [
    "Another Formulation for Ridge Regression and the Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0a85bb",
   "metadata": {},
   "source": [
    "One can show that the lasso and ridge regression coefficient estimates solve\n",
    "the problems:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{minimize} & \\quad \\sum_{i=1}^{n} \\left( y_i - \\beta_0 - \\sum_{j=1}^{p} \\beta_j x_{ij} \\right)^2\n",
    "\\text{subject to} & \\quad \\sum_{j=1}^{p} | \\beta_j | \\leq s \\tag{6.8}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{minimize} & \\quad \\sum_{i=1}^{n} \\left( y_i - \\beta_0 - \\sum_{j=1}^{p} \\beta_j x_{ij} \\right)^2\n",
    "\\text{subject to} & \\quad \\sum_{j=1}^{p} \\beta_j^2 \\leq s \\tag{6.9}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "respectively. In other words, for every value of $\\lambda$, there is some $s$ such that\n",
    "the Equations (6.7) and (6.8) will give the same lasso coefficient estimates.\n",
    "Similarly, for every value of $\\lambda$ there is a corresponding $s$ such that Equations (6.5) and (6.9) will give the same ridge regression coefficient estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3b2589",
   "metadata": {},
   "source": [
    "When $ p = 2 $, then (6.8) indicates that the lasso coefficient estimates have\n",
    "the smallest RSS out of all points that lie within the diamond defined by\n",
    "$| \\beta_1| + | \\beta_2| \\leq s$. Similarly, the ridge regression estimates have the smallest\n",
    "RSS out of all points that lie within the circle defined by $ \\beta_1^2 + \\beta_2^2 \\leq s $.\n",
    "We can think of (6.8) as follows. When we perform the lasso we are trying\n",
    "to find the set of coefficient estimates that lead to the smallest RSS, subject\n",
    "to the constraint that there is a budget $ s $ for how large $ \\sum_{j=1}^{p} | \\beta_j | $ can be.\n",
    "When $ s $ is extremely large, then this budget is not very restrictive, and so\n",
    "the coefficient estimates can be large. In fact, if $ s $ is large enough that the\n",
    "least squares solution falls within the budget, then (6.8) will simply yield\n",
    "the least squares solution. In contrast, if $ s $ is small, then $ \\sum_{j=1}^{p} | \\beta_j | $ must be\n",
    "small in order to avoid violating the budget. Similarly, (6.9) indicates that\n",
    "when we perform ridge regression, we seek a set of coefficient estimates\n",
    "such that the RSS is as small as possible, subject to the requirement that\n",
    "$ \\sum_{j=1}^{p} \\beta_j^2 $ not exceed the budget $ s $.\n",
    "\n",
    "The formulations (6.8) and (6.9) reveal a close connection between the\n",
    "lasso, ridge regression, and best subset selection. Consider the problem:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{minimize} & \\quad \\sum_{i=1}^{n} \\left( y_i - \\beta_0 - \\sum_{j=1}^{p} \\beta_j x_{ij} \\right)^2 \n",
    "\\text{subject to} & \\quad \\sum_{j=1}^{p} I( \\beta_j ≠ 0) \\leq s. \\tag{6.10}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Here $ I( \\beta_j ≠ 0) $ is an indicator variable: it takes on a value of 1 if $ \\beta_j = 0 $, and\n",
    "equals zero otherwise. Then (6.10) amounts to finding a set of coefficient\n",
    "estimates such that RSS is as small as possible, subject to the constraint\n",
    "that no more than $ s $ coefficients can be nonzero. The problem (6.10) is\n",
    "equivalent to best subset selection. Unfortunately, solving (6.10) is com\n",
    "putationally infeasible when $ p $ is large, since it requires considering all $ p \\choose s $\n",
    "models containing $ s $ predictors. Therefore, we can interpret ridge regression\n",
    "and the lasso as computationally feasible alternatives to best subset selec\n",
    "tion that replace the intractable form of the budget in (6.10) with forms\n",
    "that are much easier to solve. Of course, the lasso is much more closely\n",
    "related to best subset selection, since the lasso performs feature selection\n",
    "for $ s $ sufficiently small in (6.8), while ridge regression does not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0b030",
   "metadata": {},
   "source": [
    "The Variable Selection Property of the Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6d7ada",
   "metadata": {},
   "source": [
    "Why is it that the lasso, unlike ridge regression, results in coefficient esti\n",
    "mates that are exactly equal to zero? The formulations (6.8) and (6.9) can\n",
    "be used to shed light on the issue. Figure 6.7 illustrates the situation. The\n",
    "least squares solution is marked as $ \\hat{\\beta} $, while the blue diamond and circle\n",
    "represent the lasso and ridge regression constraints in (6.8) and (6.9), re\n",
    "spectively. If $ s $ is sufficiently large, then the constraint regions will contain\n",
    "$ \\hat{\\beta} $, and so the ridge regression and lasso estimates will be the same as the\n",
    "least squares estimates. (Such a large value of $ s $ corresponds to $ \\lambda = 0 $ in\n",
    "(6.5) and (6.7).) However, in Figure 6.7 the least squares estimates lie out\n",
    "side of the diamond and the circle, and so the least squares estimates are\n",
    "not the same as the lasso and ridge regression estimates.\n",
    "\n",
    "Each of the ellipses centered around $ \\hat{\\beta} $ represents a contour: this means\n",
    "that all of the points on a particular ellipse have the same RSS value. As the ellipses expand away from the least squares coefficient estimates, the\n",
    "RSS increases. Equations (6.8) and (6.9) indicate that the lasso and ridge\n",
    "regression coefficient estimates are given by the first point at which an\n",
    "ellipse contacts the constraint region. Since ridge regression has a circular\n",
    "constraint with no sharp points, this intersection will not generally occur on\n",
    "an axis, and so the ridge regression coefficient estimates will be exclusively\n",
    "non-zero. However, the lasso constraint has corners at each of the axes, and\n",
    "so the ellipse will often intersect the constraint region at an axis. When this\n",
    "occurs, one of the coefficients will equal zero. In higher dimensions, many of\n",
    "the coefficient estimates may equal zero simultaneously. In Figure 6.7, the\n",
    ".\n",
    "intersection occurs at 1 =0, and so the resulting model will only include $ \\beta_2$\n",
    "\n",
    "\n",
    "In Figure 6.7, we considered the simple case of p =2. When p =3,\n",
    "then the constraint region for ridge regression becomes a sphere, and the\n",
    "constraint region for the lasso becomes a polyhedron. When p>3, the\n",
    "constraint for ridge regression becomes a hypersphere, and the constraint\n",
    "for the lasso becomes a polytope. However, the key ideas depicted in Fig\n",
    "ure 6.7 still hold. In particular, the lasso leads to feature selection when\n",
    "p>2 due to the sharp corners of the polyhedron or polytope.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb29395",
   "metadata": {},
   "source": [
    "Comparing the Lasso and Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32aaaab",
   "metadata": {},
   "source": [
    "\n",
    "It is clear that the lasso has a major advantage over ridge regression, in\n",
    "that it produces simpler and more interpretable models that involve only a\n",
    "subset of the predictors. However, which method leads to better prediction\n",
    "accuracy? Figure 6.8 displays the variance, squared bias, and test MSE of\n",
    "the lasso applied to the same simulated data as in Figure 6.5. Clearly the\n",
    "lasso leads to qualitatively similar behavior to ridge regression, in that as $ \\lambda $\n",
    "increases, the variance decreases and the bias increases. In the right-hand panel of Figure 6.8, the dotted lines represent the ridge regression fits.\n",
    "Here we plot both against their R2 on the training data. This is another\n",
    "useful way to index models, and can be used to compare models with\n",
    "different types of regularization, as is the case here. In this example, the\n",
    "lasso and ridge regression result in almost identical biases. However, the\n",
    "variance of ridge regression is slightly lower than the variance of the lasso.\n",
    "Consequently, the minimum MSE of ridge regression is slightly smaller than\n",
    "that of the lasso.\n",
    "\n",
    "However, the data in Figure 6.8 were generated in such a way that all 45\n",
    "predictors were related to the response—that is, none of the true coefficients\n",
    "1,..., 45 equaled zero. The lasso implicitly assumes that a number of the\n",
    "coefficients truly equal zero. Consequently, it is not surprising that ridge\n",
    "regression outperforms the lasso in terms of prediction error in this setting.\n",
    "Figure 6.9 illustrates a similar situation, except that now the response is a\n",
    "function of only 2 out of 45 predictors. Now the lasso tends to outperform\n",
    "ridge regression in terms of bias, variance, and MSE.\n",
    "\n",
    "These two examples illustrate that neither ridge regression nor the lasso\n",
    "will universally dominate the other. In general, one might expect the lasso\n",
    "to perform better in a setting where a relatively small number of predictors\n",
    "have substantial coefficients, and the remaining predictors have coefficients\n",
    "that are very small or that equal zero. Ridge regression will perform better\n",
    "when the response is a function of many predictors, all with coefficients of\n",
    "roughly equal size. However, the number of predictors that is related to the\n",
    "response is never known a priori for real data sets. A technique such as\n",
    "cross-validation can be used in order to determine which approach is better\n",
    "on a particular data set.\n",
    "\n",
    "As with ridge regression, when the least squares estimates have exces\n",
    "sively high variance, the lasso solution can yield a reduction in variance\n",
    "at the expense of a small increase in bias, and consequently can gener\n",
    "ate more accurate predictions. Unlike ridge regression, the lasso performs\n",
    "variable selection, and hence results in models that are easier to interpret.\n",
    "There are very efficient algorithms for fitting both ridge and lasso models;\n",
    "in both cases the entire coefficient paths can be computed with about the\n",
    "same amount of work as a single least squares fit. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da35da",
   "metadata": {},
   "source": [
    "A Simple Special Case for Ridge Regression and the Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab85b585",
   "metadata": {},
   "source": [
    "In order to obtain a better intuition about the behavior of ridge regression\n",
    "and the lasso, consider a simple special case with $ n = p $, and $ X $ a diag\n",
    "onal matrix with 1’s on the diagonal and 0’s in all off-diagonal elements.\n",
    "To simplify the problem further, assume also that we are performing regres\n",
    "sion without an intercept. With these assumptions, the usual least squares\n",
    "problem simplifies to finding $ \\beta_1, \\ldots, \\beta_p $ that minimize\n",
    "\n",
    "$$\n",
    "\\sum_{j=1}^{p} (y_j - \\beta_j)^2.\n",
    "$$\n",
    "\n",
    "In this case, the least squares solution is given by\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_j = y_j. \\tag{6.11}\n",
    "$$\n",
    "\n",
    "And in this setting, ridge regression amounts to finding $ \\beta_1, \\ldots, \\beta_p $ such that\n",
    "\n",
    "$$\n",
    "\\sum_{j=1}^{p} (y_j - \\beta_j)^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2 \\tag{6.12}\n",
    "$$\n",
    "\n",
    "is minimized, and the lasso amounts to finding the coefficients such that is minimized. \n",
    "\n",
    "$$\n",
    "\\sum_{j=1}^{p} (y_j - \\beta_j)^2 + \\lambda \\sum_{j=1}^{p} |\\beta_j| \\tag{6.13}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bfecd4",
   "metadata": {},
   "source": [
    "One can show that in this setting, the ridge regression esti\n",
    "mates take the form\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_j^R = \\frac{y_j}{1 + \\lambda},\n",
    "$$\n",
    "\n",
    "and the lasso estimates take the form\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_j^L =\n",
    "\\begin{cases}\n",
    "y_j - \\lambda/2 & \\text{if } y_j > \\lambda/2, \\\\\n",
    "y_j + \\lambda/2 & \\text{if } y_j < -\\lambda/2, \\\\\n",
    "0 & \\text{if } |y_j| \\leq \\lambda/2.\n",
    "\\end{cases}\n",
    "\\tag{6.14}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Figure 6.10 displays the situation. We can see that ridge regression and\n",
    "the lasso perform two very different types of shrinkage. In ridge regression,\n",
    "each least squares coefficient estimate is shrunken by the same proportion.\n",
    "In contrast, the lasso shrinks each least squares coefficient towards zero by\n",
    "a constant amount, $\\lambda/2$; the least squares coefficients that are less than\n",
    "$\\lambda/2$ in absolute value are shrunken entirely to zero. The type of shrink\n",
    "age performed by the lasso in this simple setting (6.15) is known as soft\n",
    "thresholding. The fact that some lasso coefficients are shrunken entirely to\n",
    "zero explains why the lasso performs feature selection.\n",
    "\n",
    "In the case of a more general data matrix $X$, the story is a little more\n",
    "complicated than what is depicted in Figure 6.10, but the main ideas still\n",
    "hold approximately: ridge regression more or less shrinks every dimension\n",
    "of the data by the same proportion, whereas the lasso more or less shrinks\n",
    "all coefficients toward zero by a similar amount, and sufficiently small co\n",
    "efficients are shrunken all the way to zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37411582",
   "metadata": {},
   "source": [
    "We now show that one can view ridge regression and the lasso through\n",
    "a Bayesian lens. A Bayesian viewpoint for regression assumes that the\n",
    "coefficient vector $\\beta$ has some prior distribution, say $p(\\beta)$, where \n",
    "$\\beta = (\\beta_0, \\beta_1, \\ldots, \\beta_p)^T$. The likelihood of the data can be written as $f(Y|X, \\beta)$, where $ X = (X_1,\\ldots,X_p) $. Multiplying the prior distribution by the likelihood gives us (up to a proportionality constant) the posterior distribution, which takes the form\n",
    "\n",
    "$$\n",
    "p(\\beta | X, Y) \\propto f(Y | X, \\beta)p(\\beta | X) = f(Y | X, \\beta)p(\\beta),\n",
    "$$\n",
    "\n",
    "where the proportionality above follows from Bayes’ theorem, and the\n",
    "equality above follows from the assumption that $X$ is fixed.\n",
    "\n",
    "We assume the usual linear model,\n",
    "\n",
    "$$\n",
    "Y = \\beta_0 + X_1 \\beta_1 + \\cdots + X_p \\beta_p + \\epsilon,\n",
    "$$\n",
    "\n",
    "and suppose that the errors are independent and drawn from a normal distribution. Furthermore, assume that \n",
    "\n",
    "$$\n",
    "p(\\beta) = \\prod_{j=1}^p g(\\beta_j),\n",
    "$$\n",
    "\n",
    "for some density function $g$. It turns out that ridge regression and the lasso follow naturally from two special cases of $g$:\n",
    "\n",
    "- If $g$ is a Gaussian distribution with mean zero and standard deviation a function of $\\lambda$, then it follows that the posterior mode for $\\beta$—that is, the most likely value for $\\beta$, given the data—is given by the ridge regression solution. (In fact, the ridge regression solution is also the posterior mean.)\n",
    "  \n",
    "- If $g$ is a double-exponential (Laplace) distribution with mean zero and scale parameter a function of $\\lambda$, then it follows that the posterior mode for $\\beta$ is the lasso solution. (However, the lasso solution is not the posterior mean, and in fact, the posterior mean does not yield a sparse coefficient vector.)\n",
    "\n",
    "The Gaussian and double-exponential priors are displayed in Figure 6.11. Therefore, from a Bayesian viewpoint, ridge regression and the lasso follow directly from assuming the usual linear model with normal errors, together with a simple prior distribution for $\\beta$. Notice that the lasso prior is steeply peaked at zero, while the Gaussian is flatter and fatter at zero. Hence, the lasso expects a priori that many of the coefficients are (exactly) zero, while ridge assumes the coefficients are randomly distributed about zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96060134",
   "metadata": {},
   "source": [
    "Selecting the Tuning Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530e3e82",
   "metadata": {},
   "source": [
    "Just as the subset selection approaches considered in Section 6.1 require\n",
    "a method to determine which of the models under consideration is best,\n",
    "implementing ridge regression and the lasso requires a method for selecting\n",
    "a value for the tuning parameter in $ \\lambda $ (6.5) and (6.7), or equivalently, the\n",
    "value of the constraint s in (6.9) and (6.8). Cross-validation provides a sim\n",
    "ple way to tackle this problem. We choose a grid of $ \\lambda $ values, and compute\n",
    "the cross-validation error for each value of $ \\lambda $, as described in Chapter 5.We\n",
    "then select the tuning parameter value for which the cross-validation error\n",
    "is smallest. Finally, the model is re-fit using all of the available observations\n",
    "and the selected value of the tuning parameter.\n",
    "\n",
    "  Figure 6.12 displays the choice of $ \\lambda $ that results from performing leave\n",
    "one-out cross-validation on the ridge regression fits from the `Credit` data\n",
    "set. The dashed vertical lines indicate the selected value of $ \\lambda $. In this case\n",
    "the value is relatively small, indicating that the optimal fit only involves a\n",
    "small amount of shrinkage relative to the least squares solution. In addition,\n",
    "the dip is not very pronounced, so there is rather a wide range of values\n",
    "that would give a very similar error. In a case like this we might simply use\n",
    "the least squares solution.\n",
    "    \n",
    "  Figure 6.13 provides an illustration of ten-fold cross-validation applied to\n",
    "the lasso fits on the sparse simulated data from Figure 6.9. The left-hand\n",
    "panel of Figure 6.13 displays the cross-validation error, while the right-hand\n",
    "panel displays the coefficient estimates. The vertical dashed lines indicate\n",
    "the point at which the cross-validation error is smallest. The two colored\n",
    "lines in the right-hand panel of Figure 6.13 represent the two predictors\n",
    "that are related to the response, while the grey lines represent the unre\n",
    "lated predictors; these are often referred to as $signal$ and $noise$ variables,\n",
    "respectively. Not only has the lasso correctly given much larger coeffi\n",
    "cient estimates to the two signal predictors, but also the minimum cross\n",
    "validation error corresponds to a set of coefficient estimates for which only\n",
    "the signal variables are non-zero. Hence cross-validation together with the\n",
    "lasso has correctly identified the two signal variables in the model, even\n",
    "though this is a challenging setting, with $p = 45$ variables and only $n = 50$ observations. In contrast, the least squares solution—displayed on the far\n",
    "right of the right-hand panel of Figure 6.13—assigns a large coefficient\n",
    "estimate to only one of the two signal variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e81886c",
   "metadata": {},
   "source": [
    "#### Dimension Reduction Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28170071",
   "metadata": {},
   "source": [
    "The methods that we have discussed so far in this chapter have controlled variance in two different ways, either by using a subset of the original variables, or by shrinking their coefficients toward zero. All of these methods are defined using the original predictors, $X_1, X_2, \\ldots, X_p$. We now explore a class of approaches that transform the predictors and then fit a least squares model using the transformed variables. We will refer to these techniques as dimension reduction methods.\n",
    "\n",
    "Let $Z_1, Z_2, \\ldots, Z_M$ represent $M$ linear combinations of our original $p$ predictors. That is,\n",
    "\n",
    "$$\n",
    "Z_m = \\sum_{j=1}^p \\gamma_{jm} X_j \\tag{6.16}\n",
    "$$\n",
    "\n",
    "for some constants $\\gamma_{1m}, \\gamma_{2m}, \\ldots, \\gamma_{pm}$, $m = 1, \\ldots, M$. We can then fit the linear regression model\n",
    "\n",
    "$$\n",
    "y_i = \\beta_0 + \\sum_{m=1}^M \\beta_m Z_{im} + \\epsilon_i, \\quad i = 1, \\ldots, n, \\tag{6.17}\n",
    "$$\n",
    "\n",
    "using least squares. Note that in (6.17), the regression coefficients are given by $\\beta_0, \\beta_1, \\ldots, \\beta_M$. If the constants $\\gamma_{1m}, \\gamma_{2m}, \\ldots, \\gamma_{pm}$ are chosen wisely, then such dimension reduction approaches can often outperform least squares regression. In other words, fitting (6.17) using least squares can lead to better results than fitting (6.1) using least squares.\n",
    "\n",
    "The term dimension reduction comes from the fact that this approach reduces the problem of estimating the $p+1$ coefficients $\\beta_0, \\beta_1, \\ldots, \\beta_p$ to the simpler problem of estimating the $M + 1$ coefficients $\\beta_0, \\beta_1, \\ldots, \\beta_M$, where $M < p$. In other words, the dimension of the problem has been reduced from $p + 1$ to $M + 1$.\n",
    "\n",
    "Notice that from (6.16),\n",
    "\n",
    "$$\n",
    "\\sum_{m=1}^M \\beta_m Z_{im} = \\sum_{m=1}^M \\beta_m \\left( \\sum_{j=1}^p \\gamma_{jm} X_j \\right) = \\sum_{j=1}^p \\left( \\sum_{m=1}^M \\beta_m \\gamma_{jm} \\right) X_j,\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\beta_j = \\sum_{m=1}^M \\beta_m \\gamma_{jm}. \\tag{6.18}\n",
    "$$\n",
    "\n",
    "Hence (6.17) can be thought of as a special case of the original linear regression model given by (6.1). Dimension reduction serves to constrain the estimated $\\beta_j$ coefficients, since now they must take the form (6.18). This constraint on the form of the coefficients has the potential to bias the coefficient estimates. However, in situations where $p$ is larger relative to $M$, selecting a value of $M<p$ can significantly reduce the variance of the fitted coefficients. If $M=p$, and all the $Z_m$ are linearly independent, then (6.18) poses no constraints. In this case, no dimension reduction occurs, and so fitting (6.17) is equivalent to performing least squares on the original $p$ predictors.\n",
    "\n",
    "All dimension reduction methods work in two steps. First, the transformed predictors $Z_1, Z_2, \\ldots, Z_M$ are obtained. Second, the model is fit using these $M$ predictors. However, the choice of $Z_1, Z_2, \\ldots, Z_M$, or equivalently, the selection of the $\\gamma_m$’s, can be achieved in different ways. In this chapter, we will consider two approaches for this task: principal components and partial least squares.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85566728",
   "metadata": {},
   "source": [
    "Principal Components Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387c77d5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$Principal$ $components$ $analysis$ (PCA) is a popular approach for deriving a low-dimensional set of features from a large set of variables. PCA is discussed in greater detail as a tool for unsupervised learning in Chapter 12. Here we describe its use as a dimension reduction technique for regression. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76958a6b",
   "metadata": {},
   "source": [
    "\n",
    "An Overview of Principal Components Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad7ad75",
   "metadata": {},
   "source": [
    "PCA is a technique for reducing the dimension of an $n \\times p$ data matrix $X$. The first principal component direction of the data is that along which the observations vary the most. For instance, consider Figure 6.14, which shows population size ($pop$) in tens of thousands of people, and ad spending for a particular company ($ad$) in thousands of dollars, for 100 cities. The green solid line represents the first principal component direction of the data. We can see by eye that this is the direction along which there is the greatest variability in the data. That is, if we projected the 100 observations onto this line (as shown in the left-hand panel of Figure 6.15), then the resulting projected observations would have the largest possible variance; projecting the observations onto any other line would yield projected observations with lower variance. Projecting a point onto a line simply involves finding the location on the line which is closest to the point.\n",
    "\n",
    "The first principal component is displayed graphically in Figure 6.14, but how can it be summarized mathematically? It is given by the formula\n",
    "\n",
    "$$\n",
    "Z_1 = 0.839 (pop - \\bar{pop}) + 0.544 (ad - \\bar{ad}). \\tag{6.19}\n",
    "$$\n",
    "\n",
    "Here $\\gamma_{11} = 0.839$ and $\\gamma_{21} = 0.544$ are the principal component loadings, which define the direction referred to above. In (6.19), $pop$ indicates the mean of all $pop$ values in this data set, and $ad$ indicates the mean of all advertising spending. The idea is that out of every possible linear combination of $pop$ and $ad$ such that $\\gamma_{11}^2 + \\gamma_{21}^2 = 1$, this particular linear combination yields the highest variance: i.e., this is the linear combination for which \n",
    "\n",
    "$$\n",
    "Var( \\gamma_{11} (pop - \\bar{pop}) + \\gamma_{21} (ad - \\bar{ad})) \\text{ is maximized.}\n",
    "$$\n",
    "\n",
    "It is necessary to consider only linear combinations of the form $\\gamma_{11}^2 + \\gamma_{21}^2 = 1$, since otherwise we could increase $\\gamma_{11}$ and $\\gamma_{21}$ arbitrarily in order to blow up the variance. In (6.19), the two loadings are both positive and have similar size, and so $Z_1$ is almost an average of the two variables.\n",
    "\n",
    "Since $n = 100$, $pop$ and $ad$ are vectors of length 100, and so is $Z_1$ in (6.19). For instance,\n",
    "\n",
    "$$\n",
    "z_{i1} = 0.839 (pop_i - \\bar{pop}) + 0.544 (ad_i - \\bar{ad}). \\tag{6.20}\n",
    "$$\n",
    "\n",
    "The values of $z_{11}, \\ldots, z_{n1}$ are known as the principal component scores, and can be seen in the right-hand panel of Figure 6.15.\n",
    "\n",
    "There is also another interpretation of PCA: the first principal component vector defines the line that is as close as possible to the data. For instance, in Figure 6.14, the first principal component line minimizes the sum of the squared perpendicular distances between each point and the line. These distances are plotted as dashed line segments in the left-hand panel of Figure 6.15, in which the crosses represent the projection of each point onto the first principal component line. The first principal component has been chosen so that the projected observations are as close as possible to the original observations.\n",
    "\n",
    "In the right-hand panel of Figure 6.15, the left-hand panel has been rotated so that the first principal component direction coincides with the x-axis. It is possible to show that the first principal component score for the $i$th observation, given in (6.20), is the distance in the x-direction of the $i$th cross from zero. So for example, the point in the bottom-left corner of the left-hand panel of Figure 6.15 has a large negative principal component score, $z_{i1} = -26.1$, while the point in the top-right corner has a large positive score, $z_{i1} = 18.7$. These scores can be computed directly using (6.20).\n",
    "\n",
    "We can think of the values of the principal component $Z_1$ as single number summaries of the joint $pop$ and $ad$ budgets for each location. In this example, if $z_{i1} = 0.839 (pop_i - \\bar{pop}) + 0.544 (ad_i - \\bar{ad}) < 0$, then this indicates a city with below-average population size and below-average ad spending. A positive score suggests the opposite. How well can a single number represent both $pop$ and $ad$? In this case, Figure 6.14 indicates that $pop$ and $ad$ have approximately a linear relationship, and so we might expect that a single-number summary will work well. Figure 6.16 displays $z_{i1}$ versus both $pop$ and $ad$. The plots show a strong relationship between the first principal component and the two features. In other words, the first principal component appears to capture most of the information contained in the $pop$ and $ad$ predictors.\n",
    "\n",
    "So far we have concentrated on the first principal component. In general, one can construct up to $p$ distinct principal components. The second principal component $Z_2$ is a linear combination of the variables that is uncorrelated with $Z_1$, and has largest variance subject to this constraint. The second principal component direction is illustrated as a dashed blue line in Figure 6.14. It turns out that the zero correlation condition of $Z_1$ with $Z_2$ is equivalent to the condition that the direction must be perpendicular, or orthogonal, to the first principal component direction. The second principal component is given by the formula\n",
    "\n",
    "$$\n",
    "Z_2 = 0.544 \\cdot (pop - \\bar{pop}) - 0.839 \\cdot (ad - \\bar{ad}).\n",
    "$$\n",
    "\n",
    "Since the advertising data has two predictors, the first two principal components contain all of the information that is in $pop$ and $ad$. However, by construction, the first component will contain the most information. Consider, for example, the much larger variability of $z_{i1}$ (the x-axis) versus $z_{i2}$ (the y-axis) in the right-hand panel of Figure 6.15. The fact that the second principal component scores are much closer to zero indicates that this component captures far less information. As another illustration, Figure 6.17 displays $z_{i2}$ versus $pop$ and $ad$. There is little relationship between the second principal component and these two predictors, again suggesting that in this case, one only needs the first principal component in order to accurately represent the $pop$ and $ad$ budgets.\n",
    "\n",
    "With two-dimensional data, such as in our advertising example, we can construct at most two principal components. However, if we had other predictors, such as population age, income level, education, and so forth, then additional components could be constructed. They would successively maximize variance, subject to the constraint of being uncorrelated with the preceding components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b188ed20",
   "metadata": {},
   "source": [
    "The Principal Components Regression Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f69ab99",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The principal components regression (PCR) approach involves constructing the first $M$ principal components, $Z_1, \\ldots, Z_M$, and then using these components as the predictors in a linear regression model that is fit using least squares. The key idea is that often a small number of principal components suffice to explain most of the variability in the data, as well as the relationship with the response. In other words, we assume that the directions in which $X_1, \\ldots, X_p$ show the most variation are the directions that are associated with $Y$. While this assumption is not guaranteed to be true, it often turns out to be a reasonable enough approximation to give good results.\n",
    "\n",
    "If the assumption underlying PCR holds, then fitting a least squares model to $Z_1, \\ldots, Z_M$ will lead to better results than fitting a least squares model to $X_1, \\ldots, X_p$, since most or all of the information in the data that relates to the response is contained in $Z_1, \\ldots, Z_M$, and by estimating only $M < p$ coefficients we can mitigate overfitting. In the advertising data, the first principal component explains most of the variance in both $pop$ and $ad$, so a principal component regression that uses this single variable to predict some response of interest, such as sales, will likely perform quite well.\n",
    "\n",
    "Figure 6.18 displays the PCR fits on the simulated data sets from Figures 6.8 and 6.9. Recall that both data sets were generated using $n = 50$ observations and $p = 45$ predictors. However, while the response in the first data set was a function of all the predictors, the response in the second data set was generated using only two of the predictors. The curves are plotted as a function of $M$, the number of principal components used as predictors in the regression model. As more principal components are used in the regression model, the bias decreases, but the variance increases. This\n",
    "results in a typical U-shape for the mean squared error. When $M$ = p = 45$,\n",
    "then PCR amounts simply to a least squares fit using all of the original\n",
    "predictors. The figure indicates that performing PCR with an appropriate\n",
    "choice of $M$ can result in a substantial improvement over least squares, es\n",
    "pecially in the left-hand panel. However, by examining the ridge regression\n",
    "and lasso results in Figures 6.5, 6.8, and 6.9, we see that PCR does not\n",
    "perform as well as the two shrinkage methods in this example.\n",
    "\n",
    "The relatively worse performance of PCR in Figure 6.18 is a consequence\n",
    "of the fact that the data were generated in such a way that many princi\n",
    "pal components are required in order to adequately model the response.\n",
    "In contrast, PCR will tend to do well in cases when the first few principal\n",
    "components are sufficient to capture most of the variation in the predictors\n",
    "as well as the relationship with the response. The left-hand panel of Fig\n",
    "ure 6.19 illustrates the results from another simulated data set designed to\n",
    "be more favorable to PCR. Here the response was generated in such a way\n",
    "that it depends exclusively on the first five principal components. Now the\n",
    "bias drops to zero rapidly as $M$, the number of principal components used\n",
    "in PCR, increases. The mean squared error displays a clear minimum at\n",
    "$M =5$.The right-hand panel of Figure 6.19 displays the results on these\n",
    "data using ridge regression and the lasso. All three methods offer a signif\n",
    "icant improvement over least squares. However, PCR and ridge regression\n",
    "slightly outperform the lasso.\n",
    "\n",
    "We note that even though PCR provides a simple way to perform re\n",
    "gression using $M<p$ predictors, it is not a feature selection method. This\n",
    "is because each of the $M$ principal components used in the regression is a\n",
    "linear combination of all p of the original features. For instance, in (6.19),\n",
    "$Z_1$ was a linear combination of both `pop` and `ad`. Therefore, while PCR of\n",
    "ten performs quite well in many practical settings, it does not result in the development of a model that relies upon a small set of the original features.\n",
    "In this sense, PCR is more closely related to ridge regression than to the\n",
    "lasso. In fact, one can show that PCR and ridge regression are very closely\n",
    "related. One can even think of ridge regression as a continuous version of\n",
    "PCR!\n",
    "\n",
    "In PCR, the number of principal components, $M$, is typically chosen by\n",
    "cross-validation. The results of applying PCR to the `Credit` data set are\n",
    "shown in Figure 6.20; the right-hand panel displays the cross-validation er\n",
    "rors obtained, as a function of $M$. On these data, the lowest cross-validation\n",
    "error occurs when there are $M = 10$ components; this corresponds to al\n",
    "most no dimension reduction at all, since PCR with $M = 11$ is equivalent\n",
    "to simply performing least squares.\n",
    "\n",
    "When performing PCR, we generally recommend $standardizing$ each pre\n",
    "dictor, using (6.6), prior to generating the principal components. This stan\n",
    "dardization ensures that all variables are on the same scale. In the absence\n",
    "of standardization, the high-variance variables will tend to play a larger\n",
    "role in the principal components obtained, and the scale on which the vari\n",
    "ables are measured will ultimately have an effect on the final PCR model.\n",
    "However, if the variables are all measured in the same units (say, kilograms,\n",
    "or inches), then one might choose not to standardize them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6923400",
   "metadata": {},
   "source": [
    "#### Partial Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed841a",
   "metadata": {},
   "source": [
    "\n",
    "The PCR approach that we just described involves identifying linear combi\n",
    "nations, or directions, that best represent the predictors $X1,...,Xp$. These\n",
    "directions are identified in an $unsupervised$ way, since the response Y is\n",
    "not used to help determine the principal component directions. That is,\n",
    "the response does not supervise the identification of the principal compo\n",
    "nents. Consequently, PCR suffers from a drawback: there is no guarantee that the directions that best explain the predictors will also be the best directions to use for predicting the response. Unsupervised methods are discussed further in Chapter 12.\n",
    "\n",
    "We now present partial least squares (PLS), a supervised alternative to PCR. Like PCR, PLS is a dimension reduction method, which first identifies a new set of features $Z_1, \\ldots, Z_M$ that are linear combinations of the original features, and then fits a linear model via least squares using these $M$ new features. But unlike PCR, PLS identifies these new features in a supervised way—that is, it makes use of the response $Y$ in order to identify new features that not only approximate the old features well, but also that are related to the response. Roughly speaking, the PLS approach attempts to find directions that help explain both the response and the predictors.\n",
    "\n",
    "We now describe how the first PLS direction is computed. After standardizing the $p$ predictors, PLS computes the first direction $Z_1$ by setting each $\\beta_1$ in (6.16) equal to the coefficient from the simple linear regression of $Y$ onto $X_j$. One can show that this coefficient is proportional to the correlation between $Y$ and $X_j$. Hence, in computing $Z_1 = \\sum_{j=1}^{p} \\beta_1 X_j$, PLS places the highest weight on the variables that are most strongly related to the response.\n",
    "\n",
    "Figure 6.21 displays an example of PLS on a synthetic dataset with Sales in each of 100 regions as the response, and two predictors: Population Size and Advertising Spending. The solid green line indicates the first PLS direction, while the dotted line shows the first principal component direction. PLS has chosen a direction that has less change in the ad dimension per unit change in the pop dimension, relative to PCA. This suggests that pop is more highly correlated with the response than is ad. The PLS direction does not fit the predictors as closely as does PCA, but it does a better job explaining the response.\n",
    "\n",
    "To identify the second PLS direction we first adjust each of the variables for $Z_1$, by regressing each variable on $Z_1$ and taking residuals. These residuals can be interpreted as the remaining information that has not been explained by the first PLS direction. We then compute $Z_2$ using this $orthogonalized$ $data$ in exactly the same fashion as $Z_1$ was computed based on the original data. This iterative approach can be repeated $M$ times to identify multiple PLS components $Z_1, \\ldots, Z_M$. Finally, at the end of this procedure, we use least squares to fit a linear model to predict $Y$ using $Z_1, \\ldots, Z_M$ in exactly the same fashion as for PCR.\n",
    "\n",
    "As with PCR, the number $M$ of partial least squares directions used in PLS is a tuning parameter that is typically chosen by cross-validation. We generally standardize the predictors and response before performing PLS. PLS is popular in the field of chemometrics, where many variables arise from digitized spectrometry signals. In practice, it often performs no better than ridge regression or PCR. While the supervised dimension reduction of PLS can reduce bias, it also has the potential to increase variance, so that the overall benefit of PLS relative to PCR is a wash.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edeab45",
   "metadata": {},
   "source": [
    "#### Considerations in High Dimensions\n",
    "\n",
    "##### High-Dimensional Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd80cc23",
   "metadata": {},
   "source": [
    "\n",
    "Most traditional statistical techniques for regression and classification are intended for the low-dimensional setting in which $n$, the number of observations, is much greater than $p$, the number of features. This is due in part to the fact that throughout most of the field’s history, the bulk of scientific problems requiring the use of statistics have been low-dimensional. For instance, consider the task of developing a model to predict a patient’s blood pressure on the basis of his or her age, sex, and body mass index (BMI). There are three predictors, or four if an intercept is included in the model, and perhaps several thousand patients for whom blood pressure and age, sex, and BMI are available. Hence $n \\gg p$, and so the problem is low-dimensional. (By dimension here we are referring to the size of $p$.)\n",
    "\n",
    "In the past 20 years, new technologies have changed the way that data are collected in fields as diverse as finance, marketing, and medicine. It is now commonplace to collect an almost unlimited number of feature measurements ($p$ very large). While $p$ can be extremely large, the number of observations $n$ is often limited due to cost, sample availability, or other considerations. Two examples are as follows:\n",
    "\n",
    "1. Rather than predicting blood pressure on the basis of just age, sex, and BMI, one might also collect measurements for half a million $single$ $nucleotide$ $polymorphisms$ (SNPs; these are individual DNA mutations that are relatively common in the population) for inclusion in the predictive model. Then $n = 200$ and $p = 500,000$.\n",
    "\n",
    "2. A marketing analyst interested in understanding people’s online shopping patterns could treat as features all of the search terms entered by users of a search engine. This is sometimes known as the “bag-of-words” model. The same researcher might have access to the search histories of only a few hundred or a few thousand search engine users who have consented to share their information with the researcher. For a given user, each of the $p$ search terms is scored present (1) or absent (0) or absent (1), creating a large binary feature vector. Then $n$ $\\approx$ 1,000 and $p$ is much larger.\n",
    "\n",
    "Data sets containing more features than observations are often referred\n",
    "to as $high-dimensional$. Classical approaches such as least squares linear\n",
    "regression are not appropriate in this setting. Many of the issues that arise\n",
    "in the analysis of high-dimensional data were discussed earlier in this book,\n",
    "since they apply also when $n>p$: these include the role of the bias-variance\n",
    "trade-off and the danger of overfitting. Though these issues are always rele\n",
    "vant, they can become particularly important when the number of features\n",
    "is very large relative to the number of observations.\n",
    "\n",
    "We have defined the high-dimensional setting as the case where the num\n",
    "ber of features p is larger than the number of observations n. But the con\n",
    "siderations that we will now discuss certainly also apply if p is slightly\n",
    "smaller than n, and are best always kept in mind when performing super\n",
    "vised learning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79eba15",
   "metadata": {},
   "source": [
    "##### What Goes Wrong in High Dimensions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be5f77c",
   "metadata": {},
   "source": [
    "\n",
    "In order to illustrate the need for extra care and specialized techniques\n",
    "for regression and classification when p>n, we begin by examining what\n",
    "can go wrong if we apply a statistical technique not intended for the high\n",
    "dimensional setting. For this purpose, we examine least squares regression.\n",
    "But the same concepts apply to logistic regression, linear discriminant analysis, and other classical statistical approaches.\n",
    "\n",
    "When the number of features p is as large as, or larger than, the number\n",
    "of observations n, least squares as described in Chapter 3 cannot (or rather,\n",
    "should not) be performed. The reason is simple: regardless of whether or\n",
    "not there truly is a relationship between the features and the response,\n",
    "least squares will yield a set of coefficient estimates that result in a perfect\n",
    "fit to the data, such that the residuals are zero.\n",
    "\n",
    "An example is shown in Figure 6.22 with $p =1$ feature (plus an intercept)\n",
    "in two cases: when there are 20 observations, and when there are only\n",
    "two observations. When there are 20 observations, n>pand the least\n",
    "squares regression line does not perfectly fit the data; instead, the regression\n",
    "line seeks to approximate the 20 observations as well as possible. On the\n",
    "other hand, when there are only two observations, then regardless of the\n",
    "values of those observations, the regression line will fit the data exactly.\n",
    "This is problematic because this perfect fit will almost certainly lead to\n",
    "overfitting of the data. In other words, though it is possible to perfectly fit\n",
    "the training data in the high-dimensional setting, the resulting linear model\n",
    "will perform extremely poorly on an independent test set, and therefore\n",
    "does not constitute a useful model. In fact, we can see that this happened\n",
    "in Figure 6.22: the least squares line obtained in the right-hand panel will\n",
    "perform very poorly on a test set comprised of the observations in the left\n",
    "hand panel. The problem is simple: when $p>n$ or p $\\approx$ n, a simple least\n",
    "squares regression line is too flexible and hence overfits the data.\n",
    "\n",
    "Figure 6.23 further illustrates the risk of carelessly applying least squares\n",
    "when the number of features $p$ is large. Data were simulated with $n = 20$\n",
    "observations, and regression was performed with between 1 and 20 features, each of which was completely unrelated to the response. As shown in the\n",
    "figure, the model $R^2$ increases to 1 as the number of features included in the\n",
    "model increases, and correspondingly the training set MSE decreases to 0\n",
    "as the number of features increases, **even though the features are completely\n",
    "unrelated to the response**. On the other hand, the MSE on an independent\n",
    "test set becomes extremely large as the number of features included in the\n",
    "model increases, because including the additional predictors leads to a vast\n",
    "increase in the variance of the coefficient estimates. Looking at the test\n",
    "set MSE, it is clear that the best model contains at most a few variables.\n",
    "However, someone who carelessly examines only the $R^2$ or the training set\n",
    "MSE might erroneously conclude that the model with the greatest number\n",
    "of variables is best. This indicates the importance of applying extra care\n",
    "when analyzing data sets with a large number of variables, and of always\n",
    "evaluating model performance on an independent test set.\n",
    "\n",
    "In Section 6.1.3, we saw a number of approaches for adjusting the training\n",
    "set RSS or $R^2$ in order to account for the number of variables used to fit\n",
    "a least squares model. Unfortunately, the $C_p$, AIC, and BIC approaches\n",
    "are not appropriate in the high-dimensional setting, because estimating $\\hat{\\sigma}^2$\n",
    "is problematic. (For instance, the formula for $\\hat{\\sigma}^2$ from Chapter 3 yields an\n",
    "estimate $\\hat{\\sigma}^2$ = 0 in this setting.) Similarly, problems arise in the application\n",
    "of adjusted $R^2$ in the high-dimensional setting, since one can easily obtain\n",
    "a model with an adjusted $R^2$ value of 1. Clearly, alternative approaches\n",
    "that are better-suited to the high-dimensional setting are required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7691f557",
   "metadata": {},
   "source": [
    "##### Regression in High Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66b5d12",
   "metadata": {},
   "source": [
    "\n",
    "It turns out that many of the methods seen in this chapter for fitting\n",
    "less flexible least squares models, such as forward stepwise selection, ridge\n",
    "regression, the lasso, and principal components regression, are particularly\n",
    "useful for performing regression in the high-dimensional setting. Essentially,\n",
    "these approaches avoid overfitting by using a less flexible fitting approach\n",
    "than least squares.\n",
    "\n",
    "Figure 6.24 illustrates the performance of the lasso in a simple simulated\n",
    "example. There are $p = 20$, 50, or 2,000 features, of which 20 are truly\n",
    "associated with the outcome. The lasso was performed on $n = 100$ training\n",
    "observations, and the mean squared error was evaluated on an independent\n",
    "test set. As the number of features increases, the test set error increases.\n",
    "When $p = 20$, the lowest validation set error was achieved when $\\lambda$ in (6.7) was small; however, when $p$ was larger then the lowest validation\n",
    "set error was achieved using a larger value of $\\lambda$. In each boxplot, rather\n",
    "than reporting the values of $\\lambda$ used, the *degrees of freedom* of the resulting\n",
    "lasso solution is displayed; this is simply the number of non-zero coefficient\n",
    "estimates in the lasso solution, and is a measure of the flexibility of the\n",
    "lasso fit. Figure 6.24 highlights three important points: (1) regularization\n",
    "or shrinkage plays a key role in high-dimensional problems, (2) appropriate\n",
    "tuning parameter selection is crucial for good predictive performance, and\n",
    "(3) the test error tends to increase as the dimensionality of the problem\n",
    "(i.e. the number of features or predictors) increases, unless the additional\n",
    "features are truly associated with the response.\n",
    "\n",
    "The third point above is in fact a key principle in the analysis of high\n",
    "dimensional data, which is known as the *curse of dimensionality*. One might\n",
    "think that as the number of features used to fit a model increases, the\n",
    "quality of the fitted model will increase as well. However, comparing the\n",
    "left-hand and right-hand panels in Figure 6.24, we see that this is not\n",
    "necessarily the case: in this example, the test set MSE almost doubles as\n",
    "p increases from 20 to 2,000. In general, *adding additional signal features\n",
    "that are truly associated with the response will improve the fitted model*,\n",
    "in the sense of leading to a reduction in test set error. However, adding\n",
    "noise features that are not truly associated with the response will lead\n",
    "to a deterioration in the fitted model, and consequently an increased test\n",
    "set error. This is because noise features increase the dimensionality of the\n",
    "problem, exacerbating the risk of overfitting (since noise features may be\n",
    "assigned nonzero coefficients due to chance associations with the response\n",
    "on the training set) without any potential upside in terms of improved test\n",
    "set error. Thus, we see that new technologies that allow for the collection\n",
    "of measurements for thousands or millions of features are a double-edged\n",
    "sword: they can lead to improved predictive models if these features are in\n",
    "fact relevant to the problem at hand, but will lead to worse results if the\n",
    "features are not relevant. Even if they are relevant, the variance incurred\n",
    "in fitting their coefficients may outweigh the reduction in bias that they\n",
    "bring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeb2a05",
   "metadata": {},
   "source": [
    "##### Interpreting Results in High Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dacfb07",
   "metadata": {},
   "source": [
    "\n",
    "When we perform the lasso, ridge regression, or other regression proce\n",
    "dures in the high-dimensional setting, we must be quite cautious in the way\n",
    "that we report the results obtained. In Chapter 3, we learned about multi\n",
    "collinearity, the concept that the variables in a regression might be corre\n",
    "lated with each other. In the high-dimensional setting, the multicollinearity\n",
    "problem is extreme: any variable in the model can be written as a linear\n",
    "combination of all of the other variables in the model. Essentially, this\n",
    "means that we can never know exactly which variables (if any) truly are\n",
    "predictive of the outcome, and we can never identify the best coefficients\n",
    "for use in the regression. At most, we can hope to assign large regression\n",
    "coefficients to variables that are correlated with the variables that truly are\n",
    "predictive of the outcome.\n",
    "\n",
    "For instance, suppose that we are trying to predict blood pressure on the\n",
    "basis of half a million SNPs, and that forward stepwise selection indicates\n",
    "that 17 of those SNPs lead to a good predictive model on the training data.\n",
    "It would be incorrect to conclude that these 17 SNPs predict blood pressure\n",
    "more effectively than the other SNPs not included in the model. There are\n",
    "likely to be many sets of 17 SNPs that would predict blood pressure just\n",
    "as well as the selected model. If we were to obtain an independent data set\n",
    "and perform forward stepwise selection on that data set, we would likely\n",
    "obtain a model containing a different, and perhaps even non-overlapping,\n",
    "set of SNPs. This does not detract from the value of the model obtained—\n",
    "for instance, the model might turn out to be very effective in predicting\n",
    "blood pressure on an independent set of patients, and might be clinically\n",
    "useful for physicians. But we must be careful not to overstate the results\n",
    "obtained, and to make it clear that what we have identified is simply one\n",
    "of *many possible models* for predicting blood pressure, and that it must be\n",
    "further validated on independent data sets.\n",
    "\n",
    "It is also important to be particularly careful in reporting errors and mea\n",
    "sures of model fit in the high-dimensional setting. We have seen that when\n",
    "$p>n$, it is easy to obtain a useless model that has zero residuals. There\n",
    "fore, one should never use sum of squared errors, p-values, $R^2$ statistics, or\n",
    "other traditional measures of model fit on the training data as evidence of\n",
    "a good model fit in the high-dimensional setting. For instance, as we saw\n",
    "in Figure 6.23, one can easily obtain a model with $R^2 =1$ when $p>n$.\n",
    "Reporting this fact might mislead others into thinking that a statistically\n",
    "valid and useful model has been obtained, whereas in fact this provides\n",
    "absolutely no evidence of a compelling model. It is important to instead\n",
    "report results on an independent test set, or cross-validation errors. For\n",
    "instance, the MSE or $R^2$ on an independent test set is a valid measure of\n",
    "model fit, but the MSE on the training set certainly is not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c661afcd",
   "metadata": {},
   "source": [
    "#### Lab: Linear Models and Regularization Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64bfdc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "from statsmodels.api import OLS\n",
    "import sklearn.model_selection as skm\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ba85bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting l0bnb\n",
      "  Downloading l0bnb-1.0.0.tar.gz (79 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\zoe oladokun\\appdata\\local\\anaconda3\\envs\\islp_clean\\lib\\site-packages (from l0bnb) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\zoe oladokun\\appdata\\local\\anaconda3\\envs\\islp_clean\\lib\\site-packages (from l0bnb) (1.16.3)\n",
      "Collecting numba>=0.53.1 (from l0bnb)\n",
      "  Downloading numba-0.63.1-cp311-cp311-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting llvmlite<0.47,>=0.46.0dev0 (from numba>=0.53.1->l0bnb)\n",
      "  Downloading llvmlite-0.46.0-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Downloading numba-0.63.1-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.8/2.7 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 4.4 MB/s  0:00:00\n",
      "Downloading llvmlite-0.46.0-cp311-cp311-win_amd64.whl (38.1 MB)\n",
      "   ---------------------------------------- 0.0/38.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.3/38.1 MB 6.1 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.4/38.1 MB 5.6 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.4/38.1 MB 5.4 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 4.5/38.1 MB 5.5 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 5.8/38.1 MB 5.4 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 6.8/38.1 MB 5.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 8.1/38.1 MB 5.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 9.4/38.1 MB 5.5 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 10.5/38.1 MB 5.5 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 11.8/38.1 MB 5.5 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 13.1/38.1 MB 5.6 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 14.2/38.1 MB 5.6 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 15.5/38.1 MB 5.6 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 16.8/38.1 MB 5.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 18.1/38.1 MB 5.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 19.1/38.1 MB 5.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 20.4/38.1 MB 5.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 21.8/38.1 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 23.1/38.1 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 24.4/38.1 MB 5.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 25.4/38.1 MB 5.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 26.7/38.1 MB 5.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.0/38.1 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.4/38.1 MB 5.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 30.7/38.1 MB 5.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.0/38.1 MB 5.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.3/38.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 34.6/38.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 35.9/38.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.2/38.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.1/38.1 MB 5.7 MB/s  0:00:06\n",
      "Building wheels for collected packages: l0bnb\n",
      "  Building wheel for l0bnb (pyproject.toml): started\n",
      "  Building wheel for l0bnb (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for l0bnb: filename=l0bnb-1.0.0-py3-none-any.whl size=22409 sha256=55200f080d10bd81e9871b3edbb3e2ee72bb395b13f557c3b0a72d28219cc3e6\n",
      "  Stored in directory: c:\\users\\zoe oladokun\\appdata\\local\\pip\\cache\\wheels\\56\\b6\\7a\\2a78772d92aa67f0d038759a09c7e950b5a708d5ecd5c0e38d\n",
      "Successfully built l0bnb\n",
      "Installing collected packages: llvmlite, numba, l0bnb\n",
      "\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [l0bnb]\n",
      "   -------------------------- ------------- 2/3 [l0bnb]\n",
      "   -------------------------- ------------- 2/3 [l0bnb]\n",
      "   -------------------------- ------------- 2/3 [l0bnb]\n",
      "   ---------------------------------------- 3/3 [l0bnb]\n",
      "\n",
      "Successfully installed l0bnb-1.0.0 llvmlite-0.46.0 numba-0.63.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from ISLP.models import \\\n",
    "    (Stepwise,\n",
    "     sklearn_selected,\n",
    "     sklearn_selection_path)\n",
    "%pip install l0bnb\n",
    "from l0bnb import fit_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b970eb",
   "metadata": {},
   "source": [
    "##### Subset Selection Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4100f8f",
   "metadata": {},
   "source": [
    "Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8db37719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hitters = load_data('Hitters')\n",
    "np.isnan(Hitters['Salary']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a87f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hitters = Hitters.dropna();\n",
    "Hitters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f88e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nCp(sigma2, estimator, X, Y):\n",
    "    \"Negative Cp statistic\"\n",
    "    n, p = X.shape\n",
    "    Yhat = estimator.predict(X)\n",
    "    RSS = np.sum((Y- Yhat)**2)\n",
    "    return-(RSS + 2 * p * sigma2) / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5a638bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = MS(Hitters.columns.drop('Salary')).fit(Hitters)\n",
    "Y = np.array(Hitters['Salary'])\n",
    "X = design.transform(Hitters)\n",
    "sigma2 = OLS(Y,X).fit().scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2eeb429",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_Cp = partial(nCp, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4903b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = Stepwise.first_peak(design,\n",
    "                               direction='forward',\n",
    "                               max_terms=len(design.terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95c90131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Assists',\n",
       " 'AtBat',\n",
       " 'CAtBat',\n",
       " 'CHits',\n",
       " 'CHmRun',\n",
       " 'CRBI',\n",
       " 'CRuns',\n",
       " 'CWalks',\n",
       " 'Division',\n",
       " 'Errors',\n",
       " 'Hits',\n",
       " 'HmRun',\n",
       " 'League',\n",
       " 'NewLeague',\n",
       " 'PutOuts',\n",
       " 'RBI',\n",
       " 'Runs',\n",
       " 'Walks',\n",
       " 'Years')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters_MSE = sklearn_selected(OLS,\n",
    "                               strategy,\n",
    "                               scoring=\"neg_mean_squared_error\")\n",
    "hitters_MSE.fit(Hitters, Y)\n",
    "hitters_MSE.selected_state_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d720b272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Assists',\n",
       " 'AtBat',\n",
       " 'CAtBat',\n",
       " 'CRBI',\n",
       " 'CRuns',\n",
       " 'CWalks',\n",
       " 'Division',\n",
       " 'Hits',\n",
       " 'PutOuts',\n",
       " 'Walks')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters_Cp = sklearn_selected(OLS,\n",
    "                              strategy,\n",
    "                              scoring=neg_Cp)\n",
    "hitters_Cp.fit(Hitters, Y)\n",
    "hitters_Cp.selected_state_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944b080d",
   "metadata": {},
   "source": [
    "Choosing Among Models Using the Validation Set Approach and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78f3925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = Stepwise.fixed_steps(design,\n",
    "                                len(design.terms),\n",
    "                                direction='forward')\n",
    "full_path = sklearn_selection_path(OLS, strategy, scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6964a9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_path.fit(Hitters, Y)\n",
    "Yhat_in = full_path.predict(Hitters)\n",
    "Yhat_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b82b7ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse_fig, ax = subplots(figsize=(8,8))\n",
    "insample_mse = ((Yhat_in- Y[:,None])**2).mean(0)\n",
    "n_steps = insample_mse.shape[0]\n",
    "ax.plot(np.arange(n_steps),\n",
    "        insample_mse,\n",
    "        'k', # color black\n",
    "        label='In-sample')\n",
    "ax.set_ylabel('MSE',\n",
    "              fontsize=20)\n",
    "ax.set_xlabel('# steps of forward stepwise',\n",
    "                fontsize=20)\n",
    "ax.set_xticks(np.arange(n_steps)[::2])\n",
    "ax.legend()\n",
    "ax.set_ylim([50000,250000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a98e1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 5\n",
    "kfold = skm.KFold(K,\n",
    "                  random_state=0,\n",
    "                  shuffle=True)\n",
    "Yhat_cv = skm.cross_val_predict(full_path,\n",
    "                                Hitters,\n",
    "                                Y,\n",
    "                                cv=kfold)\n",
    "Yhat_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85b533c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_mse = []\n",
    "for train_idx, test_idx in kfold.split(Y):\n",
    "    errors = (Yhat_cv[test_idx]- Y[test_idx,None])**2\n",
    "    cv_mse.append(errors.mean(0)) # column means\n",
    "\n",
    "cv_mse = np.array(cv_mse).T\n",
    "cv_mse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f178fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax.errorbar(np.arange(n_steps),cv_mse.mean(1),\n",
    "            cv_mse.std(1) / np.sqrt(K),\n",
    "            label='Cross-validated',\n",
    "            c='r') # color red\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.legend()\n",
    "mse_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c6ec8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = skm.ShuffleSplit(n_splits=1,\n",
    "                              test_size=0.2,\n",
    "                              random_state=0)\n",
    "for train_idx, test_idx in validation.split(Y):\n",
    "    full_path.fit(Hitters.iloc[train_idx],\n",
    "                  Y[train_idx])\n",
    "    Yhat_val = full_path.predict(Hitters.iloc[test_idx])\n",
    "    errors = (Yhat_val- Y[test_idx,None])**2\n",
    "    validation_mse = errors.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "275bd274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax.plot(np.arange(n_steps),\n",
    "        validation_mse,\n",
    "        'b--', # color blue, broken line\n",
    "        label='Validation')\n",
    "ax.set_xticks(np.arange(n_steps)[::2])\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.legend()\n",
    "mse_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f56e0",
   "metadata": {},
   "source": [
    "Best Subset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a206c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = design.fit_transform(Hitters)\n",
    "D = D.drop('intercept', axis=1)\n",
    "X = np.asarray(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02dff9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Data.\n",
      "BnB Started.\n",
      "Iteration: 1. Number of non-zeros:  1\n",
      "Iteration: 2. Number of non-zeros:  2\n",
      "Iteration: 3. Number of non-zeros:  2\n",
      "Iteration: 4. Number of non-zeros:  2\n",
      "Iteration: 5. Number of non-zeros:  3\n",
      "Iteration: 6. Number of non-zeros:  3\n",
      "Iteration: 7. Number of non-zeros:  4\n",
      "Iteration: 8. Number of non-zeros:  9\n",
      "Iteration: 9. Number of non-zeros:  9\n",
      "Iteration: 10. Number of non-zeros:  9\n",
      "Iteration: 11. Number of non-zeros:  9\n",
      "Iteration: 12. Number of non-zeros:  9\n",
      "Iteration: 13. Number of non-zeros:  9\n",
      "Iteration: 14. Number of non-zeros:  9\n",
      "Iteration: 15. Number of non-zeros:  9\n",
      "Iteration: 16. Number of non-zeros:  9\n",
      "Iteration: 17. Number of non-zeros:  9\n",
      "Iteration: 18. Number of non-zeros:  17\n",
      "Iteration: 19. Number of non-zeros:  19\n"
     ]
    }
   ],
   "source": [
    "path = fit_path(X,\n",
    "                Y,\n",
    "                max_nonzeros=X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76401858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': array([0.        , 3.25484367, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.67775265, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'B0': -38.98216739555505,\n",
       " 'lambda_0': 0.01141624802745019,\n",
       " 'M': 0.5829861733382015,\n",
       " 'Time_exceeded': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2e774b",
   "metadata": {},
   "source": [
    "##### Ridge Regression and the Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1347858",
   "metadata": {},
   "source": [
    "Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c826facc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs = X- X.mean(0)[None,:]\n",
    "X_scale = X.std(0)\n",
    "Xs = Xs / X_scale[None,:]\n",
    "lambdas = 10**np.linspace(8,-2, 100) / Y.std()\n",
    "soln_array = skl.ElasticNet.path(Xs,\n",
    "                                 Y,\n",
    "                                 l1_ratio=0.01,        # can't be zero\n",
    "                                 alphas=lambdas,\n",
    "                                 max_iter=100_000,\n",
    "                                 tol=1e-6)[1]\n",
    "soln_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ccd10d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "negative log(lambda)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AtBat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Hits",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HmRun",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Runs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RBI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Walks",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Years",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CAtBat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CHits",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CHmRun",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CRuns",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CRBI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CWalks",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "League[N]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Division[W]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PutOuts",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Assists",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Errors",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "NewLeague[N]",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c807b899-229d-4ed5-ba4f-74c1e674d9c9",
       "rows": [
        [
         "-12.310855053159447",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-12.078270700331764",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-11.845686347504083",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-11.613101994676402",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-11.380517641848721",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-11.147933289021038",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-10.915348936193357",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-10.682764583365676",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-10.450180230537995",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-10.217595877710313",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-9.985011524882632",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.000926524147407067",
         "0.0014038751154456098",
         "0.0009013013500769851",
         "0.0016924552081139653",
         "0.0017823311349777437",
         "0.0001654141332483804",
         "-0.0",
         "-0.0",
         "0.0",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-9.752427172054952",
         "0.0003395317329701145",
         "0.0015007321072621458",
         "0.0",
         "0.0010030740353089824",
         "0.0017857435530327212",
         "0.0016379394913920047",
         "0.0004945261267786553",
         "0.0038130694600841944",
         "0.004415418344246363",
         "0.003781305340027065",
         "0.004779544684227367",
         "0.004892954070225775",
         "0.0028526976788759034",
         "-0.0",
         "-0.0",
         "0.0",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-9.51984281922727",
         "0.0030721194881827636",
         "0.004537402533137301",
         "0.0013452386506931128",
         "0.003909422713103173",
         "0.004896857131497363",
         "0.004710486675497952",
         "0.0032673492817598794",
         "0.007454551991454835",
         "0.008214624438171558",
         "0.007414551686412146",
         "0.008674052965783316",
         "0.008817155508205696",
         "0.006242787292669977",
         "-0.0",
         "-0.0",
         "0.0",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-9.287258466399589",
         "0.006519319779450192",
         "0.008368325473000794",
         "0.004340309957374113",
         "0.007575888989704634",
         "0.008821563165610221",
         "0.008586665651876737",
         "0.006765245471268628",
         "0.012048350063522275",
         "0.013007440401200032",
         "0.011997962046347193",
         "0.013587095961777986",
         "0.013767644957317034",
         "0.010519412680735151",
         "-0.0",
         "-0.0",
         "0.002551397204670377",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-9.054674113571906",
         "0.010867842981570223",
         "0.01320106812764384",
         "0.008118351529891292",
         "0.012201101450157266",
         "0.013772443717367746",
         "0.013476475538430344",
         "0.011177491583741204",
         "0.017843143628448615",
         "0.01905335854524447",
         "0.01777969850124482",
         "0.01978467729661112",
         "0.02001246299604744",
         "0.015914059799352398",
         "-0.0",
         "-0.00012836761216336522",
         "0.005862903028292573",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-8.822089760744225",
         "0.016352891244043866",
         "0.019297148329700933",
         "0.012883605096740514",
         "0.018035284170098417",
         "0.020017271741110745",
         "0.019644507297901567",
         "0.01674256372593568",
         "0.025152278759499738",
         "0.026679363338776536",
         "0.025072435532943752",
         "0.027601977516902337",
         "0.02788935420406319",
         "0.022718383427880264",
         "-0.0",
         "-0.0028059712238952647",
         "0.010040584834385765",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-8.589505407916544",
         "0.023270812100698517",
         "0.02698614004596752",
         "0.018893353818284702",
         "0.025393769571423284",
         "0.027893446921848884",
         "0.027424193595319613",
         "0.02376083689660708",
         "0.0343704912312022",
         "0.0362974001824477",
         "0.0342700833430839",
         "0.037461280299979305",
         "0.037823819008818295",
         "0.031299792607017776",
         "-0.0",
         "-0.006184114706939873",
         "0.015310695840481055",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-8.356921055088863",
         "0.03199478895636548",
         "0.03668315524172097",
         "0.02647151580184437",
         "0.03467368668472855",
         "0.0378258416107609",
         "0.03723549654626957",
         "0.03261044795759535",
         "0.04599480849101582",
         "0.048426207077940056",
         "0.0458686535764804",
         "0.04989433695854203",
         "0.050351666445546985",
         "0.04212086796810455",
         "-0.0",
         "-0.010445879117513284",
         "0.021958394416406617",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-8.12433670226118",
         "0.04299453147202788",
         "0.048910823961538036",
         "0.036025672043164036",
         "0.04637496349413389",
         "0.05034922263725563",
         "0.04960713233102411",
         "0.04376713947875915",
         "0.06065071056406741",
         "0.06371865274403336",
         "0.06049238881056154",
         "0.06557039477319465",
         "0.0661472524652093",
         "0.05576369108528022",
         "-0.0",
         "-0.01582207385881549",
         "0.030342977357063757",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-7.891752349433501",
         "0.05686084871905855",
         "0.06432675313996782",
         "0.04806829318017036",
         "0.06112654402875173",
         "0.0661362269070903",
         "0.06520433368151157",
         "0.05782898796455423",
         "0.07912476776113823",
         "0.08299585710221935",
         "0.0789263682769303",
         "0.0853311737539761",
         "0.08605872507629288",
         "0.07296017841842009",
         "-0.0",
         "-0.022603609320902152",
         "0.04091698012821535",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-7.6591679966058175",
         "0.07433624518162602",
         "0.0837577681992746",
         "0.06324312581669965",
         "0.0797190595846166",
         "0.08603219341619282",
         "0.08486346304231249",
         "0.0755471212864661",
         "0.10240524033671271",
         "0.10728965958554343",
         "0.10215708237233961",
         "0.11023440083626225",
         "0.11115189321012371",
         "0.09462979751696088",
         "-0.0",
         "-0.031157035752271092",
         "0.054250094856821134",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-7.426583643778137",
         "0.09635287713651311",
         "0.10824247652450487",
         "0.08235785768506682",
         "0.10314540514293713",
         "0.11109837437702971",
         "0.10963502668424013",
         "0.09786371150270408",
         "0.13173238570124496",
         "0.13789528054188682",
         "0.13142273219443745",
         "0.14160779319394898",
         "0.14276462603876477",
         "0.12192627300908221",
         "-0.0",
         "-0.041944034471021734",
         "0.07105906061461642",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-7.1939992909504555",
         "0.12407942113565126",
         "0.13908395990353078",
         "0.10642434191066502",
         "0.13265091541802962",
         "0.14266529097182667",
         "0.14083690660796455",
         "0.12595870534303635",
         "0.16866048213263782",
         "0.17643630944577401",
         "0.16827528120571594",
         "0.1811156779772619",
         "0.18257398771871963",
         "0.1562951246120348",
         "-0.0",
         "-0.05554582852296663",
         "0.09224492132353651",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-6.961414938122774",
         "0.15897832564299305",
         "0.17791442261115167",
         "0.1367079150466899",
         "0.16979492278818697",
         "0.18239816767642136",
         "0.18011980383690745",
         "0.16130695201403036",
         "0.21513380712934524",
         "0.22494441885072836",
         "0.21465667138603967",
         "0.2308407280385107",
         "0.23267865285691994",
         "0.1995441238718069",
         "-0.0",
         "-0.07269368043045409",
         "0.11893935019836484",
         "0.0008247679437351692",
         "-0.0",
         "-0.0"
        ],
        [
         "-6.728830585295094",
         "0.2028756896026843",
         "0.2267744097109401",
         "0.17478708913831587",
         "0.21652599039472975",
         "0.23237664028312505",
         "0.22954728605349278",
         "0.2057472587508304",
         "0.27357891178240634",
         "0.2859563346297601",
         "0.27299139754131574",
         "0.29338337989473234",
         "0.29569912818056865",
         "0.2539287156000584",
         "-0.0",
         "-0.09430692610551063",
         "0.15256194405308404",
         "0.0036689876587601335",
         "-0.0",
         "-0.0"
        ],
        [
         "-6.496246232467412",
         "0.2580467686811564",
         "0.2882099940574421",
         "0.22262441106881542",
         "0.27527355969409456",
         "0.29519104939836405",
         "0.2916931430081778",
         "0.2615645377548661",
         "0.3470154117999191",
         "0.362630508663565",
         "0.3462971286943414",
         "0.37198135545237104",
         "0.3748980297379812",
         "0.32225416432347836",
         "-0.0",
         "-0.12154031383882972",
         "0.1948905698714683",
         "0.007248117671350793",
         "-0.0",
         "-0.0"
        ],
        [
         "-6.26366187963973",
         "0.3273146038824291",
         "0.36538650635392933",
         "0.2826505810367557",
         "0.34905547736409787",
         "0.37405593064006104",
         "0.36975696993752466",
         "0.3315867917937351",
         "0.4391870596746734",
         "0.45888561914546944",
         "0.4383169885334586",
         "0.4706516568041762",
         "0.47432343126274024",
         "0.4079965121239681",
         "-0.0013714792737646337",
         "-0.1558424815401702",
         "0.24814779611362078",
         "0.011748956751379169",
         "-0.0",
         "-0.0"
        ],
        [
         "-6.031077526812051",
         "0.41416775297446945",
         "0.4622252166046504",
         "0.35786194728546367",
         "0.4416064413924259",
         "0.47294389283232197",
         "0.46770126255026545",
         "0.4192960598339658",
         "0.5547137692765228",
         "0.5795618757907395",
         "0.5536730218476699",
         "0.5943560100476953",
         "0.5989755931851493",
         "0.5154421008460637",
         "-0.004071092840645963",
         "-0.1990280626314884",
         "0.3151051372344957",
         "0.017403788464276856",
         "-0.0",
         "-0.0"
        ],
        [
         "-5.798493173984366",
         "0.5228930753897719",
         "0.5835602377327616",
         "0.4519288024482426",
         "0.5575243931906738",
         "0.5967370815686616",
         "0.5904090725996614",
         "0.5289512948615689",
         "0.699262730282087",
         "0.7306037650452101",
         "0.6980396296107424",
         "0.7491882388337696",
         "0.7549959157054285",
         "0.649843806897509",
         "-0.007301594421468952",
         "-0.253365928508279",
         "0.3992081422317314",
         "0.024500340666261278",
         "-0.0",
         "-0.0"
        ],
        [
         "-5.565908821156687",
         "0.658720159546654",
         "0.7353136200007405",
         "0.5693095551202348",
         "0.7024319584770411",
         "0.7513920707239029",
         "0.7438599100929788",
         "0.665717352783935",
         "0.8797329441576568",
         "0.9192591263688041",
         "0.8783314904245701",
         "0.9425782547325829",
         "0.9498727369290985",
         "0.8175880406368873",
         "-0.011102012767806544",
         "-0.32168634646332683",
         "0.5047242482886298",
         "0.03339350254465508",
         "-0.0",
         "-0.0"
        ],
        [
         "-5.333324468329005",
         "0.827974411688069",
         "0.9246869518052283",
         "0.715363627026721",
         "0.8831498508911736",
         "0.9441125115297816",
         "0.9353188285692422",
         "0.835787418487818",
         "1.1044406337730428",
         "1.1542827166930942",
         "1.1028938032939852",
         "1.1835005047586382",
         "1.1926515039042802",
         "1.0263592435247488",
         "-0.015465427945755915",
         "-0.4075097666213686",
         "0.6369146301764856",
         "0.04452637631431682",
         "-0.0024103324648855613",
         "-0.0"
        ],
        [
         "-5.100740115501322",
         "1.038208090205807",
         "1.1603431898200813",
         "0.8964464133157594",
         "1.1078585481606071",
         "1.1835048554522376",
         "1.173521461179303",
         "1.046486390565135",
         "1.3832870229121181",
         "1.446126482990478",
         "1.3816813333583642",
         "1.4826695776053165",
         "1.494132914273094",
         "1.2852862349692382",
         "-0.0203005640417076",
         "-0.5151996339874122",
         "0.8022254286634007",
         "0.05842829129089376",
         "-0.005899399702656962",
         "-0.0"
        ],
        [
         "-4.868155762673643",
         "1.298307909723676",
         "1.4525770375472147",
         "1.1199600409427113",
         "1.386238854937906",
         "1.47970018932976",
         "1.4688381362602128",
         "1.3063129888238858",
         "1.7278683230066363",
         "1.8070775437613111",
         "1.7263808268569596",
         "1.8526812107839121",
         "1.8670155584883668",
         "1.605026400442687",
         "-0.02536573053826971",
         "-0.6501407869856479",
         "1.0084988430602715",
         "0.07574021917660013",
         "-0.01042710193126952",
         "0.0"
        ],
        [
         "-4.6355714098459595",
         "1.6185223709703425",
         "1.813423364512975",
         "1.3943216107355028",
         "1.7295438411427826",
         "1.8443906037950357",
         "1.8333765682007646",
         "1.6248831627953533",
         "2.1514786857756065",
         "2.2512956735317253",
         "2.150435032148963",
         "2.3080505889982454",
         "2.3259358879838565",
         "1.997742751908644",
         "-0.030169070553391016",
         "-0.8189433966518956",
         "1.265189860568691",
         "0.09722663380998907",
         "-0.01633812848096696",
         "0.0"
        ],
        [
         "-4.402987057018279",
         "2.0103583850230957",
         "2.256657363274147",
         "1.7287936140448186",
         "2.150552058213091",
         "2.290720769137889",
         "2.280972270098432",
         "2.0127081187987566",
         "2.668930481583819",
         "2.794676077481541",
         "2.6688938201127947",
         "2.865071295874871",
         "2.887328151355271",
         "2.4768985799189034",
         "-0.0338188998431168",
         "-1.029669919234003",
         "1.5835729950429278",
         "0.12378366005988051",
         "-0.024108879070743397",
         "0.0"
        ],
        [
         "-4.1704027041905976",
         "2.486283297392939",
         "2.7976292172625716",
         "2.1331289784395575",
         "2.6633494335450196",
         "2.8329701706675774",
         "2.8269998141600925",
         "2.4807283176675905",
         "3.29609635795571",
         "3.454442842628059",
         "3.298012296497764",
         "3.5414021845303285",
         "3.569011425953556",
         "3.0567786111436726",
         "-0.034916052086216134",
         "-1.2920785165455149",
         "1.9769065073026566",
         "0.1564344020198369",
         "-0.034412485252945255",
         "0.008282965691620906"
        ],
        [
         "-3.9378183513629157",
         "3.0591060998094104",
         "3.452812306159906",
         "2.6168629493608027",
         "3.282789730349279",
         "3.485870031512955",
         "3.487911605483814",
         "3.0395031070207947",
         "4.049064769308014",
         "4.248368937881567",
         "4.054450361939848",
         "4.355259717076696",
         "4.389379974625682",
         "3.751620463337119",
         "-0.03109751713316397",
         "-1.6178733954237194",
         "2.4605450848012365",
         "0.1963240093647273",
         "-0.04819062459715232",
         "0.02372700893231525"
        ],
        [
         "-3.7052339985352356",
         "3.740997880654964",
         "4.239037259140093",
         "3.188290812492019",
         "4.0236397971125895",
         "4.263544559240597",
         "4.280434755425204",
         "3.697987100461161",
         "4.942810022161813",
         "5.193522642866529",
         "4.954038553916901",
         "5.324134881537589",
         "5.366117385479602",
         "4.57427108164162",
         "-0.018762978285599453",
         "-2.0209437135556017",
         "3.0519255673843584",
         "0.24468003817396514",
         "-0.06678259614109755",
         "0.04821724061095901"
        ],
        [
         "-3.472649645707554",
         "4.542016717977915",
         "5.172284668394637",
         "3.8529516934654913",
         "4.899242574348874",
         "5.177916859328326",
         "5.220345158700276",
         "4.4618389222120145",
         "5.98932334496635",
         "6.30449207928952",
         "6.010003060624909",
         "6.462963209908293",
         "6.514363534224525",
         "5.534301251355167",
         "-0.0",
         "-2.517570718660972",
         "3.7704201512323543",
         "0.30276001279740117",
         "-0.09207901579421124",
         "0.08622840827298493"
        ],
        [
         "-3.240065292879872",
         "5.468248915137522",
         "6.266161143635605",
         "4.61182043016842",
         "5.91986707506998",
         "6.236741230063645",
         "6.320868694719747",
         "5.331340075939642",
         "7.1952752040635914",
         "7.591159794487062",
         "7.230795899721042",
         "7.781848548096359",
         "7.844433959645194",
         "6.635644069419959",
         "0.03525813826438026",
         "-3.1265704436395625",
         "4.636988128099238",
         "0.3717344297572494",
         "-0.12679666250424584",
         "0.14360424583020998"
        ],
        [
         "-3.00748094005219",
         "6.519602129198747",
         "7.530105138803029",
         "5.459245016946557",
         "7.090767698439064",
         "7.441324028355986",
         "7.590792729670133",
         "6.299108765517479",
         "8.559427773667236",
         "9.056250945008026",
         "8.617714440577796",
         "9.283556445078172",
         "9.359312335775735",
         "7.873954827818596",
         "0.11405651548390626",
         "-3.8693367165907055",
         "5.67363771576559",
         "0.45252780903377826",
         "-0.17484900450764368",
         "0.2272743853376826"
        ],
        [
         "-2.7748965872245104",
         "7.6871983760061715",
         "8.967283650402486",
         "6.380449503000258",
         "8.409788924401042",
         "8.783882469604091",
         "9.0324506597735",
         "7.347936605910434",
         "10.07022969993337",
         "10.693094961767088",
         "10.162546956011198",
         "10.96115325920554",
         "11.05230971010362",
         "9.234076178855371",
         "0.23703208225265243",
         "-4.769752503689516",
         "6.902850583296467",
         "0.5457570643636623",
         "-0.24158731479801357",
         "0.34668990656682813"
        ],
        [
         "-2.5423122343968285",
         "8.951479025817266",
         "10.57330135681144",
         "7.350109445541907",
         "9.865905354469376",
         "10.245889431372861",
         "10.640227152481598",
         "8.449396404901362",
         "11.704268167111982",
         "12.484278907618698",
         "11.846345638328",
         "12.796648516487052",
         "12.905734999009567",
         "10.688270882190904",
         "0.4197730443486387",
         "-5.853877938967304",
         "8.346778407375416",
         "0.6515315867254474",
         "-0.33438406437889284",
         "0.5122171523704248"
        ],
        [
         "-2.3097278815691467",
         "10.280858477067897",
         "12.335579442296774",
         "8.331548974974705",
         "11.438309995169249",
         "11.797211442238858",
         "12.39982487078959",
         "9.563655889989194",
         "13.426199417538866",
         "14.401825559747584",
         "13.63956230016147",
         "14.761138704938372",
         "14.89110532425667",
         "12.195755336533603",
         "0.6798741469016517",
         "-7.149343989798067",
         "10.026501112592554",
         "0.7694334052081938",
         "-0.46304697836915754",
         "0.7344777917516774"
        ],
        [
         "-2.077143528741465",
         "11.631667414175917",
         "14.234151172293597",
         "9.277448459544729",
         "13.09688703485342",
         "13.396888178472418",
         "14.288774469512116",
         "10.640891390512339",
         "15.190619792018936",
         "16.40937128569812",
         "15.50420738421828",
         "16.817012441590823",
         "16.971461380599912",
         "13.70397306333004",
         "1.0355278756616348",
         "-8.684302231210479",
         "11.961261128894298",
         "0.8986671225555665",
         "-0.6401479992389179",
         "1.0226951978758645"
        ],
        [
         "-1.8445591759137852",
         "12.94948847701062",
         "16.244011259816336",
         "10.132176539393507",
         "14.804191620175969",
         "14.995708147331912",
         "16.278295447154516",
         "11.624231508858365",
         "16.9458603791164",
         "18.466339810621164",
         "17.39801800171359",
         "18.922191636593027",
         "19.105767645398476",
         "15.151540455455574",
         "1.5034275692297738",
         "-10.485751634347716",
         "14.167603732049477",
         "1.0385132900780014",
         "-0.8810737399456982",
         "1.3823939550981494"
        ],
        [
         "-1.611974823086103",
         "14.171728680957559",
         "18.338885099897027",
         "10.83559483424066",
         "16.518759897047897",
         "16.54035423112385",
         "18.336254931842966",
         "12.453651384518183",
         "18.639043185047957",
         "20.53346523063943",
         "19.280029947124394",
         "21.035765257092663",
         "21.25476292872797",
         "16.472237003766363",
         "2.0962417313687256",
         "-12.577056944535341",
         "16.65821817150085",
         "1.1891677382915051",
         "-1.203631301995762",
         "1.8127020208717564"
        ],
        [
         "-1.3793904702584214",
         "15.230787137976675",
         "20.495831646448043",
         "11.327783463022431",
         "18.199170559797537",
         "17.97847342505096",
         "20.430657224552615",
         "13.069874382797703",
         "20.221314656154753",
         "22.578596229557675",
         "21.116499845299494",
         "23.12390075955955",
         "23.38712442746754",
         "17.598969086913296",
         "2.820173425514612",
         "-14.974561792948261",
         "19.440228246329",
         "1.352966292465248",
         "-1.6270868709013389",
         "2.303750551443936"
        ],
        [
         "-1.1468061174307396",
         "16.057014678522034",
         "22.69992448157005",
         "11.553989489042362",
         "19.808071461669137",
         "19.263792858536128",
         "22.53296707627475",
         "13.417306286541375",
         "21.652022145688367",
         "24.58156341897926",
         "22.885946894875367",
         "25.164802544368516",
         "25.48468624759022",
         "18.466591302978234",
         "3.6732972117758065",
         "-17.68342481502696",
         "22.512768961796475",
         "1.535841848807117",
         "-2.170639196539953",
         "2.8348491110757457"
        ],
        [
         "-0.9142217646030576",
         "16.580614974033303",
         "24.948225355840297",
         "11.469120623819178",
         "21.315400142478072",
         "20.360452364338233",
         "24.620727836475265",
         "13.445385920594127",
         "22.900959795456235",
         "26.537262380636932",
         "24.582372966713013",
         "27.151850989674344",
         "27.545763801191764",
         "19.0128360189237",
         "4.645340636017917",
         "-20.693173087983308",
         "25.863958368403544",
         "1.7486965299970956",
         "-2.8514875433928335",
         "3.374119438509219"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 100
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League[N]</th>\n",
       "      <th>Division[W]</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>NewLeague[N]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative log(lambda)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-12.310855</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-12.078271</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-11.845686</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-11.613102</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-11.380518</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.784658</th>\n",
       "      <td>-290.837766</td>\n",
       "      <td>336.954891</td>\n",
       "      <td>37.331027</td>\n",
       "      <td>-59.763826</td>\n",
       "      <td>-26.514159</td>\n",
       "      <td>134.861012</td>\n",
       "      <td>-17.217903</td>\n",
       "      <td>-387.718709</td>\n",
       "      <td>89.421403</td>\n",
       "      <td>-12.315389</td>\n",
       "      <td>476.163294</td>\n",
       "      <td>257.338575</td>\n",
       "      <td>-213.144917</td>\n",
       "      <td>31.257042</td>\n",
       "      <td>-58.457540</td>\n",
       "      <td>78.761611</td>\n",
       "      <td>53.621261</td>\n",
       "      <td>-22.207105</td>\n",
       "      <td>-12.401324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.017243</th>\n",
       "      <td>-290.890547</td>\n",
       "      <td>337.134052</td>\n",
       "      <td>37.438128</td>\n",
       "      <td>-59.929261</td>\n",
       "      <td>-26.612677</td>\n",
       "      <td>134.904695</td>\n",
       "      <td>-17.109579</td>\n",
       "      <td>-388.410292</td>\n",
       "      <td>88.875452</td>\n",
       "      <td>-12.695293</td>\n",
       "      <td>477.099683</td>\n",
       "      <td>258.021642</td>\n",
       "      <td>-213.297335</td>\n",
       "      <td>31.255466</td>\n",
       "      <td>-58.448598</td>\n",
       "      <td>78.761524</td>\n",
       "      <td>53.644409</td>\n",
       "      <td>-22.197696</td>\n",
       "      <td>-12.390685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.249827</th>\n",
       "      <td>-290.932551</td>\n",
       "      <td>337.276951</td>\n",
       "      <td>37.523513</td>\n",
       "      <td>-60.061230</td>\n",
       "      <td>-26.691212</td>\n",
       "      <td>134.939492</td>\n",
       "      <td>-17.023535</td>\n",
       "      <td>-388.957478</td>\n",
       "      <td>88.435079</td>\n",
       "      <td>-12.999054</td>\n",
       "      <td>477.847159</td>\n",
       "      <td>258.567478</td>\n",
       "      <td>-213.419091</td>\n",
       "      <td>31.254166</td>\n",
       "      <td>-58.441482</td>\n",
       "      <td>78.761463</td>\n",
       "      <td>53.662732</td>\n",
       "      <td>-22.190172</td>\n",
       "      <td>-12.382160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.482412</th>\n",
       "      <td>-290.965955</td>\n",
       "      <td>337.390785</td>\n",
       "      <td>37.591502</td>\n",
       "      <td>-60.166365</td>\n",
       "      <td>-26.753744</td>\n",
       "      <td>134.967183</td>\n",
       "      <td>-16.955223</td>\n",
       "      <td>-389.390510</td>\n",
       "      <td>88.081133</td>\n",
       "      <td>-13.241497</td>\n",
       "      <td>478.442971</td>\n",
       "      <td>259.002924</td>\n",
       "      <td>-213.516199</td>\n",
       "      <td>31.253102</td>\n",
       "      <td>-58.435825</td>\n",
       "      <td>78.761420</td>\n",
       "      <td>53.677236</td>\n",
       "      <td>-22.184166</td>\n",
       "      <td>-12.375344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.714996</th>\n",
       "      <td>-290.992504</td>\n",
       "      <td>337.481373</td>\n",
       "      <td>37.645587</td>\n",
       "      <td>-60.250034</td>\n",
       "      <td>-26.803485</td>\n",
       "      <td>134.989200</td>\n",
       "      <td>-16.901009</td>\n",
       "      <td>-389.733277</td>\n",
       "      <td>87.797466</td>\n",
       "      <td>-13.434724</td>\n",
       "      <td>478.917338</td>\n",
       "      <td>259.349840</td>\n",
       "      <td>-213.593552</td>\n",
       "      <td>31.252239</td>\n",
       "      <td>-58.431329</td>\n",
       "      <td>78.761389</td>\n",
       "      <td>53.688721</td>\n",
       "      <td>-22.179378</td>\n",
       "      <td>-12.369904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           AtBat        Hits      HmRun       Runs        RBI  \\\n",
       "negative log(lambda)                                                            \n",
       "-12.310855              0.000000    0.000000   0.000000   0.000000   0.000000   \n",
       "-12.078271              0.000000    0.000000   0.000000   0.000000   0.000000   \n",
       "-11.845686              0.000000    0.000000   0.000000   0.000000   0.000000   \n",
       "-11.613102              0.000000    0.000000   0.000000   0.000000   0.000000   \n",
       "-11.380518              0.000000    0.000000   0.000000   0.000000   0.000000   \n",
       "...                          ...         ...        ...        ...        ...   \n",
       " 9.784658            -290.837766  336.954891  37.331027 -59.763826 -26.514159   \n",
       " 10.017243           -290.890547  337.134052  37.438128 -59.929261 -26.612677   \n",
       " 10.249827           -290.932551  337.276951  37.523513 -60.061230 -26.691212   \n",
       " 10.482412           -290.965955  337.390785  37.591502 -60.166365 -26.753744   \n",
       " 10.714996           -290.992504  337.481373  37.645587 -60.250034 -26.803485   \n",
       "\n",
       "                           Walks      Years      CAtBat      CHits     CHmRun  \\\n",
       "negative log(lambda)                                                            \n",
       "-12.310855              0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "-12.078271              0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "-11.845686              0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "-11.613102              0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "-11.380518              0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "...                          ...        ...         ...        ...        ...   \n",
       " 9.784658             134.861012 -17.217903 -387.718709  89.421403 -12.315389   \n",
       " 10.017243            134.904695 -17.109579 -388.410292  88.875452 -12.695293   \n",
       " 10.249827            134.939492 -17.023535 -388.957478  88.435079 -12.999054   \n",
       " 10.482412            134.967183 -16.955223 -389.390510  88.081133 -13.241497   \n",
       " 10.714996            134.989200 -16.901009 -389.733277  87.797466 -13.434724   \n",
       "\n",
       "                           CRuns        CRBI      CWalks  League[N]  \\\n",
       "negative log(lambda)                                                  \n",
       "-12.310855              0.000000    0.000000    0.000000   0.000000   \n",
       "-12.078271              0.000000    0.000000    0.000000   0.000000   \n",
       "-11.845686              0.000000    0.000000    0.000000   0.000000   \n",
       "-11.613102              0.000000    0.000000    0.000000   0.000000   \n",
       "-11.380518              0.000000    0.000000    0.000000   0.000000   \n",
       "...                          ...         ...         ...        ...   \n",
       " 9.784658             476.163294  257.338575 -213.144917  31.257042   \n",
       " 10.017243            477.099683  258.021642 -213.297335  31.255466   \n",
       " 10.249827            477.847159  258.567478 -213.419091  31.254166   \n",
       " 10.482412            478.442971  259.002924 -213.516199  31.253102   \n",
       " 10.714996            478.917338  259.349840 -213.593552  31.252239   \n",
       "\n",
       "                      Division[W]    PutOuts    Assists     Errors  \\\n",
       "negative log(lambda)                                                 \n",
       "-12.310855               0.000000   0.000000   0.000000   0.000000   \n",
       "-12.078271               0.000000   0.000000   0.000000   0.000000   \n",
       "-11.845686               0.000000   0.000000   0.000000   0.000000   \n",
       "-11.613102               0.000000   0.000000   0.000000   0.000000   \n",
       "-11.380518               0.000000   0.000000   0.000000   0.000000   \n",
       "...                           ...        ...        ...        ...   \n",
       " 9.784658              -58.457540  78.761611  53.621261 -22.207105   \n",
       " 10.017243             -58.448598  78.761524  53.644409 -22.197696   \n",
       " 10.249827             -58.441482  78.761463  53.662732 -22.190172   \n",
       " 10.482412             -58.435825  78.761420  53.677236 -22.184166   \n",
       " 10.714996             -58.431329  78.761389  53.688721 -22.179378   \n",
       "\n",
       "                      NewLeague[N]  \n",
       "negative log(lambda)                \n",
       "-12.310855                0.000000  \n",
       "-12.078271                0.000000  \n",
       "-11.845686                0.000000  \n",
       "-11.613102                0.000000  \n",
       "-11.380518                0.000000  \n",
       "...                            ...  \n",
       " 9.784658               -12.401324  \n",
       " 10.017243              -12.390685  \n",
       " 10.249827              -12.382160  \n",
       " 10.482412              -12.375344  \n",
       " 10.714996              -12.369904  \n",
       "\n",
       "[100 rows x 19 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soln_path = pd.DataFrame(soln_array.T,\n",
    "                         columns=D.columns,\n",
    "                         index=-np.log(lambdas))\n",
    "soln_path.index.name = 'negative log(lambda)'\n",
    "soln_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9c70aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_fig, ax = subplots(figsize=(8,8))\n",
    "soln_path.plot(ax=ax, legend=False)\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Standardized coefficients', fontsize=20)\n",
    "ax.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b0729ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25.53538897200662,\n",
       " AtBat           5.468249\n",
       " Hits            6.266161\n",
       " HmRun           4.611820\n",
       " Runs            5.919867\n",
       " RBI             6.236741\n",
       " Walks           6.320869\n",
       " Years           5.331340\n",
       " CAtBat          7.195275\n",
       " CHits           7.591160\n",
       " CHmRun          7.230796\n",
       " CRuns           7.781849\n",
       " CRBI            7.844434\n",
       " CWalks          6.635644\n",
       " League[N]       0.035258\n",
       " Division[W]    -3.126570\n",
       " PutOuts         4.636988\n",
       " Assists         0.371734\n",
       " Errors         -0.126797\n",
       " NewLeague[N]    0.143604\n",
       " Name: -3.240065292879872, dtype: float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_hat = soln_path.loc[soln_path.index[39]]\n",
    "lambdas[39], beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "802b6ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.331320564843033"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12b90141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24374766133488554, 160.90961591542953)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_hat = soln_path.loc[soln_path.index[59]]\n",
    "lambdas[59], np.linalg.norm(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5432442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.446e+07, tolerance: 5.332e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;ridge&#x27;, ElasticNet(alpha=0.24374766133488554, l1_ratio=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=steps,-list%20of%20tuples\">\n",
       "            steps\n",
       "            <span class=\"param-doc-description\">steps: list of tuples<br><br>List of (name of step, estimator) tuples that are to be chained in<br>sequential order. To be compatible with the scikit-learn API, all steps<br>must define `fit`. All non-last steps must also define `transform`. See<br>:ref:`Combining Estimators <combining_estimators>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">[(&#x27;scaler&#x27;, ...), (&#x27;ridge&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=transform_input,-list%20of%20str%2C%20default%3DNone\">\n",
       "            transform_input\n",
       "            <span class=\"param-doc-description\">transform_input: list of str, default=None<br><br>The names of the :term:`metadata` parameters that should be transformed by the<br>pipeline before passing it to the step consuming it.<br><br>This enables transforming some input arguments to ``fit`` (other than ``X``)<br>to be transformed by the steps of the pipeline up to the step which requires<br>them. Requirement is defined via :ref:`metadata routing <metadata_routing>`.<br>For instance, this can be used to pass a validation set through the pipeline.<br><br>You can only set this if metadata routing is enabled, which you<br>can enable using ``sklearn.set_config(enable_metadata_routing=True)``.<br><br>.. versionadded:: 1.6</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=memory,-str%20or%20object%20with%20the%20joblib.Memory%20interface%2C%20default%3DNone\">\n",
       "            memory\n",
       "            <span class=\"param-doc-description\">memory: str or object with the joblib.Memory interface, default=None<br><br>Used to cache the fitted transformers of the pipeline. The last step<br>will never be cached, even if it is a transformer. By default, no<br>caching is performed. If a string is given, it is the path to the<br>caching directory. Enabling caching triggers a clone of the transformers<br>before fitting. Therefore, the transformer instance given to the<br>pipeline cannot be inspected directly. Use the attribute ``named_steps``<br>or ``steps`` to inspect estimators within the pipeline. Caching the<br>transformers is advantageous when fitting is time consuming. See<br>:ref:`sphx_glr_auto_examples_neighbors_plot_caching_nearest_neighbors.py`<br>for an example on how to enable caching.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>If True, the time elapsed while fitting each step will be printed as it<br>is completed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"scaler__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>If False, try to avoid a copy and do inplace scaling instead.<br>This is not guaranteed to always work inplace; e.g. if the data is<br>not a NumPy array or scipy.sparse CSR matrix, a copy may still be<br>returned.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_mean',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_mean,-bool%2C%20default%3DTrue\">\n",
       "            with_mean\n",
       "            <span class=\"param-doc-description\">with_mean: bool, default=True<br><br>If True, center the data before scaling.<br>This does not work (and will raise an exception) when attempted on<br>sparse matrices, because centering them entails building a dense<br>matrix which in common use cases is likely to be too large to fit in<br>memory.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_std',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_std,-bool%2C%20default%3DTrue\">\n",
       "            with_std\n",
       "            <span class=\"param-doc-description\">with_std: bool, default=True<br><br>If True, scale the data to unit variance (or equivalently,<br>unit standard deviation).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ElasticNet</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"ridge__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=alpha,-float%2C%20default%3D1.0\">\n",
       "            alpha\n",
       "            <span class=\"param-doc-description\">alpha: float, default=1.0<br><br>Constant that multiplies the penalty terms. Defaults to 1.0.<br>See the notes for the exact mathematical meaning of this<br>parameter. ``alpha = 0`` is equivalent to an ordinary least square,<br>solved by the :class:`LinearRegression` object. For numerical<br>reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.<br>Given this, you should use the :class:`LinearRegression` object.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.24374766133488554</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=l1_ratio,-float%2C%20default%3D0.5\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.5<br><br>The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For<br>``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it<br>is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a<br>combination of L1 and L2.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Whether the intercept should be estimated or not. If ``False``, the<br>data is assumed to be already centered.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('precompute',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=precompute,-bool%20or%20array-like%20of%20shape%20%28n_features%2C%20n_features%29%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DFalse\">\n",
       "            precompute\n",
       "            <span class=\"param-doc-description\">precompute: bool or array-like of shape (n_features, n_features),                 default=False<br><br>Whether to use a precomputed Gram matrix to speed up<br>calculations. The Gram matrix can also be passed as argument.<br>For sparse input this option is always ``False`` to preserve sparsity.<br>Check :ref:`an example on how to use a precomputed Gram Matrix in ElasticNet<br><sphx_glr_auto_examples_linear_model_plot_elastic_net_precomputed_gram_matrix_with_weighted_samples.py>`<br>for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=max_iter,-int%2C%20default%3D1000\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=1000<br><br>The maximum number of iterations.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=copy_X,-bool%2C%20default%3DTrue\">\n",
       "            copy_X\n",
       "            <span class=\"param-doc-description\">copy_X: bool, default=True<br><br>If ``True``, X will be copied; else, it may be overwritten.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>The tolerance for the optimization: if the updates are smaller or equal to<br>``tol``, the optimization code checks the dual gap for optimality and continues<br>until it is smaller or equal to ``tol``, see Notes below.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>See :term:`the Glossary <warm_start>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=positive,-bool%2C%20default%3DFalse\">\n",
       "            positive\n",
       "            <span class=\"param-doc-description\">positive: bool, default=False<br><br>When set to ``True``, forces the coefficients to be positive.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>The seed of the pseudo random number generator that selects a random<br>feature to update. Used when ``selection`` == 'random'.<br>Pass an int for reproducible output across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('selection',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=selection,-%7B%27cyclic%27%2C%20%27random%27%7D%2C%20default%3D%27cyclic%27\">\n",
       "            selection\n",
       "            <span class=\"param-doc-description\">selection: {'cyclic', 'random'}, default='cyclic'<br><br>If set to 'random', a random coefficient is updated every iteration<br>rather than looping over features sequentially by default. This<br>(setting to 'random') often leads to significantly faster convergence<br>especially when tol is higher than 1e-4.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;cyclic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('ridge', ElasticNet(alpha=0.24374766133488554, l1_ratio=0))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = skl.ElasticNet(alpha=lambdas[59], l1_ratio=0)\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('ridge', ridge)])\n",
    "pipe.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20134d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.4237101772592"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d378ed5",
   "metadata": {},
   "source": [
    "Estimating Test Error of Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48b73d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.486e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([134214.00419204])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = skm.ShuffleSplit(n_splits=1,\n",
    "                              test_size=0.5,\n",
    "                              random_state=0)\n",
    "ridge.alpha = 0.01\n",
    "results = skm.cross_validate(ridge,\n",
    "                             X,\n",
    "                             Y,\n",
    "                             scoring='neg_mean_squared_error',\n",
    "                             cv=validation)\n",
    "-results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1b8baa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([231788.32155285])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.alpha = 1e10\n",
    "results = skm.cross_validate(ridge,\n",
    "                             X,\n",
    "                             Y,\n",
    "                             scoring='neg_mean_squared_error',\n",
    "                             cv=validation)\n",
    "-results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e41d4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.127e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.113e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.107e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.081e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.977e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.744e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.494e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.234e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.968e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.704e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.448e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.204e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.977e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.769e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.581e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.412e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.261e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.127e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.008e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.900e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.803e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.714e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.632e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.554e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.480e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.342e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.276e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.214e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.154e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.097e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.043e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.991e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.943e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.898e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.856e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.817e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.780e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.746e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.715e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.687e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.661e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.637e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.616e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.596e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.579e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.563e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.550e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.538e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.528e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.519e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.512e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.506e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.500e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.496e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.493e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.490e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.488e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.486e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.485e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.483e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.483e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.482e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e+07, tolerance: 5.332e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;ridge&#x27;, ElasticNet(alpha=0.005899006046740856, l1_ratio=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=steps,-list%20of%20tuples\">\n",
       "            steps\n",
       "            <span class=\"param-doc-description\">steps: list of tuples<br><br>List of (name of step, estimator) tuples that are to be chained in<br>sequential order. To be compatible with the scikit-learn API, all steps<br>must define `fit`. All non-last steps must also define `transform`. See<br>:ref:`Combining Estimators <combining_estimators>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">[(&#x27;scaler&#x27;, ...), (&#x27;ridge&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=transform_input,-list%20of%20str%2C%20default%3DNone\">\n",
       "            transform_input\n",
       "            <span class=\"param-doc-description\">transform_input: list of str, default=None<br><br>The names of the :term:`metadata` parameters that should be transformed by the<br>pipeline before passing it to the step consuming it.<br><br>This enables transforming some input arguments to ``fit`` (other than ``X``)<br>to be transformed by the steps of the pipeline up to the step which requires<br>them. Requirement is defined via :ref:`metadata routing <metadata_routing>`.<br>For instance, this can be used to pass a validation set through the pipeline.<br><br>You can only set this if metadata routing is enabled, which you<br>can enable using ``sklearn.set_config(enable_metadata_routing=True)``.<br><br>.. versionadded:: 1.6</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=memory,-str%20or%20object%20with%20the%20joblib.Memory%20interface%2C%20default%3DNone\">\n",
       "            memory\n",
       "            <span class=\"param-doc-description\">memory: str or object with the joblib.Memory interface, default=None<br><br>Used to cache the fitted transformers of the pipeline. The last step<br>will never be cached, even if it is a transformer. By default, no<br>caching is performed. If a string is given, it is the path to the<br>caching directory. Enabling caching triggers a clone of the transformers<br>before fitting. Therefore, the transformer instance given to the<br>pipeline cannot be inspected directly. Use the attribute ``named_steps``<br>or ``steps`` to inspect estimators within the pipeline. Caching the<br>transformers is advantageous when fitting is time consuming. See<br>:ref:`sphx_glr_auto_examples_neighbors_plot_caching_nearest_neighbors.py`<br>for an example on how to enable caching.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>If True, the time elapsed while fitting each step will be printed as it<br>is completed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"scaler__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>If False, try to avoid a copy and do inplace scaling instead.<br>This is not guaranteed to always work inplace; e.g. if the data is<br>not a NumPy array or scipy.sparse CSR matrix, a copy may still be<br>returned.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_mean',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_mean,-bool%2C%20default%3DTrue\">\n",
       "            with_mean\n",
       "            <span class=\"param-doc-description\">with_mean: bool, default=True<br><br>If True, center the data before scaling.<br>This does not work (and will raise an exception) when attempted on<br>sparse matrices, because centering them entails building a dense<br>matrix which in common use cases is likely to be too large to fit in<br>memory.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_std',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_std,-bool%2C%20default%3DTrue\">\n",
       "            with_std\n",
       "            <span class=\"param-doc-description\">with_std: bool, default=True<br><br>If True, scale the data to unit variance (or equivalently,<br>unit standard deviation).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ElasticNet</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"ridge__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=alpha,-float%2C%20default%3D1.0\">\n",
       "            alpha\n",
       "            <span class=\"param-doc-description\">alpha: float, default=1.0<br><br>Constant that multiplies the penalty terms. Defaults to 1.0.<br>See the notes for the exact mathematical meaning of this<br>parameter. ``alpha = 0`` is equivalent to an ordinary least square,<br>solved by the :class:`LinearRegression` object. For numerical<br>reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.<br>Given this, you should use the :class:`LinearRegression` object.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.005899006046740856</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=l1_ratio,-float%2C%20default%3D0.5\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.5<br><br>The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For<br>``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it<br>is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a<br>combination of L1 and L2.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Whether the intercept should be estimated or not. If ``False``, the<br>data is assumed to be already centered.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('precompute',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=precompute,-bool%20or%20array-like%20of%20shape%20%28n_features%2C%20n_features%29%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DFalse\">\n",
       "            precompute\n",
       "            <span class=\"param-doc-description\">precompute: bool or array-like of shape (n_features, n_features),                 default=False<br><br>Whether to use a precomputed Gram matrix to speed up<br>calculations. The Gram matrix can also be passed as argument.<br>For sparse input this option is always ``False`` to preserve sparsity.<br>Check :ref:`an example on how to use a precomputed Gram Matrix in ElasticNet<br><sphx_glr_auto_examples_linear_model_plot_elastic_net_precomputed_gram_matrix_with_weighted_samples.py>`<br>for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=max_iter,-int%2C%20default%3D1000\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=1000<br><br>The maximum number of iterations.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=copy_X,-bool%2C%20default%3DTrue\">\n",
       "            copy_X\n",
       "            <span class=\"param-doc-description\">copy_X: bool, default=True<br><br>If ``True``, X will be copied; else, it may be overwritten.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>The tolerance for the optimization: if the updates are smaller or equal to<br>``tol``, the optimization code checks the dual gap for optimality and continues<br>until it is smaller or equal to ``tol``, see Notes below.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>See :term:`the Glossary <warm_start>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=positive,-bool%2C%20default%3DFalse\">\n",
       "            positive\n",
       "            <span class=\"param-doc-description\">positive: bool, default=False<br><br>When set to ``True``, forces the coefficients to be positive.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>The seed of the pseudo random number generator that selects a random<br>feature to update. Used when ``selection`` == 'random'.<br>Pass an int for reproducible output across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('selection',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=selection,-%7B%27cyclic%27%2C%20%27random%27%7D%2C%20default%3D%27cyclic%27\">\n",
       "            selection\n",
       "            <span class=\"param-doc-description\">selection: {'cyclic', 'random'}, default='cyclic'<br><br>If set to 'random', a random coefficient is updated every iteration<br>rather than looping over features sequentially by default. This<br>(setting to 'random') often leads to significantly faster convergence<br>especially when tol is higher than 1e-4.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;cyclic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-2');</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('ridge', ElasticNet(alpha=0.005899006046740856, l1_ratio=0))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'ridge__alpha': lambdas}\n",
    "grid = skm.GridSearchCV(pipe,\n",
    "                        param_grid,\n",
    "                        cv=validation,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid.fit(X, Y)\n",
    "grid.best_params_['ridge__alpha']\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "175eba9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.230e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.219e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.097e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.229e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.219e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.096e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.875e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.095e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.211e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.225e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.872e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.212e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.870e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.210e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.867e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.200e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.864e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.203e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.196e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.077e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.208e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.197e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.190e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.855e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.071e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.191e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.849e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.063e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.841e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.054e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.163e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.043e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.149e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.820e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.806e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.012e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.139e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.789e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.992e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.117e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.087e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.968e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.081e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.058e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.745e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.939e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.060e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.051e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.718e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.907e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.686e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.869e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.975e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.939e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.938e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.929e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.783e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.568e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.734e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.834e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.826e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.772e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.684e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.770e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.478e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.633e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.721e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.713e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.646e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.655e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.520e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.494e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.404e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.403e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.177e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.098e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.126e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.110e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.982e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.804e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.894e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.713e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.808e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.627e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.727e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.548e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.650e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.474e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.579e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.406e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.514e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.343e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.454e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.286e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.402e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.234e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.355e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.969e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.187e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.314e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.966e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.914e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.145e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.279e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.865e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.249e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.843e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.824e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.075e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.223e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.790e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.790e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.047e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.202e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.743e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.761e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.022e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.184e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.700e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.990e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.737e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.000e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.169e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.663e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.971e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.717e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.982e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.156e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.630e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.956e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.701e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.966e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.146e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.601e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.943e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.688e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.953e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.138e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.575e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.933e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.677e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.942e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.132e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.554e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.924e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.668e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.933e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.126e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.535e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.917e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.661e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.122e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.520e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.911e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.655e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.920e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.119e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.507e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.906e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.651e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.915e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.116e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.496e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.647e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.911e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.114e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.487e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.899e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.644e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.907e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.112e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.480e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.897e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.642e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.905e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.111e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.474e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.895e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.640e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.903e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.110e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.469e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.893e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.639e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.901e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.109e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.465e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.892e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.638e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.900e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.462e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.891e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.637e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.899e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.460e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.636e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.898e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.107e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.458e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.636e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.897e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.107e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.456e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.889e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.635e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.897e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+07, tolerance: 5.332e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-3.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-3.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;ridge&#x27;, ElasticNet(alpha=0.01185247763144249, l1_ratio=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=steps,-list%20of%20tuples\">\n",
       "            steps\n",
       "            <span class=\"param-doc-description\">steps: list of tuples<br><br>List of (name of step, estimator) tuples that are to be chained in<br>sequential order. To be compatible with the scikit-learn API, all steps<br>must define `fit`. All non-last steps must also define `transform`. See<br>:ref:`Combining Estimators <combining_estimators>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">[(&#x27;scaler&#x27;, ...), (&#x27;ridge&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=transform_input,-list%20of%20str%2C%20default%3DNone\">\n",
       "            transform_input\n",
       "            <span class=\"param-doc-description\">transform_input: list of str, default=None<br><br>The names of the :term:`metadata` parameters that should be transformed by the<br>pipeline before passing it to the step consuming it.<br><br>This enables transforming some input arguments to ``fit`` (other than ``X``)<br>to be transformed by the steps of the pipeline up to the step which requires<br>them. Requirement is defined via :ref:`metadata routing <metadata_routing>`.<br>For instance, this can be used to pass a validation set through the pipeline.<br><br>You can only set this if metadata routing is enabled, which you<br>can enable using ``sklearn.set_config(enable_metadata_routing=True)``.<br><br>.. versionadded:: 1.6</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=memory,-str%20or%20object%20with%20the%20joblib.Memory%20interface%2C%20default%3DNone\">\n",
       "            memory\n",
       "            <span class=\"param-doc-description\">memory: str or object with the joblib.Memory interface, default=None<br><br>Used to cache the fitted transformers of the pipeline. The last step<br>will never be cached, even if it is a transformer. By default, no<br>caching is performed. If a string is given, it is the path to the<br>caching directory. Enabling caching triggers a clone of the transformers<br>before fitting. Therefore, the transformer instance given to the<br>pipeline cannot be inspected directly. Use the attribute ``named_steps``<br>or ``steps`` to inspect estimators within the pipeline. Caching the<br>transformers is advantageous when fitting is time consuming. See<br>:ref:`sphx_glr_auto_examples_neighbors_plot_caching_nearest_neighbors.py`<br>for an example on how to enable caching.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>If True, the time elapsed while fitting each step will be printed as it<br>is completed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"scaler__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>If False, try to avoid a copy and do inplace scaling instead.<br>This is not guaranteed to always work inplace; e.g. if the data is<br>not a NumPy array or scipy.sparse CSR matrix, a copy may still be<br>returned.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_mean',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_mean,-bool%2C%20default%3DTrue\">\n",
       "            with_mean\n",
       "            <span class=\"param-doc-description\">with_mean: bool, default=True<br><br>If True, center the data before scaling.<br>This does not work (and will raise an exception) when attempted on<br>sparse matrices, because centering them entails building a dense<br>matrix which in common use cases is likely to be too large to fit in<br>memory.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_std',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_std,-bool%2C%20default%3DTrue\">\n",
       "            with_std\n",
       "            <span class=\"param-doc-description\">with_std: bool, default=True<br><br>If True, scale the data to unit variance (or equivalently,<br>unit standard deviation).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ElasticNet</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"ridge__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=alpha,-float%2C%20default%3D1.0\">\n",
       "            alpha\n",
       "            <span class=\"param-doc-description\">alpha: float, default=1.0<br><br>Constant that multiplies the penalty terms. Defaults to 1.0.<br>See the notes for the exact mathematical meaning of this<br>parameter. ``alpha = 0`` is equivalent to an ordinary least square,<br>solved by the :class:`LinearRegression` object. For numerical<br>reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.<br>Given this, you should use the :class:`LinearRegression` object.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.01185247763144249</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=l1_ratio,-float%2C%20default%3D0.5\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.5<br><br>The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For<br>``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it<br>is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a<br>combination of L1 and L2.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Whether the intercept should be estimated or not. If ``False``, the<br>data is assumed to be already centered.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('precompute',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=precompute,-bool%20or%20array-like%20of%20shape%20%28n_features%2C%20n_features%29%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DFalse\">\n",
       "            precompute\n",
       "            <span class=\"param-doc-description\">precompute: bool or array-like of shape (n_features, n_features),                 default=False<br><br>Whether to use a precomputed Gram matrix to speed up<br>calculations. The Gram matrix can also be passed as argument.<br>For sparse input this option is always ``False`` to preserve sparsity.<br>Check :ref:`an example on how to use a precomputed Gram Matrix in ElasticNet<br><sphx_glr_auto_examples_linear_model_plot_elastic_net_precomputed_gram_matrix_with_weighted_samples.py>`<br>for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=max_iter,-int%2C%20default%3D1000\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=1000<br><br>The maximum number of iterations.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=copy_X,-bool%2C%20default%3DTrue\">\n",
       "            copy_X\n",
       "            <span class=\"param-doc-description\">copy_X: bool, default=True<br><br>If ``True``, X will be copied; else, it may be overwritten.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>The tolerance for the optimization: if the updates are smaller or equal to<br>``tol``, the optimization code checks the dual gap for optimality and continues<br>until it is smaller or equal to ``tol``, see Notes below.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>See :term:`the Glossary <warm_start>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=positive,-bool%2C%20default%3DFalse\">\n",
       "            positive\n",
       "            <span class=\"param-doc-description\">positive: bool, default=False<br><br>When set to ``True``, forces the coefficients to be positive.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>The seed of the pseudo random number generator that selects a random<br>feature to update. Used when ``selection`` == 'random'.<br>Pass an int for reproducible output across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('selection',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=selection,-%7B%27cyclic%27%2C%20%27random%27%7D%2C%20default%3D%27cyclic%27\">\n",
       "            selection\n",
       "            <span class=\"param-doc-description\">selection: {'cyclic', 'random'}, default='cyclic'<br><br>If set to 'random', a random coefficient is updated every iteration<br>rather than looping over features sequentially by default. This<br>(setting to 'random') often leads to significantly faster convergence<br>especially when tol is higher than 1e-4.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;cyclic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-3');</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('ridge', ElasticNet(alpha=0.01185247763144249, l1_ratio=0))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = skm.GridSearchCV(pipe,\n",
    "                        param_grid,\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid.fit(X, Y)\n",
    "grid.best_params_['ridge__alpha']\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01e2d1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ridge_fig, ax = subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(lambdas),\n",
    "            -grid.cv_results_['mean_test_score'],\n",
    "            yerr=grid.cv_results_['std_test_score'] / np.sqrt(K))\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d93be681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.230e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.219e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.097e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.229e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.219e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.096e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.875e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.095e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.211e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.225e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.872e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.212e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.870e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.210e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.867e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.200e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.864e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.203e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.196e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.077e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.208e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.197e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.190e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.855e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.071e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.191e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.849e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.063e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.841e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.054e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.163e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.043e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.149e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.820e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.806e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.012e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.139e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.789e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.992e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.117e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.087e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.968e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.081e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.058e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.745e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.939e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.060e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.051e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.718e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.907e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.686e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.869e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.975e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.939e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.938e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.929e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.783e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.568e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.734e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.834e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.826e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.772e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.684e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.770e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.478e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.633e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.721e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.713e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.646e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.655e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.520e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.494e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.404e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.403e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.177e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.098e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.126e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.110e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.982e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.804e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.894e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.713e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.808e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.627e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.727e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.548e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.650e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.474e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.579e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.406e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.514e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.343e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.454e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.286e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.402e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.234e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.355e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.969e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.187e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.314e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.966e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.914e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.145e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.279e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.865e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.249e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.843e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.824e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.075e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.223e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.790e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.790e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.047e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.202e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.743e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.761e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.022e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.184e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.700e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.990e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.737e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.000e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.169e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.663e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.971e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.717e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.982e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.156e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.630e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.956e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.701e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.966e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.146e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.601e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.943e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.688e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.953e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.138e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.575e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.933e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.677e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.942e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.132e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.554e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.924e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.668e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.933e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.126e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.535e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.917e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.661e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.122e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.520e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.911e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.655e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.920e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.119e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.507e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.906e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.651e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.915e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.116e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.496e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.647e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.911e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.114e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.487e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.899e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.644e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.907e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.112e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.480e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.897e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.642e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.905e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.111e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.474e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.895e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.640e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.903e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.110e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.469e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.893e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.639e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.901e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.109e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.465e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.892e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.638e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.900e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.462e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.891e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.637e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.899e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.460e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.636e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.898e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.107e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.458e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.636e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.897e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.107e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.456e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.889e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.635e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.897e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+07, tolerance: 5.332e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-4.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-4.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;ridge&#x27;,\n",
       "                                        ElasticNet(alpha=10000000000.0,\n",
       "                                                   l1_ratio=0))]),\n",
       "             param_grid={&#x27;ridge__alpha&#x27;: array([2.22093791e+05, 1.76005531e+05, 1.39481373e+05, 1.10536603e+05,\n",
       "       8.75983676e+04, 6.94202082e+04, 5.50143278e+04, 4.35979140e+04,\n",
       "       3.45506012e+04, 2.73807606...\n",
       "       4.67486141e-03, 3.70474772e-03, 2.93594921e-03, 2.32668954e-03,\n",
       "       1.84386167e-03, 1.46122884e-03, 1.15799887e-03, 9.17694298e-04,\n",
       "       7.27257037e-04, 5.76338765e-04, 4.56738615e-04, 3.61957541e-04,\n",
       "       2.86845161e-04, 2.27319885e-04, 1.80147121e-04, 1.42763513e-04,\n",
       "       1.13137642e-04, 8.96596467e-05, 7.10537367e-05, 5.63088712e-05,\n",
       "       4.46238174e-05, 3.53636122e-05, 2.80250579e-05, 2.22093791e-05])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">Pipeline(step...l1_ratio=0))])</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;ridge__alpha&#x27;: array([2.2209...22093791e-05])}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">KFold(n_split... shuffle=True)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___scaler__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>If False, try to avoid a copy and do inplace scaling instead.<br>This is not guaranteed to always work inplace; e.g. if the data is<br>not a NumPy array or scipy.sparse CSR matrix, a copy may still be<br>returned.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_mean',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_mean,-bool%2C%20default%3DTrue\">\n",
       "            with_mean\n",
       "            <span class=\"param-doc-description\">with_mean: bool, default=True<br><br>If True, center the data before scaling.<br>This does not work (and will raise an exception) when attempted on<br>sparse matrices, because centering them entails building a dense<br>matrix which in common use cases is likely to be too large to fit in<br>memory.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_std',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_std,-bool%2C%20default%3DTrue\">\n",
       "            with_std\n",
       "            <span class=\"param-doc-description\">with_std: bool, default=True<br><br>If True, scale the data to unit variance (or equivalently,<br>unit standard deviation).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ElasticNet</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___ridge__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=alpha,-float%2C%20default%3D1.0\">\n",
       "            alpha\n",
       "            <span class=\"param-doc-description\">alpha: float, default=1.0<br><br>Constant that multiplies the penalty terms. Defaults to 1.0.<br>See the notes for the exact mathematical meaning of this<br>parameter. ``alpha = 0`` is equivalent to an ordinary least square,<br>solved by the :class:`LinearRegression` object. For numerical<br>reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.<br>Given this, you should use the :class:`LinearRegression` object.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.01185247763144249</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=l1_ratio,-float%2C%20default%3D0.5\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.5<br><br>The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For<br>``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it<br>is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a<br>combination of L1 and L2.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Whether the intercept should be estimated or not. If ``False``, the<br>data is assumed to be already centered.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('precompute',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=precompute,-bool%20or%20array-like%20of%20shape%20%28n_features%2C%20n_features%29%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DFalse\">\n",
       "            precompute\n",
       "            <span class=\"param-doc-description\">precompute: bool or array-like of shape (n_features, n_features),                 default=False<br><br>Whether to use a precomputed Gram matrix to speed up<br>calculations. The Gram matrix can also be passed as argument.<br>For sparse input this option is always ``False`` to preserve sparsity.<br>Check :ref:`an example on how to use a precomputed Gram Matrix in ElasticNet<br><sphx_glr_auto_examples_linear_model_plot_elastic_net_precomputed_gram_matrix_with_weighted_samples.py>`<br>for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=max_iter,-int%2C%20default%3D1000\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=1000<br><br>The maximum number of iterations.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=copy_X,-bool%2C%20default%3DTrue\">\n",
       "            copy_X\n",
       "            <span class=\"param-doc-description\">copy_X: bool, default=True<br><br>If ``True``, X will be copied; else, it may be overwritten.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>The tolerance for the optimization: if the updates are smaller or equal to<br>``tol``, the optimization code checks the dual gap for optimality and continues<br>until it is smaller or equal to ``tol``, see Notes below.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>See :term:`the Glossary <warm_start>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=positive,-bool%2C%20default%3DFalse\">\n",
       "            positive\n",
       "            <span class=\"param-doc-description\">positive: bool, default=False<br><br>When set to ``True``, forces the coefficients to be positive.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>The seed of the pseudo random number generator that selects a random<br>feature to update. Used when ``selection`` == 'random'.<br>Pass an int for reproducible output across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('selection',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=selection,-%7B%27cyclic%27%2C%20%27random%27%7D%2C%20default%3D%27cyclic%27\">\n",
       "            selection\n",
       "            <span class=\"param-doc-description\">selection: {'cyclic', 'random'}, default='cyclic'<br><br>If set to 'random', a random coefficient is updated every iteration<br>rather than looping over features sequentially by default. This<br>(setting to 'random') often leads to significantly faster convergence<br>especially when tol is higher than 1e-4.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;cyclic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-4');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('ridge',\n",
       "                                        ElasticNet(alpha=10000000000.0,\n",
       "                                                   l1_ratio=0))]),\n",
       "             param_grid={'ridge__alpha': array([2.22093791e+05, 1.76005531e+05, 1.39481373e+05, 1.10536603e+05,\n",
       "       8.75983676e+04, 6.94202082e+04, 5.50143278e+04, 4.35979140e+04,\n",
       "       3.45506012e+04, 2.73807606...\n",
       "       4.67486141e-03, 3.70474772e-03, 2.93594921e-03, 2.32668954e-03,\n",
       "       1.84386167e-03, 1.46122884e-03, 1.15799887e-03, 9.17694298e-04,\n",
       "       7.27257037e-04, 5.76338765e-04, 4.56738615e-04, 3.61957541e-04,\n",
       "       2.86845161e-04, 2.27319885e-04, 1.80147121e-04, 1.42763513e-04,\n",
       "       1.13137642e-04, 8.96596467e-05, 7.10537367e-05, 5.63088712e-05,\n",
       "       4.46238174e-05, 3.53636122e-05, 2.80250579e-05, 2.22093791e-05])})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_r2 = skm.GridSearchCV(pipe,\n",
    "                           param_grid,\n",
    "                           cv=kfold)\n",
    "grid_r2.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5adb3b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r2_fig, ax = subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(lambdas),\n",
    "            grid_r2.cv_results_['mean_test_score'],\n",
    "            yerr=grid_r2.cv_results_['std_test_score'] / np.sqrt(K)\n",
    "            )\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated $R^2$', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e96be72",
   "metadata": {},
   "source": [
    "Fast Cross-Validation for Solution Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a0418b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.875e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.874e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.872e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.870e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.868e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.865e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.861e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.857e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.851e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.844e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.835e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.824e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.811e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.795e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.776e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.753e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.726e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.696e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.661e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.622e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.491e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.445e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.399e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.314e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.276e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.241e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.210e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.049e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.998e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.908e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.822e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.740e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.662e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.590e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.524e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.464e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.410e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.363e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.321e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.285e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.254e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.228e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.205e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.187e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.171e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.159e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.148e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.140e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.133e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.127e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.123e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.119e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.116e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.114e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.112e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.111e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.110e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.109e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.107e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.107e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.097e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.096e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.095e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.078e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.072e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.064e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.044e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.031e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.014e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.971e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.911e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.875e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.834e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.789e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.741e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.691e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.639e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.589e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.492e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.407e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.104e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.081e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.049e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.040e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.989e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.924e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.864e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.810e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.761e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.716e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.677e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.643e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.612e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.586e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.563e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.543e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.526e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.512e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.501e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.491e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.483e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.476e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.471e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.467e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.463e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.461e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.458e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.457e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.230e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.229e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.225e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.193e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.170e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.155e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.136e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.114e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.088e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.056e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.020e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.933e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.882e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.772e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.714e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.657e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.601e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.548e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.499e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.340e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.309e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.282e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.179e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.163e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.107e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.094e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.988e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.969e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.954e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.942e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.931e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.923e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.915e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.910e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.905e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.901e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.898e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.895e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.893e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.892e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.889e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.889e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.888e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.887e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.219e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.212e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.206e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.196e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.190e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.171e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.144e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.125e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.103e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.076e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.045e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.009e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.967e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.921e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.871e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.817e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.761e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.647e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.592e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.489e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.401e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.363e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.298e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.246e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.026e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.959e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.904e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.858e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.818e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.784e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.756e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.733e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.714e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.698e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.685e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.675e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.666e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.660e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.654e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.650e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.646e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.643e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.641e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.639e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.638e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.637e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.636e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.635e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.635e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.634e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.212e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.211e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.200e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.189e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.147e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.085e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.020e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.980e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.934e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.883e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.826e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.766e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.576e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.514e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.399e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.348e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.301e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.221e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.107e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.023e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.000e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.896e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.799e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.708e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.624e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.545e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.471e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.403e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.340e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.283e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.231e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.184e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.143e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.105e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.073e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.044e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.019e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.998e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.980e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.965e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.952e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.941e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.932e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.924e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.918e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.913e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.909e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.906e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.903e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.901e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.900e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.898e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.897e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.896e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.896e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.895e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+07, tolerance: 5.332e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-5.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-5.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;ridge&#x27;,\n",
       "                 ElasticNetCV(alphas=array([2.22093791e+05, 1.76005531e+05, 1.39481373e+05, 1.10536603e+05,\n",
       "       8.75983676e+04, 6.94202082e+04, 5.50143278e+04, 4.35979140e+04,\n",
       "       3.45506012e+04, 2.73807606e+04, 2.16987845e+04, 1.71959156e+04,\n",
       "       1.36274691e+04, 1.07995362e+04, 8.55844774e+03, 6.78242347e+03,\n",
       "       5.37495461e+03, 4.25955961e+03,...\n",
       "       1.84386167e-03, 1.46122884e-03, 1.15799887e-03, 9.17694298e-04,\n",
       "       7.27257037e-04, 5.76338765e-04, 4.56738615e-04, 3.61957541e-04,\n",
       "       2.86845161e-04, 2.27319885e-04, 1.80147121e-04, 1.42763513e-04,\n",
       "       1.13137642e-04, 8.96596467e-05, 7.10537367e-05, 5.63088712e-05,\n",
       "       4.46238174e-05, 3.53636122e-05, 2.80250579e-05, 2.22093791e-05]),\n",
       "                              cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "                              l1_ratio=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=steps,-list%20of%20tuples\">\n",
       "            steps\n",
       "            <span class=\"param-doc-description\">steps: list of tuples<br><br>List of (name of step, estimator) tuples that are to be chained in<br>sequential order. To be compatible with the scikit-learn API, all steps<br>must define `fit`. All non-last steps must also define `transform`. See<br>:ref:`Combining Estimators <combining_estimators>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">[(&#x27;scaler&#x27;, ...), (&#x27;ridge&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=transform_input,-list%20of%20str%2C%20default%3DNone\">\n",
       "            transform_input\n",
       "            <span class=\"param-doc-description\">transform_input: list of str, default=None<br><br>The names of the :term:`metadata` parameters that should be transformed by the<br>pipeline before passing it to the step consuming it.<br><br>This enables transforming some input arguments to ``fit`` (other than ``X``)<br>to be transformed by the steps of the pipeline up to the step which requires<br>them. Requirement is defined via :ref:`metadata routing <metadata_routing>`.<br>For instance, this can be used to pass a validation set through the pipeline.<br><br>You can only set this if metadata routing is enabled, which you<br>can enable using ``sklearn.set_config(enable_metadata_routing=True)``.<br><br>.. versionadded:: 1.6</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=memory,-str%20or%20object%20with%20the%20joblib.Memory%20interface%2C%20default%3DNone\">\n",
       "            memory\n",
       "            <span class=\"param-doc-description\">memory: str or object with the joblib.Memory interface, default=None<br><br>Used to cache the fitted transformers of the pipeline. The last step<br>will never be cached, even if it is a transformer. By default, no<br>caching is performed. If a string is given, it is the path to the<br>caching directory. Enabling caching triggers a clone of the transformers<br>before fitting. Therefore, the transformer instance given to the<br>pipeline cannot be inspected directly. Use the attribute ``named_steps``<br>or ``steps`` to inspect estimators within the pipeline. Caching the<br>transformers is advantageous when fitting is time consuming. See<br>:ref:`sphx_glr_auto_examples_neighbors_plot_caching_nearest_neighbors.py`<br>for an example on how to enable caching.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>If True, the time elapsed while fitting each step will be printed as it<br>is completed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"scaler__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>If False, try to avoid a copy and do inplace scaling instead.<br>This is not guaranteed to always work inplace; e.g. if the data is<br>not a NumPy array or scipy.sparse CSR matrix, a copy may still be<br>returned.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_mean',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_mean,-bool%2C%20default%3DTrue\">\n",
       "            with_mean\n",
       "            <span class=\"param-doc-description\">with_mean: bool, default=True<br><br>If True, center the data before scaling.<br>This does not work (and will raise an exception) when attempted on<br>sparse matrices, because centering them entails building a dense<br>matrix which in common use cases is likely to be too large to fit in<br>memory.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_std',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_std,-bool%2C%20default%3DTrue\">\n",
       "            with_std\n",
       "            <span class=\"param-doc-description\">with_std: bool, default=True<br><br>If True, scale the data to unit variance (or equivalently,<br>unit standard deviation).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ElasticNetCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html\">?<span>Documentation for ElasticNetCV</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"ridge__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=l1_ratio,-float%20or%20list%20of%20float%2C%20default%3D0.5\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float or list of float, default=0.5<br><br>Float between 0 and 1 passed to ElasticNet (scaling between<br>l1 and l2 penalties). For ``l1_ratio = 0``<br>the penalty is an L2 penalty. For ``l1_ratio = 1`` it is an L1 penalty.<br>For ``0 < l1_ratio < 1``, the penalty is a combination of L1 and L2<br>This parameter can be a list, in which case the different<br>values are tested by cross-validation and the one giving the best<br>prediction score is used. Note that a good choice of list of<br>values for l1_ratio is often to put more values close to 1<br>(i.e. Lasso) and less close to 0 (i.e. Ridge), as in ``[.1, .5, .7,<br>.9, .95, .99, 1]``.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=eps,-float%2C%20default%3D1e-3\">\n",
       "            eps\n",
       "            <span class=\"param-doc-description\">eps: float, default=1e-3<br><br>Length of the path. ``eps=1e-3`` means that<br>``alpha_min / alpha_max = 1e-3``.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_alphas',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=n_alphas,-int%2C%20default%3D100\">\n",
       "            n_alphas\n",
       "            <span class=\"param-doc-description\">n_alphas: int, default=100<br><br>Number of alphas along the regularization path, used for each l1_ratio.<br><br>.. deprecated:: 1.7<br>    `n_alphas` was deprecated in 1.7 and will be removed in 1.9. Use `alphas`<br>    instead.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alphas',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=alphas,-int%2C%20default%3D100\">\n",
       "            alphas\n",
       "            <span class=\"param-doc-description\">alphas: array-like or int, default=None<br><br>Values of alphas to test along the regularization path, used for each l1_ratio.<br>If int, `alphas` values are generated automatically.<br>If array-like, list of alpha values to use.<br><br>.. versionchanged:: 1.7<br>    `alphas` accepts an integer value which removes the need to pass<br>    `n_alphas`.<br><br>.. deprecated:: 1.7<br>    `alphas=None` was deprecated in 1.7 and will be removed in 1.9, at which<br>    point the default value will be set to 100.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">array([2.2209...22093791e-05])</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Whether to calculate the intercept for this model. If set<br>to false, no intercept will be used in calculations<br>(i.e. data is expected to be centered).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('precompute',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=precompute,-%27auto%27%2C%20bool%20or%20array-like%20of%20shape%20%20%20%20%20%20%20%20%20%20%20%20%20%28n_features%2C%20n_features%29%2C%20default%3D%27auto%27\">\n",
       "            precompute\n",
       "            <span class=\"param-doc-description\">precompute: 'auto', bool or array-like of shape             (n_features, n_features), default='auto'<br><br>Whether to use a precomputed Gram matrix to speed up<br>calculations. If set to ``'auto'`` let us decide. The Gram<br>matrix can also be passed as argument.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=max_iter,-int%2C%20default%3D1000\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=1000<br><br>The maximum number of iterations.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>The tolerance for the optimization: if the updates are smaller or equal to<br>``tol``, the optimization code checks the dual gap for optimality and continues<br>until it is smaller or equal to ``tol``.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross-validation,<br>- int, to specify the number of folds.<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For int/None inputs, :class:`~sklearn.model_selection.KFold` is used.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">KFold(n_split... shuffle=True)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=copy_X,-bool%2C%20default%3DTrue\">\n",
       "            copy_X\n",
       "            <span class=\"param-doc-description\">copy_X: bool, default=True<br><br>If ``True``, X will be copied; else, it may be overwritten.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=verbose,-bool%20or%20int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool or int, default=0<br><br>Amount of verbosity.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of CPUs to use during the cross validation.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=positive,-bool%2C%20default%3DFalse\">\n",
       "            positive\n",
       "            <span class=\"param-doc-description\">positive: bool, default=False<br><br>When set to ``True``, forces the coefficients to be positive.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>The seed of the pseudo random number generator that selects a random<br>feature to update. Used when ``selection`` == 'random'.<br>Pass an int for reproducible output across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('selection',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=selection,-%7B%27cyclic%27%2C%20%27random%27%7D%2C%20default%3D%27cyclic%27\">\n",
       "            selection\n",
       "            <span class=\"param-doc-description\">selection: {'cyclic', 'random'}, default='cyclic'<br><br>If set to 'random', a random coefficient is updated every iteration<br>rather than looping over features sequentially by default. This<br>(setting to 'random') often leads to significantly faster convergence<br>especially when tol is higher than 1e-4.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;cyclic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-5');</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('ridge',\n",
       "                 ElasticNetCV(alphas=array([2.22093791e+05, 1.76005531e+05, 1.39481373e+05, 1.10536603e+05,\n",
       "       8.75983676e+04, 6.94202082e+04, 5.50143278e+04, 4.35979140e+04,\n",
       "       3.45506012e+04, 2.73807606e+04, 2.16987845e+04, 1.71959156e+04,\n",
       "       1.36274691e+04, 1.07995362e+04, 8.55844774e+03, 6.78242347e+03,\n",
       "       5.37495461e+03, 4.25955961e+03,...\n",
       "       1.84386167e-03, 1.46122884e-03, 1.15799887e-03, 9.17694298e-04,\n",
       "       7.27257037e-04, 5.76338765e-04, 4.56738615e-04, 3.61957541e-04,\n",
       "       2.86845161e-04, 2.27319885e-04, 1.80147121e-04, 1.42763513e-04,\n",
       "       1.13137642e-04, 8.96596467e-05, 7.10537367e-05, 5.63088712e-05,\n",
       "       4.46238174e-05, 3.53636122e-05, 2.80250579e-05, 2.22093791e-05]),\n",
       "                              cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "                              l1_ratio=0))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgeCV = skl.ElasticNetCV(alphas=lambdas,\n",
    "                           l1_ratio=0,\n",
    "                           cv=kfold)\n",
    "pipeCV = Pipeline(steps=[('scaler', scaler),\n",
    "                         ('ridge', ridgeCV)])\n",
    "pipeCV.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "939b1bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuned_ridge = pipeCV.named_steps['ridge']\n",
    "ridgeCV_fig, ax = subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(lambdas),\n",
    "            tuned_ridge.mse_path_.mean(1),\n",
    "            yerr=tuned_ridge.mse_path_.std(1) / np.sqrt(K))\n",
    "ax.axvline(-np.log(tuned_ridge.alpha_), c='k', ls='--')\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "217f0bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115526.70630987742"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(tuned_ridge.mse_path_.mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a12dab02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-222.80877051,  238.77246614,    3.21103754,   -2.93050845,\n",
       "          3.64888723,  108.90953869,  -50.81896152, -105.15731984,\n",
       "        122.00714801,   57.1859509 ,  210.35170348,  118.05683748,\n",
       "       -150.21959435,   30.36634231,  -61.62459095,   77.73832472,\n",
       "         40.07350744,  -25.02151514,  -13.68429544])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_ridge.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09223eb8",
   "metadata": {},
   "source": [
    "Evaluating Test Error of Cross-Validated Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf132e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_valid = skm.ShuffleSplit(n_splits=1,\n",
    "                               test_size=0.25,\n",
    "                               random_state=1)\n",
    "inner_cv = skm.KFold(n_splits=5,\n",
    "                     shuffle=True,\n",
    "                     random_state=2)\n",
    "ridgeCV = skl.ElasticNetCV(alphas=lambdas,\n",
    "                           l1_ratio=0,\n",
    "                           cv=inner_cv)\n",
    "pipeCV = Pipeline(steps=[('scaler', scaler),\n",
    "                         ('ridge', ridgeCV)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fae7e65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.596e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.595e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.594e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.592e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.590e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.587e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.579e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.574e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.568e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.550e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.507e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.487e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.464e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.407e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.339e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.302e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.885e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.687e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.507e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.341e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.189e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.046e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.912e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.783e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.659e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.536e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.415e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.295e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.176e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.059e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.944e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.833e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.726e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.625e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.530e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.442e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.361e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.287e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.221e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.161e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.107e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.059e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.016e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.979e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.945e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.916e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.891e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.869e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.849e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.833e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.819e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.807e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.798e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.790e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.783e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.777e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.773e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.769e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.767e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.764e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.762e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.761e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.516e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.516e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.516e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.515e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.515e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.514e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.513e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.512e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.511e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.509e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.507e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.501e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.497e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.491e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.477e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.467e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.441e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.223e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.113e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.870e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.617e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.388e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.183e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.999e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.835e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.687e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.554e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.432e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.320e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.215e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.116e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.020e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.928e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.837e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.749e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.664e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.581e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.427e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.357e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.293e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.235e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.183e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.137e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.097e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.062e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.031e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.005e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.982e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.962e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.946e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.931e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.919e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.909e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.900e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.893e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.887e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.882e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.878e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.874e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.872e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.870e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.868e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.866e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.865e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.864e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.864e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.863e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.596e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.595e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.594e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.593e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.591e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.588e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.585e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.577e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.571e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.564e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.555e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.544e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.515e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.495e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.473e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.267e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.103e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.066e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.750e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.505e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.287e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.093e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.920e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.766e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.627e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.503e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.389e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.286e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.190e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.100e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.016e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.937e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.862e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.790e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.722e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.658e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.598e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.542e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.491e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.445e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.405e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.368e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.337e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.309e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.285e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.264e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.246e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.231e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.217e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.205e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.195e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.186e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.179e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.172e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.167e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.162e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.158e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.155e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.152e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.150e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.148e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.147e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.146e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.145e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.144e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.143e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.375e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.375e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.375e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.373e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.372e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.369e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.367e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.365e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.358e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.340e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.320e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.307e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.173e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.075e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.042e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.778e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.486e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.217e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.972e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.751e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.553e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.377e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.219e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.079e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.953e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.839e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.735e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.639e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.550e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.465e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.384e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.306e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.232e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.160e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.090e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.024e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.962e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.903e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.848e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.798e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.752e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.712e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.645e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.618e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.595e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.575e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.559e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.545e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.534e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.525e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.517e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.511e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.505e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.501e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.498e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.495e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.492e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.491e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.489e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.488e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.487e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.486e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.486e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.485e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.485e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.484e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.610e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.609e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.609e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.608e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.605e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.603e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.601e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.594e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.589e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.583e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.576e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.567e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.556e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.542e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.525e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.505e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.340e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.245e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.848e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.380e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.947e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.550e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.188e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.861e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.564e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.296e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.052e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.831e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.628e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.441e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.270e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.111e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.964e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.829e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.703e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.588e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.481e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.384e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.295e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.215e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.142e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.077e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.020e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.924e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.885e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.851e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.822e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.797e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.775e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.756e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.740e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.725e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.713e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.702e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.693e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.684e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.677e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.672e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.667e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.662e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.659e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.656e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.654e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.652e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.650e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.649e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.648e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.647e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.647e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 3.855e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([132393.84003227])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = skm.cross_validate(pipeCV,\n",
    "                             X,\n",
    "                             Y,\n",
    "                             cv=outer_valid,\n",
    "                             scoring='neg_mean_squared_error')\n",
    "-results['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396090d7",
   "metadata": {},
   "source": [
    "The Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "540db925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1663: FutureWarning: 'n_alphas' was deprecated in 1.7 and will be removed in 1.9. 'alphas' now accepts an integer value which removes the need to pass 'n_alphas'. The default value of 'alphas' will change from None to 100 in 1.9. Pass an explicit value to 'alphas' and leave 'n_alphas' to its default value to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1472370031649866"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassoCV = skl.ElasticNetCV(n_alphas=100,\n",
    "                           l1_ratio=1,\n",
    "                           cv=kfold)\n",
    "pipeCV = Pipeline(steps=[('scaler', scaler),\n",
    "                         ('lasso', lassoCV)])\n",
    "pipeCV.fit(X, Y)\n",
    "tuned_lasso = pipeCV.named_steps['lasso']\n",
    "tuned_lasso.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea590f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas, soln_array = skl.Lasso.path(Xs,\n",
    "                                     Y,\n",
    "                                     l1_ratio=1,\n",
    "                                     n_alphas=100)[:2]\n",
    "soln_path = pd.DataFrame(soln_array.T,\n",
    "                         columns=D.columns,\n",
    "                         index=-np.log(lambdas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79733176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_fig, ax = subplots(figsize=(8,8))\n",
    "soln_path.plot(ax=ax, legend=False)\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Standardized coefficiients', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a6fe960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114690.73118253506"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(tuned_lasso.mse_path_.mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7fcfa72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lassoCV_fig, ax = subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(tuned_lasso.alphas_),\n",
    "            tuned_lasso.mse_path_.mean(1),\n",
    "            yerr=tuned_lasso.mse_path_.std(1) / np.sqrt(K))\n",
    "ax.axvline(-np.log(tuned_lasso.alpha_), c='k', ls='--')\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "547516f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-210.01008773,  243.4550306 ,    0.        ,    0.        ,\n",
       "          0.        ,   97.69397357,  -41.52283116,   -0.        ,\n",
       "          0.        ,   39.62298193,  205.75273856,  124.55456561,\n",
       "       -126.29986768,   15.70262427,  -59.50157967,   75.24590036,\n",
       "         21.62698014,  -12.04423675,   -0.        ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c3a9a3",
   "metadata": {},
   "source": [
    "##### PCR and PLS Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f7437f",
   "metadata": {},
   "source": [
    "Principal Components Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f63ae11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09846131, 0.4758765 ])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "linreg = skl.LinearRegression()\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('linreg', linreg)])\n",
    "pipe.fit(X, Y)\n",
    "pipe.named_steps['linreg'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec8ffd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([106.36859204,  21.60350456])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('scaler', scaler),\n",
    "                 ('pca', pca),\n",
    "                 ('linreg', linreg)])\n",
    "pipe.fit(X, Y)\n",
    "pipe.named_steps['linreg'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87aec2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-6.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-6.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;pca&#x27;, PCA(n_components=2)),\n",
       "                                       (&#x27;linreg&#x27;, LinearRegression())]),\n",
       "             param_grid={&#x27;pca__n_components&#x27;: range(1, 20)},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">Pipeline(step...egression())])</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;pca__n_components&#x27;: range(1, 20)}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;neg_mean_squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">KFold(n_split... shuffle=True)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___scaler__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>If False, try to avoid a copy and do inplace scaling instead.<br>This is not guaranteed to always work inplace; e.g. if the data is<br>not a NumPy array or scipy.sparse CSR matrix, a copy may still be<br>returned.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_mean',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_mean,-bool%2C%20default%3DTrue\">\n",
       "            with_mean\n",
       "            <span class=\"param-doc-description\">with_mean: bool, default=True<br><br>If True, center the data before scaling.<br>This does not work (and will raise an exception) when attempted on<br>sparse matrices, because centering them entails building a dense<br>matrix which in common use cases is likely to be too large to fit in<br>memory.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_std',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_std,-bool%2C%20default%3DTrue\">\n",
       "            with_std\n",
       "            <span class=\"param-doc-description\">with_std: bool, default=True<br><br>If True, scale the data to unit variance (or equivalently,<br>unit standard deviation).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>PCA</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___pca__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_components',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=n_components,-int%2C%20float%20or%20%27mle%27%2C%20default%3DNone\">\n",
       "            n_components\n",
       "            <span class=\"param-doc-description\">n_components: int, float or 'mle', default=None<br><br>Number of components to keep.<br>if n_components is not set all components are kept::<br><br>    n_components == min(n_samples, n_features)<br><br>If ``n_components == 'mle'`` and ``svd_solver == 'full'``, Minka's<br>MLE is used to guess the dimension. Use of ``n_components == 'mle'``<br>will interpret ``svd_solver == 'auto'`` as ``svd_solver == 'full'``.<br><br>If ``0 < n_components < 1`` and ``svd_solver == 'full'``, select the<br>number of components such that the amount of variance that needs to be<br>explained is greater than the percentage specified by n_components.<br><br>If ``svd_solver == 'arpack'``, the number of components must be<br>strictly less than the minimum of n_features and n_samples.<br><br>Hence, the None case results in::<br><br>    n_components == min(n_samples, n_features) - 1</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">17</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>If False, data passed to fit are overwritten and running<br>fit(X).transform(X) will not yield the expected results,<br>use fit_transform(X) instead.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('whiten',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=whiten,-bool%2C%20default%3DFalse\">\n",
       "            whiten\n",
       "            <span class=\"param-doc-description\">whiten: bool, default=False<br><br>When True (False by default) the `components_` vectors are multiplied<br>by the square root of n_samples and then divided by the singular values<br>to ensure uncorrelated outputs with unit component-wise variances.<br><br>Whitening will remove some information from the transformed signal<br>(the relative variance scales of the components) but can sometime<br>improve the predictive accuracy of the downstream estimators by<br>making their data respect some hard-wired assumptions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('svd_solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=svd_solver,-%7B%27auto%27%2C%20%27full%27%2C%20%27covariance_eigh%27%2C%20%27arpack%27%2C%20%27randomized%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27auto%27\">\n",
       "            svd_solver\n",
       "            <span class=\"param-doc-description\">svd_solver: {'auto', 'full', 'covariance_eigh', 'arpack', 'randomized'},            default='auto'<br><br>\"auto\" :<br>    The solver is selected by a default 'auto' policy is based on `X.shape` and<br>    `n_components`: if the input data has fewer than 1000 features and<br>    more than 10 times as many samples, then the \"covariance_eigh\"<br>    solver is used. Otherwise, if the input data is larger than 500x500<br>    and the number of components to extract is lower than 80% of the<br>    smallest dimension of the data, then the more efficient<br>    \"randomized\" method is selected. Otherwise the exact \"full\" SVD is<br>    computed and optionally truncated afterwards.<br>\"full\" :<br>    Run exact full SVD calling the standard LAPACK solver via<br>    `scipy.linalg.svd` and select the components by postprocessing<br>\"covariance_eigh\" :<br>    Precompute the covariance matrix (on centered data), run a<br>    classical eigenvalue decomposition on the covariance matrix<br>    typically using LAPACK and select the components by postprocessing.<br>    This solver is very efficient for n_samples >> n_features and small<br>    n_features. It is, however, not tractable otherwise for large<br>    n_features (large memory footprint required to materialize the<br>    covariance matrix). Also note that compared to the \"full\" solver,<br>    this solver effectively doubles the condition number and is<br>    therefore less numerical stable (e.g. on input data with a large<br>    range of singular values).<br>\"arpack\" :<br>    Run SVD truncated to `n_components` calling ARPACK solver via<br>    `scipy.sparse.linalg.svds`. It requires strictly<br>    `0 < n_components < min(X.shape)`<br>\"randomized\" :<br>    Run randomized SVD by the method of Halko et al.<br><br>.. versionadded:: 0.18.0<br><br>.. versionchanged:: 1.5<br>    Added the 'covariance_eigh' solver.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=tol,-float%2C%20default%3D0.0\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=0.0<br><br>Tolerance for singular values computed by svd_solver == 'arpack'.<br>Must be of range [0.0, infinity).<br><br>.. versionadded:: 0.18.0</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('iterated_power',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=iterated_power,-int%20or%20%27auto%27%2C%20default%3D%27auto%27\">\n",
       "            iterated_power\n",
       "            <span class=\"param-doc-description\">iterated_power: int or 'auto', default='auto'<br><br>Number of iterations for the power method computed by<br>svd_solver == 'randomized'.<br>Must be of range [0, infinity).<br><br>.. versionadded:: 0.18.0</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_oversamples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=n_oversamples,-int%2C%20default%3D10\">\n",
       "            n_oversamples\n",
       "            <span class=\"param-doc-description\">n_oversamples: int, default=10<br><br>This parameter is only relevant when `svd_solver=\"randomized\"`.<br>It corresponds to the additional number of random vectors to sample the<br>range of `X` so as to ensure proper conditioning. See<br>:func:`~sklearn.utils.extmath.randomized_svd` for more details.<br><br>.. versionadded:: 1.1</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('power_iteration_normalizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=power_iteration_normalizer,-%7B%27auto%27%2C%20%27QR%27%2C%20%27LU%27%2C%20%27none%27%7D%2C%20default%3D%27auto%27\">\n",
       "            power_iteration_normalizer\n",
       "            <span class=\"param-doc-description\">power_iteration_normalizer: {'auto', 'QR', 'LU', 'none'}, default='auto'<br><br>Power iteration normalizer for randomized SVD solver.<br>Not used by ARPACK. See :func:`~sklearn.utils.extmath.randomized_svd`<br>for more details.<br><br>.. versionadded:: 1.1</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Used when the 'arpack' or 'randomized' solvers are used. Pass an int<br>for reproducible results across multiple function calls.<br>See :term:`Glossary <random_state>`.<br><br>.. versionadded:: 0.18.0</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___linreg__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Whether to calculate the intercept for this model. If set<br>to False, no intercept will be used in calculations<br>(i.e. data is expected to be centered).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=copy_X,-bool%2C%20default%3DTrue\">\n",
       "            copy_X\n",
       "            <span class=\"param-doc-description\">copy_X: bool, default=True<br><br>If True, X will be copied; else, it may be overwritten.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=tol,-float%2C%20default%3D1e-6\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-6<br><br>The precision of the solution (`coef_`) is determined by `tol` which<br>specifies a different convergence criterion for the `lsqr` solver.<br>`tol` is set as `atol` and `btol` of :func:`scipy.sparse.linalg.lsqr` when<br>fitting on sparse training data. This parameter has no effect when fitting<br>on dense data.<br><br>.. versionadded:: 1.7</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to use for the computation. This will only provide<br>speedup in case of sufficiently large problems, that is if firstly<br>`n_targets > 1` and secondly `X` is sparse or if `positive` is set<br>to `True`. ``None`` means 1 unless in a<br>:obj:`joblib.parallel_backend` context. ``-1`` means using all<br>processors. See :term:`Glossary <n_jobs>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=positive,-bool%2C%20default%3DFalse\">\n",
       "            positive\n",
       "            <span class=\"param-doc-description\">positive: bool, default=False<br><br>When set to ``True``, forces the coefficients to be positive. This<br>option is only supported for dense arrays.<br><br>For a comparison between a linear regression model with positive constraints<br>on the regression coefficients and a linear regression without such constraints,<br>see :ref:`sphx_glr_auto_examples_linear_model_plot_nnls.py`.<br><br>.. versionadded:: 0.24</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-6');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('pca', PCA(n_components=2)),\n",
       "                                       ('linreg', LinearRegression())]),\n",
       "             param_grid={'pca__n_components': range(1, 20)},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'pca__n_components': range(1, 20)}\n",
    "grid = skm.GridSearchCV(pipe,\n",
    "                        param_grid,\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "175e707a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pcr_fig, ax = subplots(figsize=(8,8))\n",
    "n_comp = param_grid['pca__n_components']\n",
    "ax.errorbar(n_comp,\n",
    "            -grid.cv_results_['mean_test_score'],\n",
    "            grid.cv_results_['std_test_score'] / np.sqrt(K))\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20)\n",
    "ax.set_xlabel('# principal components', fontsize=20)\n",
    "ax.set_xticks(n_comp[::2])\n",
    "ax.set_ylim([50000,250000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f71399c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204139.30692994667"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xn = np.zeros((X.shape[0], 1))\n",
    "cv_null = skm.cross_validate(linreg,\n",
    "                             Xn,\n",
    "                             Y,\n",
    "                             cv=kfold,\n",
    "                             scoring='neg_mean_squared_error')\n",
    "-cv_null['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1dd3c5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3831424 , 0.21841076])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps['pca'].explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a12e3d",
   "metadata": {},
   "source": [
    "Partial Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "386cb0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-7.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-7.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PLSRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>PLSRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html\">?<span>Documentation for PLSRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_components',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=n_components,-int%2C%20default%3D2\">\n",
       "            n_components\n",
       "            <span class=\"param-doc-description\">n_components: int, default=2<br><br>Number of components to keep. Should be in `[1, n_features]`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=scale,-bool%2C%20default%3DTrue\">\n",
       "            scale\n",
       "            <span class=\"param-doc-description\">scale: bool, default=True<br><br>Whether to scale `X` and `y`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=max_iter,-int%2C%20default%3D500\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=500<br><br>The maximum number of iterations of the power method when<br>`algorithm='nipals'`. Ignored otherwise.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">500</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=tol,-float%2C%20default%3D1e-06\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-06<br><br>The tolerance used as convergence criteria in the power method: the<br>algorithm stops whenever the squared norm of `u_i - u_{i-1}` is less<br>than `tol`, where `u` corresponds to the left singular vector.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>Whether to copy `X` and `y` in :term:`fit` before applying centering,<br>and potentially scaling. If `False`, these operations will be done<br>inplace, modifying both arrays.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-7');</script></body>"
      ],
      "text/plain": [
       "PLSRegression()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pls = PLSRegression(n_components=2,\n",
    "                    scale=True)\n",
    "pls.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a6da065e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-8.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-8.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=PLSRegression(),\n",
       "             param_grid={&#x27;n_components&#x27;: range(1, 20)},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">PLSRegression()</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;n_components&#x27;: range(1, 20)}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;neg_mean_squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">KFold(n_split... shuffle=True)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: PLSRegression</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>PLSRegression(n_components=12)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>PLSRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html\">?<span>Documentation for PLSRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_components',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=n_components,-int%2C%20default%3D2\">\n",
       "            n_components\n",
       "            <span class=\"param-doc-description\">n_components: int, default=2<br><br>Number of components to keep. Should be in `[1, n_features]`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">12</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=scale,-bool%2C%20default%3DTrue\">\n",
       "            scale\n",
       "            <span class=\"param-doc-description\">scale: bool, default=True<br><br>Whether to scale `X` and `y`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=max_iter,-int%2C%20default%3D500\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=500<br><br>The maximum number of iterations of the power method when<br>`algorithm='nipals'`. Ignored otherwise.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">500</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=tol,-float%2C%20default%3D1e-06\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-06<br><br>The tolerance used as convergence criteria in the power method: the<br>algorithm stops whenever the squared norm of `u_i - u_{i-1}` is less<br>than `tol`, where `u` corresponds to the left singular vector.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>Whether to copy `X` and `y` in :term:`fit` before applying centering,<br>and potentially scaling. If `False`, these operations will be done<br>inplace, modifying both arrays.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-8');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=PLSRegression(),\n",
       "             param_grid={'n_components': range(1, 20)},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_components':range(1, 20)}\n",
    "grid = skm.GridSearchCV(pls,\n",
    "                        param_grid,\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "324a2b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pls_fig, ax = subplots(figsize=(8,8))\n",
    "n_comp = param_grid['n_components']\n",
    "ax.errorbar(n_comp,\n",
    "            -grid.cv_results_['mean_test_score'],\n",
    "            grid.cv_results_['std_test_score'] / np.sqrt(K))\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20)\n",
    "ax.set_xlabel('# principal components', fontsize=20)\n",
    "ax.set_xticks(n_comp[::2])\n",
    "ax.set_ylim([50000,250000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ec4278",
   "metadata": {},
   "source": [
    "#### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f309d2d6",
   "metadata": {},
   "source": [
    "$Conceptual$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d10c828",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33fe514d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de4f1358",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e1d74df",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a37d2cfe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c05b7cee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d95e7c6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe9c927d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8c676c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d91eb568",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6590cbae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "facbc3f5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e59dc7a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23257a86",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a06546f",
   "metadata": {},
   "source": [
    "$Applied$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01304c5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab76a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a81bd8d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f3101c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "670d9d32",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df5298f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7b8526f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff48dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "islp_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
