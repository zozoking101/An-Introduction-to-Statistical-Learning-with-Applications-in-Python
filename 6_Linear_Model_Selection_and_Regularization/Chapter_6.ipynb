{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d02f63a",
   "metadata": {},
   "source": [
    "### Linear Model Selection and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee38c5e2",
   "metadata": {},
   "source": [
    "In the regression setting, the standard linear model\n",
    "Y = 0+ 1X1+···+ pXp+\n",
    "(6.1)\n",
    "is commonly used to describe the relationship between a response Y and\n",
    "a set of variables X1,X2,...,Xp. We have seen in Chapter 3 that one\n",
    "typically fits this model using least squares.\n",
    "In the chapters that follow, we consider some approaches for extending\n",
    "the linear model framework. In Chapter 7 we generalize (6.1) in order to\n",
    "accommodate non-linear, but still additive, relationships, while in Chap\n",
    "ters 8 and 10 we consider even more general non-linear models. However,\n",
    "the linear model has distinct advantages in terms of inference and, on real\n",
    "world problems, is often surprisingly competitive in relation to non-linear\n",
    "methods. Hence, before moving to the non-linear world, we discuss in this\n",
    "chapter some ways in which the simple linear model can be improved, by re\n",
    "placing plain least squares fitting with some alternative fitting procedures.\n",
    "Why might we want to use another fitting procedure instead of least\n",
    "squares? As we will see, alternative fitting procedures can yield better pre\n",
    "diction accuracy and model interpretability.\n",
    "\n",
    "• Prediction Accuracy: Provided that the true relationship between the\n",
    "response and the predictors is approximately linear, the least squares\n",
    "estimates will have low bias. If n \n",
    "p—that is, if n, the number of\n",
    "observations, is much larger than p, the number of variables—then the\n",
    "least squares estimates tend to also have low variance, and hence will\n",
    "perform well on test observations. However, if n is not much larger\n",
    "than p, then there can be a lot of variability in the least squares fit,\n",
    "resulting in overfitting and consequently poor predictions on future\n",
    "observations not used in model training. And if p>n, then there is no\n",
    "longer a unique least squares coefficient estimate: there are infinitely many solutions. Each of these least squares solutions gives zero error\n",
    "on the training data, but typically very poor test set performance\n",
    "due to extremely high variance.1 By constraining or shrinking the\n",
    "estimated coefficients, we can often substantially reduce the variance\n",
    "at the cost of a negligible increase in bias. This can lead to substantial\n",
    "improvements in the accuracy with which we can predict the response\n",
    "for observations not used in model training.\n",
    "\n",
    "• Model Interpretability: It is often the case that some or many of the\n",
    "variables used in a multiple regression model are in fact not associ\n",
    "ated with the response. Including such irrelevant variables leads to\n",
    "unnecessary complexity in the resulting model. By removing these\n",
    "variables—that is, by setting the corresponding coefficient estimates\n",
    "to zero—we can obtain a model that is more easily interpreted. Now\n",
    "least squares is extremely unlikely to yield any coefficient estimates\n",
    "that are exactly zero. In this chapter, we see some approaches for au\n",
    "tomatically performing feature selection or variable selection—that is, feature\n",
    "for excluding irrelevant variables from a multiple regression model.\n",
    "\n",
    "There are many alternatives, both classical and modern, to using least\n",
    "squares to fit (6.1). In this chapter, we discuss three important classes of\n",
    "methods.\n",
    "\n",
    "• Subset Selection. This approach involves identifying a subset of the p\n",
    "predictors that we believe to be related to the response. We then fit\n",
    "a model using least squares on the reduced set of variables.\n",
    "\n",
    "• Shrinkage. This approach involves fitting a model involving all p pre\n",
    "dictors. However, the estimated coefficients are shrunken towards zero\n",
    "relative to the least squares estimates. This shrinkage (also known as\n",
    "regularization) has the effect of reducing variance. Depending on what\n",
    "type of shrinkage is performed, some of the coefficients may be esti\n",
    "mated to be exactly zero. Hence, shrinkage methods can also perform\n",
    "variable selection.\n",
    "\n",
    "• Dimension Reduction. This approach involves projecting the p predic\n",
    "tors into an M-dimensional subspace, where M<p.This is achieved\n",
    "by computing M different linear combinations, or projections, of the\n",
    "variables. Then these M projections are used as predictors to fit a\n",
    "linear regression model by least squares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96fdead",
   "metadata": {},
   "source": [
    "#### Subset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9d046b",
   "metadata": {},
   "source": [
    "##### Best Subset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaac9018",
   "metadata": {},
   "source": [
    "To perform *best subset selection*, we fit a separate least squares regression for each of the models of the p predictors. That is, we fit all p models that contain exactly one predictor, all $ \\binom{p}{2} $ models that contain exactly two predictors, and so on. We look at all of the resulting models, with the goal of identifying the one that is the best.\n",
    "\n",
    "The problem of selecting the best model from among the $ 2^p $ possibilities considered by best subset selection is then usually broken up into two stages, as described in Algorithm 6.1.\n",
    "\n",
    "##### **Algorithm 6.1** *Best subset selection*\n",
    "\n",
    "1. Let $ M_0 $ denote the null model, which contains no predictors. This model simply predicts the sample mean for each observation.\n",
    "\n",
    "2. For $ k = 1, 2, \\ldots, p $:\n",
    "\n",
    "   (a) Fit all $ \\binom{p}{k} $ models that contain exactly k predictors.\n",
    "   \n",
    "   (b) Pick the best among these models, and call it $ M_k $. Here “best” is defined as having the smallest RSS, or equivalently $ R^2 $.\n",
    "\n",
    "3. Select a single best model from among $ M_0, \\ldots, M_p $ using the prediction error on a validation set, $ C_p $ (AIC), BIC, or adjusted $ R^2 $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a33b0f1",
   "metadata": {},
   "source": [
    "In Algorithm 6.1, Step 2 identifies the best model (on the training data)\n",
    "for each subset size, in order to reduce the problem from one of 2p possible\n",
    "models to one of p +1possible models. In Figure 6.1, these models form\n",
    "the lower frontier depicted in red.\n",
    "Now in order to select a single best model, we must simply choose among\n",
    "these p +1options. This task must be performed with care, because the\n",
    "RSS of these p +1models decreases monotonically, and the R2 increases\n",
    "monotonically, as the number of features included in the models increases.\n",
    "Therefore, if we use these statistics to select the best model, then we will\n",
    "always end up with a model involving all of the variables. The problem is\n",
    "that a low RSS or a high R2 indicates a model with a low training error,\n",
    "whereas we wish to choose a model that has a low test error. (As shown in\n",
    "Chapter 2 in Figures 2.9–2.11, training error tends to be quite a bit smaller\n",
    "than test error, and a low training error by no means guarantees a low test\n",
    "error.) Therefore, in Step 3, we use the error on a validation set, Cp, BIC, or\n",
    "adjusted R2 in order to select among M0,M1,...,Mp. If cross-validation\n",
    "is used to select the best model, then Step 2 is repeated on each training\n",
    "fold, and the validation errors are averaged to select the best value of k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cd273c",
   "metadata": {},
   "source": [
    "Then the model Mk fit on the full training set is delivered for the chosen\n",
    "k. These approaches are discussed in Section 6.1.3.\n",
    "An application of best subset selection is shown in Figure 6.1. Each\n",
    "plotted point corresponds to a least squares regression model fit using a\n",
    "different subset of the 10 predictors in the Credit data set, discussed in\n",
    "Chapter 3. Here the variable region is a three-level qualitative variable,\n",
    "and so is represented by two dummy variables, which are selected sepa\n",
    "rately in this case. Hence, there are a total of 11 possible variables which\n",
    "can be included in the model. We have plotted the RSS and R2 statistics\n",
    "for each model, as a function of the number of variables. The red curves\n",
    "connect the best models for each model size, according to RSS or R2. The\n",
    "f\n",
    "igure shows that, as expected, these quantities improve as the number of\n",
    "variables increases; however, from the three-variable model on, there is little\n",
    "improvement in RSS and R2 as a result of including additional predictors.\n",
    "Although we have presented best subset selection here for least squares\n",
    "regression, the same ideas apply to other types of models, such as logistic\n",
    "regression. In the case of logistic regression, instead of ordering models by\n",
    "RSS in Step 2 of Algorithm 6.1, we instead use the deviance, a measure deviance\n",
    "that plays the role of RSS for a broader class of models. The deviance is\n",
    "negative two times the maximized log-likelihood; the smaller the deviance,\n",
    "the better the fit.\n",
    "While best subset selection is a simple and conceptually appealing ap\n",
    "proach, it suffers from computational limitations. The number of possible\n",
    "models that must be considered grows rapidly as p increases. In general,\n",
    "there are 2p models that involve subsets of p predictors. So if p = 10,\n",
    "then there are approximately 1,000 possible models to be considered, and if\n",
    "p =20,then there are over one million possibilities! Consequently, best sub\n",
    "set selection becomes computationally infeasible for values of p greater than around 40, even with extremely fast modern computers. There are compu\n",
    "tational shortcuts—so called branch-and-bound techniques—for eliminat\n",
    "ing some choices, but these have their limitations as p gets large. They also\n",
    "only work for least squares linear regression. We present computationally\n",
    "efficient alternatives to best subset selection next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097842b",
   "metadata": {},
   "source": [
    "##### **Algorithm 6.2** *Forward stepwise selection*\n",
    "\n",
    "1. Let $ M_0 $ denote the null model, which contains no predictors.\n",
    "\n",
    "2. For $ k = 0, \\ldots, p - 1 $:\n",
    "\n",
    "   - (a) Consider all $ p - k $ models that augment the predictors in $ M_k $ with one additional predictor.\n",
    "   \n",
    "   - (b) Choose the best among these $ p - k $ models, and call it $ M_{k+1} $. Here best is defined as having the smallest RSS or highest $ R^2 $.\n",
    "\n",
    "3. Select a single best model from among $ M_0, \\ldots, M_p $ using the prediction error on a validation set, $ C_p $ (AIC), BIC, or adjusted $ R^2 $. Or use the cross-validation method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f255d",
   "metadata": {},
   "source": [
    "##### Stepwise Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc158be",
   "metadata": {},
   "source": [
    "For computational reasons, best subset selection cannot be applied with\n",
    "very large p. Best subset selection may also suffer from statistical problems\n",
    "when p is large. The larger the search space, the higher the chance of finding\n",
    "models that look good on the training data, even though they might not\n",
    "have any predictive power on future data. Thus an enormous search space\n",
    "can lead to overfitting and high variance of the coefficient estimates.\n",
    "For both of these reasons, stepwise methods, which explore a far more\n",
    "restricted set of models, are attractive alternatives to best subset selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679aab05",
   "metadata": {},
   "source": [
    "Forward Stepwise Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36191d1",
   "metadata": {},
   "source": [
    "*Forward stepwise selection* is a computationally efficient alternative to best subset selection. While the best subset selection procedure considers all\n",
    "2p possible models containing subsets of the p predictors, forward step\n",
    "wise considers a much smaller set of models. Forward stepwise selection\n",
    "begins with a model containing no predictors, and then adds predictors\n",
    "to the model, one-at-a-time, until all of the predictors are in the model.\n",
    "In particular, at each step the variable that gives the greatest additional\n",
    "improvement to the fit is added to the model. More formally, the forward\n",
    "stepwise selection procedure is given in Algorithm 6.2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a161f3",
   "metadata": {},
   "source": [
    "## 6. Linear Model Selection and Regularization\n",
    "\n",
    "Unlike best subset selection, which involved fitting $ 2^p $ models, forward stepwise selection involves fitting one null model, along with $ p - k $ models in the $ k $-th iteration, for $ k = 0, \\ldots, p - 1 $. This amounts to a total of $ 1 + \\sum_{i=0}^{p-1} (p - i) = 1 + p(p + 1)/2 $ models. This is a substantial difference: when $p$ = 20, best subset selection requires fitting $ 1,048,576 $ models, whereas forward stepwise selection requires fitting only $ 21 $ models. \n",
    "\n",
    "In step 2(b) of Algorithm 6.2, we identify the best model from those available, which augment $ M_k $ with one additional predictor. We do this by simply choosing the model with the lowest RSS or the highest $ R^2 $. In this case, we must identify the best model from a set of models with different numbers of variables. This is more challenging, and is discussed in Section 6.1.3.\n",
    "\n",
    "Forward stepwise selection's computational advantage over best subset selection is clear. Though forward stepwise seems to work well in practice, it is important to keep in mind that it is fundamentally a greedy algorithm. In a data set with $ p $ predictors, the best possible model will include predictors $ X_2 $ and $ X_1 $. However, forward stepwise selection is still unable to find the best possible model among $ M_1, M_2, $ and those available with $ X_1 $ together with an additional variable.\n",
    "\n",
    "As shown in Section 6.1.3, the forward stepwise selection on the Credit data set illustrates this phenomenon. Both forward stepwise selection and best subset selection favored models that included the predictors rating and income, whereas the best subset selection also included the variable student.\n",
    "\n",
    "In high-dimensional settings where $ p $ is greater than $ n $, forward stepwise selection can still be applied even when subset selection cannot. If $ p $ is greater than $ n $, each time an additional variable is included, only the subset of $ M_0, \\ldots, M_k $ can be constructed, which avoids overfitting, as each submodel is fit using least squares, which does not yield a unique solution if $ p > n $.\n",
    "\n",
    "\n",
    "\n",
    "| # Variables | Best subset                      | Forward stepwise                  |\n",
    "|-------------|----------------------------------|-----------------------------------|\n",
    "| One         | `rating`                           | `rating`                            |\n",
    "| Two         | `rating`, `income`                   | `rating`, `income`                    |\n",
    "| Three       | `rating`, `income`, `student`              | `rating`, `income`, `student`               |\n",
    "| Four        | `cards`, `income`, `student`, `limit` | `rating`, `income`, `student`, `limit` |\n",
    "\n",
    "The first four selected models for best subset selection and forward stepwise selection on the Credit data set. The first three models are identical but the fourth models differ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d33c838",
   "metadata": {},
   "source": [
    "Backward Stepwise Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4bc443",
   "metadata": {},
   "source": [
    "Like forward stepwise selection, backward stepwise selection provides an efficient alternative to best subset selection. However, unlike forward step\n",
    "wise selection, it begins with the full least squares model containing all p\n",
    "predictors, and then iteratively removes the least useful predictor, one-at\n",
    "a-time. Details are given in Algorithm 6.3.\n",
    "\n",
    "\n",
    "Like forward stepwise selection, the backward selection approach searches\n",
    "through only 1+p(p+1)/2 models, and so can be applied in settings where\n",
    "p is too large to apply best subset selection.3 Also like forward stepwise\n",
    "selection, backward stepwise selection is not guaranteed to yield the best\n",
    "model containing a subset of the p predictors.\n",
    "Backward selection requires that the number of samples n is larger than\n",
    "the number of variables p (so that the full model can be fit). In contrast,\n",
    "forward stepwise can be used even when n<p, and so is the only viable\n",
    "subset method when p is very large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2df46a",
   "metadata": {},
   "source": [
    "Hybrid Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a7e4e",
   "metadata": {},
   "source": [
    "The best subset, forward stepwise, and backward stepwise selection ap\n",
    "proaches generally give similar but not identical models. As another al\n",
    "ternative, hybrid versions of forward and backward stepwise selection are\n",
    "available, in which variables are added to the model sequentially, in analogy\n",
    "to forward selection. However, after adding each new variable, the method\n",
    "may also remove any variables that no longer provide an improvement in\n",
    "the model fit. Such an approach attempts to more closely mimic best sub\n",
    "set selection while retaining the computational advantages of forward and\n",
    "backward stepwise selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b066da3",
   "metadata": {},
   "source": [
    "##### Choosing the Optimal Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df32254",
   "metadata": {},
   "source": [
    "Best subset selection, forward selection, and backward selection result in\n",
    "the creation of a set of models, each of which contains a subset of the p predictors. To apply these methods, we need a way to determine which of\n",
    "these models is best. As we discussed in Section 6.1.1, the model containing\n",
    "all of the predictors will always have the smallest RSS and the largest R2,\n",
    "since these quantities are related to the training error. Instead, we wish to\n",
    "choose a model with a low test error. As is evident here, and as we show\n",
    "in Chapter 2, the training error can be a poor estimate of the test error.\n",
    "Therefore, RSS and R2 are not suitable for selecting the best model among\n",
    "a collection of models with different numbers of predictors.\n",
    "In order to select the best model with respect to test error, we need to\n",
    "estimate this test error. There are two common approaches:\n",
    "\n",
    "1. We can indirectly estimate test error by making an adjustment to the\n",
    "training error to account for the bias due to overfitting.\n",
    "\n",
    "\n",
    "2. We can directly estimate the test error, using either a validation set\n",
    "approach or a cross-validation approach, as discussed in Chapter 5.\n",
    "\n",
    "We consider both of these approaches below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5f37cc",
   "metadata": {},
   "source": [
    "We show in Chapter 2 that the training set $ R^2 $ is generally an under-estimate of the test MSE. (Recall that MSE = RSS/n.) In training RSS, but when we fit a model to the training data using least squares, we (not the test RSS) is as small as possible, this can sometimes misestimate the regression coefficients in a model. Thus, we need to choose from among a set of models with different variables.\n",
    "\n",
    "However, a number of techniques for adjusting the training error can lead to a set of models with different variables. We introduce the following metrics for model selection criteria: \n",
    "\n",
    "- **Akaike information criterion (AIC)**, \n",
    "- **Bayesian information criterion (BIC)**, and \n",
    "- **Adjusted $ R^2 $**. \n",
    "\n",
    "Figure 6.2 gives a comparison of the best model selection criteria and selects the best subset on the Credit data set.\n",
    "\n",
    "For a fitted least squares model containing $ p $ predictors, the $ C_p $ estimate of test MSE is computed using the equation:\n",
    "\n",
    "$$\n",
    "C_p = \\frac{(RSS + 2d\\hat{\\sigma}^2)}{n}\n",
    "$$\n",
    "\n",
    "where $ \\hat{\\sigma}^2 $ is an estimate of the variance of the error $ \\epsilon $ associated with the regression model in (6.1). Typically $ d $ is chosen to be $ p $ or the number of parameters in the model. The $ C_p $ statistic adds a penalty term involving $ d $ in order to adjust for the number of predictors  in the model increases; this is intended to adjust for the corresponding decrease in training RSS. Based on the scope of this book, one can show that if $ \\hat{\\sigma}^2 $ in (6.2), then $ C_p $ is an unbiased estimate of test MSE. As a consequence, the $ C_p $ statistic tends to take a larger value in the model selected with the lowest $ C_p $ value. In Figure 6.2, C_p selects the six-variable model containing the predictors income, lint, age, and risk.\n",
    "\n",
    "The AIC criterion is defined as follows:\n",
    "$$\n",
    "AIC = \\frac{1}{n} (RSS + 2d\\hat{\\sigma}^2)\n",
    "$$\n",
    "where, for simplicity, we have omitted irrelevant constants. Here for least squares models, AIC and $ C_p $ are proportional to each other, as shown in Figure 6.2.\n",
    "\n",
    "BIC is derived from a Bayesian point of view; it ends up looking similar to $ C_p $ and $ AIC $ for the least squares model but with a different penalty term:\n",
    "$$\n",
    "BIC = \\frac{1}{n} (RSS + \\log(n)d\\hat{\\sigma}^2)\n",
    "$$\n",
    "Like $ C_p $, the BIC also penalizes a more complex model for a loss in precision, and generally we select the model with the lowest BIC. Notice that the BIC penalty includes the $ 2d\\ \\log(n) $ term, where $ n $ is the number of observations. Since $ \\log n > 2 $ for any $ n > 7 $, the BIC statistic generally places a heavier penalty on models with many variables, and hence reveals in the selection of smaller models than $ C_p $. In Figure 6.2, we see that the direct task decider is a single model that contains only the four predictors income, lint, age, and assertion. In this case the chosen model does not appear to make much difference in accuracy between the four-variable and six-variable models.\n",
    "\n",
    "The adjusted $ R^2 $ statistic is another popular approach for selecting among a set of models that contain different numbers of variables. Recall from Chapter 3 that the adjusted $ R^2 $ is defined as follows, where $ RSS = \\sum(y_i - \\hat{y})^2 $ is the total sum of squared response. Since $ RSS $ increases as more variables are added to the model, the $ R^2 $ measure becomes biased toward a larger selected model of variables, the adjusted $ R^2 $ is calculated as\n",
    "\n",
    "$$\n",
    "\\text{Adjusted } R^2 = 1 - \\frac{RSS/(n - d - 1)}{TSS/(n - 1)}\n",
    "$$\n",
    "\n",
    "Unlike $ C_p $ and BIC, for which a small value indicates a model with a low extent error, a large value of adjusted $ R^2 $ indicates a model with a small test error. Additionally, the adjusted $ R^2 $ is equivalent to how much variability is explained by the model. Consequently, the adjusted $ R^2 $ may increase or decrease depending on the fits of new variables added, and one must be cautious of the laws of diminishing returns when adding additional predictors. \n",
    "\n",
    "Nonetheless, the adjusted $ R^2 $ provides a more robust measure than $ C_p $ and BIC in model selection, owing to the fact that the adjusted $ R^2 $ accounts for degrees of freedom in models where fewer predictor variables yield higher estimates; hence, $ AIC $ and BIC can be less robust than the adjusted $ R^2 $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c8d92",
   "metadata": {},
   "source": [
    "Validation and Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856f8235",
   "metadata": {},
   "source": [
    "\n",
    "As an alternative to the approaches just discussed, we can directly esti\n",
    "mate the test error using the validation set and cross-validation methods\n",
    "discussed in Chapter 5. We can compute the validation set error or the\n",
    "cross-validation error for each model under consideration, and then select the model for which the resulting estimated test error is smallest. This pro\n",
    "cedure has an advantage relative to AIC, BIC, Cp, and adjusted R2, in that\n",
    "it provides a direct estimate of the test error, and makes fewer assumptions\n",
    "about the true underlying model. It can also be used in a wider range of\n",
    "model selection tasks, even in cases where it is hard to pinpoint the model\n",
    "degrees of freedom (e.g. the number of predictors in the model) or hard\n",
    "to estimate the error variance 2. Note that when cross-validation is used,\n",
    "the sequence of models Mk in Algorithms 6.1–6.3 is determined separately\n",
    "for each training fold, and the validation errors are averaged over all folds\n",
    "for each model size k. This means, for example with best-subset regression,\n",
    "that Mk, the best subset of size k, can differ across the folds. Once the\n",
    "best size k is chosen, we find the best model of that size on the full data\n",
    "set.\n",
    "In the past, performing cross-validation was computationally prohibitive\n",
    "for many problems with large p and/or large n, and so AIC, BIC, Cp,\n",
    "and adjusted R2 were more attractive approaches for choosing among a\n",
    "set of models. However, nowadays with fast computers, the computations\n",
    "required to perform cross-validation are hardly ever an issue. Thus, cross\n",
    "validation is a very attractive approach for selecting from among a number\n",
    "of models under consideration.\n",
    "Figure 6.3 displays, as a function of d, the BIC, validation set errors, and\n",
    "cross-validation errors on the Credit data, for the best d-variable model.\n",
    "The validation errors were calculated by randomly selecting three-quarters\n",
    "of the observations as the training set, and the remainder as the valida\n",
    "tion set. The cross-validation errors were computed using k = 10 folds.\n",
    "In this case, the validation and cross-validation methods both result in a\n",
    "six-variable model. However, all three approaches suggest that the four-,\n",
    "f\n",
    "ive-, and six-variable models are roughly equivalent in terms of their test\n",
    "errors.\n",
    "In fact, the estimated test error curves displayed in the center and right\n",
    "hand panels of Figure 6.3 are quite flat. While a three-variable model clearly\n",
    "has lower estimated test error than a two-variable model, the estimated test\n",
    "errors of the 3- to 11-variable models are quite similar. Furthermore, if we repeated the validation set approach using a different split of the data into\n",
    "a training set and a validation set, or if we repeated cross-validation using\n",
    "a different set of cross-validation folds, thentheprecisemodelwiththe\n",
    "lowest estimatedtest errorwouldsurelychange. Inthis setting,we can\n",
    "select amodel using theone-standard-error rule.Wefirst calculate the \n",
    "standarderrorof theestimatedtestMSEfor eachmodel size, andthen\n",
    "selectthesmallestmodel forwhichtheestimatedtesterror iswithinone\n",
    "standarderrorofthelowestpointonthecurve.Therationalehereisthat\n",
    "ifasetofmodelsappeartobemoreor lessequallygood, thenwemight\n",
    "aswell choose the simplestmodel—that is, themodelwiththe smallest\n",
    "number of predictors. Inthis case, applying theone-standard-error rule\n",
    "tothevalidationsetorcross-validationapproachleadstoselectionof the\n",
    "three-variablemodel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3c8f6a",
   "metadata": {},
   "source": [
    "#### Shrinkage Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d169a73",
   "metadata": {},
   "source": [
    "The subset selection methods described in Section 6.1 involve using least squares to fit a linear model that contains as many predictors. As an alternative, we can find a model containing all predictors and then calibrate or regularize the coefficient estimates, or equivalently, shrink the estimates toward zero. It may not be immediately obvious why such a constraint should improve the fit, but it turns out that shrinking the coefficients can significantly reduce their variance. The two best-known techniques for shrinking the coefficient estimates towards zero are ridge regression and the lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a861857a",
   "metadata": {},
   "source": [
    "##### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cf6e54",
   "metadata": {},
   "source": [
    "Recall from Chapter 3 that the least squares fitting procedure for $ \\beta_0, \\beta_1, \\ldots, \\beta_p $ using the values that minimize\n",
    "\n",
    "$$\n",
    "RSS = \\sum (y_i - \\beta_0 - \\beta_1 x_{1i} - \\ldots - \\beta_p x_{pi})^2\n",
    "$$\n",
    "\n",
    "Ridge regression is simply a variation of this, where the estimator is determined by minimizing a slightly different quantity. In particular, the ridge regression coefficient estimates $ \\hat{\\beta}_P $ are those that minimize\n",
    "\n",
    "$$\n",
    "RSS + \\lambda \\sum_{j=1}^p \\beta_j^2\n",
    "$$\n",
    "\n",
    "where $ \\lambda > 0 $ is a tuning parameter, to be determined separately. Expressing $ \\lambda $ trades off too much variance in estimates; ridge regression seeks coefficient estimates that fit the data well, by making them smaller. The second term, $ \\lambda \\sum_{j=1}^p \\beta_j^2 $, penalizes large values of the coefficients, thus shrinking the estimates of $ \\beta_j $ towards zero. The tuning parameter $ \\lambda $ serves to control the relative impact of these two terms on the regression coefficient esti\n",
    "mates. When =0, the penalty term has no effect, and ridge regression\n",
    "will produce the least squares estimates. However, as \n",
    ", the impact of\n",
    "the shrinkage penalty grows, and the ridge regression coefficient estimates\n",
    "will approach zero. Unlike least squares, which generates only one set of co\n",
    "efficient estimates, ridge regression will produce a different set of coefficient\n",
    "estimates, ˆR, for each value of . Selecting a good value for is critical;\n",
    "we defer this discussion to Section 6.2.3, where we use cross-validation.\n",
    "Note that in (6.5), the shrinkage penalty is applied to 1,..., p, but\n",
    "not to the intercept 0. We want to shrink the estimated association of\n",
    "each variable with the response; however, we do not want to shrink the\n",
    "intercept, which is simply a measure of the mean value of the response\n",
    "when xi1 = xi2 = ...= xip =0. If we assume that the variables—that is,\n",
    "the columns of the data matrix X—have been centered to have mean zero\n",
    "before ridge regression is performed, then the estimated intercept will take\n",
    "the form ˆ0 =¯y= n\n",
    "i=1yi/n.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9bd596",
   "metadata": {},
   "source": [
    "An Application to the Credit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3690562a",
   "metadata": {},
   "source": [
    "In Figure 6.4, the ridge regression coefficient estimates for the Credit data\n",
    "set are displayed. In the left-hand panel, each curve corresponds to the\n",
    "ridge regression coefficient estimate for one of the ten variables, plotted\n",
    "as a function of . For example, the black solid line represents the ridge\n",
    "regression estimate for the income coefficient, as is varied. At the extreme\n",
    "left-hand side of the plot, is essentially zero, and so the corresponding\n",
    "ridge coefficient estimates are the same as the usual least squares esti\n",
    "mates. But as increases, the ridge coefficient estimates shrink towards\n",
    "zero. When is extremely large, then all of the ridge coefficient estimates\n",
    "are basically zero; this corresponds to the null model that contains no predictors. In this plot, the income, limit, rating, and student variables are\n",
    "displayed in distinct colors, since these variables tend to have by far the\n",
    "largest coefficient estimates. While the ridge coefficient estimates tend to\n",
    "decrease in aggregate as increases, individual coefficients, such as rating\n",
    "and income, may occasionally increase as increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7ff260",
   "metadata": {},
   "source": [
    "The right-hand panel of Figure 6.4 displays the same ridge coefficient estimates as the left-hand panel, but instead of displaying on the x-axis, we now display $\\hat{R}^2/\\hat{2}$, where $\\hat{}$ denotes the vector of least squares coefficient estimates. The notation $\\|\\cdot\\|_2$ denotes the 2 norm (pronounced “ell 2”) of a vector, and is defined as $\\|\\beta\\|_2 = \\sqrt{\\sum_{j=1}^{p} \\beta_j^2}$. It measures the distance of $\\beta$ from zero. As $\\lambda$ increases, the 2 norm of $\\hat{R}$ will always decrease, and so will $\\hat{R}^2/\\hat{2}$. The latter quantity ranges from 1 (when $\\lambda=0$, in which case the ridge regression coefficient estimate is the same as the least squares estimate, and so their 2 norms are the same) to 0 (when $\\lambda = \\infty$, in which case the ridge regression coefficient estimate is a vector of zeros, with 2 norm equal to zero). Therefore, we can think of the x-axis in the right-hand panel of Figure 6.4 as the amount that the ridge regression coefficient estimates have been shrunken towards zero; a small value indicates that they have been shrunken very close to zero.\n",
    "\n",
    "The standard least squares coefficient estimates discussed in Chapter 3 are scale equivariant: multiplying $X_j$ by a constant $c$ simply leads to a scaling of the least squares coefficient estimates by a factor of $1/c$. In other words, regardless of how the jth predictor is scaled, $X_j \\hat{\\beta}_j$ will remain the same. In contrast, the ridge regression coefficient estimates can change substantially when multiplying a given predictor by a constant. For instance, consider the income variable, which is measured in dollars. One could reasonably have measured income in thousands of dollars, which would result in a reduction in the observed values of income by a factor of 1,000. Now due to the sum of squared coefficients term in the ridge regression formulation (6.5), such a change in scale will not simply cause the ridge regression coefficient estimate for income to change by a factor of 1,000. In other words, $X_j \\hat{R}_j$ will depend not only on the value of $\\lambda$, but also on the scaling of the jth predictor. In fact, the value of $X_j \\hat{R}_j$ may even depend on the scaling of the other predictors! Therefore, it is best to apply ridge regression after standardizing the predictors, using the formula\n",
    "\n",
    "$$\n",
    "\\tilde{x}_{ij} = \\frac{x_{ij}}{1 / n \\sum_{i=1}^n (x_{ij} - \\bar{x}_j)^2}\n",
    "$$\n",
    "\n",
    "so that they are all on the same scale. In (6.6), the denominator is the estimated standard deviation of the jth predictor. Consequently, all of the standardized predictors will have a standard deviation of one. As a result, the final fit will not depend on the scale on which the predictors are measured. In Figure 6.4, the y-axis displays the standardized ridge regression coefficient estimates—that is, the coefficient estimates that result from performing ridge regression using standardized predictors.\n",
    "\n",
    "Why Does Ridge Regression Improve Over Least Squares?\n",
    "\n",
    "Ridge regression’s advantage over least squares is rooted in the bias-variance trade-off. As $\\lambda$ increases, the flexibility of the ridge regression fit decreases, leading to decreased variance but increased bias. This is illustrated in the left-hand panel of Figure 6.5, using a simulated data set containing $p = 45$ predictors and $n = 50$ observations. The green curve in the left-hand panel of Figure 6.5 displays the variance of the ridge regression predictions as a function of $\\lambda$. At the least squares coefficient estimates, which correspond to ridge regression with $\\lambda = 0$, the variance is high but there is no bias. But as $\\lambda$ increases, the shrinkage of the ridge coefficient estimates leads to a substantial reduction in the variance of the predictions, at the expense of a slight increase in bias. Recall that the least mean squared error (MSE), plotted in bias-variance bias, is closely related to the variance plus the squared bias. For values of $\\lambda$ that are not too small, the variance generally remains very low, as shown in the figure, plotted in black. However, as $\\lambda$ increases from 0 to 10. Beyond this point, the decrease in variance is no longer sufficient to offset the increased bias, and the MSE can begin to be significantly underestimated, resulting in a large increase in the bias. \n",
    "\n",
    "The minimum MSE is achieved at and around the value of $\\lambda$ that results in the smallest MSE associated with the least squares fit, when using the same hyperparameter that will yield the best fit for any model designed for use with $\\lambda$. However, for an inflexible estimator, the MSE is considerably higher.\n",
    "\n",
    "In general, as the number of observations increases, the ridge regression estimates become more stable against the errors in the left-hand curve; however, the fitted values may still have high variance. This means that while ridge regression can improve the fitted values' stability by controlling their variance, the coefficients of the variables in the model may be increasingly biased.\n",
    "\n",
    "In Figure 6.5, the least squares estimates continue to outperform ridge regression predictions, even when $\\lambda > 0$, because the least squares estimation can still perform well by trading off a small increase in bias for a large decrease in variance. Hence, ridge regression works best in situations\n",
    "where the least squares estimates have high variance.\n",
    "Ridge regression also has substantial computational advantages over best\n",
    "subset selection, which requires searching through $2^p$ models. As we dis\n",
    "cussed previously, even for moderate values of $p$, such a search can be\n",
    "computationally infeasible. In contrast, for any fixed value of $\\lambda$, ridge re\n",
    "gression only fits a single model, and the model-fitting procedure can be\n",
    "performed quite quickly. In fact, one can show that the computations re\n",
    "quired to solve (6.5), simultaneously for all values of $\\lambda$, are almost identical\n",
    "to those for fitting a model using least squares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ade56",
   "metadata": {},
   "source": [
    "#### The Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21238e86",
   "metadata": {},
   "source": [
    "Ridge regression does have one obvious disadvantage. Unlike best subset,\n",
    "forward stepwise, and backward stepwise selection, which will generally\n",
    "select models that involve just a subset of the variables, ridge regression\n",
    "will include all $p$ predictors in the final model. The penalty \n",
    "$$\n",
    "\\sum_{j=1}^{p} \\beta_j^2\n",
    "$$ \n",
    "in (6.5) will shrink all of the coefficients towards zero, but it will not set any of them\n",
    "exactly to zero (unless $\\lambda = \\infty$). This may not be a problem for prediction\n",
    "accuracy, but it can create a challenge in model interpretation in settings in\n",
    "which the number of variables $p$ is quite large. For example, in the Credit\n",
    "data set, it appears that the most important variables are income, limit,\n",
    "rating, and student. So we might wish to build a model including just\n",
    "these predictors. However, ridge regression will always generate a model\n",
    "involving all ten predictors. Increasing the value of $\\lambda$ will tend to reduce\n",
    "the magnitudes of the coefficients, but will not result in exclusion of any of\n",
    "the variables.\n",
    "\n",
    "The lasso is a relatively recent alternative to ridge regression that over-\n",
    "comes this disadvantage. The lasso coefficients, $\\hat{\\beta}_L$, minimize the quantity\n",
    "$$\n",
    "\\sum_{i=1}^{n} \\left( y_i - \\sum_{j=1}^{p} \\beta_j x_{ij} \\right)^2 + \\lambda \\sum_{j=1}^{p} | \\beta_j | = \\text{RSS} + \\lambda \\sum_{j=1}^{p} | \\beta_j |.\n",
    "$$\n",
    "Comparing (6.7) to (6.5), we see that the lasso and ridge regression have\n",
    "similar formulations. The only difference is that the $\\beta_j^2$ term in the ridge\n",
    "regression penalty (6.5) has been replaced by $|\\beta_j|$ in the lasso penalty (6.7).\n",
    "In statistical parlance, the lasso uses an $L_1$ (pronounced “ell 1”) penalty\n",
    "instead of an $L_2$ penalty. The $L_1$ norm of a coefficient vector is given by\n",
    "$$\n",
    "||\\beta||_1 = \\sum_{j=1}^{p} | \\beta_j |.\n",
    "$$\n",
    "\n",
    "As with ridge regression, the lasso shrinks the coefficient estimates to\n",
    "wards zero. However, in the case of the lasso, the $L_1$ penalty has the effect\n",
    "of forcing some of the coefficient estimates to be exactly equal to zero when\n",
    "the tuning parameter is sufficiently large. Hence, much like best subset se\n",
    "lection, the lasso performs variable selection. As a result, models generated\n",
    "from the lasso are generally much easier to interpret than those produced\n",
    "by ridge regression. We say that the lasso yields sparse models—that is,\n",
    "models that involve only a subset of the variables. As in ridge regression,\n",
    "selecting a good value of $\\lambda$ for the lasso is critical; we defer this discussion\n",
    "to Section 6.2.3, where we use cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc1b249",
   "metadata": {},
   "source": [
    "As an example, consider the coefficient plots in Figure 6.6, which are gen\n",
    "erated from applying the lasso to the Credit dataset. When $\\lambda = 0$, then\n",
    "the lasso simply gives the least squares fit, and when $\\lambda$ becomes sufficiently\n",
    "large, the lasso gives the null model in which all coefficient estimates equal\n",
    "zero. However, in between these two extremes, the ridge regression and\n",
    "lasso models are quite different from each other. Moving from left to right\n",
    "in the right-hand panel of Figure 6.6, we observe that at first the lasso re\n",
    "sults in a model that contains only the rating predictor. Then student and\n",
    "limit enter the model almost simultaneously, shortly followed by income.\n",
    "Eventually, the remaining variables enter the model. Hence, depending on\n",
    "the value of $\\lambda$, the lasso can produce a model involving any number of vari\n",
    "ables. In contrast, ridge regression will always include all of the variables in\n",
    "the model, although the magnitude of the coefficient estimates will depend\n",
    "on $\\lambda$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6683a9",
   "metadata": {},
   "source": [
    "Another Formulation for Ridge Regression and the Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0a85bb",
   "metadata": {},
   "source": [
    "One can show that the lasso and ridge regression coefficient estimates solve\n",
    "the problems:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{minimize} & \\quad \\sum_{i=1}^{n} \\left( y_i - \\beta_0 - \\sum_{j=1}^{p} \\beta_j x_{ij} \\right)^2\n",
    "\\text{subject to} & \\quad \\sum_{j=1}^{p} | \\beta_j | \\leq s \\tag{6.8}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{minimize} & \\quad \\sum_{i=1}^{n} \\left( y_i - \\beta_0 - \\sum_{j=1}^{p} \\beta_j x_{ij} \\right)^2\n",
    "\\text{subject to} & \\quad \\sum_{j=1}^{p} \\beta_j^2 \\leq s \\tag{6.9}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "respectively. In other words, for every value of $\\lambda$, there is some $s$ such that\n",
    "the Equations (6.7) and (6.8) will give the same lasso coefficient estimates.\n",
    "Similarly, for every value of $\\lambda$ there is a corresponding $s$ such that Equations (6.5) and (6.9) will give the same ridge regression coefficient estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3b2589",
   "metadata": {},
   "source": [
    "When $ p = 2 $, then (6.8) indicates that the lasso coefficient estimates have\n",
    "the smallest RSS out of all points that lie within the diamond defined by\n",
    "$| \\beta_1| + | \\beta_2| \\leq s$. Similarly, the ridge regression estimates have the smallest\n",
    "RSS out of all points that lie within the circle defined by $ \\beta_1^2 + \\beta_2^2 \\leq s $.\n",
    "We can think of (6.8) as follows. When we perform the lasso we are trying\n",
    "to find the set of coefficient estimates that lead to the smallest RSS, subject\n",
    "to the constraint that there is a budget $ s $ for how large $ \\sum_{j=1}^{p} | \\beta_j | $ can be.\n",
    "When $ s $ is extremely large, then this budget is not very restrictive, and so\n",
    "the coefficient estimates can be large. In fact, if $ s $ is large enough that the\n",
    "least squares solution falls within the budget, then (6.8) will simply yield\n",
    "the least squares solution. In contrast, if $ s $ is small, then $ \\sum_{j=1}^{p} | \\beta_j | $ must be\n",
    "small in order to avoid violating the budget. Similarly, (6.9) indicates that\n",
    "when we perform ridge regression, we seek a set of coefficient estimates\n",
    "such that the RSS is as small as possible, subject to the requirement that\n",
    "$ \\sum_{j=1}^{p} \\beta_j^2 $ not exceed the budget $ s $.\n",
    "\n",
    "The formulations (6.8) and (6.9) reveal a close connection between the\n",
    "lasso, ridge regression, and best subset selection. Consider the problem:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{minimize} & \\quad \\sum_{i=1}^{n} \\left( y_i - \\beta_0 - \\sum_{j=1}^{p} \\beta_j x_{ij} \\right)^2 \n",
    "\\text{subject to} & \\quad \\sum_{j=1}^{p} I( \\beta_j ≠ 0) \\leq s. \\tag{6.10}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Here $ I( \\beta_j ≠ 0) $ is an indicator variable: it takes on a value of 1 if $ \\beta_j = 0 $, and\n",
    "equals zero otherwise. Then (6.10) amounts to finding a set of coefficient\n",
    "estimates such that RSS is as small as possible, subject to the constraint\n",
    "that no more than $ s $ coefficients can be nonzero. The problem (6.10) is\n",
    "equivalent to best subset selection. Unfortunately, solving (6.10) is com\n",
    "putationally infeasible when $ p $ is large, since it requires considering all $ p \\choose s $\n",
    "models containing $ s $ predictors. Therefore, we can interpret ridge regression\n",
    "and the lasso as computationally feasible alternatives to best subset selec\n",
    "tion that replace the intractable form of the budget in (6.10) with forms\n",
    "that are much easier to solve. Of course, the lasso is much more closely\n",
    "related to best subset selection, since the lasso performs feature selection\n",
    "for $ s $ sufficiently small in (6.8), while ridge regression does not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0b030",
   "metadata": {},
   "source": [
    "The Variable Selection Property of the Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6d7ada",
   "metadata": {},
   "source": [
    "Why is it that the lasso, unlike ridge regression, results in coefficient esti\n",
    "mates that are exactly equal to zero? The formulations (6.8) and (6.9) can\n",
    "be used to shed light on the issue. Figure 6.7 illustrates the situation. The\n",
    "least squares solution is marked as $ \\hat{\\beta} $, while the blue diamond and circle\n",
    "represent the lasso and ridge regression constraints in (6.8) and (6.9), re\n",
    "spectively. If $ s $ is sufficiently large, then the constraint regions will contain\n",
    "$ \\hat{\\beta} $, and so the ridge regression and lasso estimates will be the same as the\n",
    "least squares estimates. (Such a large value of $ s $ corresponds to $ \\lambda = 0 $ in\n",
    "(6.5) and (6.7).) However, in Figure 6.7 the least squares estimates lie out\n",
    "side of the diamond and the circle, and so the least squares estimates are\n",
    "not the same as the lasso and ridge regression estimates.\n",
    "\n",
    "Each of the ellipses centered around $ \\hat{\\beta} $ represents a contour: this means\n",
    "that all of the points on a particular ellipse have the same RSS value. As the ellipses expand away from the least squares coefficient estimates, the\n",
    "RSS increases. Equations (6.8) and (6.9) indicate that the lasso and ridge\n",
    "regression coefficient estimates are given by the first point at which an\n",
    "ellipse contacts the constraint region. Since ridge regression has a circular\n",
    "constraint with no sharp points, this intersection will not generally occur on\n",
    "an axis, and so the ridge regression coefficient estimates will be exclusively\n",
    "non-zero. However, the lasso constraint has corners at each of the axes, and\n",
    "so the ellipse will often intersect the constraint region at an axis. When this\n",
    "occurs, one of the coefficients will equal zero. In higher dimensions, many of\n",
    "the coefficient estimates may equal zero simultaneously. In Figure 6.7, the\n",
    ".\n",
    "intersection occurs at 1 =0, and so the resulting model will only include $ \\beta_2$\n",
    "\n",
    "\n",
    "In Figure 6.7, we considered the simple case of p =2. When p =3,\n",
    "then the constraint region for ridge regression becomes a sphere, and the\n",
    "constraint region for the lasso becomes a polyhedron. When p>3, the\n",
    "constraint for ridge regression becomes a hypersphere, and the constraint\n",
    "for the lasso becomes a polytope. However, the key ideas depicted in Fig\n",
    "ure 6.7 still hold. In particular, the lasso leads to feature selection when\n",
    "p>2 due to the sharp corners of the polyhedron or polytope.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb29395",
   "metadata": {},
   "source": [
    "Comparing the Lasso and Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32aaaab",
   "metadata": {},
   "source": [
    "\n",
    "It is clear that the lasso has a major advantage over ridge regression, in\n",
    "that it produces simpler and more interpretable models that involve only a\n",
    "subset of the predictors. However, which method leads to better prediction\n",
    "accuracy? Figure 6.8 displays the variance, squared bias, and test MSE of\n",
    "the lasso applied to the same simulated data as in Figure 6.5. Clearly the\n",
    "lasso leads to qualitatively similar behavior to ridge regression, in that as $ \\lambda $\n",
    "increases, the variance decreases and the bias increases. In the right-hand panel of Figure 6.8, the dotted lines represent the ridge regression fits.\n",
    "Here we plot both against their R2 on the training data. This is another\n",
    "useful way to index models, and can be used to compare models with\n",
    "different types of regularization, as is the case here. In this example, the\n",
    "lasso and ridge regression result in almost identical biases. However, the\n",
    "variance of ridge regression is slightly lower than the variance of the lasso.\n",
    "Consequently, the minimum MSE of ridge regression is slightly smaller than\n",
    "that of the lasso.\n",
    "\n",
    "However, the data in Figure 6.8 were generated in such a way that all 45\n",
    "predictors were related to the response—that is, none of the true coefficients\n",
    "1,..., 45 equaled zero. The lasso implicitly assumes that a number of the\n",
    "coefficients truly equal zero. Consequently, it is not surprising that ridge\n",
    "regression outperforms the lasso in terms of prediction error in this setting.\n",
    "Figure 6.9 illustrates a similar situation, except that now the response is a\n",
    "function of only 2 out of 45 predictors. Now the lasso tends to outperform\n",
    "ridge regression in terms of bias, variance, and MSE.\n",
    "\n",
    "These two examples illustrate that neither ridge regression nor the lasso\n",
    "will universally dominate the other. In general, one might expect the lasso\n",
    "to perform better in a setting where a relatively small number of predictors\n",
    "have substantial coefficients, and the remaining predictors have coefficients\n",
    "that are very small or that equal zero. Ridge regression will perform better\n",
    "when the response is a function of many predictors, all with coefficients of\n",
    "roughly equal size. However, the number of predictors that is related to the\n",
    "response is never known a priori for real data sets. A technique such as\n",
    "cross-validation can be used in order to determine which approach is better\n",
    "on a particular data set.\n",
    "\n",
    "As with ridge regression, when the least squares estimates have exces\n",
    "sively high variance, the lasso solution can yield a reduction in variance\n",
    "at the expense of a small increase in bias, and consequently can gener\n",
    "ate more accurate predictions. Unlike ridge regression, the lasso performs\n",
    "variable selection, and hence results in models that are easier to interpret.\n",
    "There are very efficient algorithms for fitting both ridge and lasso models;\n",
    "in both cases the entire coefficient paths can be computed with about the\n",
    "same amount of work as a single least squares fit. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da35da",
   "metadata": {},
   "source": [
    "A Simple Special Case for Ridge Regression and the Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab85b585",
   "metadata": {},
   "source": [
    "In order to obtain a better intuition about the behavior of ridge regression\n",
    "and the lasso, consider a simple special case with $ n = p $, and $ X $ a diag\n",
    "onal matrix with 1’s on the diagonal and 0’s in all off-diagonal elements.\n",
    "To simplify the problem further, assume also that we are performing regres\n",
    "sion without an intercept. With these assumptions, the usual least squares\n",
    "problem simplifies to finding $ \\beta_1, \\ldots, \\beta_p $ that minimize\n",
    "\n",
    "$$\n",
    "\\sum_{j=1}^{p} (y_j - \\beta_j)^2.\n",
    "$$\n",
    "\n",
    "In this case, the least squares solution is given by\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_j = y_j. \\tag{6.11}\n",
    "$$\n",
    "\n",
    "And in this setting, ridge regression amounts to finding $ \\beta_1, \\ldots, \\beta_p $ such that\n",
    "\n",
    "$$\n",
    "\\sum_{j=1}^{p} (y_j - \\beta_j)^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2 \\tag{6.12}\n",
    "$$\n",
    "\n",
    "is minimized, and the lasso amounts to finding the coefficients such that is minimized. \n",
    "\n",
    "$$\n",
    "\\sum_{j=1}^{p} (y_j - \\beta_j)^2 + \\lambda \\sum_{j=1}^{p} |\\beta_j| \\tag{6.13}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bfecd4",
   "metadata": {},
   "source": [
    "One can show that in this setting, the ridge regression esti\n",
    "mates take the form\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_j^R = \\frac{y_j}{1 + \\lambda},\n",
    "$$\n",
    "\n",
    "and the lasso estimates take the form\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_j^L =\n",
    "\\begin{cases}\n",
    "y_j - \\lambda/2 & \\text{if } y_j > \\lambda/2, \\\\\n",
    "y_j + \\lambda/2 & \\text{if } y_j < -\\lambda/2, \\\\\n",
    "0 & \\text{if } |y_j| \\leq \\lambda/2.\n",
    "\\end{cases}\n",
    "\\tag{6.14}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Figure 6.10 displays the situation. We can see that ridge regression and\n",
    "the lasso perform two very different types of shrinkage. In ridge regression,\n",
    "each least squares coefficient estimate is shrunken by the same proportion.\n",
    "In contrast, the lasso shrinks each least squares coefficient towards zero by\n",
    "a constant amount, $\\lambda/2$; the least squares coefficients that are less than\n",
    "$\\lambda/2$ in absolute value are shrunken entirely to zero. The type of shrink\n",
    "age performed by the lasso in this simple setting (6.15) is known as soft\n",
    "thresholding. The fact that some lasso coefficients are shrunken entirely to\n",
    "zero explains why the lasso performs feature selection.\n",
    "\n",
    "In the case of a more general data matrix $X$, the story is a little more\n",
    "complicated than what is depicted in Figure 6.10, but the main ideas still\n",
    "hold approximately: ridge regression more or less shrinks every dimension\n",
    "of the data by the same proportion, whereas the lasso more or less shrinks\n",
    "all coefficients toward zero by a similar amount, and sufficiently small co\n",
    "efficients are shrunken all the way to zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37411582",
   "metadata": {},
   "source": [
    "We now show that one can view ridge regression and the lasso through\n",
    "a Bayesian lens. A Bayesian viewpoint for regression assumes that the\n",
    "coefficient vector $\\beta$ has some prior distribution, say $p(\\beta)$, where \n",
    "$\\beta = (\\beta_0, \\beta_1, \\ldots, \\beta_p)^T$. The likelihood of the data can be written as $f(Y|X, \\beta)$, where $ X = (X_1,\\ldots,X_p) $. Multiplying the prior distribution by the likelihood gives us (up to a proportionality constant) the posterior distribution, which takes the form\n",
    "\n",
    "$$\n",
    "p(\\beta | X, Y) \\propto f(Y | X, \\beta)p(\\beta | X) = f(Y | X, \\beta)p(\\beta),\n",
    "$$\n",
    "\n",
    "where the proportionality above follows from Bayes’ theorem, and the\n",
    "equality above follows from the assumption that $X$ is fixed.\n",
    "\n",
    "We assume the usual linear model,\n",
    "\n",
    "$$\n",
    "Y = \\beta_0 + X_1 \\beta_1 + \\cdots + X_p \\beta_p + \\epsilon,\n",
    "$$\n",
    "\n",
    "and suppose that the errors are independent and drawn from a normal distribution. Furthermore, assume that \n",
    "\n",
    "$$\n",
    "p(\\beta) = \\prod_{j=1}^p g(\\beta_j),\n",
    "$$\n",
    "\n",
    "for some density function $g$. It turns out that ridge regression and the lasso follow naturally from two special cases of $g$:\n",
    "\n",
    "- If $g$ is a Gaussian distribution with mean zero and standard deviation a function of $\\lambda$, then it follows that the posterior mode for $\\beta$—that is, the most likely value for $\\beta$, given the data—is given by the ridge regression solution. (In fact, the ridge regression solution is also the posterior mean.)\n",
    "  \n",
    "- If $g$ is a double-exponential (Laplace) distribution with mean zero and scale parameter a function of $\\lambda$, then it follows that the posterior mode for $\\beta$ is the lasso solution. (However, the lasso solution is not the posterior mean, and in fact, the posterior mean does not yield a sparse coefficient vector.)\n",
    "\n",
    "The Gaussian and double-exponential priors are displayed in Figure 6.11. Therefore, from a Bayesian viewpoint, ridge regression and the lasso follow directly from assuming the usual linear model with normal errors, together with a simple prior distribution for $\\beta$. Notice that the lasso prior is steeply peaked at zero, while the Gaussian is flatter and fatter at zero. Hence, the lasso expects a priori that many of the coefficients are (exactly) zero, while ridge assumes the coefficients are randomly distributed about zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96060134",
   "metadata": {},
   "source": [
    "Selecting the Tuning Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530e3e82",
   "metadata": {},
   "source": [
    "Just as the subset selection approaches considered in Section 6.1 require\n",
    "a method to determine which of the models under consideration is best,\n",
    "implementing ridge regression and the lasso requires a method for selecting\n",
    "a value for the tuning parameter in $ \\lambda $ (6.5) and (6.7), or equivalently, the\n",
    "value of the constraint s in (6.9) and (6.8). Cross-validation provides a sim\n",
    "ple way to tackle this problem. We choose a grid of $ \\lambda $ values, and compute\n",
    "the cross-validation error for each value of $ \\lambda $, as described in Chapter 5.We\n",
    "then select the tuning parameter value for which the cross-validation error\n",
    "is smallest. Finally, the model is re-fit using all of the available observations\n",
    "and the selected value of the tuning parameter.\n",
    "\n",
    "  Figure 6.12 displays the choice of $ \\lambda $ that results from performing leave\n",
    "one-out cross-validation on the ridge regression fits from the `Credit` data\n",
    "set. The dashed vertical lines indicate the selected value of $ \\lambda $. In this case\n",
    "the value is relatively small, indicating that the optimal fit only involves a\n",
    "small amount of shrinkage relative to the least squares solution. In addition,\n",
    "the dip is not very pronounced, so there is rather a wide range of values\n",
    "that would give a very similar error. In a case like this we might simply use\n",
    "the least squares solution.\n",
    "    \n",
    "  Figure 6.13 provides an illustration of ten-fold cross-validation applied to\n",
    "the lasso fits on the sparse simulated data from Figure 6.9. The left-hand\n",
    "panel of Figure 6.13 displays the cross-validation error, while the right-hand\n",
    "panel displays the coefficient estimates. The vertical dashed lines indicate\n",
    "the point at which the cross-validation error is smallest. The two colored\n",
    "lines in the right-hand panel of Figure 6.13 represent the two predictors\n",
    "that are related to the response, while the grey lines represent the unre\n",
    "lated predictors; these are often referred to as $signal$ and $noise$ variables,\n",
    "respectively. Not only has the lasso correctly given much larger coeffi\n",
    "cient estimates to the two signal predictors, but also the minimum cross\n",
    "validation error corresponds to a set of coefficient estimates for which only\n",
    "the signal variables are non-zero. Hence cross-validation together with the\n",
    "lasso has correctly identified the two signal variables in the model, even\n",
    "though this is a challenging setting, with $p = 45$ variables and only $n = 50$ observations. In contrast, the least squares solution—displayed on the far\n",
    "right of the right-hand panel of Figure 6.13—assigns a large coefficient\n",
    "estimate to only one of the two signal variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e81886c",
   "metadata": {},
   "source": [
    "#### Dimension Reduction Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28170071",
   "metadata": {},
   "source": [
    "The methods that we have discussed so far in this chapter have controlled variance in two different ways, either by using a subset of the original variables, or by shrinking their coefficients toward zero. All of these methods are defined using the original predictors, $X_1, X_2, \\ldots, X_p$. We now explore a class of approaches that transform the predictors and then fit a least squares model using the transformed variables. We will refer to these techniques as dimension reduction methods.\n",
    "\n",
    "Let $Z_1, Z_2, \\ldots, Z_M$ represent $M$ linear combinations of our original $p$ predictors. That is,\n",
    "\n",
    "$$\n",
    "Z_m = \\sum_{j=1}^p \\gamma_{jm} X_j \\tag{6.16}\n",
    "$$\n",
    "\n",
    "for some constants $\\gamma_{1m}, \\gamma_{2m}, \\ldots, \\gamma_{pm}$, $m = 1, \\ldots, M$. We can then fit the linear regression model\n",
    "\n",
    "$$\n",
    "y_i = \\beta_0 + \\sum_{m=1}^M \\beta_m Z_{im} + \\epsilon_i, \\quad i = 1, \\ldots, n, \\tag{6.17}\n",
    "$$\n",
    "\n",
    "using least squares. Note that in (6.17), the regression coefficients are given by $\\beta_0, \\beta_1, \\ldots, \\beta_M$. If the constants $\\gamma_{1m}, \\gamma_{2m}, \\ldots, \\gamma_{pm}$ are chosen wisely, then such dimension reduction approaches can often outperform least squares regression. In other words, fitting (6.17) using least squares can lead to better results than fitting (6.1) using least squares.\n",
    "\n",
    "The term dimension reduction comes from the fact that this approach reduces the problem of estimating the $p+1$ coefficients $\\beta_0, \\beta_1, \\ldots, \\beta_p$ to the simpler problem of estimating the $M + 1$ coefficients $\\beta_0, \\beta_1, \\ldots, \\beta_M$, where $M < p$. In other words, the dimension of the problem has been reduced from $p + 1$ to $M + 1$.\n",
    "\n",
    "Notice that from (6.16),\n",
    "\n",
    "$$\n",
    "\\sum_{m=1}^M \\beta_m Z_{im} = \\sum_{m=1}^M \\beta_m \\left( \\sum_{j=1}^p \\gamma_{jm} X_j \\right) = \\sum_{j=1}^p \\left( \\sum_{m=1}^M \\beta_m \\gamma_{jm} \\right) X_j,\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\beta_j = \\sum_{m=1}^M \\beta_m \\gamma_{jm}. \\tag{6.18}\n",
    "$$\n",
    "\n",
    "Hence (6.17) can be thought of as a special case of the original linear regression model given by (6.1). Dimension reduction serves to constrain the estimated $\\beta_j$ coefficients, since now they must take the form (6.18). This constraint on the form of the coefficients has the potential to bias the coefficient estimates. However, in situations where $p$ is larger relative to $M$, selecting a value of $M<p$ can significantly reduce the variance of the fitted coefficients. If $M=p$, and all the $Z_m$ are linearly independent, then (6.18) poses no constraints. In this case, no dimension reduction occurs, and so fitting (6.17) is equivalent to performing least squares on the original $p$ predictors.\n",
    "\n",
    "All dimension reduction methods work in two steps. First, the transformed predictors $Z_1, Z_2, \\ldots, Z_M$ are obtained. Second, the model is fit using these $M$ predictors. However, the choice of $Z_1, Z_2, \\ldots, Z_M$, or equivalently, the selection of the $\\gamma_m$’s, can be achieved in different ways. In this chapter, we will consider two approaches for this task: principal components and partial least squares.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85566728",
   "metadata": {},
   "source": [
    "Principal Components Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387c77d5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$Principal$ $components$ $analysis$ (PCA) is a popular approach for deriving a low-dimensional set of features from a large set of variables. PCA is discussed in greater detail as a tool for unsupervised learning in Chapter 12. Here we describe its use as a dimension reduction technique for regression. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76958a6b",
   "metadata": {},
   "source": [
    "\n",
    "An Overview of Principal Components Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad7ad75",
   "metadata": {},
   "source": [
    "PCA is a technique for reducing the dimension of an $n \\times p$ data matrix $X$. The first principal component direction of the data is that along which the observations vary the most. For instance, consider Figure 6.14, which shows population size ($pop$) in tens of thousands of people, and ad spending for a particular company ($ad$) in thousands of dollars, for 100 cities. The green solid line represents the first principal component direction of the data. We can see by eye that this is the direction along which there is the greatest variability in the data. That is, if we projected the 100 observations onto this line (as shown in the left-hand panel of Figure 6.15), then the resulting projected observations would have the largest possible variance; projecting the observations onto any other line would yield projected observations with lower variance. Projecting a point onto a line simply involves finding the location on the line which is closest to the point.\n",
    "\n",
    "The first principal component is displayed graphically in Figure 6.14, but how can it be summarized mathematically? It is given by the formula\n",
    "\n",
    "$$\n",
    "Z_1 = 0.839 (pop - \\bar{pop}) + 0.544 (ad - \\bar{ad}). \\tag{6.19}\n",
    "$$\n",
    "\n",
    "Here $\\gamma_{11} = 0.839$ and $\\gamma_{21} = 0.544$ are the principal component loadings, which define the direction referred to above. In (6.19), $pop$ indicates the mean of all $pop$ values in this data set, and $ad$ indicates the mean of all advertising spending. The idea is that out of every possible linear combination of $pop$ and $ad$ such that $\\gamma_{11}^2 + \\gamma_{21}^2 = 1$, this particular linear combination yields the highest variance: i.e., this is the linear combination for which \n",
    "\n",
    "$$\n",
    "Var( \\gamma_{11} (pop - \\bar{pop}) + \\gamma_{21} (ad - \\bar{ad})) \\text{ is maximized.}\n",
    "$$\n",
    "\n",
    "It is necessary to consider only linear combinations of the form $\\gamma_{11}^2 + \\gamma_{21}^2 = 1$, since otherwise we could increase $\\gamma_{11}$ and $\\gamma_{21}$ arbitrarily in order to blow up the variance. In (6.19), the two loadings are both positive and have similar size, and so $Z_1$ is almost an average of the two variables.\n",
    "\n",
    "Since $n = 100$, $pop$ and $ad$ are vectors of length 100, and so is $Z_1$ in (6.19). For instance,\n",
    "\n",
    "$$\n",
    "z_{i1} = 0.839 (pop_i - \\bar{pop}) + 0.544 (ad_i - \\bar{ad}). \\tag{6.20}\n",
    "$$\n",
    "\n",
    "The values of $z_{11}, \\ldots, z_{n1}$ are known as the principal component scores, and can be seen in the right-hand panel of Figure 6.15.\n",
    "\n",
    "There is also another interpretation of PCA: the first principal component vector defines the line that is as close as possible to the data. For instance, in Figure 6.14, the first principal component line minimizes the sum of the squared perpendicular distances between each point and the line. These distances are plotted as dashed line segments in the left-hand panel of Figure 6.15, in which the crosses represent the projection of each point onto the first principal component line. The first principal component has been chosen so that the projected observations are as close as possible to the original observations.\n",
    "\n",
    "In the right-hand panel of Figure 6.15, the left-hand panel has been rotated so that the first principal component direction coincides with the x-axis. It is possible to show that the first principal component score for the $i$th observation, given in (6.20), is the distance in the x-direction of the $i$th cross from zero. So for example, the point in the bottom-left corner of the left-hand panel of Figure 6.15 has a large negative principal component score, $z_{i1} = -26.1$, while the point in the top-right corner has a large positive score, $z_{i1} = 18.7$. These scores can be computed directly using (6.20).\n",
    "\n",
    "We can think of the values of the principal component $Z_1$ as single number summaries of the joint $pop$ and $ad$ budgets for each location. In this example, if $z_{i1} = 0.839 (pop_i - \\bar{pop}) + 0.544 (ad_i - \\bar{ad}) < 0$, then this indicates a city with below-average population size and below-average ad spending. A positive score suggests the opposite. How well can a single number represent both $pop$ and $ad$? In this case, Figure 6.14 indicates that $pop$ and $ad$ have approximately a linear relationship, and so we might expect that a single-number summary will work well. Figure 6.16 displays $z_{i1}$ versus both $pop$ and $ad$. The plots show a strong relationship between the first principal component and the two features. In other words, the first principal component appears to capture most of the information contained in the $pop$ and $ad$ predictors.\n",
    "\n",
    "So far we have concentrated on the first principal component. In general, one can construct up to $p$ distinct principal components. The second principal component $Z_2$ is a linear combination of the variables that is uncorrelated with $Z_1$, and has largest variance subject to this constraint. The second principal component direction is illustrated as a dashed blue line in Figure 6.14. It turns out that the zero correlation condition of $Z_1$ with $Z_2$ is equivalent to the condition that the direction must be perpendicular, or orthogonal, to the first principal component direction. The second principal component is given by the formula\n",
    "\n",
    "$$\n",
    "Z_2 = 0.544 \\cdot (pop - \\bar{pop}) - 0.839 \\cdot (ad - \\bar{ad}).\n",
    "$$\n",
    "\n",
    "Since the advertising data has two predictors, the first two principal components contain all of the information that is in $pop$ and $ad$. However, by construction, the first component will contain the most information. Consider, for example, the much larger variability of $z_{i1}$ (the x-axis) versus $z_{i2}$ (the y-axis) in the right-hand panel of Figure 6.15. The fact that the second principal component scores are much closer to zero indicates that this component captures far less information. As another illustration, Figure 6.17 displays $z_{i2}$ versus $pop$ and $ad$. There is little relationship between the second principal component and these two predictors, again suggesting that in this case, one only needs the first principal component in order to accurately represent the $pop$ and $ad$ budgets.\n",
    "\n",
    "With two-dimensional data, such as in our advertising example, we can construct at most two principal components. However, if we had other predictors, such as population age, income level, education, and so forth, then additional components could be constructed. They would successively maximize variance, subject to the constraint of being uncorrelated with the preceding components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b188ed20",
   "metadata": {},
   "source": [
    "The Principal Components Regression Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f69ab99",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The principal components regression (PCR) approach involves constructing the first $M$ principal components, $Z_1, \\ldots, Z_M$, and then using these components as the predictors in a linear regression model that is fit using least squares. The key idea is that often a small number of principal components suffice to explain most of the variability in the data, as well as the relationship with the response. In other words, we assume that the directions in which $X_1, \\ldots, X_p$ show the most variation are the directions that are associated with $Y$. While this assumption is not guaranteed to be true, it often turns out to be a reasonable enough approximation to give good results.\n",
    "\n",
    "If the assumption underlying PCR holds, then fitting a least squares model to $Z_1, \\ldots, Z_M$ will lead to better results than fitting a least squares model to $X_1, \\ldots, X_p$, since most or all of the information in the data that relates to the response is contained in $Z_1, \\ldots, Z_M$, and by estimating only $M < p$ coefficients we can mitigate overfitting. In the advertising data, the first principal component explains most of the variance in both $pop$ and $ad$, so a principal component regression that uses this single variable to predict some response of interest, such as sales, will likely perform quite well.\n",
    "\n",
    "Figure 6.18 displays the PCR fits on the simulated data sets from Figures 6.8 and 6.9. Recall that both data sets were generated using $n = 50$ observations and $p = 45$ predictors. However, while the response in the first data set was a function of all the predictors, the response in the second data set was generated using only two of the predictors. The curves are plotted as a function of $M$, the number of principal components used as predictors in the regression model. As more principal components are used in the regression model, the bias decreases, but the variance increases. This\n",
    "results in a typical U-shape for the mean squared error. When $M$ = p = 45$,\n",
    "then PCR amounts simply to a least squares fit using all of the original\n",
    "predictors. The figure indicates that performing PCR with an appropriate\n",
    "choice of $M$ can result in a substantial improvement over least squares, es\n",
    "pecially in the left-hand panel. However, by examining the ridge regression\n",
    "and lasso results in Figures 6.5, 6.8, and 6.9, we see that PCR does not\n",
    "perform as well as the two shrinkage methods in this example.\n",
    "\n",
    "The relatively worse performance of PCR in Figure 6.18 is a consequence\n",
    "of the fact that the data were generated in such a way that many princi\n",
    "pal components are required in order to adequately model the response.\n",
    "In contrast, PCR will tend to do well in cases when the first few principal\n",
    "components are sufficient to capture most of the variation in the predictors\n",
    "as well as the relationship with the response. The left-hand panel of Fig\n",
    "ure 6.19 illustrates the results from another simulated data set designed to\n",
    "be more favorable to PCR. Here the response was generated in such a way\n",
    "that it depends exclusively on the first five principal components. Now the\n",
    "bias drops to zero rapidly as $M$, the number of principal components used\n",
    "in PCR, increases. The mean squared error displays a clear minimum at\n",
    "$M =5$.The right-hand panel of Figure 6.19 displays the results on these\n",
    "data using ridge regression and the lasso. All three methods offer a signif\n",
    "icant improvement over least squares. However, PCR and ridge regression\n",
    "slightly outperform the lasso.\n",
    "\n",
    "We note that even though PCR provides a simple way to perform re\n",
    "gression using $M<p$ predictors, it is not a feature selection method. This\n",
    "is because each of the $M$ principal components used in the regression is a\n",
    "linear combination of all p of the original features. For instance, in (6.19),\n",
    "$Z_1$ was a linear combination of both `pop` and `ad`. Therefore, while PCR of\n",
    "ten performs quite well in many practical settings, it does not result in the development of a model that relies upon a small set of the original features.\n",
    "In this sense, PCR is more closely related to ridge regression than to the\n",
    "lasso. In fact, one can show that PCR and ridge regression are very closely\n",
    "related. One can even think of ridge regression as a continuous version of\n",
    "PCR!\n",
    "\n",
    "In PCR, the number of principal components, $M$, is typically chosen by\n",
    "cross-validation. The results of applying PCR to the `Credit` data set are\n",
    "shown in Figure 6.20; the right-hand panel displays the cross-validation er\n",
    "rors obtained, as a function of $M$. On these data, the lowest cross-validation\n",
    "error occurs when there are $M = 10$ components; this corresponds to al\n",
    "most no dimension reduction at all, since PCR with $M = 11$ is equivalent\n",
    "to simply performing least squares.\n",
    "\n",
    "When performing PCR, we generally recommend $standardizing$ each pre\n",
    "dictor, using (6.6), prior to generating the principal components. This stan\n",
    "dardization ensures that all variables are on the same scale. In the absence\n",
    "of standardization, the high-variance variables will tend to play a larger\n",
    "role in the principal components obtained, and the scale on which the vari\n",
    "ables are measured will ultimately have an effect on the final PCR model.\n",
    "However, if the variables are all measured in the same units (say, kilograms,\n",
    "or inches), then one might choose not to standardize them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6923400",
   "metadata": {},
   "source": [
    "#### Partial Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed841a",
   "metadata": {},
   "source": [
    "\n",
    "The PCR approach that we just described involves identifying linear combi\n",
    "nations, or directions, that best represent the predictors $X1,...,Xp$. These\n",
    "directions are identified in an $unsupervised$ way, since the response Y is\n",
    "not used to help determine the principal component directions. That is,\n",
    "the response does not supervise the identification of the principal compo\n",
    "nents. Consequently, PCR suffers from a drawback: there is no guarantee that the directions that best explain the predictors will also be the best directions to use for predicting the response. Unsupervised methods are discussed further in Chapter 12.\n",
    "\n",
    "We now present partial least squares (PLS), a supervised alternative to PCR. Like PCR, PLS is a dimension reduction method, which first identifies a new set of features $Z_1, \\ldots, Z_M$ that are linear combinations of the original features, and then fits a linear model via least squares using these $M$ new features. But unlike PCR, PLS identifies these new features in a supervised way—that is, it makes use of the response $Y$ in order to identify new features that not only approximate the old features well, but also that are related to the response. Roughly speaking, the PLS approach attempts to find directions that help explain both the response and the predictors.\n",
    "\n",
    "We now describe how the first PLS direction is computed. After standardizing the $p$ predictors, PLS computes the first direction $Z_1$ by setting each $\\beta_1$ in (6.16) equal to the coefficient from the simple linear regression of $Y$ onto $X_j$. One can show that this coefficient is proportional to the correlation between $Y$ and $X_j$. Hence, in computing $Z_1 = \\sum_{j=1}^{p} \\beta_1 X_j$, PLS places the highest weight on the variables that are most strongly related to the response.\n",
    "\n",
    "Figure 6.21 displays an example of PLS on a synthetic dataset with Sales in each of 100 regions as the response, and two predictors: Population Size and Advertising Spending. The solid green line indicates the first PLS direction, while the dotted line shows the first principal component direction. PLS has chosen a direction that has less change in the ad dimension per unit change in the pop dimension, relative to PCA. This suggests that pop is more highly correlated with the response than is ad. The PLS direction does not fit the predictors as closely as does PCA, but it does a better job explaining the response.\n",
    "\n",
    "To identify the second PLS direction we first adjust each of the variables for $Z_1$, by regressing each variable on $Z_1$ and taking residuals. These residuals can be interpreted as the remaining information that has not been explained by the first PLS direction. We then compute $Z_2$ using this $orthogonalized$ $data$ in exactly the same fashion as $Z_1$ was computed based on the original data. This iterative approach can be repeated $M$ times to identify multiple PLS components $Z_1, \\ldots, Z_M$. Finally, at the end of this procedure, we use least squares to fit a linear model to predict $Y$ using $Z_1, \\ldots, Z_M$ in exactly the same fashion as for PCR.\n",
    "\n",
    "As with PCR, the number $M$ of partial least squares directions used in PLS is a tuning parameter that is typically chosen by cross-validation. We generally standardize the predictors and response before performing PLS. PLS is popular in the field of chemometrics, where many variables arise from digitized spectrometry signals. In practice, it often performs no better than ridge regression or PCR. While the supervised dimension reduction of PLS can reduce bias, it also has the potential to increase variance, so that the overall benefit of PLS relative to PCR is a wash.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edeab45",
   "metadata": {},
   "source": [
    "#### Considerations in High Dimensions\n",
    "\n",
    "##### High-Dimensional Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd80cc23",
   "metadata": {},
   "source": [
    "\n",
    "Most traditional statistical techniques for regression and classification are intended for the low-dimensional setting in which $n$, the number of observations, is much greater than $p$, the number of features. This is due in part to the fact that throughout most of the field’s history, the bulk of scientific problems requiring the use of statistics have been low-dimensional. For instance, consider the task of developing a model to predict a patient’s blood pressure on the basis of his or her age, sex, and body mass index (BMI). There are three predictors, or four if an intercept is included in the model, and perhaps several thousand patients for whom blood pressure and age, sex, and BMI are available. Hence $n \\gg p$, and so the problem is low-dimensional. (By dimension here we are referring to the size of $p$.)\n",
    "\n",
    "In the past 20 years, new technologies have changed the way that data are collected in fields as diverse as finance, marketing, and medicine. It is now commonplace to collect an almost unlimited number of feature measurements ($p$ very large). While $p$ can be extremely large, the number of observations $n$ is often limited due to cost, sample availability, or other considerations. Two examples are as follows:\n",
    "\n",
    "1. Rather than predicting blood pressure on the basis of just age, sex, and BMI, one might also collect measurements for half a million $single$ $nucleotide$ $polymorphisms$ (SNPs; these are individual DNA mutations that are relatively common in the population) for inclusion in the predictive model. Then $n = 200$ and $p = 500,000$.\n",
    "\n",
    "2. A marketing analyst interested in understanding people’s online shopping patterns could treat as features all of the search terms entered by users of a search engine. This is sometimes known as the “bag-of-words” model. The same researcher might have access to the search histories of only a few hundred or a few thousand search engine users who have consented to share their information with the researcher. For a given user, each of the $p$ search terms is scored present (1) or absent (0) or absent (1), creating a large binary feature vector. Then $n$ $\\approx$ 1,000 and $p$ is much larger.\n",
    "\n",
    "Data sets containing more features than observations are often referred\n",
    "to as $high-dimensional$. Classical approaches such as least squares linear\n",
    "regression are not appropriate in this setting. Many of the issues that arise\n",
    "in the analysis of high-dimensional data were discussed earlier in this book,\n",
    "since they apply also when $n>p$: these include the role of the bias-variance\n",
    "trade-off and the danger of overfitting. Though these issues are always rele\n",
    "vant, they can become particularly important when the number of features\n",
    "is very large relative to the number of observations.\n",
    "\n",
    "We have defined the high-dimensional setting as the case where the num\n",
    "ber of features p is larger than the number of observations n. But the con\n",
    "siderations that we will now discuss certainly also apply if p is slightly\n",
    "smaller than n, and are best always kept in mind when performing super\n",
    "vised learning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79eba15",
   "metadata": {},
   "source": [
    "##### What Goes Wrong in High Dimensions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be5f77c",
   "metadata": {},
   "source": [
    "\n",
    "In order to illustrate the need for extra care and specialized techniques\n",
    "for regression and classification when p>n, we begin by examining what\n",
    "can go wrong if we apply a statistical technique not intended for the high\n",
    "dimensional setting. For this purpose, we examine least squares regression.\n",
    "But the same concepts apply to logistic regression, linear discriminant analysis, and other classical statistical approaches.\n",
    "\n",
    "When the number of features p is as large as, or larger than, the number\n",
    "of observations n, least squares as described in Chapter 3 cannot (or rather,\n",
    "should not) be performed. The reason is simple: regardless of whether or\n",
    "not there truly is a relationship between the features and the response,\n",
    "least squares will yield a set of coefficient estimates that result in a perfect\n",
    "fit to the data, such that the residuals are zero.\n",
    "\n",
    "An example is shown in Figure 6.22 with $p =1$ feature (plus an intercept)\n",
    "in two cases: when there are 20 observations, and when there are only\n",
    "two observations. When there are 20 observations, n>pand the least\n",
    "squares regression line does not perfectly fit the data; instead, the regression\n",
    "line seeks to approximate the 20 observations as well as possible. On the\n",
    "other hand, when there are only two observations, then regardless of the\n",
    "values of those observations, the regression line will fit the data exactly.\n",
    "This is problematic because this perfect fit will almost certainly lead to\n",
    "overfitting of the data. In other words, though it is possible to perfectly fit\n",
    "the training data in the high-dimensional setting, the resulting linear model\n",
    "will perform extremely poorly on an independent test set, and therefore\n",
    "does not constitute a useful model. In fact, we can see that this happened\n",
    "in Figure 6.22: the least squares line obtained in the right-hand panel will\n",
    "perform very poorly on a test set comprised of the observations in the left\n",
    "hand panel. The problem is simple: when $p>n$ or p $\\approx$ n, a simple least\n",
    "squares regression line is too flexible and hence overfits the data.\n",
    "\n",
    "Figure 6.23 further illustrates the risk of carelessly applying least squares\n",
    "when the number of features $p$ is large. Data were simulated with $n = 20$\n",
    "observations, and regression was performed with between 1 and 20 features, each of which was completely unrelated to the response. As shown in the\n",
    "figure, the model $R^2$ increases to 1 as the number of features included in the\n",
    "model increases, and correspondingly the training set MSE decreases to 0\n",
    "as the number of features increases, **even though the features are completely\n",
    "unrelated to the response**. On the other hand, the MSE on an independent\n",
    "test set becomes extremely large as the number of features included in the\n",
    "model increases, because including the additional predictors leads to a vast\n",
    "increase in the variance of the coefficient estimates. Looking at the test\n",
    "set MSE, it is clear that the best model contains at most a few variables.\n",
    "However, someone who carelessly examines only the $R^2$ or the training set\n",
    "MSE might erroneously conclude that the model with the greatest number\n",
    "of variables is best. This indicates the importance of applying extra care\n",
    "when analyzing data sets with a large number of variables, and of always\n",
    "evaluating model performance on an independent test set.\n",
    "\n",
    "In Section 6.1.3, we saw a number of approaches for adjusting the training\n",
    "set RSS or $R^2$ in order to account for the number of variables used to fit\n",
    "a least squares model. Unfortunately, the $C_p$, AIC, and BIC approaches\n",
    "are not appropriate in the high-dimensional setting, because estimating $\\hat{\\sigma}^2$\n",
    "is problematic. (For instance, the formula for $\\hat{\\sigma}^2$ from Chapter 3 yields an\n",
    "estimate $\\hat{\\sigma}^2$ = 0 in this setting.) Similarly, problems arise in the application\n",
    "of adjusted $R^2$ in the high-dimensional setting, since one can easily obtain\n",
    "a model with an adjusted $R^2$ value of 1. Clearly, alternative approaches\n",
    "that are better-suited to the high-dimensional setting are required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7691f557",
   "metadata": {},
   "source": [
    "##### Regression in High Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66b5d12",
   "metadata": {},
   "source": [
    "\n",
    "It turns out that many of the methods seen in this chapter for fitting\n",
    "less flexible least squares models, such as forward stepwise selection, ridge\n",
    "regression, the lasso, and principal components regression, are particularly\n",
    "useful for performing regression in the high-dimensional setting. Essentially,\n",
    "these approaches avoid overfitting by using a less flexible fitting approach\n",
    "than least squares.\n",
    "\n",
    "Figure 6.24 illustrates the performance of the lasso in a simple simulated\n",
    "example. There are $p = 20$, 50, or 2,000 features, of which 20 are truly\n",
    "associated with the outcome. The lasso was performed on $n = 100$ training\n",
    "observations, and the mean squared error was evaluated on an independent\n",
    "test set. As the number of features increases, the test set error increases.\n",
    "When $p = 20$, the lowest validation set error was achieved when $\\lambda$ in (6.7) was small; however, when $p$ was larger then the lowest validation\n",
    "set error was achieved using a larger value of $\\lambda$. In each boxplot, rather\n",
    "than reporting the values of $\\lambda$ used, the *degrees of freedom* of the resulting\n",
    "lasso solution is displayed; this is simply the number of non-zero coefficient\n",
    "estimates in the lasso solution, and is a measure of the flexibility of the\n",
    "lasso fit. Figure 6.24 highlights three important points: (1) regularization\n",
    "or shrinkage plays a key role in high-dimensional problems, (2) appropriate\n",
    "tuning parameter selection is crucial for good predictive performance, and\n",
    "(3) the test error tends to increase as the dimensionality of the problem\n",
    "(i.e. the number of features or predictors) increases, unless the additional\n",
    "features are truly associated with the response.\n",
    "\n",
    "The third point above is in fact a key principle in the analysis of high\n",
    "dimensional data, which is known as the *curse of dimensionality*. One might\n",
    "think that as the number of features used to fit a model increases, the\n",
    "quality of the fitted model will increase as well. However, comparing the\n",
    "left-hand and right-hand panels in Figure 6.24, we see that this is not\n",
    "necessarily the case: in this example, the test set MSE almost doubles as\n",
    "p increases from 20 to 2,000. In general, *adding additional signal features\n",
    "that are truly associated with the response will improve the fitted model*,\n",
    "in the sense of leading to a reduction in test set error. However, adding\n",
    "noise features that are not truly associated with the response will lead\n",
    "to a deterioration in the fitted model, and consequently an increased test\n",
    "set error. This is because noise features increase the dimensionality of the\n",
    "problem, exacerbating the risk of overfitting (since noise features may be\n",
    "assigned nonzero coefficients due to chance associations with the response\n",
    "on the training set) without any potential upside in terms of improved test\n",
    "set error. Thus, we see that new technologies that allow for the collection\n",
    "of measurements for thousands or millions of features are a double-edged\n",
    "sword: they can lead to improved predictive models if these features are in\n",
    "fact relevant to the problem at hand, but will lead to worse results if the\n",
    "features are not relevant. Even if they are relevant, the variance incurred\n",
    "in fitting their coefficients may outweigh the reduction in bias that they\n",
    "bring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeb2a05",
   "metadata": {},
   "source": [
    "##### Interpreting Results in High Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dacfb07",
   "metadata": {},
   "source": [
    "\n",
    "When we perform the lasso, ridge regression, or other regression proce\n",
    "dures in the high-dimensional setting, we must be quite cautious in the way\n",
    "that we report the results obtained. In Chapter 3, we learned about multi\n",
    "collinearity, the concept that the variables in a regression might be corre\n",
    "lated with each other. In the high-dimensional setting, the multicollinearity\n",
    "problem is extreme: any variable in the model can be written as a linear\n",
    "combination of all of the other variables in the model. Essentially, this\n",
    "means that we can never know exactly which variables (if any) truly are\n",
    "predictive of the outcome, and we can never identify the best coefficients\n",
    "for use in the regression. At most, we can hope to assign large regression\n",
    "coefficients to variables that are correlated with the variables that truly are\n",
    "predictive of the outcome.\n",
    "\n",
    "For instance, suppose that we are trying to predict blood pressure on the\n",
    "basis of half a million SNPs, and that forward stepwise selection indicates\n",
    "that 17 of those SNPs lead to a good predictive model on the training data.\n",
    "It would be incorrect to conclude that these 17 SNPs predict blood pressure\n",
    "more effectively than the other SNPs not included in the model. There are\n",
    "likely to be many sets of 17 SNPs that would predict blood pressure just\n",
    "as well as the selected model. If we were to obtain an independent data set\n",
    "and perform forward stepwise selection on that data set, we would likely\n",
    "obtain a model containing a different, and perhaps even non-overlapping,\n",
    "set of SNPs. This does not detract from the value of the model obtained—\n",
    "for instance, the model might turn out to be very effective in predicting\n",
    "blood pressure on an independent set of patients, and might be clinically\n",
    "useful for physicians. But we must be careful not to overstate the results\n",
    "obtained, and to make it clear that what we have identified is simply one\n",
    "of *many possible models* for predicting blood pressure, and that it must be\n",
    "further validated on independent data sets.\n",
    "\n",
    "It is also important to be particularly careful in reporting errors and mea\n",
    "sures of model fit in the high-dimensional setting. We have seen that when\n",
    "$p>n$, it is easy to obtain a useless model that has zero residuals. There\n",
    "fore, one should never use sum of squared errors, p-values, $R^2$ statistics, or\n",
    "other traditional measures of model fit on the training data as evidence of\n",
    "a good model fit in the high-dimensional setting. For instance, as we saw\n",
    "in Figure 6.23, one can easily obtain a model with $R^2 =1$ when $p>n$.\n",
    "Reporting this fact might mislead others into thinking that a statistically\n",
    "valid and useful model has been obtained, whereas in fact this provides\n",
    "absolutely no evidence of a compelling model. It is important to instead\n",
    "report results on an independent test set, or cross-validation errors. For\n",
    "instance, the MSE or $R^2$ on an independent test set is a valid measure of\n",
    "model fit, but the MSE on the training set certainly is not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c661afcd",
   "metadata": {},
   "source": [
    "#### Lab: Linear Models and Regularization Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64bfdc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "from statsmodels.api import OLS\n",
    "import sklearn.model_selection as skm\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ba85bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting l0bnb\n",
      "  Downloading l0bnb-1.0.0.tar.gz (79 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\zoe oladokun\\appdata\\local\\anaconda3\\envs\\islp_clean\\lib\\site-packages (from l0bnb) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\zoe oladokun\\appdata\\local\\anaconda3\\envs\\islp_clean\\lib\\site-packages (from l0bnb) (1.16.3)\n",
      "Collecting numba>=0.53.1 (from l0bnb)\n",
      "  Downloading numba-0.63.1-cp311-cp311-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting llvmlite<0.47,>=0.46.0dev0 (from numba>=0.53.1->l0bnb)\n",
      "  Downloading llvmlite-0.46.0-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Downloading numba-0.63.1-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.8/2.7 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 4.4 MB/s  0:00:00\n",
      "Downloading llvmlite-0.46.0-cp311-cp311-win_amd64.whl (38.1 MB)\n",
      "   ---------------------------------------- 0.0/38.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.3/38.1 MB 6.1 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.4/38.1 MB 5.6 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.4/38.1 MB 5.4 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 4.5/38.1 MB 5.5 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 5.8/38.1 MB 5.4 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 6.8/38.1 MB 5.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 8.1/38.1 MB 5.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 9.4/38.1 MB 5.5 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 10.5/38.1 MB 5.5 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 11.8/38.1 MB 5.5 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 13.1/38.1 MB 5.6 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 14.2/38.1 MB 5.6 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 15.5/38.1 MB 5.6 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 16.8/38.1 MB 5.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 18.1/38.1 MB 5.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 19.1/38.1 MB 5.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 20.4/38.1 MB 5.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 21.8/38.1 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 23.1/38.1 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 24.4/38.1 MB 5.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 25.4/38.1 MB 5.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 26.7/38.1 MB 5.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.0/38.1 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.4/38.1 MB 5.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 30.7/38.1 MB 5.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.0/38.1 MB 5.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.3/38.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 34.6/38.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 35.9/38.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.2/38.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.1/38.1 MB 5.7 MB/s  0:00:06\n",
      "Building wheels for collected packages: l0bnb\n",
      "  Building wheel for l0bnb (pyproject.toml): started\n",
      "  Building wheel for l0bnb (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for l0bnb: filename=l0bnb-1.0.0-py3-none-any.whl size=22409 sha256=55200f080d10bd81e9871b3edbb3e2ee72bb395b13f557c3b0a72d28219cc3e6\n",
      "  Stored in directory: c:\\users\\zoe oladokun\\appdata\\local\\pip\\cache\\wheels\\56\\b6\\7a\\2a78772d92aa67f0d038759a09c7e950b5a708d5ecd5c0e38d\n",
      "Successfully built l0bnb\n",
      "Installing collected packages: llvmlite, numba, l0bnb\n",
      "\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ---------------------------------------- 0/3 [llvmlite]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   ------------- -------------------------- 1/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [l0bnb]\n",
      "   -------------------------- ------------- 2/3 [l0bnb]\n",
      "   -------------------------- ------------- 2/3 [l0bnb]\n",
      "   -------------------------- ------------- 2/3 [l0bnb]\n",
      "   ---------------------------------------- 3/3 [l0bnb]\n",
      "\n",
      "Successfully installed l0bnb-1.0.0 llvmlite-0.46.0 numba-0.63.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from ISLP.models import \\\n",
    "    (Stepwise,\n",
    "     sklearn_selected,\n",
    "     sklearn_selection_path)\n",
    "%pip install l0bnb\n",
    "from l0bnb import fit_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b970eb",
   "metadata": {},
   "source": [
    "##### Subset Selection Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4100f8f",
   "metadata": {},
   "source": [
    "Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8db37719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hitters = load_data('Hitters')\n",
    "np.isnan(Hitters['Salary']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a87f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hitters = Hitters.dropna();\n",
    "Hitters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f88e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nCp(sigma2, estimator, X, Y):\n",
    "    \"Negative Cp statistic\"\n",
    "    n, p = X.shape\n",
    "    Yhat = estimator.predict(X)\n",
    "    RSS = np.sum((Y- Yhat)**2)\n",
    "    return-(RSS + 2 * p * sigma2) / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5a638bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = MS(Hitters.columns.drop('Salary')).fit(Hitters)\n",
    "Y = np.array(Hitters['Salary'])\n",
    "X = design.transform(Hitters)\n",
    "sigma2 = OLS(Y,X).fit().scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2eeb429",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_Cp = partial(nCp, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4903b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = Stepwise.first_peak(design,\n",
    "                               direction='forward',\n",
    "                               max_terms=len(design.terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95c90131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Assists',\n",
       " 'AtBat',\n",
       " 'CAtBat',\n",
       " 'CHits',\n",
       " 'CHmRun',\n",
       " 'CRBI',\n",
       " 'CRuns',\n",
       " 'CWalks',\n",
       " 'Division',\n",
       " 'Errors',\n",
       " 'Hits',\n",
       " 'HmRun',\n",
       " 'League',\n",
       " 'NewLeague',\n",
       " 'PutOuts',\n",
       " 'RBI',\n",
       " 'Runs',\n",
       " 'Walks',\n",
       " 'Years')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters_MSE = sklearn_selected(OLS,\n",
    "                               strategy,\n",
    "                               scoring=\"neg_mean_squared_error\")\n",
    "hitters_MSE.fit(Hitters, Y)\n",
    "hitters_MSE.selected_state_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d720b272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Assists',\n",
       " 'AtBat',\n",
       " 'CAtBat',\n",
       " 'CRBI',\n",
       " 'CRuns',\n",
       " 'CWalks',\n",
       " 'Division',\n",
       " 'Hits',\n",
       " 'PutOuts',\n",
       " 'Walks')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters_Cp = sklearn_selected(OLS,\n",
    "                              strategy,\n",
    "                              scoring=neg_Cp)\n",
    "hitters_Cp.fit(Hitters, Y)\n",
    "hitters_Cp.selected_state_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944b080d",
   "metadata": {},
   "source": [
    "Choosing Among Models Using the Validation Set Approach and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78f3925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = Stepwise.fixed_steps(design,\n",
    "                                len(design.terms),\n",
    "                                direction='forward')\n",
    "full_path = sklearn_selection_path(OLS, strategy, scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6964a9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_path.fit(Hitters, Y)\n",
    "Yhat_in = full_path.predict(Hitters)\n",
    "Yhat_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b82b7ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse_fig, ax = subplots(figsize=(8,8))\n",
    "insample_mse = ((Yhat_in- Y[:,None])**2).mean(0)\n",
    "n_steps = insample_mse.shape[0]\n",
    "ax.plot(np.arange(n_steps),\n",
    "        insample_mse,\n",
    "        'k', # color black\n",
    "        label='In-sample')\n",
    "ax.set_ylabel('MSE',\n",
    "              fontsize=20)\n",
    "ax.set_xlabel('# steps of forward stepwise',\n",
    "                fontsize=20)\n",
    "ax.set_xticks(np.arange(n_steps)[::2])\n",
    "ax.legend()\n",
    "ax.set_ylim([50000,250000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a98e1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 5\n",
    "kfold = skm.KFold(K,\n",
    "                  random_state=0,\n",
    "                  shuffle=True)\n",
    "Yhat_cv = skm.cross_val_predict(full_path,\n",
    "                                Hitters,\n",
    "                                Y,\n",
    "                                cv=kfold)\n",
    "Yhat_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85b533c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_mse = []\n",
    "for train_idx, test_idx in kfold.split(Y):\n",
    "    errors = (Yhat_cv[test_idx]- Y[test_idx,None])**2\n",
    "    cv_mse.append(errors.mean(0)) # column means\n",
    "\n",
    "cv_mse = np.array(cv_mse).T\n",
    "cv_mse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f178fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuAAAAK6CAYAAAB4y+mYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAApYNJREFUeJzs3XlcVPX+x/H3gICIMIIKiLngRhbmWq6l1lUzl7yZLRhFde22qJl669ptMVusNOtmWd1+rWZ5u5m2mVdzvSYuYea+ZCouIKY4CCrr9/fHaUZHUBFhhuX1fDzOY2bO+c45nzOivvnO93yPzRhjBAAAAMAjfLxdAAAAAFCVEMABAAAADyKAAwAAAB5EAAcAAAA8iAAOAAAAeBABHAAAAPAgAjgAAADgQQRwAAAAwIMI4AAAAIAHEcABAAAAD6qQAXzixIm68sorFRwcrPDwcA0aNEjbtm1za5OQkCCbzea2dOrUya1Ndna2RowYoTp16igoKEgDBw7Uvn373Nqkp6crPj5edrtddrtd8fHxOnr0qFub5ORkDRgwQEFBQapTp45GjhypnJwctzYbNmxQ9+7dFRgYqPr162vChAkyxpTehwIAAIAKoUIG8KVLl+qhhx7SypUrtWDBAuXl5al3797Kyspya3f99dcrJSXFtcydO9dt+6hRozR79mzNnDlTy5cvV2Zmpvr376/8/HxXm7i4OK1bt07z5s3TvHnztG7dOsXHx7u25+fnq1+/fsrKytLy5cs1c+ZMzZo1S2PGjHG1ycjIUK9evRQVFaU1a9Zo6tSpmjx5sqZMmVJGnxAAAADKK5upBN2whw4dUnh4uJYuXaprrrlGktUDfvToUc2ZM6fI9zgcDtWtW1fTp0/XrbfeKkk6cOCAGjRooLlz56pPnz7asmWLLrvsMq1cuVIdO3aUJK1cuVKdO3fW1q1bFRMTo++//179+/fX3r17FRUVJUmaOXOmEhISlJaWppCQEL311lsaN26cDh48qICAAEnSiy++qKlTp2rfvn2y2Wxl/AkBAACgvKjm7QJKg8PhkCSFhYW5rV+yZInCw8NVq1Ytde/eXc8//7zCw8MlSUlJScrNzVXv3r1d7aOiohQbG6sVK1aoT58+SkxMlN1ud4VvSerUqZPsdrtWrFihmJgYJSYmKjY21hW+JalPnz7Kzs5WUlKSevbsqcTERHXv3t0Vvp1txo0bp927dys6OrrQOWVnZys7O9v1uqCgQEeOHFHt2rUJ7AAAAOWQMUbHjh1TVFSUfHzOPtCkwgdwY4xGjx6tbt26KTY21rW+b9++GjJkiBo1aqRdu3bpySef1LXXXqukpCQFBAQoNTVV/v7+Cg0NddtfRESEUlNTJUmpqamuwH668PBwtzYRERFu20NDQ+Xv7+/WpnHjxoWO49xWVACfOHGinnnmmQv8NAAAAOBte/fu1SWXXHLW7RU+gA8fPlzr16/X8uXL3dY7h5VIUmxsrDp06KBGjRrpu+++00033XTW/Rlj3HqYi+ptLo02zpE/Z+vNHjdunEaPHu167XA41LBhQ+3du1chISFnrR8AAADekZGRoQYNGig4OPic7Sp0AB8xYoS+/vprLVu27Jy/ZUhSvXr11KhRI+3YsUOSFBkZqZycHKWnp7v1gqelpalLly6uNgcPHiy0r0OHDrl6sCMjI7Vq1Sq37enp6crNzXVr4+wNP/04kgr1njsFBAS4DVlxCgkJIYADAACUY+cbLlwhZ0Exxmj48OH68ssvtWjRoiKHcJzp8OHD2rt3r+rVqydJat++vfz8/LRgwQJXm5SUFG3cuNEVwDt37iyHw6HVq1e72qxatUoOh8OtzcaNG5WSkuJqM3/+fAUEBKh9+/auNsuWLXObmnD+/PmKiooqNDQFAAAAlVuFnAXlwQcf1KeffqqvvvpKMTExrvV2u12BgYHKzMzU+PHjNXjwYNWrV0+7d+/W448/ruTkZG3ZssX1tcADDzygb7/9Vh9++KHCwsI0duxYHT58WElJSfL19ZVkjSU/cOCA3nnnHUnSfffdp0aNGumbb76RZE1D2KZNG0VERGjSpEk6cuSIEhISNGjQIE2dOlWSNXwkJiZG1157rR5//HHt2LFDCQkJeuqpp9ymKzyXjIwM2e12ORwOesABAADKoWLnNVMBSSpy+eCDD4wxxhw/ftz07t3b1K1b1/j5+ZmGDRuau+66yyQnJ7vt58SJE2b48OEmLCzMBAYGmv79+xdqc/jwYTN06FATHBxsgoODzdChQ016erpbmz179ph+/fqZwMBAExYWZoYPH25Onjzp1mb9+vXm6quvNgEBASYyMtKMHz/eFBQUFPucHQ6HkWQcDkfxPygAAAB4THHzWoXsAa+K6AEHAKBoxhjl5eW53UgPKAu+vr6qVq3aWcd4FzevVeiLMAEAQNWWk5OjlJQUHT9+3NuloIqoUaOG6tWrJ39//xLvgwAOAAAqpIKCAu3atUu+vr6KioqSv78/N6tDmTHGKCcnR4cOHdKuXbvUvHnzc95s51wI4AAAoELKyclRQUGBGjRooBo1ani7HFQBgYGB8vPz0549e5STk6Pq1auXaD8VchpCAAAAp5L2QgIlURo/b/zEAgAAAB5EAAcAAAA8iAAOAACAUmOz2TRnzhxvl1GuEcABAAA8zHnXbFRNBHAAAADAgwjgAACg0jDGKCsry+PLxdxYvEePHho5cqQeffRRhYWFKTIyUuPHjz/ne3JycjR8+HDVq1dP1atXV+PGjTVx4kTX9ilTpqhVq1YKCgpSgwYN9OCDDyozM9O1/cMPP1StWrX07bffKiYmRjVq1NDNN9+srKwsffTRR2rcuLFCQ0M1YsQItzuMNm7cWM8++6zi4uJUs2ZNRUVFaerUqeesdf/+/br11lsVGhqq2rVr68Ybb9Tu3btL9FlVFswDDgAAKo3jx4+rZs2aHj9uZmamgoKCSvz+jz76SKNHj9aqVauUmJiohIQEde3aVb169Sqy/euvv66vv/5an3/+uRo2bKi9e/dq7969ru0+Pj56/fXX1bhxY+3atUsPPvigHn30UU2bNs3V5vjx43r99dc1c+ZMHTt2TDfddJNuuukm1apVS3PnztVvv/2mwYMHq1u3brr11ltd75s0aZIef/xxjR8/Xv/973/1yCOP6NJLLy2y1uPHj6tnz566+uqrtWzZMlWrVk3PPfecrr/+eq1fv/6i7iZZkRHAAQAAvOyKK67Q008/LUlq3ry53njjDS1cuPCsATw5OVnNmzdXt27dZLPZ1KhRI7fto0aNcj2Pjo7Ws88+qwceeMAtgOfm5uqtt95S06ZNJUk333yzpk+froMHD6pmzZq67LLL1LNnTy1evNgtgHft2lV///vfJUktWrTQjz/+qFdffbXIWmfOnCkfHx/93//9n+supR988IFq1aqlJUuWqHfv3iX4tCo+AjgAAKg0atSo4TbUwpPHvRhXXHGF2+t69eopLS1NknT//ffrk08+cW3LzMxUQkKCevXqpZiYGF1//fXq37+/W5hdvHixXnjhBW3evFkZGRnKy8vTyZMnlZWV5eqpr1Gjhit8S1JERIQaN27s9g1CRESEqw6nzp07F3r92muvFXleSUlJ+vXXXxUcHOy2/uTJk9q5c+f5PpZKiwAOAAAqDZvNdlFDQbzFz8/P7bXNZlNBQYEkacKECRo7dqzb9nbt2mnXrl36/vvv9cMPP+iWW27Rn/70J33xxRfas2ePbrjhBt1///169tlnFRYWpuXLl+vee+9Vbm7uOY95rjrOxdm7faaCggK1b99eM2bMKLStbt26591vZUUABwAAKMfCw8MVHh5eaH1ISIhuvfVW3Xrrrbr55pt1/fXX68iRI/rpp5+Ul5enV155xXXb9M8//7zU6lm5cmWh15deemmRbdu1a6d///vfCg8PV0hISKnVUNExCwoAAEAF8+qrr2rmzJnaunWrtm/frv/85z+KjIxUrVq11LRpU+Xl5Wnq1Kn67bffNH36dL399tulduwff/xRL7/8srZv364333xT//nPf/Twww8X2Xbo0KGqU6eObrzxRv3vf//Trl27tHTpUj388MPat29fqdVU0RDAAQAAKpiaNWvqpZdeUocOHXTllVdq9+7dmjt3rnx8fNSmTRtNmTJFL730kmJjYzVjxgy3KQov1pgxY5SUlKS2bdvq2Wef1SuvvKI+ffoU2bZGjRpatmyZGjZsqJtuukktW7bUPffcoxMnTlTpHnGbuZiJK+ExGRkZstvtcjgcVfoHFgAAp5MnT2rXrl2Kjo5W9erVvV1OldC4cWONGjXKbZaVquZcP3fFzWv0gAMAAAAeRAAHAAAAPIhZUAAAAFAsVf0W8qWFHnAAAADAgwjgAAAAgAcRwAEAAAAPIoADAAAAHkQABwAAyMqSbDZrycrydjWo5AjgAAAAgAcRwAEAAFAmPvzwQ9WqVcv1evz48WrTps0535OQkKBBgwaVaV1ns3v3btlsNq1bt65Mj0MABwAA8ILU1FSNGDFCTZo0UUBAgBo0aKABAwZo4cKF3i6tzIwdO7bUz89Tobk0cSMeAAAAD9u9e7e6du2qWrVq6eWXX9YVV1yh3Nxc/fe//9VDDz2krVu3FnpPbm6u/Pz8vFBt6alZs6Zq1qzp7TK8jh5wAABQeRhjXURZksWpJO815oLKfPDBB2Wz2bR69WrdfPPNatGihS6//HKNHj1aK1eulCTZbDa9/fbbuvHGGxUUFKTnnntOkvTWW2+padOm8vf3V0xMjKZPn+627/Hjx6thw4YKCAhQVFSURo4c6do2bdo0NW/eXNWrV1dERIRuvvnmIusrKCjQJZdcorfffttt/dq1a2Wz2fTbb79JkqZMmaJWrVopKChIDRo00IMPPqjMzMyznveZQ1Dy8/M1evRo1apVS7Vr19ajjz4qc8ZnOW/ePHXr1s3Vpn///tq5c6dre3R0tCSpbdu2stls6tGjh2vbBx98oJYtW6p69eq69NJLNW3aNLd9r169Wm3btlX16tXVoUMH/fzzz2etvTQRwAEAQOVx/LhUs+aFLxERp/YREXHh7z9+vNglHjlyRPPmzdNDDz2koKCgQttPHzP99NNP68Ybb9SGDRt0zz33aPbs2Xr44Yc1ZswYbdy4UX/961919913a/HixZKkL774Qq+++qreeecd7dixQ3PmzFGrVq0kST/99JNGjhypCRMmaNu2bZo3b56uueaaImv08fHRbbfdphkzZrit//TTT9W5c2c1adLE1e7111/Xxo0b9dFHH2nRokV69NFHi/1ZvPLKK3r//ff13nvvafny5Tpy5Ihmz57t1iYrK0ujR4/WmjVrtHDhQvn4+OjPf/6zCgoKJFkhWpJ++OEHpaSk6Msvv5Qkvfvuu/rHP/6h559/Xlu2bNELL7ygJ598Uh999JFrv/3791dMTIySkpI0fvx4jR07tti1XxSDCsHhcBhJxuFweLsUAADKhRMnTpjNmzebEydOnFqZmWmM1R/t2SUzs9h1r1q1ykgyX3755TnbSTKjRo1yW9elSxczbNgwt3VDhgwxN9xwgzHGmFdeecW0aNHC5OTkFNrfrFmzTEhIiMnIyChWnWvXrjU2m83s3r3bGGNMfn6+qV+/vnnzzTfP+p7PP//c1K5d2/X6gw8+MHa73fX66aefNq1bt3a9rlevnnnxxRddr3Nzc80ll1xibrzxxrMeIy0tzUgyGzZsMMYYs2vXLiPJ/Pzzz27tGjRoYD799FO3dc8++6zp3LmzMcaYd955x4SFhZmsrCzX9rfeeqvIfZ2uyJ+7PxQ3r9EDDgAAKo8aNaTMzAtfDh48tY+DBy/8/TVqFLtE88cQC5vNdt62HTp0cHu9ZcsWde3a1W1d165dtWXLFknSkCFDdOLECTVp0kTDhg3T7NmzlZeXJ0nq1auXGjVqpCZNmig+Pl4zZszQ8T967mfMmOEan12zZk3973//U9u2bXXppZfqs88+kyQtXbpUaWlpuuWWW1zHXrx4sXr16qX69esrODhYd955pw4fPqysYsyl7nA4lJKSos6dO7vWVatWrdA579y5U3FxcWrSpIlCQkJcQ06Sk5PPuu9Dhw5p7969uvfee93O67nnnnMNX9myZYtat26tGqf92Z1eS1kigAMAgMrDZpOCgkq2OJXkvcUI007NmzeXzWZzheZzKWqIypnB3RjjWtegQQNt27ZNb775pgIDA/Xggw/qmmuuUW5uroKDg7V27Vp99tlnqlevnp566im1bt1aR48e1cCBA7Vu3TrX4gzBQ4cO1aeffirJGn7Sp08f1alTR5K0Z88e3XDDDYqNjdWsWbOUlJSkN998U5J1wWhpGTBggA4fPqx3331Xq1at0qpVqyRJOTk5Z32Pc3jKu+++63ZeGzdudI2xd/4i5A0EcAAAAA8KCwtTnz599OabbxbZU3z06NGzvrdly5Zavny527oVK1aoZcuWrteBgYEaOHCgXn/9dS1ZskSJiYnasGGDJKuH+U9/+pNefvllrV+/Xrt379aiRYsUHBysZs2auZbAwEBJUlxcnDZs2KCkpCR98cUXGjp0qOs4P/30k/Ly8vTKK6+oU6dOatGihQ4cOFDsz8Fut6tevXquQCxJeXl5SkpKcr0+fPiwtmzZoieeeELXXXedWrZsqfT0dLf9+Pv7S7Iu6HSKiIhQ/fr19dtvv7mdV7NmzVw96Jdddpl++eUXnThxwvW+02spS0xDCAAA4GHTpk1Tly5ddNVVV2nChAm64oorlJeXpwULFuitt946a+/43/72N91yyy1q166drrvuOn3zzTf68ssv9cMPP0iybnyTn5+vjh07qkaNGpo+fboCAwPVqFEjffvtt/rtt990zTXXKDQ0VHPnzlVBQYFiYmLOWmd0dLS6dOmie++9V3l5ebrxxhtd25o2baq8vDxNnTpVAwYM0I8//lho1pTzefjhh/Xiiy+qefPmatmypaZMmeL2C0hoaKhq166tf/3rX6pXr56Sk5P197//3W0f4eHhCgwM1Lx583TJJZeoevXqstvtGj9+vEaOHKmQkBD17dtX2dnZ+umnn5Senq7Ro0crLi5O//jHP3TvvffqiSee0O7duzV58uQLqr/EzjlCHOUGF2ECAODuXBfDXbDTL968gAsqL8aBAwfMQw89ZBo1amT8/f1N/fr1zcCBA83ixYuNMdZFmLNnzy70vmnTppkmTZoYPz8/06JFC/Pxxx+7ts2ePdt07NjRhISEmKCgINOpUyfzww8/GGOM+d///me6d+9uQkNDTWBgoLniiivMv//97/PW+eabbxpJ5s477yy0bcqUKaZevXomMDDQ9OnTx3z88cdGkklPTzfGnP8izNzcXPPwww+bkJAQU6tWLTN69Ghz5513ul2EuWDBAtOyZUsTEBBgrrjiCrNkyZJCn827775rGjRoYHx8fEz37t1d62fMmGHatGlj/P39TWhoqLnmmmvcLn5NTEw0rVu3Nv7+/qZNmzZm1qxZHrkI02aMFwfAoNgyMjJkt9vlcDgUEhLi7XIAAPC6kydPateuXYqOjlb16tUvbmdZWdZ0gpJ1UWURY68B6dw/d8XNawxBAQAACAq64JvpACXFRZgAAACABxHAAQAAAA8igAMAAAAeRAAHAAAVGvNJwJNK4+eNAA4AACokPz8/SXLdTh3wBOfPm/PnrySYBQUAAFRIvr6+qlWrltLS0iRJNWrUKHSbdqC0GGN0/PhxpaWlqVatWvL19S3xvgjgAACgwoqMjJQkVwgHylqtWrVcP3clRQAHAAAVls1mU7169RQeHq7c3Fxvl4NKzs/P76J6vp0I4AAAoMLz9fUtlWAEeAIXYQIAAAAeRAAHAAAAPIgADgAAAHgQARwAAADwIAI4AAAA4EEEcAAAAMCDCOAAAACABxHAAQAAAA8igAMAAAAeRAAHAAAAPIgADgAAAHgQARwAAADwIAI4AAAA4EEEcAAAAMCDCOAAAACABxHAAQAAAA8igAMAAAAeVCED+MSJE3XllVcqODhY4eHhGjRokLZt2+banpubq8cee0ytWrVSUFCQoqKidOedd+rAgQNu++nRo4dsNpvbctttt7m1SU9PV3x8vOx2u+x2u+Lj43X06FG3NsnJyRowYICCgoJUp04djRw5Ujk5OW5tNmzYoO7duyswMFD169fXhAkTZIwp3Q+mtGRlSTabtWRlebsaAACASqVCBvClS5fqoYce0sqVK7VgwQLl5eWpd+/eyvojLB4/flxr167Vk08+qbVr1+rLL7/U9u3bNXDgwEL7GjZsmFJSUlzLO++847Y9Li5O69at07x58zRv3jytW7dO8fHxru35+fnq16+fsrKytHz5cs2cOVOzZs3SmDFjXG0yMjLUq1cvRUVFac2aNZo6daomT56sKVOmlNEnBAAAgPLKZsptN2zxHTp0SOHh4Vq6dKmuueaaItusWbNGV111lfbs2aOGDRtKsnrA27Rpo9dee63I92zZskWXXXaZVq5cqY4dO0qSVq5cqc6dO2vr1q2KiYnR999/r/79+2vv3r2KioqSJM2cOVMJCQlKS0tTSEiI3nrrLY0bN04HDx5UQECAJOnFF1/U1KlTtW/fPtlstvOeY0ZGhux2uxwOh0JCQi70I7owWVlSzZrW88xMKSiobI8HAABQCRQ3r1XIHvAzORwOSVJYWNg529hsNtWqVctt/YwZM1SnTh1dfvnlGjt2rI4dO+balpiYKLvd7grfktSpUyfZ7XatWLHC1SY2NtYVviWpT58+ys7OVlJSkqtN9+7dXeHb2ebAgQPavXt3kfVmZ2crIyPDbQEAAEDFV83bBVwsY4xGjx6tbt26KTY2tsg2J0+e1N///nfFxcW5/TYydOhQRUdHKzIyUhs3btS4ceP0yy+/aMGCBZKk1NRUhYeHF9pfeHi4UlNTXW0iIiLctoeGhsrf39+tTePGjd3aON+Tmpqq6OjoQseYOHGinnnmmWJ+CgAAAKgoKnwAHz58uNavX6/ly5cXuT03N1e33XabCgoKNG3aNLdtw4YNcz2PjY1V8+bN1aFDB61du1bt2rWTpCKHhxhj3NaXpI1z5M/Zhp+MGzdOo0ePdr3OyMhQgwYNimwLAACAiqNCD0EZMWKEvv76ay1evFiXXHJJoe25ubm65ZZbtGvXLi1YsOC8Y6fbtWsnPz8/7dixQ5IUGRmpgwcPFmp36NAhVw92ZGSkq6fbKT09Xbm5uedsk5aWJkmFes+dAgICFBIS4rYAAACg4quQAdwYo+HDh+vLL7/UokWLihzC4QzfO3bs0A8//KDatWufd7+bNm1Sbm6u6tWrJ0nq3LmzHA6HVq9e7WqzatUqORwOdenSxdVm48aNSklJcbWZP3++AgIC1L59e1ebZcuWuU1NOH/+fEVFRRUamgIAAIDKrULOgvLggw/q008/1VdffaWYmBjXervdrsDAQOXl5Wnw4MFau3atvv32W7de5rCwMPn7+2vnzp2aMWOGbrjhBtWpU0ebN2/WmDFjFBgYqDVr1sjX11eS1LdvXx04cMA1PeF9992nRo0a6ZtvvpFkTUPYpk0bRUREaNKkSTpy5IgSEhI0aNAgTZ06VZJ1AWhMTIyuvfZaPf7449qxY4cSEhL01FNPuU1XeC7MggIAAFC+FTuvmQpIUpHLBx98YIwxZteuXWdts3jxYmOMMcnJyeaaa64xYWFhxt/f3zRt2tSMHDnSHD582O1Yhw8fNkOHDjXBwcEmODjYDB061KSnp7u12bNnj+nXr58JDAw0YWFhZvjw4ebkyZNubdavX2+uvvpqExAQYCIjI8348eNNQUFBsc/Z4XAYScbhcFzw53XBMjONkawlM7PsjwcAAFAJFDevVcge8KqIHnAAAIDyrUrNAw4AAABUFARwAAAAwIMI4AAAAIAHEcABAAAADyKAAwAAAB5EAAcAAAA8iAAOAAAAeBABHAAAAPAgAjgAAADgQQRwAAAAwIMI4AAAAIAHEcABAAAADyKAAwAAAB5EAAcAAAA8iAAOAAAAeBABHAAAAPAgAjgAAADgQQRwAAAAwIMI4AAAAIAHEcABAAAADyKAAwAAAB5EAAcAAAA8iAAOAAAAeBABHAAAAPAgAjgAAADgQQRwAAAAwIMI4AAAAIAHEcABAAAADyKAAwAAAB5EAAcAAAA8iAAOAAAAeBABHAAAAPAgAjgAAADgQQRwAAAAwIMI4AAAAIAHEcABAAAADyKAAwAAAB5EAAcAAAA8iAAOAAAAeBABHAAAAPAgAjgAAADgQQRwAAAAwIMI4AAAAIAHEcABAAAADyKAAwAAAB5EAAcAAAA8iAAOAAAAeBABHAAAAPAgAjgAAADgQQRwAAAAwIMI4AAAAIAHEcABAAAADyKAAwAAAB5EAAcAAAA8iAAOAAAAeBABHAAAAPAgAjgK+/BDb1cAAABQaRHAUVijRt6uAAAAoNIigKOwli1PPT950nt1AAAAVEIEcBQWEXHq+a+/eq8OAACASogAjkIWLlp06sWWLd4rBAAAoBIigKOQrKysUy+2bvVeIQAAAJUQARyFNGvWzPXcEMABAABKFQEchTRp0sT1PH/TJi9WAgAAUPkQwFFI9erVXc99du2ScnK8WA0AAEDlQgDHOfnk5zMTCgAAQCmqkAF84sSJuvLKKxUcHKzw8HANGjRI27Ztc2tjjNH48eMVFRWlwMBA9ejRQ5vOGE6RnZ2tESNGqE6dOgoKCtLAgQO1b98+tzbp6emKj4+X3W6X3W5XfHy8jh496tYmOTlZAwYMUFBQkOrUqaORI0cq54xe4w0bNqh79+4KDAxU/fr1NWHCBBljSu9DKUubN3u7AgAAgEqjQgbwpUuX6qGHHtLKlSu1YMEC5eXlqXfv3m6zd7z88suaMmWK3njjDa1Zs0aRkZHq1auXjh075mozatQozZ49WzNnztTy5cuVmZmp/v37Kz8/39UmLi5O69at07x58zRv3jytW7dO8fHxru35+fnq16+fsrKytHz5cs2cOVOzZs3SmDFjXG0yMjLUq1cvRUVFac2aNZo6daomT56sKVOmlPEnVUoI4AAAAKXHVAJpaWlGklm6dKkxxpiCggITGRlpXnzxRVebkydPGrvdbt5++21jjDFHjx41fn5+ZubMma42+/fvNz4+PmbevHnGGGM2b95sJJmVK1e62iQmJhpJZuvWrcYYY+bOnWt8fHzM/v37XW0+++wzExAQYBwOhzHGmGnTphm73W5OnjzpajNx4kQTFRVlCgoKinWODofDSHLts0xlZhojnVpuvbXsjwkAAFDBFTevVcge8DM5HA5JUlhYmCRp165dSk1NVe/evV1tAgIC1L17d61YsUKSlJSUpNzcXLc2UVFRio2NdbVJTEyU3W5Xx44dXW06deoku93u1iY2NlZRUVGuNn369FF2draSkpJcbbp3766AgAC3NgcOHNDu3buLPKfs7GxlZGS4Ld5i6AEHAAAoNRU+gBtjNHr0aHXr1k2xsbGSpNTUVElSxOm3VP/jtXNbamqq/P39FRoaes424eHhhY4ZHh7u1ubM44SGhsrf3/+cbZyvnW3ONHHiRNe4c7vdrgYNGpznkyhD27ZJeXneOz4AAEAlUuED+PDhw7V+/Xp99tlnhbbZbDa318aYQuvOdGabotqXRhvzxwWYZ6tn3LhxcjgcrmXv3r3nrLusHJdky8mRfvvNK8cHAACobCp0AB8xYoS+/vprLV68WJdccolrfWRkpKTCvctpaWmunufIyEjl5OQoPT39nG0OHjxY6LiHDh1ya3PmcdLT05Wbm3vONmlpaZIK99I7BQQEKCQkxG3xBtfcMgxDAQAAKBUVMoAbYzR8+HB9+eWXWrRokaKjo922R0dHKzIyUgsWLHCty8nJ0dKlS9WlSxdJUvv27eXn5+fWJiUlRRs3bnS16dy5sxwOh1avXu1qs2rVKjkcDrc2GzduVEpKiqvN/PnzFRAQoPbt27vaLFu2zG1qwvnz5ysqKkqNGzcupU+lbLhuRE8ABwAAKBUVMoA/9NBD+uSTT/Tpp58qODhYqampSk1N1YkTJyRZwzpGjRqlF154QbNnz9bGjRuVkJCgGjVqKC4uTpJkt9t17733asyYMVq4cKF+/vln3XHHHWrVqpX+9Kc/SZJatmyp66+/XsOGDdPKlSu1cuVKDRs2TP3791dMTIwkqXfv3rrssssUHx+vn3/+WQsXLtTYsWM1bNgwV691XFycAgIClJCQoI0bN2r27Nl64YUXNHr06PMOifE2AjgAAEApK+vpWMqCpCKXDz74wNWmoKDAPP300yYyMtIEBASYa665xmzYsMFtPydOnDDDhw83YWFhJjAw0PTv398kJye7tTl8+LAZOnSoCQ4ONsHBwWbo0KEmPT3drc2ePXtMv379TGBgoAkLCzPDhw93m3LQGGPWr19vrr76ahMQEGAiIyPN+PHjiz0FoTHem4ZwiHMqwrZty/64AAAAFVhx85rNmIpyO8aqLSMjQ3a7XQ6Ho+zHg2dlSTVrSpKukLRekqleXbbMTMnXt2yPDQAAUEEVN69VyCEo8Jzfa9TQSUm2kyelPXu8XQ4AAECFRwDHOTVu1oyZUAAAAEoRARzn1Lx5c7liNwEcAADgohHAcU7NmjUjgAMAAJQiAjjOiQAOAABQugjgOKdCQ1CYNAcAAOCiEMBxTk2bNtWvknIla3rCvXu9XBEAAEDFRgDHOYWGhqpWnTra7lzBMBQAAICLQgDHebVo0YJx4AAAAKWEAI7zIoADAACUHgI4zosADgAAUHoI4DivQgGcmVAAAABKjACO82rRooW2S8qXJIdDSknxckUAAAAVFwEc59W0aVPlSPrVuYJhKAAAACVGAMd51ahRQw0aNGAcOAAAQCkggKNYuBATAACgdBDAUSwEcAAAgNJBAEexuAXwTZuYCQUAAKCECOAolhYtWmibpAJJOnJEOnTIyxUBAABUTARwFEvz5s11QtJum81awTAUAACAEiGAo1gaN26satWqaZNz6AkBHAAAoEQI4CgWPz8/NWnShAsxAQAALhIBHMXGTCgAAAAXjwCOYiOAAwAAXDwCOIqtRYsW2up8cfCgdPiwN8sBAACokAjgKLbmzZsrU9L+atWsFVu2eLUeAACAiogAjmJr0aKFJGlDfr61gmEoAAAAF4wAjmKLiopSjRo1mIoQAADgIhDAUWw+Pj5q3rw5F2ICAABcBAI4LggzoQAAAFwcAjguSIsWLeS69HL/fsnh8GY5AAAAFQ4BHBekefPmckj6PSDAWsFMKAAAABeEAI4L4pwJxRW7GYYCAABwQQjguCDOAL42O9taQQAHAAC4IARwXJDatWsrLCyMCzEBAABKiACOC8ZMKAAAACVHAMcFcwvge/ZImZneLAcAAKBCIYDjgjVv3lxHJDmqV7dWbN3q1XoAAAAqEgI4LpjzQsyd/v7WCoahAAAAFBsBHBfMGcDX5eRYKwjgAAAAxUYAxwVr1qyZJCnp5ElrBQEcAACg2AjguGA1a9ZU/fr1mQkFAACgBAjgKBG3mVB++006ccKb5QAAAFQYBHCUSPPmzZUm6XhgoGSMtG2bt0sCAACoEAjgKBHnhZjJQUHWCoahAAAAFAsBHCXiDOCbjLFWEMABAACKhQCOEnEG8FXHjlkrCOAAAADFQgBHiURHR8vX11c/Mxc4AADABSGAo7CgIOvCSmOs50Xw9/dXdHT0qZlQfv1Vys72WIkAAAAVFQEcJda8eXMdkJRTvbqUny/t2OHtkgAAAMo9AjhKzDkOPCU01FrBMBQAAIDzIoCjxJwBfLufn7WCAA4AAHBeBHCUmDOAr3XeBZMADgAAcF4EcJSYM4AvP3LEWkEABwAAOC8COErskksuUfXq1bU+P99asX27lJvr3aIAAADKOQI4SszHx0fNmjXTXkl51atb4XvnTm+XBQAAUK4RwHFRWrRoISPpcN261gqGoQAAAJwTARwXxTkOfHeNGtYKAjgAAMA5EcBxUZwBfINzHDgBHAAA4JwI4LgozgCe6HBYKwjgAAAA50QAx0VxBvClhw5ZK7Zts25LDwAAgCIRwHFR6tSpI7vdrl2SCgICpJMnpd27vV0WAABAuUUAx0Wx2Wxq0aKFCiRlREVZKxmGAgAAcFYEcFw05zCU/Xa7tYIADgAAcFYEcFw0ZwDf5vPHjxMBHAAA4KwI4LhozgD+0/Hj1goCOAAAwFlVyAC+bNkyDRgwQFFRUbLZbJozZ47bdpvNVuQyadIkV5sePXoU2n7bbbe57Sc9PV3x8fGy2+2y2+2Kj4/X0aNH3dokJydrwIABCgoKUp06dTRy5Ejl5OS4tdmwYYO6d++uwMBA1a9fXxMmTJAxplQ/E28qNBPKli1SQYEXKwIAACi/qnm7gJLIyspS69atdffdd2vw4MGFtqekpLi9/v7773XvvfcWajts2DBNmDDB9TowMNBte1xcnPbt26d58+ZJku677z7Fx8frm2++kSTl5+erX79+qlu3rpYvX67Dhw/rrrvukjFGU6dOlSRlZGSoV69e6tmzp9asWaPt27crISFBQUFBGjNmzMV/GOVA8+bNJUmrDh+W8fOTLStL2rtXatTIy5UBAACUPxUygPft21d9+/Y96/bIyEi311999ZV69uypJk2auK2vUaNGobZOW7Zs0bx587Ry5Up17NhRkvTuu++qc+fO2rZtm2JiYjR//nxt3rxZe/fuVdQfM4C88sorSkhI0PPPP6+QkBDNmDFDJ0+e1IcffqiAgADFxsZq+/btmjJlikaPHi2bzXYxH0W5EBwcrMjISKWmpupEw4aqsXOnNQyFAA4AAFBIhRyCciEOHjyo7777Tvfee2+hbTNmzFCdOnV0+eWXa+zYsTp27JhrW2Jioux2uyt8S1KnTp1kt9u1YsUKV5vY2FhX+JakPn36KDs7W0lJSa423bt3V0BAgFubAwcOaPc55svOzs5WRkaG21KeOYehHKpTx1rBOHAAAIAiVfoA/tFHHyk4OFg33XST2/qhQ4fqs88+05IlS/Tkk09q1qxZbm1SU1MVHh5eaH/h4eFKTU11tYmIiHDbHhoaKn9//3O2cb52tinKxIkTXWPP7Xa7GjRocAFn7XnOAP5b9erWCgI4AABAkSrkEJQL8f7772vo0KGq7gyGfxg2bJjreWxsrJo3b64OHTpo7dq1ateunSQVOTzEGOO2viRtnBdgnmv4ybhx4zR69GjX64yMjHIdwp0BfH1ennpKBHAAAICzqNQ94P/73/+0bds2/eUvfzlv23bt2snPz087duyQZI0jP3jwYKF2hw4dcvVgO8c9ny49PV25ubnnbJOWliZJhXrGTxcQEKCQkBC3pTxzBvAVzlliNm+WKtFMLwAAAKWlUgfw9957T+3bt1fr1q3P23bTpk3Kzc1VvXr1JEmdO3eWw+HQ6tWrXW1WrVolh8OhLl26uNps3LjRbdaV+fPnKyAgQO3bt3e1WbZsmdvUhPPnz1dUVJQaN25cGqdZLjhnQlmYnCzj6ytlZEgHDni5KgAAgPKnQgbwzMxMrVu3TuvWrZMk7dq1S+vWrVNycrKrTUZGhv7zn/8U2fu9c+dOTZgwQT/99JN2796tuXPnasiQIWrbtq26du0qSWrZsqWuv/56DRs2TCtXrtTKlSs1bNgw9e/fXzExMZKk3r1767LLLlN8fLx+/vlnLVy4UGPHjtWwYcNcPdZxcXEKCAhQQkKCNm7cqNmzZ+uFF16oNDOgODVt2lQ2m02Hjx1TvnO2GYahAAAAFFIhA/hPP/2ktm3bqm3btpKk0aNHq23btnrqqadcbWbOnCljjG6//fZC7/f399fChQvVp08fxcTEaOTIkerdu7d++OEH+fr6utrNmDFDrVq1Uu/evdW7d29dccUVmj59umu7r6+vvvvuO1WvXl1du3bVLbfcokGDBmny5MmuNna7XQsWLNC+ffvUoUMHPfjggxo9erTb+O7KICAgwNWjf/SPbxEI4AAAAIXZTGW6JWMllpGRIbvdLofDUW7Hg19//fX673//q7X9+6vtt99K990nvfOOt8sCAADwiOLmtQrZA47yyXkh5hbnCnrAAQAACiGAo9Q4A/iarCxrxaZNzIQCAABwBgI4So1zJpRlqamSj4+Uni79MeUiAAAALARwlBpnD/im336TYSYUAACAIhHAUWoaNmwof39/ZWdn64RzjnMCOAAAgBsCOEqNr6+vmjVrJklKrV3bWkkABwAAcEMAR6lyDkPZ6e9vrSCAAwAAuCGAo1Q5A/i6nBxrBQEcAADADQEcpco5E8qPhw9bK9LSpN9/92JFAAAA5QsBHKXK2QO+4bffJOeFmFu2nP0NAAAAVQwBHKXKGcB3796t/EsvtVYyDAUAAMCFAI5SFRERoeDgYBUUFOhovXrWSgI4AACACwEcpcpms7l6wZNr1rRWEsABAABcCOAoda47YhpjrSCAAwAAuBDAUeqcM6GsPnbMWnHggHT0qPcKAgAAKEcI4Ch1zh7w9bt3S5dcYq1kJhQAAABJBHCUAWcA3759u3TZZdZKhqEAAABIIoCjDDiHoKSkpCinWTNrJQEcAABAEgEcZaBWrVoKDw+XJKWEhlorCeAAAACSCOAoI85hKDv8/KwVBHAAAABJBHCUEecwlJ9PnrRWJCdLzllRAAAAqjACOMqEayaUffukyEhr5datXqwIAACgfCCAo0wwEwoAAEDRCOAoE6cHcNOypbWSAA4AAEAAR9lo2rSpbDabjh49qsyGDa2VBHAAAAACOMpGYGCgGv4RvHfXqGGtJIADAAAQwFF2nDOhbCwosFbs2iUdP+7FigAAALyPAI4y4xwHviE1VapTRzJG2rbNy1UBAAB4FwEcZYaZUAAAAAojgKPMEMABAAAKI4CjzLhuR79jhwqYihAAAEASARxlqFGjRvLz89PJkyd1qE4dayUBHAAAVHEEcJSZatWqqUmTJpKk7dWqWSt//VXKzvZiVQAAAN5FAEeZcg5D2fj771KtWlJBgbR9u3eLAgAA8CICOMqU60LMHTu4EBMAAEAEcJQxZkIBAABwRwBHmSKAAwAAuCOAo0w5A/iuXbuU98dzAjgAAKjKCOAoU/Xq1VNQUJDy8/OVXLOmtXL7dik317uFAQAAeAkBHGXKZrOpefPmkqTNGRlSzZpSXp41HSEAAEAVRABHmWMmFAAAgFMI4ChzXIgJAABwCgEcZY4ADgAAcAoBHGWOAA4AAHAKARxlznkR5v79+3W8cWNr5bZt1sWYAAAAVQwBHGUuLCxMtWvXliTtyMmRAgOl7Gxp1y4vVwYAAOB5JQrg69ev1/r165WTk3NRBz9y5Ihef/11vf766xe1H5R/rmEov/4qtWxprWQYCgAAqIJKFMDbtGmjdu3a6dezzOW8e/duXXvttbruuuvOuZ+UlBSNGjVKo0ePLkkZqEAYBw4AAGCpVtI3GmPOui0rK0tLliyRzWa76H2hcjhvAM/Ksm7SI0mZmVJQkIcrBAAA8AzGgMMj6AEHAACwEMDhEc6ZUHacfjfMLVukggIvVgUAAOB5BHB4RLNmzSRJhw8f1uGQECkgQDpxQtqzx8uVAQAAeBYBHB4RFBSkSy65RJK0Y9cuKSbG2sAwFAAAUMUQwOExjAMHAAAggMODCOAAAAAEcHgQARwAAOAi5gGXrBvp1HTO3XyaAwcOuJ7v3bv3rPN8n94OlZ9zJpRCAZx54AEAQBVyUQG8d+/eZ93mvAlP48aNL+YQqEScPeA7duyQadpUtmrVrJvu7NsnhYV5uToAAADPKPEQFGNMqSyoOqKjo+Xr66vjx4/rwKFD0h+BnGEoAACgKilRD/hdd91V2nWgCvDz81OTJk20Y8cObd++XfUvu8wK35s3S926ebs8AAAAjyhRAP/ggw9Kuw5UES1atHAF8J5ciAkAAKogZkGBRzETCgAAqOoI4PAoZkIBAABVnUcD+OHDh5Wenu7JQ6KcOX0mFLVoIfn4SEePSgcPercwAAAADynzAH7w4EHdd999qlOnjsLDw1WnTh2FhoYqISFBycnJZX14lDPOAL5z507l+fpKzZpZG7Zs8WJVAAAAnlOiAJ6amqqoqChFRUXprbfeOmu73377Te3bt9d7772nI0eOuKYedDgcmj59utq2bat169aVtHZUQPXr11dgYKDy8vK0e/fuU8NQtm71al0AAACeUqIAvnTpUqWmpurIkSO65ZZbztrutttu04EDB1zzfTdo0EAdO3ZUcHCwjDFKT0/X7bffrry8vAs6/rJlyzRgwABFRUXJZrNpzpw5btsTEhJks9nclk6dOrm1yc7O1ogRI1SnTh0FBQVp4MCB2rdvn1ub9PR0xcfHy263y263Kz4+XkePHnVrk5ycrAEDBigoKEh16tTRyJEjlZOT49Zmw4YN6t69uwIDA1W/fn1NmDChys6B7uPjU/Q4cAI4AACoIkoUwJcsWSJJ6tmzp2rXrl1km2+//VY//fSTbDabwsLCNG/ePO3Zs0eJiYlKTU3V3XffLckKYbNmzbqg42dlZal169Z64403ztrm+uuvV0pKimuZO3eu2/ZRo0Zp9uzZmjlzppYvX67MzEz1799f+fn5rjZxcXFat26d5s2bp3nz5mndunWKj493bc/Pz1e/fv2UlZWl5cuXa+bMmZo1a5bGjBnjapORkaFevXopKipKa9as0dSpUzV58mRNmTLlgs65MilyJhQCOAAAqCpMCXTu3Nn4+PiYV1555axtbrvtNmOz2YyPj4/58MMPC20vKCgwV1xxhfHx8TG33357ScowxhgjycyePdtt3V133WVuvPHGs77n6NGjxs/Pz8ycOdO1bv/+/cbHx8fMmzfPGGPM5s2bjSSzcuVKV5vExEQjyWzdutUYY8zcuXONj4+P2b9/v6vNZ599ZgICAozD4TDGGDNt2jRjt9vNyZMnXW0mTpxooqKiTEFBQbHP0+FwGEmu/VZk48aNM5LMAw88YMzatcZIxtSubT1KxmRmertEAACAC1bcvFaiHvCDf8xY0bp167O2cfaS2+12xcXFFdpus9l0zz33yBijX375pSRlnNOSJUsUHh6uFi1aaNiwYUpLS3NtS0pKUm5urnr37u1aFxUVpdjYWK1YsUKSlJiYKLvdro4dO7radOrUSXa73a1NbGysoqKiXG369Omj7OxsJSUludp0795dAQEBbm0OHDhgjYE+i+zsbGVkZLgtlYXbTCgxMZLNJh0+7OWqAAAAPKNEAdwZZuvUqVPk9t9++00HDx6UzWbT1VdfLT8/vyLbtW3bVpJ04MCBkpRxVn379tWMGTO0aNEivfLKK1qzZo2uvfZaZWdnS7IuIvX391doaKjb+yIiIpSamupqEx4eXmjf4eHhbm0iIiLctoeGhsrf3/+cbZyvnW2KMnHiRNfYc7vdrgYNGlzIR1CuuQ1BqVFDio72ckUAAACeU6IA7rxo8syLDZ1WrVrlet6+ffuz7qdWrVqSrDHdpenWW29Vv379FBsbqwEDBuj777/X9u3b9d13353zfcYY2Ww21+vTn5dmG/PHBZhFvddp3LhxcjgcrmXv3r3nrL0icQbw5ORknThx4tQ4cAAAgCqgRAHc2fO9ffv2IrcnJia6nnfo0OGs+zl27JgkqXr16iUpo9jq1aunRo0aWUMeJEVGRionJ6fQTYHS0tJcvdORkZGuoTanO3TokFubM3ux09PTlZube842zm8QzuwZP11AQIBCQkLclsqidu3arm8ffv31VwI4AACoUkoUwJ1jv4uavcQYo2+++cbauY+Punbtetb97NmzR9K5g2hpOHz4sPbu3at69epJsnrl/fz8tGDBAleblJQUbdy4UV26dJEkde7cWQ6HQ6tXr3a1WbVqlRwOh1ubjRs3KiUlxdVm/vz5CggIcPX8d+7cWcuWLXP7tmD+/PmKiopS48aNy+ycyzObzVb0TCgAAABVQIkC+I033ihjjL766it9/PHHbtsmTZqkPXv2yGaz6brrrpPdbj/rfpw95TExMRd0/MzMTK1bt851E59du3Zp3bp1Sk5OVmZmpsaOHavExETt3r1bS5Ys0YABA1SnTh39+c9/lmRdGHrvvfdqzJgxWrhwoX7++WfdcccdatWqlf70pz9Jklq2bKnrr79ew4YN08qVK7Vy5UoNGzZM/fv3d9Xbu3dvXXbZZYqPj9fPP/+shQsXauzYsRo2bJirxzouLk4BAQFKSEjQxo0bNXv2bL3wwgsaPXr0OYegVHZFzgUOAABQFZRkipWsrCzTuHFj4+PjY3x8fMxVV11l4uLiTNu2bY2Pj49r+sH//ve/Z91HQUGBueSSS4yPj4959tlnL+j4ixcvNpIKLXfddZc5fvy46d27t6lbt67x8/MzDRs2NHfddZdJTk5228eJEyfM8OHDTVhYmAkMDDT9+/cv1Obw4cNm6NChJjg42AQHB5uhQ4ea9PR0tzZ79uwx/fr1M4GBgSYsLMwMHz7cbcpBY4xZv369ufrqq01AQICJjIw048ePv6ApCI2pXNMQGmPMhAkTjCRz9913G5ORcWoKQqYhBAAAFVRx85rNmJLdknH16tXq3bu3MjIy3Hpynbu799579e677571/d99950GDBggm82mH3/8sdCdKuEuIyNDdrtdDoejUowH//e//63bbrtNXbt21fLly6WGDSXnhaaZmVJQkHcLBAAAuEDFzWslGoIiSVdddZWSkpI0ZMgQBQYGyhgjY4waNWqkyZMn61//+tc53//ss89Ksi5SJHxXPW5jwCXp0ku9WI0XZGVZ85/bbNZzAABQZVS7mDc3bdpU//73v1VQUKBDhw4VObf22SxcuNAqoNpFlYAKyjkG/NChQ0pPT1fopZdKp10UCwAAUFmVuAfcbSc+PoqIiCh2+JakoKAgBQUFud0hElVHzZo1XXcQ3bFjR9XrAQcAAFVWqQRwoCTcZkIhgAMAgCqiROM/li1bVtp16Jprrin1faJ8a9GihZYuXWr1gPfseWpDRgYXYQIAgEqrRAG8R48epTqHtc1mc93eHlWH24WYtWqd2rBtm/THTZMAAAAqm4saguKc+aQ0FlQ9hWZCcfruOy9UAwAA4BkXNQVJYGCgbrzxRvXq1Us+Pgwnx4U5PYAbY+T6TmXyZKlLF+mPO5cCAABUJiW6EY/dbtexY8esHdhsioiIUFxcnOLj49W6detSLxKV70Y8kpSTk6PAwEAVFBQo5ddfFdms2amNQUFSYqLUqlXZFpGVJdWsaT335A2AvHVcAABQZsr0RjwHDx7UZ599phtuuEG+vr5KTU3Vq6++qnbt2ql169aaPHmyDhw4UOLiUTX4+/urcePGkv6YitCpZ08roA4cKB065J3iAAAAykiJAnj16tV166236ttvv9X+/fv16quvqm3btjLGaMOGDXrsscfUqFEj9erVS9OnT1cWd/rDWTiHoezcufPUyo8+kpo2lXbvlm6+WcrJ8U5xAAAAZeCiB27XrVtXDz/8sH766Sdt2rRJjz32mC655BLl5+dr4cKFSkhIUEREhOLj4/Xf//6XCy7hxhnA3XrAw8Kkr7+WgoOlZcukhx/2UnUAAAClr1SvnGzZsqUmTpyoPXv2aNGiRUpISFBwcLCOHz+uGTNm6IYbblD9+vX12GOPleZhUYE5A/ivv/7qvuGyy6TPPpNsNuntt6Vp07xQHQAAQOkrs6lLevTooffff1+pqan69NNP1bdvX9d48alTp5bVYVHBnDWAS1K/ftKLL1rPR46UFi3yYGUAAABlo8znDrTZbPLx8ZHNZivVm/egcihyDPjp/vY36Y47pPx8acgQ6bffPFgdAABA6buoecDPZenSpZo+fbq++OIL15SFxhjVq1dP8fHxZXVYVDANGjRQQECAcrOzi25gs0nvvitt3y6tXm3NjLJihVRJpmIEAABVT6kG8C1btmj69OmaMWOG9u3bJ8kK3TVq1NCf//xn3Xnnnbruuuu4aQ9cfHx81KxZM+3atOnsjapXl2bPljp0kDZtsnrE58yR+DkCAAAV0EUH8LS0NH322WeaPn26fv75Z0lW6Pbx8VHPnj1155136qabblIQNxrBWbRo0eLcAVySoqKs0H3NNdI330hPPik9/7xH6gMAAChNJQrgJ0+e1Jw5czR9+nQtWLBA+fn5rukFY2NjFR8fr6FDhyoqKqpUi0Xl1KJFC/23OA2vukp67z2rB/yFF6TYWOn228u6PAAAgFJVogAeHh7uurmOMUaRkZG6/fbbFR8frzZt2pRmfagCnBdiFsvQodKGDdJLL0n33CM1b24NTQEAAKggShTAMzMzZbPZVL16dQ0cOFC9e/eWr6+v1q9fr/Xr15eokDvvvLNE70PFd0EBXLKGnmzcKH33nTRokLRmjVSvXpnUBgAAUNpspgS3pnROK1hqRdhsysvLK7X9VUYZGRmy2+1yOBwKqWQzgBw8eFBNIiOV5VyRmSmd75qBjAypUydpyxapY0dpyRLrYs0LlZUl1axZ/OOWFm8dFwAAlJni5rUSTyNhjCnVBVVXeHi4QoKDL+xNISHW7epDQ6VVq6T77pP4OUJVlZVlTdlps1nPAQDlWomGoCxevLi060AVZrPZ1KxZM+mPWXSKrVkz6T//kfr0kaZPl1q3lsaMKZsiAQAASkmJAnj37t1Luw5Ucc2bN7/wAC5J110nvfaaNGKE9Oij0mWXSX37lnp9AAAApYU7maBcaNasWcnf/NBD0rBhUkGBdNtt0tatpVcYcCEYCgIAKAYCOMqFiwrgNpv0xhvS1VdbF2cOHCilp5decQAAAKWIAI5y4aICuCT5+0uzZkmNGkk7dki33ioxsw4AACiHCOAoF5o2bep6npGRUbKd1K0rffWVVKOGtGCB9Le/lVJ1AAAApYcAjnLBbre7nu/cubPkO2rd2poRRbIuznz//YsrDAAAoJQRwFHubL3Yiyhvukl65hnr+f33Sz/+ePFFlbbkZG9XAAAAvIQAjnLnk08+ufidPPGEdPPNUm6uFcjLQ+A9cUL67DOpVy/p8stPrU9N9V5NAADA4wjgKHeWLF2qtWvXXtxOfHykDz+U2rSR0tKkG2/0zrRwxkhJSdZUiVFRUlyc9MMP7nftvPNO6xcFoKJh2kUAKBECOMqlSZMmXfxOgoKsizLr1pXWrZMSEjx3u/rff5f++U/rF4AOHaRp06SjR61ZWsaPlzZtOtV2xQrp73/3TF0ASoZfNgCUIgI4yqXPP/9cu3btuvgdNWwoffml5OcnffGF9NxzF7/Ps8nLk+bOtYa+REVJo0ZJ69dLAQGner5/+016+mkriJ9uyhTp88/LrjYAAFBuEMBR7lx37bUqKCjQq6++Wjo77NZNeust6/lTT1mBvDTt2CE9/rgVqvv1s+Yjz8091fOdkiLNmCFdd501NOZMo0dbj/fcI23eXLq1AQCAcocAjnJn1KhRkqT33ntPhw8fLp2d3nuv9PDD1vP4eOmXXy5uf5mZ1hjza66RWrSQJk6UDhyQate2er5/+UVas0Z64AEpNPTc+3rqKalnT+tr7Ztusu7mCQAAKi0COMqdnj17qk2bNjp+/LjecvZcl4bJk6U//Uk6fty6KPPQoQt7vzHWeO2//EWqV0+6+27pf/+zerVvuMEa4nLggPTqq9IVVxR/v9WqSTNnSvXrS9u2WT3hnhqrDgAAPI4AjnLHZrPpb3/cxXLq1Kk6ceJE6ey4WjXp3/+WmjWT9uyRBg+WcnLO/76UFOnll6WWLaWuXaX33rN6wJs1k154wZri8LvvrP35+5estvBwK8D7+VlDWF55pWT7AQAA5R4BHOXSkCFD1LBhQ6Wlpenjjz8uvR2HhUlffy2FhFi9187x12fKzZXmzJEGDpQaNJAee8zqna5Rw5pNZdkyaft2adw4q+e6NHTqZN29U7JmRVmypHT2CwAAyhUCOMolPz8/PfLII5KkV155Rfn5+aW385YtrRvi2GzWOO7TbdokjRljheo//1n65hspP1/q0kX6v/+zbprzwQfS1Vdb7y9tDzxgjVHPz5duvVXav7/0jwEAALyKAI5y6y9/+YtCQ0O1Y8cOff3116W78xtukF56yX1djx5SbKw1JeChQ1JkpPToo9KWLdbt7O+9VwoOLt06zmSzSW+/bY0hT0uThgwp3jCZ4mAeYwAAygUCOMqtmjVr6oEHHpBUSjfmOdPYsdLtt596/dNP1jjxQYOsYSp791oh/dJLS//Y51KjhjVVot0uJSZadQKw8IskgEqAAI7yISjImvnDGOv5H0aMGCF/f38lJibqxx9/LN1j2mzS1KmnXr/wgrRvnzR7tjRggBXGvaVpU2n6dOv51KnWPOIAAKBSIICjXIuMjNSdd94pSXr55ZdL/wDVq596PnKkFBFR+scoqQEDpCeesJ4PGyZt2ODdegAAQKkggKPcGzNmjCTp66+/1tatW71cjYeNHy/17i2dOGHdpMfh8HZFACo7hvkAZY4AjnLv0ksv1Y033ijJmhGlSvH1tYafNGwo/fqrdNddUkGBt6sCAAAXgQCOCsF5Y56PP/5YqampXq7Gw+rUsW7O4+8vffVV4dlbAABAhUIAR4XQtWtXde7cWTk5OZp6+oWTVUWHDtIbb1jPn3hC+uEH79YDAABKjACOCsPZCz5t2jQdO3bMy9V4wV/+It1zjzUE5fbbpeRkb1dUPIwnBQDADQEcFcbAgQPVvHlzHT16VO+99563y/E8m83qBW/XTvr9d+nmm6XsbG9XBQClg1/WUYUQwFFh+Pr6auwfN6V59dVXlZub6+WKvCAwUPriCyk0VFqzRho1ytsVAShLhFKgUiKAo0K58847FR4eruTkZP3nP//xdjneER1tzYzivG39hx96uyIAqLj4JafseeMzLud/rgRwVCjVq1fXiBEjJFm3pzfGeLkiL+nb15ojXJIeeEBat86b1QAAKoJyHkqrEgI4KpwHHnhANWrU0Lp16/RDVZ4N5IknpBtukE6etG7Sk57u7YoAAMVBEK7yCOCocGrXrq2//OUvkqxe8CrLx0eaPt0akrJrl3THHdykBwCACoAAjgrpkUceka+vrxYsWKB1VXn4RViYdZOe6tWluXOl557zdkUAAOA8COCokBo3bqwhQ4ZIkiZPnuzlarysbVvprbes5+PHS/PmebUcAABwbgRwVFjOG/PMnDlTe/bs8XI1XpaQIP31r5IxUlycNSSlqmOMJQCgnCKAo8Jq166drr32WuXn5+u1117zdjne989/SldeaV2MefPN1sWZqHyOHZN++smaivKpp6Rbb5U6dz61fdAg6dlnpcWL+cUDAMqpat4uALgYjz76qBYtWqR3331XTz31lEJDQ71dkvcEBFg36WnfXlq7Vho+XPq///N2VSiJ/Hxpzx5p2zZr2br11POUlHO/94cfrEWSqlWzhih17Sp162Y9RkaWff0AgHMigKNC6927t6644gqtX79eb7/9tsaNG+ftkryrYUPps8+kPn2k996TOnWS/pgxBuVQevqpYH368uuvUnb22d8XHi5deqkUE2MtjRpJf1wTocmTrR7y5culffusO6auWSM5vyVq2tQ9kF96qTWjDgDAYwjgqNBsNpvGjh2rO++8U6+//rpGjx6tgIAAb5flXX/6kzUbyuOPSw89JLVpI3Xo4O2qqq7cXGtMflFBOy3t7O8LCJCaNz8Vsk9fatVyb3v6UJP775eCgqznyclWEP/xR+txwwZp505r+fhjq01YmNSly6lA3qGDNasOAKDMEMBR4d122216/PHHtW/fPn3yySe69957vV3S+QUFWRdMlpXHHpNWrZK++koaPFhKSpICA8vueCjs1lutnuydO6W8vLO3i4oqHLAvvdT6NsPX9+JqaNjQuig3Ls567XBIiYmnAvmqVdKRI9K331qLJPn7WyHcGci7dJHq1Lm4OgAAbgjgqPD8/Pw0atQojR07VpMmTdLdd98tn6r+lbqPj/TRR1aQ+vVXaehQ6T//8XZVlVtBgTRt2qnX33136nlgoNSihfuwkZgYa11wsOdqtNul66+3Fsnqnf/551OB/McfpYMHpRUrrMXp0ktPBfKuXaVmzazZZaqK33+3Lmp1Sk21hvIAQAkRwFEpDBs2TM8++6y2bdumb7/9VgMHDvR2Sd5nt0tffil17CjNny89/7y3K6q89u+X7r5bWrDg1LrJk6UrrrCC9iWXlM9x1n5+0lVXWcsjj1jfyuzc6R7It2yxLgLduvXURb3h4VYQv+oq79ZfFgoKrHP98cdTv4hs3+7epmVL6fbbpVGjrItcAeAClcP/Ec5v2bJlGjBggKKiomSz2TRnzhzXttzcXD322GNq1aqVgoKCFBUVpTvvvFMHDhxw20ePHj1ks9nclttuu82tTXp6uuLj42W322W32xUfH6+jR4+6tUlOTtaAAQMUFBSkOnXqaOTIkcrJyXFrs2HDBnXv3l2BgYGqX7++JkyYIFOWww+qoJCQEN1///2Sqvjt6c/UqpX07rvW85df9m4tldV//mN9zgsWuA/zuf9+qVcvaxhIeQzfRbHZrN7tu+6yfm42b7Z6f7/+Wnr0USt0+/tbY9dnz5ZOv+i5fXtr2M3zz1vtd+8u22FWpSUz0+rdfu456YYbpNq1pcsvl+67T/rww1Ph+9JLT70nN9caQ9+undS9uzRnjjVzDQAUU4XsAc/KylLr1q119913a/DgwW7bjh8/rrVr1+rJJ59U69atlZ6erlGjRmngwIH66aef3NoOGzZMEyZMcL0OPGOMbFxcnPbt26d5f9xZ8L777lN8fLy++eYbSVJ+fr769eununXravny5Tp8+LDuuusuGWM0depUSVJGRoZ69eqlnj17as2aNdq+fbsSEhIUFBSkMWPGlPpnU5WNHDlSU6ZM0fLly7Vy5Up16tTJ2yWVD0OHSitXSm+84e1KKheHw5rq8ZNPrNft20v/+pf1WJnUri0NGGAtkjW/fFKS1UO+bJk0d6613nlh6eefn3pvcLAUG2t9E9Cq1anHMy8i9RRjpL173Xu3f/mlcHiuUcP65qhLF2vp1Mm6KLZmTWv70qXSO+9Y57psmbU0aSKNHGl9ExIS4vlzA1CxmApOkpk9e/Y526xevdpIMnv27HGt6969u3n44YfP+p7NmzcbSWblypWudYmJiUaS2bp1qzHGmLlz5xofHx+zf/9+V5vPPvvMBAQEGIfDYYwxZtq0acZut5uTJ0+62kycONFERUWZgoKCYp+nw+Ewklz7RdHuvvtuI8ncdNNNxXtDZqYx1n/L1vPKKjvbmI4dT53rZ58Zs2mTMaf9XJYZb33GZXncpUuNadjQ2rePjzFPPGFMTk7lPNfiHnf2bGNeesmYO+4w5oorjPHzO7XtzKVBA2NuuMGYxx4zZsYMY9avt35GL/SY5zvXnBxjVq825tVXjRkyxJj69Yuup2FDY267zZjXXzfmp5+Myc0t3nH37TNm3DhjwsJObQsONmbUKGN+++1CPsnSOd/SUh5+nir7cavSuXrruF461+LmtQrZA36hHA6HbDabap3R6zJjxgx98sknioiIUN++ffX0008r+I8LohITE2W329WxY0dX+06dOslut2vFihWKiYlRYmKiYmNjFRUV5WrTp08fZWdnKykpST179lRiYqK6d+/uNjVenz59NG7cOO3evVvR0dFF1pydna3s0+YBzsjIKI2PotIbO3asPvjgA82ePVvbt29XixYtvF1S+eDvL02fbl30J1njVyVraESjRtb6M5cGDS5+Fo7KJjvbuvvkpEnWP+tNmlifa5cu1vYzhp9VKb16WXfhdMrNtXrEN2ywlvXrrcfkZKsXeu/eU73nkjUe/dJL3XvKr7hCql+/+Bd8Hj58qmd7xQpr/vMTJ9zbOG9O5Ozd7tLFGqNfEvXrSy+8ID3xhPVNyGuvWWPmX3tNev116cYbrbH13bpVrYtWAZxXpQ/gJ0+e1N///nfFxcUp5LSvBYcOHaro6GhFRkZq48aNGjdunH755Rct+OMiqtTUVIWHhxfaX3h4uFJTU11tIiIi3LaHhobK39/frU3jxo3d2jjfk5qaetYAPnHiRD3zzDMlO+kq7LLLLlP//v317bffasqUKXr77be9XVL5cdovimrXTtqxw7qt+a5d1vLf/7q3DwiwZnooKpyHh1e9QLFxo3THHdaQBUm6917p1Vc9O4tJReLnZw0/iY099QufJB09an2WzkDuDOfHjp16/emnp9rXqnUqkLdqZc2N7rRli7Ru3anAvW1b4Tqc85w7lyuvtIaYlKYaNawx43/5i3UtwKuvWn+fZs+2lnbtrCB+yy3WL8MAqrxKHcBzc3N12223qaCgQNNOnx5M1vhvp9jYWDVv3lwdOnTQ2rVr1a5dO0nWTV7OZIxxW1+SNuaPC5OKeq/TuHHjNHr0aNfrjIwMNWjQ4Kztccrf/vY3ffvtt/rwww81YcKEIn+RqvKWLbNCQ1qadZHZmYvzToybN1vLmUJCig7mzZtXvvGvBQXSP/9pXXCYnW3Nif3uu+69vSi+WrWsHuFu3U6tM8bqGXeGcufjtm1WYHeOsz7TlVcWXteypXvgjonx3C+LPj7WXWj79LH+3vzzn9bFmmvXSvHx0t/+Zt0c6/77mVsdqOIqbQDPzc3VLbfcol27dmnRokVuvd9Fadeunfz8/LRjxw61a9dOkZGROnjwYKF2hw4dcvVgR0ZGatWqVW7b09PTlZub69bG2RvulPbH3e/O7D0/XUBAAHd0LKGrr75aV111lVavXq033njD7UJbnMZmkyIirOXqq9235edbgWj7dqun/PRwvnu3lJFh3e78jAubJUmRke6BvGFDj5xOmdi3T0pIkBYutF7fcIP03nvWOaL02GzWUKhGjU5d7ClZv/Bs2eIeyn/5xZqHW7JmnTnzYsnatb1zDme67DLrQs0XXrAuzn3jDenAAenJJ62ZYu64w5rG8PLLvV2p9fd9507rs/3lF+sXBqfISCk01Fpq1bqw59WrV71vyoBiqpQB3Bm+d+zYocWLF6t2Mf5B3rRpk3Jzc1WvXj1JUufOneVwOLR69Wpd9cdct6tWrZLD4VCXP8Z7du7cWc8//7xSUlJc75s/f74CAgLU/o+ZEDp37qzHH39cOTk58v/jq8f58+crKiqq0NAUlA6bzaa//e1vGjJkiN5880099thjCnLemhvF4+srRUdbS58+7ttOnpR++63onvODB61wlJpadI/lqFHSX/9qzRRS3v9jnjlTeuABqwc2MFCaMsWqvbzXXZkEBEht2liLU1bWqdlIDhzw3owqxVW7tvXtyZgx0hdfWMNTfvrJmlP9//7PGjs/apR1cyRPTFfpcJz6Rca5bNwoHT9edPvMTGvZu/fCj+Xvf2GBnU4nVCE24xwPUYFkZmbq119/lSS1bdtWU6ZMUc+ePRUWFqaoqCgNHjxYa9eu1bfffuvWyxwWFiZ/f3/t3LlTM2bM0A033KA6depo8+bNGjNmjAIDA7VmzRr5/nHhWd++fXXgwAG98847kqxpCBs1auQ2DWGbNm0UERGhSZMm6ciRI0pISNCgQYNc0xA6HA7FxMTo2muv1eOPP64dO3YoISFBTz311AVNQ5iRkSG73S6Hw3He3nxYfzYxMTHauXOnXn/9dY0YMaLohqf/Z56Zad0ivrLyxLk6HO495jt2WDc1Ob1HTbLGBd9zj9ULWLdu6dchlfx8jx61hgk4xyFfeaV1gV1xLuj11s9TVTpuRT9XY6zx6q++ao0PLyiw1sfESA8/LN15p/u+S3rcggLr2o7Tg/Yvv1jfYBWlevVTF75eeqk1XEayxthnZ1t/L9LTreV8z48ePXVeJWW3W9et1K9/9iU8vHQuFOfnuHIe10vnWty8ViED+JIlS9SzZ89C6++66y6NHz/+rBc2Ll68WD169NDevXt1xx13aOPGjcrMzFSDBg3Ur18/Pf300woLC3O1P3LkiEaOHKmvv/5akjRw4EC98cYbbrOpJCcn68EHH9SiRYsUGBiouLg4TZ482W34yIYNG/TQQw9p9erVCg0N1f3336+nnnrqnGPAz0QAv3BvvfWWHnzwQTVu3Fg7duxQtWpFfOFDAPfscW+5xbpJy8mT1utq1awhB3ffLfXta70ui+MW93wXL7ZuQrN3r/Uf+z/+Yc1w4edXdscsDVXpuJXpXHfvlqZOtXrCnTNdhYZaF3Q+9JA1E1FxjnvsmNWLfXrQ3rDBal+USy6RWre2wnbr1tbSvPmpMHux51pQYL2vuIHd+fzIEetbtOLy9bWGyJwrpNevf+pczoaf44p3XGOsmZZyc63Zp4p6dDhOXWuyc6c1a5UHVOoAXhURwC/ciRMn1LBhQ/3++++aOXOmbr311sKNCOCeP25urjW84/33rWninCIjrd6/u+92v+tgaR33XOebnW2F7SlTrH/Ymza1er0v9GZO5eUzrszHrYzneuyYddfNf/7TCgqSFS6HDLEu2OzR41S7Q4es8fCnh23ne84UEGCNMT89bF9xxfnHyZeHz/inn6xgvn+/+3LggPWYmlr8Xvbg4HMH9NDQU7PrVLWf48DAs4fYswXb820rqs3x45JzVrLbbrP+nS3OPs72mJd3Yef91lvW3yUPIIBXMgTwknnmmWc0fvx4tW/fXmvWrCn8rQMB3LvH3bhR+uADay7tQ4dOre/c2Qrit95a8llVinu+GzZYdwvdsMF6PWyYFcTP12t2MccsbVXpuJX5XPPzpe++s4anLFlSeHtIyKme8jPVq1e4VzsmpmTfKlWEzzgvz+otPzOgnx7S9++3fmm5EMHB1i8/1apZy/meX0jb058bY12kK1nXmvj4WOeUn3/2x3Ntu5DHo0et4/r6Fr4LbEXm52ddd+B8rFbN+lmQpI8+sjp4PIAAXskQwEvm999/V8OGDXXixAktWrSoyKFLVUZ5/k81J8e6Kcv771uPzv8UAgOtXsC775auuebCLlI733ELCqyg8/jj1vHr1rWGAgwceOHnWNxjlpWqdNyqcq7r1lk39PnsM/cbPPn5WTOsnB60W7cu3WspKtNnfOzYuQO6sze9MgXRi+Xv7x5knY8Xs06SXn7ZenzhBevP+cw2F/NYrVrhC+QZA47SQAAvuYceekjTpk3T9ddfr++//97b5XhPRflPNTXV6hF//33rAk6nJk2sKQHvuqt4Uxue67jJyda+Fi+2Xvfvb4Xvc0wNWiwV5TOuyMetSucqWTMONW1qPV+50rqLZ1nfzKeqfcYZGdZFn5I1vMff373HuKhe5OI8P9f248ell16yjjl2rHVfBl/fwj3rRT2WdFu1atZwuz9madP27dYsNKeHWV/fspnpqQr9W0EAr2QI4CW3c+dOtWjRQgUFBVq/fr1atWrl7ZK8o6L9p2qMtGqVFcRnzjz1VbLNZk3ddvfd1s1wqle/sON++qn04IPWBTo1ali9jH/5S+n8p1PRPuOKeNyqdK7eOm5VOldvHbcqnau3jlvOA7gHJh0FvKtp06YaPHiwJGny5MlergbFZrNZF0H+619Wr/jHH0s9e1rBfP586/bm9epZs0UkJVnrzyU93XrP0KFW+O7Y0fqaf9gw5vYGAHgUARxVwt/+mNP2008/1b59+7xcDS5YjRrWrbwXLbJmfHjySWuKtqNHpWnTpA4drHGwr73mfjGn0+LF1pjZmTOtr1jHj5eWLz818wEAAB5EAEeVcOWVV6p79+7Ky8vTP//5T2+Xg4vRpIk0YYJ1kxFnT3hAgDWLySOPWNOKDR4szZt36j0DBli3lW/eXPrxR+npp0t3znEAAC4AARxVhrMX/J133pHD4fByNbhovr7WWPBPP5VSUqQ337R6wnNzpS+/lG6+2b39/fdLP/9sDT0BAMCLCOCoMvr27avLL79cx44d0zvO+VdROYSGWhdWrlljzWLwyCPuNxv54gvrRgyVeZ53AECFQQBHleHj46OxY8dKkv75z38q5/S5dVF5tGpl3Uhnx45T666/3nv1AABwBgI4qpS4uDhFRUXpwIED+vTTT71dDspSWc+VDABACRHAUaX4+/vr4YcflmRNSVhQUODligAAQFVDAEeV89e//lXBwcHatGlT1b4zJgAA8AoCOKocu92uv/71r5KkSZMmebkaAABQ1RDAUSU9/PDDqlatmpYuXao1a9Z4uxwAAFCFEMBRJV1yySWKi4uTRC84AADwLAI4qiznlISzZs3Szp07vVwNAACoKgjgqLJatWqlvn37qqCgQFOmTPF2OQAAoIoggKNKc96e/l//+pcefvhh/f77716uCAAAVHYEcFRpPXr0UHx8vPLy8vT666+rWbNmevnll3Xy5ElvlwYAACopAjiqNJvNpo8//lg//PCD2rRpI4fDoccee0wxMTH65JNPuFEPAEtQkGSMtQQFebsaABUcARyQdN111ykpKUkfffSRLrnkEiUnJys+Pl5XXnmlFi1a5O3ySgcBovLizxYAKhQCOPAHHx8f3Xnnndq+fbsmTpyokJAQrV27Vtddd5369eunTZs2ebvEiolwCACAGwI4cIbAwED9/e9/16+//qrhw4erWrVqmjt3rq644grdd999SklJ8XaJAFD58Ms6qhACOHAWdevW1dSpU7Vp0ybddNNNKigo0LvvvqvmzZtr/PjxyszM9HaJAFD6CMJAmSOAA+fRokULzZo1S8uXL1enTp2UlZWlZ555Rs2bN9e7776rvLw8b5cIeIc3ghrhEEBxlPN/KwjgQDF17dpVK1as0Oeff64mTZooNTVV9913n1q3bq3vvvtOxhhvlwgAqAi8FQ6r2nHLMQI4cAFsNpuGDBmiLVu26LXXXlNYWJg2b96s/v3767rrrtPatWu9XSK8if9kgIqHv7fwAgI4UAL+/v56+OGHtXPnTv3tb39TQECAFi9erPbt2ys+Pl7JycneLhEAAJRTBHDgItSqVUsvv/yytm3bpqFDh0qSPvnkE7Vo0UKPPfaYjh496t0CAVRs9M4ClRIBHCgFjRo10ieffKI1a9aoR48eys7O1ssvv6xmzZrpn//8p3JycrxdIgAAKCcI4EAp6tChgxYtWqRvvvlGLVu21OHDhzVq1Chddtll+uKLL7hQEwAAEMCB0maz2dS/f3+tX79eb7/9tiIiIrRz504NGTLENZMKAACougjgQBmpVq2a/vrXv2rHjh166qmnVKNGDSUmJqpr1666+eabtWPHDm+XCAAAvIAADpSx4OBgPfPMM9qxY4f+8pe/yMfHR7NmzdJll12mBx98UPv27fN2iQAAwIMI4ICHREVF6d1339Uvv/yivn37Ki8vT2+99ZaaNm2qESNG6MCBA94usXJh9ggAQDlFAAc8LDY2VnPnztXixYt1zTXXKCcnR2+88YaaNGmihx9+WCkpKd4uEQAAlCECOOAlPXr00JIlS7Rw4UJ169ZN2dnZev3119WkSRM98sgjSk1N9XaJAACgDBDAAS+y2Wy69tprtWzZMi1YsEBdunTRyZMn9dprr6lJkyYaO3as0tLSvF0mAAAoRQRwoByw2Wz605/+pOXLl2vevHnq2LGjTpw4oVdeeUXR0dF69NFHdejQIW+XCQAASgEBHChHbDab+vTpo8TERM2dO1dXXnmljh8/rkmTJik6Olrjxo3T4cOHvV0mAAC4CARwoByy2Wzq27evVq1apW+++Ubt27dXVlaWXnzxRTVu3Fj/+Mc/dOTIEW+XCQAASoAADpRjzrtqrlmzRl999ZXatm2rzMxMvfDCC2rcuLGefPJJpaene7tMAABwAQjgQAVgs9k0cOBAJSUlafbs2WrdurWOHTum5557To0bN9b48eN19OhRb5cJAACKgQAOVCA2m02DBg3S2rVr9cUXXyg2NlYZGRl65plnFB0drQkTJsjhcHi7TAAAcA4EcKAC8vHx0eDBg/XLL7/o888/1+WXX66jR4/q6aefVnR0tJ5//nllZGR4u0wAAFAEAjhQgfn4+GjIkCFav369Zs6cqZYtWyo9PV1PPPGEoqOjNXHiRB07dszbZQIAgNMQwIFKwMfHR7feeqs2bNigGTNmKCYmRkeOHNHjjz+u6OhovfTSS8rMzPR2mQAAQARwoFLx9fVVXFycNm3apOnTp6tZs2Y6fPiw/v73v6tJkyaaPHmyjh8/7u0yAQCo0gjgQCXk6+urO+64Q1u2bNGHH36opk2b6tChQ/rb3/6mxo0ba/jw4Vq8eLHy8vK8XSoAAFWOzRhjvF0Ezi8jI0N2u10Oh0MhISHeLgcVTF5enqZPn65nn31Wu3btcq2vU6eOBg0apMGDB+vaa6+Vv7+/F6sEAKBiK25eI4BXEARwlIbc3FzNnz9fs2bN0ldffeV2N81atWppwIABGjx4sHr37q3AwEAvVgoAQMVDAK9kCOAobbm5uVq6dKlmzZql2bNn6+DBg65tQUFB6tevnwYPHqwbbrhBNWvW9GKlAABUDATwSoYAjrKUn5+vFStWaNasWfryyy+1d+9e17bq1aurT58+Gjx4sAYMGKBatWp5r1AAAMoxAnglQwCHpxhjtGbNGs2aNUuzZs3Szp07Xdv8/Px03XXXafDgwbrxxhtVt25dL1YKAED5QgCvZAjg8AZjjNavX+8K45s3b3Zt8/Hx0TXXXKPBgwfrpptuUlRUlBcrBQDA+wjglQwBHOXB1q1b9eWXX2rWrFlau3at27bOnTtr8ODBGjx4sBo3buydAgEA8CICeCVDAEd5s2vXLlcYT0xMdNvWvn173XTTTRo8eLBiYmK8VCEAAJ5FAK9kCOAoz/bv36/Zs2dr1qxZWrZsmQoKClzbLr/8cg0ePFi33HKLLr/8ci9WCQBA2SKAVzIEcFQUaWlp+uqrrzRr1iwtXLjQ7W6bHTp0UEJCgm6//XaFhYV5sUoAAEofAbySIYCjIkpPT9c333yjL774Qt9//70rjPv7++vGG2/U3XffrV69eqlatWperhQAgItHAK9kCOCo6A4dOqRPP/1UH3zwgX755RfX+qioKMXHxyshIUGXXnqpFysEAODiEMArGQI4KpN169bpgw8+0IwZM3T48GHX+k6dOikhIUG33Xab7Ha7FysEAODCEcArGQI4KqOcnBx9++23+vDDDzV37lzl5+dLsu6++ec//1l33323rr32Wvn6+nq5UgAAzo8AXskQwFHZpaam6pNPPtEHH3zgdsOfBg0a6M4771RCQoKaNWvmxQoBADg3AnglQwBHVWGMUVJSkj744AN9+umnOnr0qGtbt27ddPfdd2vIkCEKDg72XpEAABShuHnNx4M1lZply5ZpwIABioqKks1m05w5c9y2G2M0fvx4RUVFKTAwUD169NCmTZvc2mRnZ2vEiBGqU6eOgoKCNHDgQO3bt8+tTXp6uuLj42W322W32xUfH+8WBiQpOTlZAwYMUFBQkOrUqaORI0cqJyfHrc2GDRvUvXt3BQYGqn79+powYYL4vQcoms1mU4cOHfTmm28qJSVF//73v9W3b1/5+Pho+fLluvfeexUZGam77rpLixcvdptzHACAiqBCBvCsrCy1bt1ab7zxRpHbX375ZU2ZMkVvvPGG1qxZo8jISPXq1UvHjh1ztRk1apRmz56tmTNnavny5crMzFT//v1dY1AlKS4uTuvWrdO8efM0b948rVu3TvHx8a7t+fn56tevn7KysrR8+XLNnDlTs2bN0pgxY1xtMjIy1KtXL0VFRWnNmjWaOnWqJk+erClTppTBJwNULtWrV9ctt9yiuXPnKjk5WS+++KJiYmJ0/Phxffzxx7r22mvVtGlTjR8/Xrt27fJ2uQAAFI+p4CSZ2bNnu14XFBSYyMhI8+KLL7rWnTx50tjtdvP2228bY4w5evSo8fPzMzNnznS12b9/v/Hx8THz5s0zxhizefNmI8msXLnS1SYxMdFIMlu3bjXGGDN37lzj4+Nj9u/f72rz2WefmYCAAONwOIwxxkybNs3Y7XZz8uRJV5uJEyeaqKgoU1BQUOzzdDgcRpJrv0BVVVBQYBITE819991nQkJCjCTX0qNHD/PRRx+ZzMxMb5cJAKiCipvXKmQP+Lns2rVLqamp6t27t2tdQECAunfvrhUrVkiSkpKSlJub69YmKipKsbGxrjaJiYmy2+3q2LGjq02nTp1kt9vd2sTGxioqKsrVpk+fPsrOzlZSUpKrTffu3RUQEODW5sCBA9q9e/dZzyM7O1sZGRluCwBriEqnTp30zjvvKDU1VTNmzFCvXr1ks9m0ZMkS3XXXXYqMjNS9996r//3vf4WGhAEA4G2V7vZzqampkqSIiAi39REREdqzZ4+rjb+/v0JDQwu1cb4/NTVV4eHhhfYfHh7u1ubM44SGhsrf39+tTePGjQsdx7ktOjq6yPOYOHGinnnmmfOeL1CVBQYGKi4uTnFxcUpOTtb06dP14Ycf6tdff9X777+v999/X5IUFhamevXqKTIyUpGRkWd9HhoaKpvN5uWzAgBUdpUugDud+Z+oMea8/7Ge2aao9qXRxvxxAea56hk3bpxGjx7tep2RkaEGDRqcs36gKmvYsKH+8Y9/6PHHH9ePP/6oDz/8UJ9//rmOHTumI0eO6MiRI4Uuxj6Tv79/kcG8qNenf6sFAMCFqHQBPDIyUpLVu1yvXj3X+rS0NFfPc2RkpHJycpSenu7WC56WlqYuXbq42hw8eLDQ/g8dOuS2n1WrVrltT09PV25urlsbZ2/46ceRCvfSny4gIID/4IESsNls6tatm7p166Z3331XR44cUWpqqlJTU5WSknLW5+np6crJyVFycrKSk5PPe5zQ0NCz9qY3bNhQnTp1kr+/vwfOGABQ0VS6AB4dHa3IyEgtWLBAbdu2lWTdbW/p0qV66aWXJEnt27eXn5+fFixYoFtuuUWSlJKSoo0bN+rll1+WJHXu3FkOh0OrV6/WVVddJUlatWqVHA6HK6R37txZzz//vFJSUlxhf/78+QoICFD79u1dbR5//HHl5OS4/jOeP3++oqKiCg1NAVC6bDabateurdq1a+vyyy8/Z9vs7GwdPHjwvEE9NTXV9Qt8enq6tmzZUuT+QkJCdMMNN2jQoEHq27cv8/cDAFwq5I14MjMz9euvv0qS2rZtqylTpqhnz54KCwtTw4YN9dJLL2nixIn64IMP1Lx5c73wwgtasmSJtm3b5rp5xwMPPOC6BXZYWJjGjh2rw4cPKykpyXXb6759++rAgQN65513JEn33XefGjVqpG+++UaSNQ1hmzZtFBERoUmTJunIkSNKSEjQoEGDNHXqVEmSw+FQTEyMrr32Wj3++OPasWOHEhIS9NRTT7lNV3g+3IgHKB+MMTp69Og5Q/qmTZvcvvny9/fXddddp0GDBunGG28857dfAICKq9h5rYxnYykTixcvdpt6zLncddddxhhrmrKnn37aREZGmoCAAHPNNdeYDRs2uO3jxIkTZvjw4SYsLMwEBgaa/v37m+TkZLc2hw8fNkOHDjXBwcEmODjYDB061KSnp7u12bNnj+nXr58JDAw0YWFhZvjw4W5TDhpjzPr1683VV19tAgICTGRkpBk/fvwFTUFoDNMQAhVJfn6+SUxMNI899php0aKF279TNpvNdOnSxUyaNMns2LHD26UCAEpRcfNahewBr4roAQcqri1btmjOnDmaM2eOVq9e7bbt8ssv15///GcNGjRI7dq1YxYWAKjAipvXCOAVBAEcqBz27dunr7/+WrNnz9aSJUuUl5fn2tagQQMNGjRIgwYN0tVXXy0/Pz8vVgoAuFAE8EqGAA5UPunp6Zo7d65mz56tefPmKSsry7UtNDRUAwYM0KBBg9S7d28FBQV5sVIAQHEQwCsZAjhQuZ04cUILFy7U7Nmz9fXXX+v33393bQsMDFTv3r01aNAgDRgwQLVr1/ZipQCAsyGAVzIEcKDqyM/P14oVKzRnzhzNnj1bu3btcm3z8fHRNddc4xqq0qhRIy9WCgA4HQG8kiGAA1WTMUYbNmzQ7NmzNWfOHK1bt85te9u2bV1hvFWrVlzECQBeRACvZAjgACRp9+7drhlV/ve//6mgoMC1rW7dumrWrJmaNm1aaAkPDyecA0AZI4BXMgRwAGf6/fff9c0332jOnDmaP3++Tp48eda2QUFBatKkSZHhvGHDhsy4AgClgABeyRDAAZzL8ePHtXXrVu3cubPQsnfvXp3rn3pfX181atTorAG9Zs2aHjwTAKi4COCVDAEcQEllZ2drz549RYbz33777Zw955IUHh5+1nAeERHB0BYA+AMBvJIhgAMoCwUFBUpJSXGF8TMD+uHDh8/5/ho1aig6OlqNGjVS48aNXYvzdd26dQnoAKoMAnglQwAH4A0Oh8Ott/zMoS2nXwRalMDAQLdwfmZQpwcdQGVCAK9kCOAAypucnBzt3r1be/bs0e7duws9P3DgwDnHnktSQECAK5QXFdTr1asnHx8fD50RAFwcAnglQwAHUNHk5ORo7969RYbz3bt3a//+/eftQff391eDBg0KDW9p0KCBgoODVbNmTQUFBbkemc0FgDcRwCsZAjiAyiY3N1f79u07ay/63r17lZ+ff0H79Pf3V1BQkFsoP9tjcdo4H6tXr85QGQDnVdy8Vs2DNQEA4OLn56fo6GhFR0cXuT0vL0/79+8vMpzv379fmZmZysrKUmZmpvLy8iRZve45OTlKT08v1Vp9fHwUFBSkwMBA+fn5yd/fX35+fm7PL/TxQttWq1at0GNR64p69PHx4RcIoByhB7yCoAccAM4uJyfHFcidofxcj8Vtc+LECW+fWqkpTlg/27ozl3Ntu9j3+Pr6ymazuX5pOP15UesudntxHi9mHb/4VC30gAMAqgx/f3+FhYUpLCysVPebn5+v48ePKzMzU5mZmTp58qRyc3OVm5urnJycC3q8mLZ5eXnKzc0956Pz+dmG7TjbwPPOFfDLy+Ks82yvS6tNcT+vC/lsz2fs2LHq27dvsffpCQRwAADOwtfXV8HBwQoODvZ2KcVmjHEL5OcK6+d7zM/PL/S+sy2l1SYvL0/GGBljVFBQUGbPz7Xu9MfT213Mn8mFXs+A0hMXF+ftEgohgAMAUInYbDbXuPHAwEBvl1OpnC2cn2/d+bZ5e3Ge29lel1ab4n7GF/LnURxXXnllsffpKQRwAACAYrDZbPL19fV2GagEuLsBAAAA4EEEcAAAAMCDCOAAAACABxHAAQAAAA8igAMAAAAeRAAHAAAAPIgADgAAAHgQARwAAADwIAI4AAAA4EEEcAAAAMCDCOAAAACABxHAAQAAAA8igAMAAAAeRAAHAAAAPIgADgAAAHgQARwAAADwIAI4AAAA4EEEcAAAAMCDCOAAAACABxHAAQAAAA8igAMAAAAeRAAHAAAAPIgADgAAAHgQARwAAADwIAI4AAAA4EEEcAAAAMCDCOAAAACABxHAAQAAAA8igAMAAAAeRAAHAAAAPIgADgAAAHgQARwAAADwIAI4AAAA4EEEcAAAAMCDCOAAAACABxHAAQAAAA8igAMAAAAeRAAHAAAAPIgADgAAAHgQARwAAADwIAI4AAAA4EEEcAAAAMCDCOAAAACABxHAAQAAAA8igAMAAAAeRAAHAAAAPKjSBvDGjRvLZrMVWh566CFJUkJCQqFtnTp1cttHdna2RowYoTp16igoKEgDBw7Uvn373Nqkp6crPj5edrtddrtd8fHxOnr0qFub5ORkDRgwQEFBQapTp45GjhypnJycMj1/AAAAlE+VNoCvWbNGKSkprmXBggWSpCFDhrjaXH/99W5t5s6d67aPUaNGafbs2Zo5c6aWL1+uzMxM9e/fX/n5+a42cXFxWrdunebNm6d58+Zp3bp1io+Pd23Pz89Xv379lJWVpeXLl2vmzJmaNWuWxowZU8afAAAAAMojmzHGeLsITxg1apS+/fZb7dixQzabTQkJCTp69KjmzJlTZHuHw6G6detq+vTpuvXWWyVJBw4cUIMGDTR37lz16dNHW7Zs0WWXXaaVK1eqY8eOkqSVK1eqc+fO2rp1q2JiYvT999+rf//+2rt3r6KioiRJM2fOVEJCgtLS0hQSElKs+jMyMmS32+VwOIr9HgAAAHhOcfNape0BP11OTo4++eQT3XPPPbLZbK71S5YsUXh4uFq0aKFhw4YpLS3NtS0pKUm5ubnq3bu3a11UVJRiY2O1YsUKSVJiYqLsdrsrfEtSp06dZLfb3drExsa6wrck9enTR9nZ2UpKSjprzdnZ2crIyHBbAAAAUPFViQA+Z84cHT16VAkJCa51ffv21YwZM7Ro0SK98sorWrNmja699lplZ2dLklJTU+Xv76/Q0FC3fUVERCg1NdXVJjw8vNDxwsPD3dpERES4bQ8NDZW/v7+rTVEmTpzoGldut9vVoEGDEp07AAAAypdq3i7AE9577z317dvXrRfaOaxEkmJjY9WhQwc1atRI3333nW666aaz7ssY49aLfvrzi2lzpnHjxmn06NGu1xkZGYRwAACASqDS94Dv2bNHP/zwg/7yl7+cs129evXUqFEj7dixQ5IUGRmpnJwcpaenu7VLS0tz9WhHRkbq4MGDhfZ16NAhtzZn9nSnp6crNze3UM/46QICAhQSEuK2AAAAoOKr9AH8gw8+UHh4uPr163fOdocPH9bevXtVr149SVL79u3l5+fnmj1FklJSUrRx40Z16dJFktS5c2c5HA6tXr3a1WbVqlVyOBxubTZu3KiUlBRXm/nz5ysgIEDt27cvtfMEAABAxVCpZ0EpKChQdHS0br/9dr344ouu9ZmZmRo/frwGDx6sevXqaffu3Xr88ceVnJysLVu2KDg4WJL0wAMP6Ntvv9WHH36osLAwjR07VocPH1ZSUpJ8fX0lWWPJDxw4oHfeeUeSdN9996lRo0b65ptvJFnTELZp00YRERGaNGmSjhw5ooSEBA0aNEhTp04t9rkwCwoAAED5xiwokn744QclJyfrnnvucVvv6+urDRs26MYbb1SLFi101113qUWLFkpMTHSFb0l69dVXNWjQIN1yyy3q2rWratSooW+++cYVviVpxowZatWqlXr37q3evXvriiuu0PTp092O9d1336l69erq2rWrbrnlFg0aNEiTJ08u+w8AAAAA5U6l7gGvTOgBBwAAKN/oAQcAAADKIQI4AAAA4EEEcAAAAMCDCOAAAACABxHAAQAAAA8igAMAAAAeRAAHAAAAPIgADgAAAHgQARwAAADwIAI4AAAA4EEEcAAAAMCDCOAAAACABxHAAQAAAA8igAMAAAAeRAAHAAAAPIgADgAAAHgQARwAAADwIAI4AAAA4EEEcAAAAMCDCOAAAACABxHAAQAAAA8igAMAAAAeRAAHAAAAPIgADgAAAHgQARwAAADwIAI4AAAA4EEEcAAAAMCDCOAAAACABxHAAQAAAA8igAMAAAAeRAAHAAAAPIgADgAAAHgQARwAAADwIAI4AAAA4EEEcAAAAMCDCOAAAACABxHAAQAAAA8igAMAAAAeRAAHAAAAPIgADgAAAHgQARwAAADwIAI4AAAA4EEEcAAAAMCDCOAAAACABxHAAQAAAA8igAMAAAAeRAAHAAAAPIgADgAAAHgQARwAAADwIAI4AAAA4EEEcAAAAMCDCOAAAACABxHAAQAAAA8igAMAAAAeRAAHAAAAPIgADgAAAHgQARwAAADwIAI4AAAA4EEEcAAAAMCDCOAAAACABxHAAQAAAA8igAMAAAAeRAAHAAAAPIgADgAAAHgQARwAAADwIAI4AAAA4EGVMoCPHz9eNpvNbYmMjHRtN8Zo/PjxioqKUmBgoHr06KFNmza57SM7O1sjRoxQnTp1FBQUpIEDB2rfvn1ubdLT0xUfHy+73S673a74+HgdPXrUrU1ycrIGDBigoKAg1alTRyNHjlROTk6ZnTsAAADKt0oZwCXp8ssvV0pKimvZsGGDa9vLL7+sKVOm6I033tCaNWsUGRmpXr166dixY642o0aN0uzZszVz5kwtX75cmZmZ6t+/v/Lz811t4uLitG7dOs2bN0/z5s3TunXrFB8f79qen5+vfv36KSsrS8uXL9fMmTM1a9YsjRkzxjMfAgAAAMofUwk9/fTTpnXr1kVuKygoMJGRkebFF190rTt58qSx2+3m7bffNsYYc/ToUePn52dmzpzparN//37j4+Nj5s2bZ4wxZvPmzUaSWblypatNYmKikWS2bt1qjDFm7ty5xsfHx+zfv9/V5rPPPjMBAQHG4XBc0Dk5HA4j6YLfBwAAAM8obl6r5t34X3Z27NihqKgoBQQEqGPHjnrhhRfUpEkT7dq1S6mpqerdu7erbUBAgLp3764VK1bor3/9q5KSkpSbm+vWJioqSrGxsVqxYoX69OmjxMRE2e12dezY0dWmU6dOstvtWrFihWJiYpSYmKjY2FhFRUW52vTp00fZ2dlKSkpSz549z1p/dna2srOzXa8dDockKSMjo1Q+HwAAAJQuZ04zxpyzXaUM4B07dtTHH3+sFi1a6ODBg3ruuefUpUsXbdq0SampqZKkiIgIt/dERERoz549kqTU1FT5+/srNDS0UBvn+1NTUxUeHl7o2OHh4W5tzjxOaGio/P39XW3OZuLEiXrmmWcKrW/QoME53wcAAADvOnbsmOx2+1m3V8oA3rdvX9fzVq1aqXPnzmratKk++ugjderUSZJks9nc3mOMKbTuTGe2Kap9SdoUZdy4cRo9erTrdUFBgY4cOaLatWuf972lISMjQw0aNNDevXsVEhJS5sfzJs618qpK58u5Vl5V6Xw518qrqpyvMUbHjh1zG/1QlEoZwM8UFBSkVq1aaceOHRo0aJAkq3e6Xr16rjZpaWmu3urIyEjl5OQoPT3drRc8LS1NXbp0cbU5ePBgoWMdOnTIbT+rVq1y256enq7c3NxCPeNnCggIUEBAgNu6WrVqFe+ES1FISEil/otyOs618qpK58u5Vl5V6Xw518qrKpzvuXq+nSrtLCiny87O1pYtW1SvXj1FR0crMjJSCxYscG3PycnR0qVLXeG6ffv28vPzc2uTkpKijRs3utp07txZDodDq1evdrVZtWqVHA6HW5uNGzcqJSXF1Wb+/PkKCAhQ+/bty/ScAQAAUD5Vyh7wsWPHasCAAWrYsKHS0tL03HPPKSMjQ3fddZdsNptGjRqlF154Qc2bN1fz5s31wgsvqEaNGoqLi5Nk/eZy7733asyYMapdu7bCwsI0duxYtWrVSn/6058kSS1bttT111+vYcOG6Z133pEk3Xffferfv79iYmIkSb1799Zll12m+Ph4TZo0SUeOHNHYsWM1bNiwSv/bHwAAAIpWKQP4vn37dPvtt+v3339X3bp11alTJ61cuVKNGjWSJD366KM6ceKEHnzwQaWnp6tjx46aP3++goODXft49dVXVa1aNd1yyy06ceKErrvuOn344Yfy9fV1tZkxY4ZGjhzpmi1l4MCBeuONN1zbfX199d133+nBBx9U165dFRgYqLi4OE2ePNlDn0TJBQQE6Omnny40DKYy4lwrr6p0vpxr5VWVzpdzrbyq2vmej82cb54UAAAAAKWmSowBBwAAAMoLAjgAAADgQQRwAAAAwIMI4AAAAIAHEcBRyLRp0xQdHa3q1aurffv2+t///uftksrExIkTdeWVVyo4OFjh4eEaNGiQtm3b5u2yPGLixImuKTkro/379+uOO+5Q7dq1VaNGDbVp00ZJSUneLqtM5OXl6YknnlB0dLQCAwPVpEkTTZgwQQUFBd4u7aItW7ZMAwYMUFRUlGw2m+bMmeO23Rij8ePHKyoqSoGBgerRo4c2bdrknWIv0rnONTc3V4899phatWqloKAgRUVF6c4779SBAwe8V/BFOt+f7en++te/ymaz6bXXXvNYfaWpOOe6ZcsWDRw4UHa7XcHBwerUqZOSk5M9X+xFOt+5ZmZmavjw4brkkksUGBioli1b6q233vJOsV5GAIebf//73xo1apT+8Y9/6Oeff9bVV1+tvn37Vsh/CM5n6dKleuihh7Ry5UotWLBAeXl56t27t7KysrxdWplas2aN/vWvf+mKK67wdillIj09XV27dpWfn5++//57bd68Wa+88opX7iTrCS+99JLefvttvfHGG9qyZYtefvllTZo0SVOnTvV2aRctKytLrVu3dpve9XQvv/yypkyZojfeeENr1qxRZGSkevXqpWPHjnm40ot3rnM9fvy41q5dqyeffFJr167Vl19+qe3bt2vgwIFeqLR0nO/P1mnOnDlatWrVeW/rXZ6d71x37typbt266dJLL9WSJUv0yy+/6Mknn1T16tU9XOnFO9+5PvLII5o3b54++eQTbdmyRY888ohGjBihr776ysOVlgMGOM1VV11l7r//frd1l156qfn73//upYo8Jy0tzUgyS5cu9XYpZebYsWOmefPmZsGCBaZ79+7m4Ycf9nZJpe6xxx4z3bp183YZHtOvXz9zzz33uK276aabzB133OGlisqGJDN79mzX64KCAhMZGWlefPFF17qTJ08au91u3n77bS9UWHrOPNeirF692kgye/bs8UxRZehs57tv3z5Tv359s3HjRtOoUSPz6quvery20lbUud56662V7u+rMUWf6+WXX24mTJjgtq5du3bmiSee8GBl5QM94HDJyclRUlKS68ZCTr1799aKFSu8VJXnOBwOSVJYWJiXKyk7Dz30kPr16+e6o2tl9PXXX6tDhw4aMmSIwsPD1bZtW7377rveLqvMdOvWTQsXLtT27dul/2/vzsOiqv4/gL9HmGEREUFBEERUFAG3RAxFkDQ1zd0UK0WpTE1z92tUX5cSLdTIzDU1l7DFXND0K6ZspoYgm2KBCkqg4q6I7J/fHzxzfjPMws4Yfl7PM4/jveeec+bMzOUz5557DoDExEScPn0aQ4YM0XHN6lZ6ejpu3bqldL4yMDCAt7f3C3O+kkgkDfbKTmlpKSZOnIiFCxfCxcVF19WpM6Wlpfjtt9/QoUMHDBo0CJaWlujVq5fWITn/Zp6enggNDUVWVhaICOHh4UhNTcWgQYN0XbV6xwE4E+7evYuSkhJYWVkpbbeyssKtW7d0VKv6QUSYN28ePD094erqquvq1Ikff/wRFy5cwMqVK3VdlTp17do1bNy4EY6Ojjh+/DimTZuGDz/8ELt27dJ11erEf/7zH0yYMAFOTk6QSqXo3r075syZgwkTJui6anVKfk56Ec9X+fn5WLx4Md58802Ymprqujp14osvvoC+vj4+/PBDXVelTuXk5CA3NxerVq3C4MGDERYWhlGjRmH06NGIjIzUdfVq3bp16+Ds7AxbW1vIZDIMHjwYGzZsgKenp66rVu8a5FL0rGYkEonS/4lIZVtDM3PmTCQlJeH06dO6rkqdyMzMxOzZsxEWFvavHFdYFaWlpXBzc0NgYCAAoHv37rh06RI2btyISZMm6bh2te+nn37Cnj17EBISAhcXFyQkJGDOnDmwsbGBn5+frqtX516081VRURF8fX1RWlqKDRs26Lo6dSIuLg5ff/01Lly40KDfSwDiZukRI0Zg7ty5AIBu3brhzJkz2LRpE7y9vXVZvVq3bt06nDt3DqGhobC3t0dUVBRmzJgBa2vrBn1lVh0OwJnQvHlz6OnpqfQe5eTkqPQyNSSzZs1CaGgooqKiYGtrq+vq1Im4uDjk5OSgR48eYltJSQmioqKwfv16FBQUQE9PT4c1rD3W1tZwdnZW2tapUyf8+uuvOqpR3Vq4cCEWL14MX19fAEDnzp1x/fp1rFy5skEH4C1btgRQ1hNubW0ttjfk81VRURHGjRuH9PR0nDp1qsH2fkdHRyMnJwetW7cW20pKSjB//nwEBwcjIyNDd5WrZc2bN4e+vr7ac1ZD6xB69uwZAgICcODAAQwdOhQA0KVLFyQkJGD16tUvXADOQ1CYIJPJ0KNHD5w4cUJp+4kTJ9C7d28d1aruEBFmzpyJ/fv349SpU3BwcNB1lepM//79kZycjISEBPFwc3PDW2+9hYSEhAYTfANAnz59VKaTTE1Nhb29vY5qVLfy8vLQqJHyqVxPT69BTEOojYODA1q2bKl0viosLERkZGSDPF/Jg++0tDT8/vvvsLCw0HWV6szEiRORlJSkdL6ysbHBwoULcfz4cV1Xr1bJZDL07NnzhThnFRUVoaio6IU8X6nDPeBMybx58zBx4kS4ubnBw8MDW7ZswY0bNzBt2jRdV63WffDBBwgJCcGhQ4fQpEkT0fPftGlTGBkZ6bh2tatJkyYqY9sbN24MCwuLBjfmfe7cuejduzcCAwMxbtw4xMTEYMuWLdiyZYuuq1Ynhg0bhhUrVqB169ZwcXFBfHw81q5dC39/f11XrcZyc3Nx5coV8f/09HQkJCTA3NwcrVu3xpw5cxAYGAhHR0c4OjoiMDAQxsbGePPNN3VY6+rR9lptbGwwduxYXLhwAUeOHEFJSYk4X5mbm0Mmk+mq2tVW0Xtb/geGVCpFy5Yt0bFjx/quao1V9FoXLlyI8ePHw8vLCz4+Pvjf//6Hw4cPIyIiQneVrqaKXqu3tzcWLlwIIyMj2NvbIzIyErt27cLatWt1WGsd0ekcLOy59O2335K9vT3JZDJ66aWXGuy0fADUPnbs2KHrqtWLhjoNIRHR4cOHydXVlQwMDMjJyYm2bNmi6yrVmcePH9Ps2bOpdevWZGhoSG3btqWPP/6YCgoKdF21GgsPD1f7HfXz8yOisqkIlyxZQi1btiQDAwPy8vKi5ORk3Va6mrS91vT0dI3nq/DwcF1XvVoqem/L+zdPQ1iZ17pt2zZq3749GRoaUteuXengwYO6q3ANVPRab968SZMnTyYbGxsyNDSkjh070po1a6i0tFS3FdcBCRFRnUb4jDHGGGOMMYHHgDPGGGOMMVaPOABnjDHGGGOsHnEAzhhjjDHGWD3iAJwxxhhjjLF6xAE4Y4wxxhhj9YgDcMYYY4wxxuoRB+CMMcYYY4zVIw7AGWOMMcYYq0ccgDPG2HNo9+7d8PLyQrNmzdCoUSNIJBJ069atyvncu3cPCxYsQKdOnWBkZASJRAKJRILg4OBarzNT7/vvvxftnpGRoevqvPDk78XSpUt1XRX2AtPXdQUYY+pdunQJrq6u0NPTw8OHD2FiYgIAKCkpgZmZGXJzc3HmzBl4eHjouKasti1atAhBQUE1zufRo0fw8PBAWlpaLdSKMcZYbeEecMaeU6dPnwYAdOvWTQTfABAfH4/c3FwYGhqiR48euqoe+vXrB4lEgn79+umsDg1RZmYm1q5dCwB4+eWXceTIESQmJiI5ORm//vprlfL69ttvRfC9aNEiREdHIzk5GcnJyZg4cWKt1509f7j3nbHnE/eAM/ackgfgffv2VdoeFRUFAHB3d4dMJqv3erG6FR4ejpKSEgDAd999BxcXl2rn9fvvvwMA3Nzc8MUXX9RK/Rj7tyMiXVeBMe4BZ+x5JQ/APT09lbZHR0er3c4ahqysLPG8Q4cOtZJXTfNhjDFWuzgAZ+w5lJ2dLS4Xlw+0NQXmrGEoKCgQz6VSaa3kVdN8GGOM1S4OwBl7DsmDbEdHR1hZWYntly9fxt27d9GoUSP07t27Vsp6+PAhVqxYAQ8PDzRr1gxSqRQtWrSAs7MzRo0ahY0bNyInJ0eknzx5MiQSCSIjIwEAkZGRYoyp/NGmTRu1ZeXl5SE4OBg+Pj6wsrKCTCaDpaUlBg4ciB07doihF+q0adMGEokEkydPBgCcP38eEyZMgJ2dHQwNDWFnZ4fJkyfj8uXLWl9vfn4+1q1bh379+qF58+aQSqUwNzeHk5MThgwZgq+++qrGY2UzMjIwd+5cuLi4oEmTJjA2NoajoyPef/99JCcna319y5YtE9vKt2tl6hURESHSX79+HQCwc+dOpXzUjdvPzc3FqlWr4OHhAXNzcxgYGMDW1hZjx47FkSNHtJZZ/n6AtLQ0zJw5E46OjjA2NhZ1DwoKgkQigVQqRW5urko+hYWFIr1EIkFcXJza8rp16waJRII33nhDZd/Fixfx+eefY9CgQbC1tYWBgQFMTEzg6OgIPz8/nDt3TutrWbp0qSgfKLuR9bPPPkP37t1hZmYGiUSC77//XumYBw8eYPHixXBycoKRkREsLS0xYMAA/PLLL1rLqqoDBw5g5MiR4nU1adIEbdu2Rd++ffHpp58iJiZGpJV/DqZMmSK2OTg4qHymIiIi1JZ14sQJvP3223BwcICRkRFMTU3RtWtXLFq0CDdv3tRYx/Lt9/DhQyxZsgQuLi4wMTGBubk5+vXrhx9++EHt8Xfu3BHHb968WW2ad999V6SZNWuW2jTBwcGQSCTQ19fH48ePlfZVNAtKVc+J5RUXF2Pbtm0YMmQIbGxsYGBggObNm8PLywvBwcHIz8/XeCx7gRBjTKd27NhBAGr8SE9Pr3LZKSkpZGNjU2He33zzjTjGz8+vwvT29vYqZcXExFCrVq20Hufu7k63bt1SW1d7e3sCQH5+frRt2zbS19dXm4eBgQH9+OOPavPIzs4mZ2fnCus/f/78Krel3M6dO8nAwEBj3np6ehQYGKjx9dX0PQ4PD68wH29vb6VjLly4UOHnYPTo0fTs2TO1ZXp7e4t8Dx48SI0bN1Zb95iYGPH/Y8eOqeQTHR2tdExQUJBKmvv371OjRo1UPpeVfe0AaPHixRrbb8mSJSJdamoqtWnTRuX4HTt2iPSXLl0ia2trjWX5+/srfcer8z0tLi6mN954o8LX1aNHjyq3RXh4uFJZubm5NGrUKK3HmJiY0OHDhytsv2vXrlG7du005jN27FgqKipSyUP+HR0/frzaMhTzdHFxUZtmxIgRKm0iJz92yZIlKvuqc05UdOXKlQrPMY6OjpSamqr2ePbi4JswGXuBTZw4EdnZ2ZBKpXjvvffw2muvoWXLligtLUV2djZiYmJUZt5YsWIFFixYgClTpiA2NhZubm7YsWOHUpryN4cmJyfDx8cHT58+haWlJaZPn46+ffvCwsICOTk5CA0NxebNmxETE4MRI0YgOjpa47CJhIQEhISEwNLSEh999BHc3d2Rn5+Po0ePIjg4GAUFBaLnzt3dXenYWbNmISUlBQDw9ttvY/To0bCxsYGenh5u376NuLg4HDx4sNrt+dtvv2Hy5MkgIpiYmGD+/PkYMGAA9PX1cebMGaxcuRJ3795FQEAAzMzMMH36dHFsWFgYCgsLsWHDBmzcuFG0m6JWrVpVWIeePXuK4wYNGoTs7GyMGDECn3/+uUjTuHFj8TwrKwv9+/fHgwcPxBUGX19fWFhYICUlBWvWrEFiYiL2798PPz8//PTTTxrLvnHjBt5++20YGxvj008/Rd++faGnp4fz58/DxMQEdnZ2MDU1xePHjxEREYHBgwcrHV++NzYiIgILFixQ2hYZGYnS0lIAUOnJLy4uRuPGjTF06FC88sorcHJygqmpKXJycnDp0iWsW7cO169fx6pVq9ChQwel3mF1xo4di6ysLMyaNQvDhw9Hs2bNkJaWBnt7ewBlveODBg0SPcLjx4+Hn58fLC0tkZqairVr12L79u0ar3pU1saNG0VvuqenJ9599120a9cOJiYmuH//Pi5evIhjx47h/v374hj55+DQoUP45JNPAADHjx+HjY2NUt4ODg7ieUlJCYYNG4bw8HBIJBL4+vpi9OjRcHBwQFFREWJiYrBmzRrcuHEDY8aMwZkzZ7TOxDR+/Hikp6dj2rRpGDt2LJo2bYqkpCR88cUXSE1Nxb59+2BtbY1169YpHeft7Y2UlBRxlU1RVlYWrl69Kv6fkpKCO3fuoEWLFmIbEYl7Zao6S1N1zolyN2/eRJ8+fXD79m00adIEU6dOxYABA2BlZYVHjx4hLCwMX3/9NdLS0jB48GBcuHABTZs2rVL9WAOi618AjL3oHj58SJcvXxaPP/74Q/SUhIWFKe2ztLQkAPTtt98qbb98+TIVFhZWqdyrV69W2JtDRFRaWkr3799X2a7Y66lNaWkpdenShQBQ165d6c6dO2rTHTt2TPRsfvfddyr7FXuI7e3t6ebNmyppTp06JXrG3dzclPY9e/aMpFIpARX3cN+7d0/rfnUKCwtFD7+JiQnFx8erpMnIyBC9pcbGxmrbQrEHsaYUrxpoMnbsWFGeunbPz88nHx8fkebo0aMqaeSfBQBkY2ND169f11jea6+9RgCoV69eKvv69+9PAGj48OEEgJo2bUrFxcVKaWbPnk0AqHnz5lRaWqq0786dO/TgwQONZRcUFNCrr74qPkPl8yZSbv9GjRpRWFiYxvzmzZsn0qq7qlFYWEgDBw5UuRJQVX379hVtpq7HWE7d57Yqve+rV68mACSVStW+z0RlVyBcXFwIAHl6eqrsV2w/ABQSEqKS5vHjx9S1a1fRxklJSUr7f/rpJ3H85cuXlfbt3r1b9Hy3bduWANAvv/yilCY+Pl4cHxoaqlK+fF/5HvCanhNff/11AkB2dnZ09epVtcdeuHBBXCH65JNPNJbBGj4OwBl7zoSGhhIAsrS0VNr+zz//iD8O6oLPqlIM9BMTE6t8fGUD8MOHD1e6nHHjxhEA6tOnj8o+xQB83759GvOYPn26SBcTEyO2Z2Vlie2HDh3S/uKqQTFoWLlypcZ0e/bsEem+/PJLlf31GYBnZ2eTnp4eAaBBgwZpzCc9PV38sBkyZIjKfsUAfNeuXVrrtGrVKgJA+vr69OTJE7G9sLCQjI2NCQD98ccfZGRkRADo/PnzSsd369aNgLIhMdWRkJAg6hobG6uyX7H9/f39NeaTn59PzZo1IwDUpUsXKikpUZsuMzNT/PCrbgDu6OhIAGju3LlVPrayAXhhYaH4cVhROUePHhV5pqWlKe1TbL/XX39dYx5//vmnSDdjxgylfbdu3RL7Nm7cqLTv3XffJQD0wQcfkL+/v3iuKDg4WAT36n6QaQrAa3JOTE5OrvT5ZdGiReLHKntx8U2YjD1n5JdO+/Tpo7T9jz/+AAC0a9cOLVu2rHE51tbW4nn5m8pq06FDhwAAHTt2RJcuXbSm9fLyAlB2g6WmGzKbNWuGESNGaMzD399fPJfPgw0AFhYWYmjM7t27UVxcXLkXUEnysiQSiVIdynvjjTfEZWfF+umC4pzj77zzjsZ0bdq0wauvvgqgbFiIpvdGJpOpvTFSkXxIQHFxsbjZGABiYmKQl5cHU1NT9OrVS6zwqjgs5cGDB0hKSgJQNkyhIgUFBbhx4wZSUlJw8eJFXLx4UWkO6MTERK3Hv/XWWxr3xcXF4cGDBwAAPz8/NGqk/s+pra0tBg4cWGFdtZF/Vw8fPoy7d+/WKC9NYmJixFCacePGaU0r/54CwNmzZzWm0zbEx93dXcxxX/57YGVlBScnJwDqhyUBZZ8j+WdJU5quXbvCzMxMYx3Kq8k5UX6eMzY2xtChQ7WmlbdfdnY2MjMzq1QOazg4AGfsOaNpmsEzZ86o3V5dDg4OYpGfr776Ci4uLvjvf/+LU6dOIS8vr1bKAIDY2FgAwN9//60yA0P5x8yZMwGUzYahOJ5VUffu3aGvr/n2lW7duolA++LFi2K7gYEBxo8fDwDYt28f2rdvj0WLFuHo0aN49OhRjV+nvKw2bdrA0tJSYzqZTIbu3bur1E8XFMvv1auX1rTy/Xl5ebh27ZraNI6OjjA0NNSaT48ePcTKroqBk/y5fNy4uuAqKipK4/hvuadPn2LlypXo2rUrGjduDHt7e7i4uKBz587o3LmzaHsAFQaz2n4wKo7r7tmzp9Z8yt+LUFV+fn4AgCtXrqB9+/bw9/fH3r178c8//9QoX0Xy7ykAeHh4aP2eKq7Me+vWLY15VrZd0tLSUFhYqLRP/gNLcRx4dnY2rly5AolEAm9vb/j4+AD4/3HgQM3Gf9fknChvv7y8POjr62ttv9dff10cp639WMPGAThjz5H8/Hwx9Vr5QFveA16+Z7wm9u7dK3oaU1JS8Nlnn6F///4wMzODt7c3Nm3aVOMps7RN16WNpj942oJbANDX14e5uTkAqATx69evx7BhwwAA169fR1BQEIYOHQoLCwu4u7tj9erVKlOWVZa8LMVpIzWRX8HQ9COjviiWX1G9Fa+6aKp3s2bNKixTX19ffIbVBeDyoEn+b3R0tOhxl6cxNzdH586dVfLOyMhA586dERAQgKSkJK3TWgLAs2fPtO7X9nrkvd9AxZ/JynwmtPH390dAQAD09fXx6NEj7NixA2+++Sbs7OzQvn17LFiwQOOPosqq7e8pUPl2ISKl9gT+//2/desW/vrrLwBlV2wAwNnZGS1atICtrS3atm0LIhKBelJSEu7duwegcldJyqvuObEu2o81bDwLCmM61KZNGzFXc3maeiSnTp2KqVOniv/7+flVewhJq1atcObMGZw8eRL79+9HZGQkUlJSUFRUhKioKERFRWH16tU4evRotVdTlAdBffr0waZNmyp9XPnZGuTk8wtrozjMQJGpqSlCQ0MRExODn3/+GeHh4UhMTERJSQnOnz+P8+fPIygoCAcPHhR/hKuqJvV7nlWmznp6epXKy9vbG8ePH0dcXBxyc3NhYGAghjLIA69evXrByMgIjx8/Rnx8PNzc3ESQ5eXlpbadJ06ciPT0dDH/ta+vLzp16oQWLVrAwMAAAFBaWirqWdFr0vZ6FI+t6D2vjfd7xYoVmDp1Kn744QecPHkS586dQ15eHq5evYo1a9Zg3bp1WLduHaZNm1at/BV/rERERMDCwqJSx2kLsmvSLorBc0REBJycnMT7r9iz3a9fP1y7dg0REREYO3asSCORSJSGylRWdc+J8vZzcHBAaGhopctTnIWGvVg4AGeMoX///ujfvz8A4N69e/j999+xZcsWnDp1ClevXsX48eMRHx9frbwtLCxw+/Zt3LlzB66urjWu6+3bt7XuLy4uFr1p8p7w8tzd3cXl7ydPniAiIgI7duzAgQMHkJOTgzFjxuDq1aswMjKqdL3kZVXmkrL8NWiqX31RLP/27dto3bq1xrSK7V7TepcfB25qaoqnT5/C1NRUDBGRyWTw8PDAqVOnEBERgfbt24sx2+p6Nv/66y8xfOujjz7CihUr1JZdvqe1usq3nbYfqNXtHS3P3t4eAQEBCAgIENMC/vLLL9i8eTPy8/MxY8YM9OrVS2mYTWUpBtwymazWvqt2dnYa98vbRSKRqFxtsLa2RocOHZCamoqIiAhMmzZN5SqJ/Pn27dvFPvm/Xbp0qdQVGU2qek6Ut9/t27fh5OSkdZgcYwAPQWFMp8LCwpCcnCwe8l7XhQsXKm2fNGkSAGDIkCFK25OTkzUGGtVlYWGB8ePH4+TJkxg+fDiAsrm309LSlNJVpqcXgAgGUlNTNfb2V0VCQoLWGygTExPFeNLKBBFNmjTBsGHDsH//fnz44YcAyubzVbxBsDLkZWVkZGgNuIqKisQf7toIcmpCsfw///xTa1r5KovGxsY17rVzc3MTc5FHRESojP+WUxwHXtH470uXLonnvr6+GstWHOtcE4pDYM6fP681bUX7q0MqlaJPnz4IDg5GSEgIgLIe5X379imlq+r3FCg7L9WGyraLo6OjytoBgPI48OzsbKSlpYnx33KK48BzcnIQFRUFoOrjv7WpzDlR3n55eXliuCBj2nAAzpgOdejQAa6urnB1dYWzs7NYJGbUqFFiu6urqzjRv/baa0rbXV1dK7U4S3XJe4AA1RvW5DfbFRQUaM1D/gcLAL788ssa1+n+/fs4fPiwxv3bt28XzwcMGFClvLW93orIyyIipTqUt2/fPnHTZ1XrV9v69esnAt5t27ZpTHfjxg2cOHFCHFPT3j2pVIrevXsDUA7AywdNiuPAT548CQAwMzNTe3Ok4o8ybeNqqzIMSpsePXqIHtbdu3drHE6RlZVVawGtJpX5ngLav6uenp6iV3/Tpk3VvhdC0c6dOzXui42NFTcBa/oeKI4Dl79v8vHfcorjwNevX1+j8d+VoamtFWdmqo3zHGv4OABn7DmRkJCAR48ewcjICG5ubmL7s2fPRK9ddcY0aisvISFB434iUppar02bNkr75VN2Xbt2TetYzjFjxqBTp04Aylb00xboAWUzc2gLsAFg3rx5aoeiREZGYsuWLQDKAiTFWRiuXbumdmU9RYqBUlV7eUeNGiXGrQcGBqqd4i4zM1Os7GhsbFzhSox1zcbGBqNGjQJQtkqiuh8OhYWF8Pf3R1FREQCImWpqSh4gxcXFiR7D8gG44jhweTDn5eWldso/R0dH8VxT4Ldx48YarXSqyMDAQLx/CQkJCAoKUklTXFyM9957T2WGj6ras2eP1qs+2j63ilPrKa4gWZ6hoaH4bN66dQu+vr54+vSpxvRPnjzB+vXrtdY7NDQUP//8s8r23NxccR9Lo0aN8P7776s9XvHzIF8tU13PtnybPE11x3/X5JzYs2dPMd3k0aNHsWTJEq1lZWRkYO/evVWuI2tA6nviccaYel999RUBIB8fH6XtJ0+eJABkbm6usvJfTcgX6OjZsyctX76cjhw5QrGxsXT27FkKCQkRKwYCoJEjR6ocv3XrVrF/zpw5FBsbS2lpaZSWlkYZGRlKaZOSksjExESkHzRoEO3cuZPOnTtHcXFxdOzYMQoMDKTevXsTNKxUKV9UpmvXriSVSqlVq1a0fv16iomJoejoaProo4/I0NBQLPJy7tw5pePDw8MJADk7O9PHH39MBw4coJiYGIqJiaFff/1VLAIEgLp3716ttj5y5AhJJBICylbDXLZsGZ0+fZrOnTtHa9euFSuZAqANGzaozaO+V8LMzMwUC8pIJBLy9/ensLAwio2NpT179oiFbwDQuHHj1OZR2UWZFJ0+fVrkC6hf9ZKI6JVXXlFKt2bNGrX5lZaWkqurq0g3YcIEOnLkCMXFxdHBgwfFip99+vTRuBALUdXa/+HDh2Rra6tU5rFjxyguLo727t1LPXv2FN8xeZrqLMQDgKysrGj69Om0e/duOnPmDF24cIGOHTtG8+bNE4sWmZiYUGZmptKxjx8/Ft+Ll156iY4fP05///23+K7m5eWJtMXFxWI1UgDUunVrCgwMpPDwcIqPj6eoqCjaunUrvfXWW9S4cWOysLDQ2n5ubm6kp6dHM2bMoFOnTlFsbCxt376dOnbsKNLMmjVL62tv37690vtfftVLIqJdu3YppencuXOF7anu/a/pOTErK0ssZgSUrVy6efNm8X6dOHGC1qxZQ6+++irp6enRmDFjtNaTNWwcgDP2nBg5cqTaPwryP2jDhw+v1fIUV8jT9vD09FS7xPWTJ0/EUtDlH/b29irpExMTxYp+FT2WLVumcrxiMLl161axMmP5h0wmo71796ocLw/AK3p06tSpWkGS3Pfff08GBgYa89fT01O7bLlcfQfgRGXLY9vY2Ghtl9GjR9OzZ8/UHl+dAFxx5UsANHToULXpli9frlSPuLg4jXnGx8eLHxPqHp07d6bs7OxaC8CJiC5evEgtW7bUWOaUKVOqtBy8OpX53JqZmdHx48fVHi9feVHdIzw8XCltXl4eTZo0qVJlOjg4qJSl2H7Xrl0jBwcHjcePGTOGioqKtL72d955R6SXSCSUk5OjkiYzM1Mp34qC+ooC8OqeE4mIMjIylH5waXtMmTJFaz1Zw8YBOGPPgdLSUmrevDkBoJMnTyrtk/cArl69ulbLLCgooPDwcAoICKC+ffuSg4MDGRsbk0wmI1tbWxo+fDiFhIRoXGKbqGzJ6NmzZ1OnTp2Ugil1ATgRUVFREe3cuZNGjhxJdnZ2ZGhoSDKZjKytralfv370ySefaAywygeTZ8+epXHjxpGNjQ3JZDJq1aoVTZo0iS5duqT2+OLiYjp79iwtX76cXnnlFWrfvj01adKEpFIpWVlZ0cCBA2nz5s1UUFBQpXZUJz09XbRL48aNycjIiNq1a0fvvfceJSUlaT1WFwE4UdkPqpUrV1KvXr3IzMyMZDIZ2djY0OjRoyk0NFTrsdUJwIlIqbc1KChIbZro6GiRpmnTplo/j0RE169fp2nTppG9vT1JpVIyNzcnd3d3Wr16tfgBUZsBOBHRvXv3aNGiReTo6EgGBgbUvHlz8vHxoZCQECKq/HLwmvz111/0zTff0MiRI8nZ2ZksLCxIX1+fmjVrRi+//DItXbqUbt++rfH40tJS2rp1K/Xt25fMzc1JT09PYwAuFxsbS9OnTycXFxdq2rQp6evrk5mZGXXr1o3eeecd2rdvH+Xn56scV7797t+/TwEBAeIc0bRpU/Ly8qI9e/ZU6rXv3r1b5Ofi4qIxXbt27US6ffv2ac1T0/tfG+dEorL2PnDgAPn6+oo8pFIptWjRgnr37k3z58+nyMjIWr2iyf59JET/wglpGWMvHPmc6TWZ95wxVreWLl2KZcuWAcC/cr57xuoL34TJGGOMMcZYPeIAnDHGGGOMsXrEAThjjDHGGGP1iANwxhhjjDHG6hEH4IwxxhhjjNUjngWFMcYYY4yxesQ94IwxxhhjjNUjDsAZY4wxxhirRxyAM8YYY4wxVo84AGeMMcYYY6wecQDOGGOMMcZYPeIAnDHGGGOMsXrEAThjjDHGGGP1iANwxhhjjDHG6tH/AZA/9wfYeIYiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax.errorbar(np.arange(n_steps),cv_mse.mean(1),\n",
    "            cv_mse.std(1) / np.sqrt(K),\n",
    "            label='Cross-validated',\n",
    "            c='r') # color red\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.legend()\n",
    "mse_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c6ec8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = skm.ShuffleSplit(n_splits=1,\n",
    "                              test_size=0.2,\n",
    "                              random_state=0)\n",
    "for train_idx, test_idx in validation.split(Y):\n",
    "    full_path.fit(Hitters.iloc[train_idx],\n",
    "                  Y[train_idx])\n",
    "    Yhat_val = full_path.predict(Hitters.iloc[test_idx])\n",
    "    errors = (Yhat_val- Y[test_idx,None])**2\n",
    "    validation_mse = errors.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "275bd274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax.plot(np.arange(n_steps),\n",
    "        validation_mse,\n",
    "        'b--', # color blue, broken line\n",
    "        label='Validation')\n",
    "ax.set_xticks(np.arange(n_steps)[::2])\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.legend()\n",
    "mse_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f56e0",
   "metadata": {},
   "source": [
    "Best Subset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a206c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = design.fit_transform(Hitters)\n",
    "D = D.drop('intercept', axis=1)\n",
    "X = np.asarray(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02dff9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Data.\n",
      "BnB Started.\n",
      "Iteration: 1. Number of non-zeros:  1\n",
      "Iteration: 2. Number of non-zeros:  2\n",
      "Iteration: 3. Number of non-zeros:  2\n",
      "Iteration: 4. Number of non-zeros:  2\n",
      "Iteration: 5. Number of non-zeros:  3\n",
      "Iteration: 6. Number of non-zeros:  3\n",
      "Iteration: 7. Number of non-zeros:  4\n",
      "Iteration: 8. Number of non-zeros:  9\n",
      "Iteration: 9. Number of non-zeros:  9\n",
      "Iteration: 10. Number of non-zeros:  9\n",
      "Iteration: 11. Number of non-zeros:  9\n",
      "Iteration: 12. Number of non-zeros:  9\n",
      "Iteration: 13. Number of non-zeros:  9\n",
      "Iteration: 14. Number of non-zeros:  9\n",
      "Iteration: 15. Number of non-zeros:  9\n",
      "Iteration: 16. Number of non-zeros:  9\n",
      "Iteration: 17. Number of non-zeros:  9\n",
      "Iteration: 18. Number of non-zeros:  17\n",
      "Iteration: 19. Number of non-zeros:  19\n"
     ]
    }
   ],
   "source": [
    "path = fit_path(X,\n",
    "                Y,\n",
    "                max_nonzeros=X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76401858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': array([0.        , 3.25484367, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.67775265, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'B0': -38.98216739555505,\n",
       " 'lambda_0': 0.01141624802745019,\n",
       " 'M': 0.5829861733382015,\n",
       " 'Time_exceeded': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2e774b",
   "metadata": {},
   "source": [
    "##### Ridge Regression and the Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1347858",
   "metadata": {},
   "source": [
    "Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c826facc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs = X- X.mean(0)[None,:]\n",
    "X_scale = X.std(0)\n",
    "Xs = Xs / X_scale[None,:]\n",
    "lambdas = 10**np.linspace(8,-2, 100) / Y.std()\n",
    "soln_array = skl.ElasticNet.path(Xs,\n",
    "                                 Y,\n",
    "                                 l1_ratio=0.01,        # can't be zero\n",
    "                                 alphas=lambdas,\n",
    "                                 max_iter=100_000,\n",
    "                                 tol=1e-6)[1]\n",
    "soln_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ccd10d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "negative log(lambda)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AtBat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Hits",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HmRun",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Runs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RBI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Walks",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Years",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CAtBat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CHits",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CHmRun",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CRuns",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CRBI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CWalks",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "League[N]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Division[W]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PutOuts",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Assists",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Errors",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "NewLeague[N]",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c807b899-229d-4ed5-ba4f-74c1e674d9c9",
       "rows": [
        [
         "-12.310855053159447",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-12.078270700331764",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-11.845686347504083",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-11.613101994676402",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-11.380517641848721",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-11.147933289021038",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-10.915348936193357",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-10.682764583365676",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-10.450180230537995",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-10.217595877710313",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "-9.985011524882632",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.000926524147407067",
         "0.0014038751154456098",
         "0.0009013013500769851",
         "0.0016924552081139653",
         "0.0017823311349777437",
         "0.0001654141332483804",
         "-0.0",
         "-0.0",
         "0.0",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-9.752427172054952",
         "0.0003395317329701145",
         "0.0015007321072621458",
         "0.0",
         "0.0010030740353089824",
         "0.0017857435530327212",
         "0.0016379394913920047",
         "0.0004945261267786553",
         "0.0038130694600841944",
         "0.004415418344246363",
         "0.003781305340027065",
         "0.004779544684227367",
         "0.004892954070225775",
         "0.0028526976788759034",
         "-0.0",
         "-0.0",
         "0.0",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-9.51984281922727",
         "0.0030721194881827636",
         "0.004537402533137301",
         "0.0013452386506931128",
         "0.003909422713103173",
         "0.004896857131497363",
         "0.004710486675497952",
         "0.0032673492817598794",
         "0.007454551991454835",
         "0.008214624438171558",
         "0.007414551686412146",
         "0.008674052965783316",
         "0.008817155508205696",
         "0.006242787292669977",
         "-0.0",
         "-0.0",
         "0.0",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-9.287258466399589",
         "0.006519319779450192",
         "0.008368325473000794",
         "0.004340309957374113",
         "0.007575888989704634",
         "0.008821563165610221",
         "0.008586665651876737",
         "0.006765245471268628",
         "0.012048350063522275",
         "0.013007440401200032",
         "0.011997962046347193",
         "0.013587095961777986",
         "0.013767644957317034",
         "0.010519412680735151",
         "-0.0",
         "-0.0",
         "0.002551397204670377",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-9.054674113571906",
         "0.010867842981570223",
         "0.01320106812764384",
         "0.008118351529891292",
         "0.012201101450157266",
         "0.013772443717367746",
         "0.013476475538430344",
         "0.011177491583741204",
         "0.017843143628448615",
         "0.01905335854524447",
         "0.01777969850124482",
         "0.01978467729661112",
         "0.02001246299604744",
         "0.015914059799352398",
         "-0.0",
         "-0.00012836761216336522",
         "0.005862903028292573",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-8.822089760744225",
         "0.016352891244043866",
         "0.019297148329700933",
         "0.012883605096740514",
         "0.018035284170098417",
         "0.020017271741110745",
         "0.019644507297901567",
         "0.01674256372593568",
         "0.025152278759499738",
         "0.026679363338776536",
         "0.025072435532943752",
         "0.027601977516902337",
         "0.02788935420406319",
         "0.022718383427880264",
         "-0.0",
         "-0.0028059712238952647",
         "0.010040584834385765",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-8.589505407916544",
         "0.023270812100698517",
         "0.02698614004596752",
         "0.018893353818284702",
         "0.025393769571423284",
         "0.027893446921848884",
         "0.027424193595319613",
         "0.02376083689660708",
         "0.0343704912312022",
         "0.0362974001824477",
         "0.0342700833430839",
         "0.037461280299979305",
         "0.037823819008818295",
         "0.031299792607017776",
         "-0.0",
         "-0.006184114706939873",
         "0.015310695840481055",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-8.356921055088863",
         "0.03199478895636548",
         "0.03668315524172097",
         "0.02647151580184437",
         "0.03467368668472855",
         "0.0378258416107609",
         "0.03723549654626957",
         "0.03261044795759535",
         "0.04599480849101582",
         "0.048426207077940056",
         "0.0458686535764804",
         "0.04989433695854203",
         "0.050351666445546985",
         "0.04212086796810455",
         "-0.0",
         "-0.010445879117513284",
         "0.021958394416406617",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-8.12433670226118",
         "0.04299453147202788",
         "0.048910823961538036",
         "0.036025672043164036",
         "0.04637496349413389",
         "0.05034922263725563",
         "0.04960713233102411",
         "0.04376713947875915",
         "0.06065071056406741",
         "0.06371865274403336",
         "0.06049238881056154",
         "0.06557039477319465",
         "0.0661472524652093",
         "0.05576369108528022",
         "-0.0",
         "-0.01582207385881549",
         "0.030342977357063757",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-7.891752349433501",
         "0.05686084871905855",
         "0.06432675313996782",
         "0.04806829318017036",
         "0.06112654402875173",
         "0.0661362269070903",
         "0.06520433368151157",
         "0.05782898796455423",
         "0.07912476776113823",
         "0.08299585710221935",
         "0.0789263682769303",
         "0.0853311737539761",
         "0.08605872507629288",
         "0.07296017841842009",
         "-0.0",
         "-0.022603609320902152",
         "0.04091698012821535",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-7.6591679966058175",
         "0.07433624518162602",
         "0.0837577681992746",
         "0.06324312581669965",
         "0.0797190595846166",
         "0.08603219341619282",
         "0.08486346304231249",
         "0.0755471212864661",
         "0.10240524033671271",
         "0.10728965958554343",
         "0.10215708237233961",
         "0.11023440083626225",
         "0.11115189321012371",
         "0.09462979751696088",
         "-0.0",
         "-0.031157035752271092",
         "0.054250094856821134",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-7.426583643778137",
         "0.09635287713651311",
         "0.10824247652450487",
         "0.08235785768506682",
         "0.10314540514293713",
         "0.11109837437702971",
         "0.10963502668424013",
         "0.09786371150270408",
         "0.13173238570124496",
         "0.13789528054188682",
         "0.13142273219443745",
         "0.14160779319394898",
         "0.14276462603876477",
         "0.12192627300908221",
         "-0.0",
         "-0.041944034471021734",
         "0.07105906061461642",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-7.1939992909504555",
         "0.12407942113565126",
         "0.13908395990353078",
         "0.10642434191066502",
         "0.13265091541802962",
         "0.14266529097182667",
         "0.14083690660796455",
         "0.12595870534303635",
         "0.16866048213263782",
         "0.17643630944577401",
         "0.16827528120571594",
         "0.1811156779772619",
         "0.18257398771871963",
         "0.1562951246120348",
         "-0.0",
         "-0.05554582852296663",
         "0.09224492132353651",
         "0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "-6.961414938122774",
         "0.15897832564299305",
         "0.17791442261115167",
         "0.1367079150466899",
         "0.16979492278818697",
         "0.18239816767642136",
         "0.18011980383690745",
         "0.16130695201403036",
         "0.21513380712934524",
         "0.22494441885072836",
         "0.21465667138603967",
         "0.2308407280385107",
         "0.23267865285691994",
         "0.1995441238718069",
         "-0.0",
         "-0.07269368043045409",
         "0.11893935019836484",
         "0.0008247679437351692",
         "-0.0",
         "-0.0"
        ],
        [
         "-6.728830585295094",
         "0.2028756896026843",
         "0.2267744097109401",
         "0.17478708913831587",
         "0.21652599039472975",
         "0.23237664028312505",
         "0.22954728605349278",
         "0.2057472587508304",
         "0.27357891178240634",
         "0.2859563346297601",
         "0.27299139754131574",
         "0.29338337989473234",
         "0.29569912818056865",
         "0.2539287156000584",
         "-0.0",
         "-0.09430692610551063",
         "0.15256194405308404",
         "0.0036689876587601335",
         "-0.0",
         "-0.0"
        ],
        [
         "-6.496246232467412",
         "0.2580467686811564",
         "0.2882099940574421",
         "0.22262441106881542",
         "0.27527355969409456",
         "0.29519104939836405",
         "0.2916931430081778",
         "0.2615645377548661",
         "0.3470154117999191",
         "0.362630508663565",
         "0.3462971286943414",
         "0.37198135545237104",
         "0.3748980297379812",
         "0.32225416432347836",
         "-0.0",
         "-0.12154031383882972",
         "0.1948905698714683",
         "0.007248117671350793",
         "-0.0",
         "-0.0"
        ],
        [
         "-6.26366187963973",
         "0.3273146038824291",
         "0.36538650635392933",
         "0.2826505810367557",
         "0.34905547736409787",
         "0.37405593064006104",
         "0.36975696993752466",
         "0.3315867917937351",
         "0.4391870596746734",
         "0.45888561914546944",
         "0.4383169885334586",
         "0.4706516568041762",
         "0.47432343126274024",
         "0.4079965121239681",
         "-0.0013714792737646337",
         "-0.1558424815401702",
         "0.24814779611362078",
         "0.011748956751379169",
         "-0.0",
         "-0.0"
        ],
        [
         "-6.031077526812051",
         "0.41416775297446945",
         "0.4622252166046504",
         "0.35786194728546367",
         "0.4416064413924259",
         "0.47294389283232197",
         "0.46770126255026545",
         "0.4192960598339658",
         "0.5547137692765228",
         "0.5795618757907395",
         "0.5536730218476699",
         "0.5943560100476953",
         "0.5989755931851493",
         "0.5154421008460637",
         "-0.004071092840645963",
         "-0.1990280626314884",
         "0.3151051372344957",
         "0.017403788464276856",
         "-0.0",
         "-0.0"
        ],
        [
         "-5.798493173984366",
         "0.5228930753897719",
         "0.5835602377327616",
         "0.4519288024482426",
         "0.5575243931906738",
         "0.5967370815686616",
         "0.5904090725996614",
         "0.5289512948615689",
         "0.699262730282087",
         "0.7306037650452101",
         "0.6980396296107424",
         "0.7491882388337696",
         "0.7549959157054285",
         "0.649843806897509",
         "-0.007301594421468952",
         "-0.253365928508279",
         "0.3992081422317314",
         "0.024500340666261278",
         "-0.0",
         "-0.0"
        ],
        [
         "-5.565908821156687",
         "0.658720159546654",
         "0.7353136200007405",
         "0.5693095551202348",
         "0.7024319584770411",
         "0.7513920707239029",
         "0.7438599100929788",
         "0.665717352783935",
         "0.8797329441576568",
         "0.9192591263688041",
         "0.8783314904245701",
         "0.9425782547325829",
         "0.9498727369290985",
         "0.8175880406368873",
         "-0.011102012767806544",
         "-0.32168634646332683",
         "0.5047242482886298",
         "0.03339350254465508",
         "-0.0",
         "-0.0"
        ],
        [
         "-5.333324468329005",
         "0.827974411688069",
         "0.9246869518052283",
         "0.715363627026721",
         "0.8831498508911736",
         "0.9441125115297816",
         "0.9353188285692422",
         "0.835787418487818",
         "1.1044406337730428",
         "1.1542827166930942",
         "1.1028938032939852",
         "1.1835005047586382",
         "1.1926515039042802",
         "1.0263592435247488",
         "-0.015465427945755915",
         "-0.4075097666213686",
         "0.6369146301764856",
         "0.04452637631431682",
         "-0.0024103324648855613",
         "-0.0"
        ],
        [
         "-5.100740115501322",
         "1.038208090205807",
         "1.1603431898200813",
         "0.8964464133157594",
         "1.1078585481606071",
         "1.1835048554522376",
         "1.173521461179303",
         "1.046486390565135",
         "1.3832870229121181",
         "1.446126482990478",
         "1.3816813333583642",
         "1.4826695776053165",
         "1.494132914273094",
         "1.2852862349692382",
         "-0.0203005640417076",
         "-0.5151996339874122",
         "0.8022254286634007",
         "0.05842829129089376",
         "-0.005899399702656962",
         "-0.0"
        ],
        [
         "-4.868155762673643",
         "1.298307909723676",
         "1.4525770375472147",
         "1.1199600409427113",
         "1.386238854937906",
         "1.47970018932976",
         "1.4688381362602128",
         "1.3063129888238858",
         "1.7278683230066363",
         "1.8070775437613111",
         "1.7263808268569596",
         "1.8526812107839121",
         "1.8670155584883668",
         "1.605026400442687",
         "-0.02536573053826971",
         "-0.6501407869856479",
         "1.0084988430602715",
         "0.07574021917660013",
         "-0.01042710193126952",
         "0.0"
        ],
        [
         "-4.6355714098459595",
         "1.6185223709703425",
         "1.813423364512975",
         "1.3943216107355028",
         "1.7295438411427826",
         "1.8443906037950357",
         "1.8333765682007646",
         "1.6248831627953533",
         "2.1514786857756065",
         "2.2512956735317253",
         "2.150435032148963",
         "2.3080505889982454",
         "2.3259358879838565",
         "1.997742751908644",
         "-0.030169070553391016",
         "-0.8189433966518956",
         "1.265189860568691",
         "0.09722663380998907",
         "-0.01633812848096696",
         "0.0"
        ],
        [
         "-4.402987057018279",
         "2.0103583850230957",
         "2.256657363274147",
         "1.7287936140448186",
         "2.150552058213091",
         "2.290720769137889",
         "2.280972270098432",
         "2.0127081187987566",
         "2.668930481583819",
         "2.794676077481541",
         "2.6688938201127947",
         "2.865071295874871",
         "2.887328151355271",
         "2.4768985799189034",
         "-0.0338188998431168",
         "-1.029669919234003",
         "1.5835729950429278",
         "0.12378366005988051",
         "-0.024108879070743397",
         "0.0"
        ],
        [
         "-4.1704027041905976",
         "2.486283297392939",
         "2.7976292172625716",
         "2.1331289784395575",
         "2.6633494335450196",
         "2.8329701706675774",
         "2.8269998141600925",
         "2.4807283176675905",
         "3.29609635795571",
         "3.454442842628059",
         "3.298012296497764",
         "3.5414021845303285",
         "3.569011425953556",
         "3.0567786111436726",
         "-0.034916052086216134",
         "-1.2920785165455149",
         "1.9769065073026566",
         "0.1564344020198369",
         "-0.034412485252945255",
         "0.008282965691620906"
        ],
        [
         "-3.9378183513629157",
         "3.0591060998094104",
         "3.452812306159906",
         "2.6168629493608027",
         "3.282789730349279",
         "3.485870031512955",
         "3.487911605483814",
         "3.0395031070207947",
         "4.049064769308014",
         "4.248368937881567",
         "4.054450361939848",
         "4.355259717076696",
         "4.389379974625682",
         "3.751620463337119",
         "-0.03109751713316397",
         "-1.6178733954237194",
         "2.4605450848012365",
         "0.1963240093647273",
         "-0.04819062459715232",
         "0.02372700893231525"
        ],
        [
         "-3.7052339985352356",
         "3.740997880654964",
         "4.239037259140093",
         "3.188290812492019",
         "4.0236397971125895",
         "4.263544559240597",
         "4.280434755425204",
         "3.697987100461161",
         "4.942810022161813",
         "5.193522642866529",
         "4.954038553916901",
         "5.324134881537589",
         "5.366117385479602",
         "4.57427108164162",
         "-0.018762978285599453",
         "-2.0209437135556017",
         "3.0519255673843584",
         "0.24468003817396514",
         "-0.06678259614109755",
         "0.04821724061095901"
        ],
        [
         "-3.472649645707554",
         "4.542016717977915",
         "5.172284668394637",
         "3.8529516934654913",
         "4.899242574348874",
         "5.177916859328326",
         "5.220345158700276",
         "4.4618389222120145",
         "5.98932334496635",
         "6.30449207928952",
         "6.010003060624909",
         "6.462963209908293",
         "6.514363534224525",
         "5.534301251355167",
         "-0.0",
         "-2.517570718660972",
         "3.7704201512323543",
         "0.30276001279740117",
         "-0.09207901579421124",
         "0.08622840827298493"
        ],
        [
         "-3.240065292879872",
         "5.468248915137522",
         "6.266161143635605",
         "4.61182043016842",
         "5.91986707506998",
         "6.236741230063645",
         "6.320868694719747",
         "5.331340075939642",
         "7.1952752040635914",
         "7.591159794487062",
         "7.230795899721042",
         "7.781848548096359",
         "7.844433959645194",
         "6.635644069419959",
         "0.03525813826438026",
         "-3.1265704436395625",
         "4.636988128099238",
         "0.3717344297572494",
         "-0.12679666250424584",
         "0.14360424583020998"
        ],
        [
         "-3.00748094005219",
         "6.519602129198747",
         "7.530105138803029",
         "5.459245016946557",
         "7.090767698439064",
         "7.441324028355986",
         "7.590792729670133",
         "6.299108765517479",
         "8.559427773667236",
         "9.056250945008026",
         "8.617714440577796",
         "9.283556445078172",
         "9.359312335775735",
         "7.873954827818596",
         "0.11405651548390626",
         "-3.8693367165907055",
         "5.67363771576559",
         "0.45252780903377826",
         "-0.17484900450764368",
         "0.2272743853376826"
        ],
        [
         "-2.7748965872245104",
         "7.6871983760061715",
         "8.967283650402486",
         "6.380449503000258",
         "8.409788924401042",
         "8.783882469604091",
         "9.0324506597735",
         "7.347936605910434",
         "10.07022969993337",
         "10.693094961767088",
         "10.162546956011198",
         "10.96115325920554",
         "11.05230971010362",
         "9.234076178855371",
         "0.23703208225265243",
         "-4.769752503689516",
         "6.902850583296467",
         "0.5457570643636623",
         "-0.24158731479801357",
         "0.34668990656682813"
        ],
        [
         "-2.5423122343968285",
         "8.951479025817266",
         "10.57330135681144",
         "7.350109445541907",
         "9.865905354469376",
         "10.245889431372861",
         "10.640227152481598",
         "8.449396404901362",
         "11.704268167111982",
         "12.484278907618698",
         "11.846345638328",
         "12.796648516487052",
         "12.905734999009567",
         "10.688270882190904",
         "0.4197730443486387",
         "-5.853877938967304",
         "8.346778407375416",
         "0.6515315867254474",
         "-0.33438406437889284",
         "0.5122171523704248"
        ],
        [
         "-2.3097278815691467",
         "10.280858477067897",
         "12.335579442296774",
         "8.331548974974705",
         "11.438309995169249",
         "11.797211442238858",
         "12.39982487078959",
         "9.563655889989194",
         "13.426199417538866",
         "14.401825559747584",
         "13.63956230016147",
         "14.761138704938372",
         "14.89110532425667",
         "12.195755336533603",
         "0.6798741469016517",
         "-7.149343989798067",
         "10.026501112592554",
         "0.7694334052081938",
         "-0.46304697836915754",
         "0.7344777917516774"
        ],
        [
         "-2.077143528741465",
         "11.631667414175917",
         "14.234151172293597",
         "9.277448459544729",
         "13.09688703485342",
         "13.396888178472418",
         "14.288774469512116",
         "10.640891390512339",
         "15.190619792018936",
         "16.40937128569812",
         "15.50420738421828",
         "16.817012441590823",
         "16.971461380599912",
         "13.70397306333004",
         "1.0355278756616348",
         "-8.684302231210479",
         "11.961261128894298",
         "0.8986671225555665",
         "-0.6401479992389179",
         "1.0226951978758645"
        ],
        [
         "-1.8445591759137852",
         "12.94948847701062",
         "16.244011259816336",
         "10.132176539393507",
         "14.804191620175969",
         "14.995708147331912",
         "16.278295447154516",
         "11.624231508858365",
         "16.9458603791164",
         "18.466339810621164",
         "17.39801800171359",
         "18.922191636593027",
         "19.105767645398476",
         "15.151540455455574",
         "1.5034275692297738",
         "-10.485751634347716",
         "14.167603732049477",
         "1.0385132900780014",
         "-0.8810737399456982",
         "1.3823939550981494"
        ],
        [
         "-1.611974823086103",
         "14.171728680957559",
         "18.338885099897027",
         "10.83559483424066",
         "16.518759897047897",
         "16.54035423112385",
         "18.336254931842966",
         "12.453651384518183",
         "18.639043185047957",
         "20.53346523063943",
         "19.280029947124394",
         "21.035765257092663",
         "21.25476292872797",
         "16.472237003766363",
         "2.0962417313687256",
         "-12.577056944535341",
         "16.65821817150085",
         "1.1891677382915051",
         "-1.203631301995762",
         "1.8127020208717564"
        ],
        [
         "-1.3793904702584214",
         "15.230787137976675",
         "20.495831646448043",
         "11.327783463022431",
         "18.199170559797537",
         "17.97847342505096",
         "20.430657224552615",
         "13.069874382797703",
         "20.221314656154753",
         "22.578596229557675",
         "21.116499845299494",
         "23.12390075955955",
         "23.38712442746754",
         "17.598969086913296",
         "2.820173425514612",
         "-14.974561792948261",
         "19.440228246329",
         "1.352966292465248",
         "-1.6270868709013389",
         "2.303750551443936"
        ],
        [
         "-1.1468061174307396",
         "16.057014678522034",
         "22.69992448157005",
         "11.553989489042362",
         "19.808071461669137",
         "19.263792858536128",
         "22.53296707627475",
         "13.417306286541375",
         "21.652022145688367",
         "24.58156341897926",
         "22.885946894875367",
         "25.164802544368516",
         "25.48468624759022",
         "18.466591302978234",
         "3.6732972117758065",
         "-17.68342481502696",
         "22.512768961796475",
         "1.535841848807117",
         "-2.170639196539953",
         "2.8348491110757457"
        ],
        [
         "-0.9142217646030576",
         "16.580614974033303",
         "24.948225355840297",
         "11.469120623819178",
         "21.315400142478072",
         "20.360452364338233",
         "24.620727836475265",
         "13.445385920594127",
         "22.900959795456235",
         "26.537262380636932",
         "24.582372966713013",
         "27.151850989674344",
         "27.545763801191764",
         "19.0128360189237",
         "4.645340636017917",
         "-20.693173087983308",
         "25.863958368403544",
         "1.7486965299970956",
         "-2.8514875433928335",
         "3.374119438509219"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 100
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League[N]</th>\n",
       "      <th>Division[W]</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>NewLeague[N]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative log(lambda)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-12.310855</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-12.078271</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-11.845686</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-11.613102</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-11.380518</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.784658</th>\n",
       "      <td>-290.837766</td>\n",
       "      <td>336.954891</td>\n",
       "      <td>37.331027</td>\n",
       "      <td>-59.763826</td>\n",
       "      <td>-26.514159</td>\n",
       "      <td>134.861012</td>\n",
       "      <td>-17.217903</td>\n",
       "      <td>-387.718709</td>\n",
       "      <td>89.421403</td>\n",
       "      <td>-12.315389</td>\n",
       "      <td>476.163294</td>\n",
       "      <td>257.338575</td>\n",
       "      <td>-213.144917</td>\n",
       "      <td>31.257042</td>\n",
       "      <td>-58.457540</td>\n",
       "      <td>78.761611</td>\n",
       "      <td>53.621261</td>\n",
       "      <td>-22.207105</td>\n",
       "      <td>-12.401324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.017243</th>\n",
       "      <td>-290.890547</td>\n",
       "      <td>337.134052</td>\n",
       "      <td>37.438128</td>\n",
       "      <td>-59.929261</td>\n",
       "      <td>-26.612677</td>\n",
       "      <td>134.904695</td>\n",
       "      <td>-17.109579</td>\n",
       "      <td>-388.410292</td>\n",
       "      <td>88.875452</td>\n",
       "      <td>-12.695293</td>\n",
       "      <td>477.099683</td>\n",
       "      <td>258.021642</td>\n",
       "      <td>-213.297335</td>\n",
       "      <td>31.255466</td>\n",
       "      <td>-58.448598</td>\n",
       "      <td>78.761524</td>\n",
       "      <td>53.644409</td>\n",
       "      <td>-22.197696</td>\n",
       "      <td>-12.390685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.249827</th>\n",
       "      <td>-290.932551</td>\n",
       "      <td>337.276951</td>\n",
       "      <td>37.523513</td>\n",
       "      <td>-60.061230</td>\n",
       "      <td>-26.691212</td>\n",
       "      <td>134.939492</td>\n",
       "      <td>-17.023535</td>\n",
       "      <td>-388.957478</td>\n",
       "      <td>88.435079</td>\n",
       "      <td>-12.999054</td>\n",
       "      <td>477.847159</td>\n",
       "      <td>258.567478</td>\n",
       "      <td>-213.419091</td>\n",
       "      <td>31.254166</td>\n",
       "      <td>-58.441482</td>\n",
       "      <td>78.761463</td>\n",
       "      <td>53.662732</td>\n",
       "      <td>-22.190172</td>\n",
       "      <td>-12.382160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.482412</th>\n",
       "      <td>-290.965955</td>\n",
       "      <td>337.390785</td>\n",
       "      <td>37.591502</td>\n",
       "      <td>-60.166365</td>\n",
       "      <td>-26.753744</td>\n",
       "      <td>134.967183</td>\n",
       "      <td>-16.955223</td>\n",
       "      <td>-389.390510</td>\n",
       "      <td>88.081133</td>\n",
       "      <td>-13.241497</td>\n",
       "      <td>478.442971</td>\n",
       "      <td>259.002924</td>\n",
       "      <td>-213.516199</td>\n",
       "      <td>31.253102</td>\n",
       "      <td>-58.435825</td>\n",
       "      <td>78.761420</td>\n",
       "      <td>53.677236</td>\n",
       "      <td>-22.184166</td>\n",
       "      <td>-12.375344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.714996</th>\n",
       "      <td>-290.992504</td>\n",
       "      <td>337.481373</td>\n",
       "      <td>37.645587</td>\n",
       "      <td>-60.250034</td>\n",
       "      <td>-26.803485</td>\n",
       "      <td>134.989200</td>\n",
       "      <td>-16.901009</td>\n",
       "      <td>-389.733277</td>\n",
       "      <td>87.797466</td>\n",
       "      <td>-13.434724</td>\n",
       "      <td>478.917338</td>\n",
       "      <td>259.349840</td>\n",
       "      <td>-213.593552</td>\n",
       "      <td>31.252239</td>\n",
       "      <td>-58.431329</td>\n",
       "      <td>78.761389</td>\n",
       "      <td>53.688721</td>\n",
       "      <td>-22.179378</td>\n",
       "      <td>-12.369904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           AtBat        Hits      HmRun       Runs        RBI  \\\n",
       "negative log(lambda)                                                            \n",
       "-12.310855              0.000000    0.000000   0.000000   0.000000   0.000000   \n",
       "-12.078271              0.000000    0.000000   0.000000   0.000000   0.000000   \n",
       "-11.845686              0.000000    0.000000   0.000000   0.000000   0.000000   \n",
       "-11.613102              0.000000    0.000000   0.000000   0.000000   0.000000   \n",
       "-11.380518              0.000000    0.000000   0.000000   0.000000   0.000000   \n",
       "...                          ...         ...        ...        ...        ...   \n",
       " 9.784658            -290.837766  336.954891  37.331027 -59.763826 -26.514159   \n",
       " 10.017243           -290.890547  337.134052  37.438128 -59.929261 -26.612677   \n",
       " 10.249827           -290.932551  337.276951  37.523513 -60.061230 -26.691212   \n",
       " 10.482412           -290.965955  337.390785  37.591502 -60.166365 -26.753744   \n",
       " 10.714996           -290.992504  337.481373  37.645587 -60.250034 -26.803485   \n",
       "\n",
       "                           Walks      Years      CAtBat      CHits     CHmRun  \\\n",
       "negative log(lambda)                                                            \n",
       "-12.310855              0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "-12.078271              0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "-11.845686              0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "-11.613102              0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "-11.380518              0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "...                          ...        ...         ...        ...        ...   \n",
       " 9.784658             134.861012 -17.217903 -387.718709  89.421403 -12.315389   \n",
       " 10.017243            134.904695 -17.109579 -388.410292  88.875452 -12.695293   \n",
       " 10.249827            134.939492 -17.023535 -388.957478  88.435079 -12.999054   \n",
       " 10.482412            134.967183 -16.955223 -389.390510  88.081133 -13.241497   \n",
       " 10.714996            134.989200 -16.901009 -389.733277  87.797466 -13.434724   \n",
       "\n",
       "                           CRuns        CRBI      CWalks  League[N]  \\\n",
       "negative log(lambda)                                                  \n",
       "-12.310855              0.000000    0.000000    0.000000   0.000000   \n",
       "-12.078271              0.000000    0.000000    0.000000   0.000000   \n",
       "-11.845686              0.000000    0.000000    0.000000   0.000000   \n",
       "-11.613102              0.000000    0.000000    0.000000   0.000000   \n",
       "-11.380518              0.000000    0.000000    0.000000   0.000000   \n",
       "...                          ...         ...         ...        ...   \n",
       " 9.784658             476.163294  257.338575 -213.144917  31.257042   \n",
       " 10.017243            477.099683  258.021642 -213.297335  31.255466   \n",
       " 10.249827            477.847159  258.567478 -213.419091  31.254166   \n",
       " 10.482412            478.442971  259.002924 -213.516199  31.253102   \n",
       " 10.714996            478.917338  259.349840 -213.593552  31.252239   \n",
       "\n",
       "                      Division[W]    PutOuts    Assists     Errors  \\\n",
       "negative log(lambda)                                                 \n",
       "-12.310855               0.000000   0.000000   0.000000   0.000000   \n",
       "-12.078271               0.000000   0.000000   0.000000   0.000000   \n",
       "-11.845686               0.000000   0.000000   0.000000   0.000000   \n",
       "-11.613102               0.000000   0.000000   0.000000   0.000000   \n",
       "-11.380518               0.000000   0.000000   0.000000   0.000000   \n",
       "...                           ...        ...        ...        ...   \n",
       " 9.784658              -58.457540  78.761611  53.621261 -22.207105   \n",
       " 10.017243             -58.448598  78.761524  53.644409 -22.197696   \n",
       " 10.249827             -58.441482  78.761463  53.662732 -22.190172   \n",
       " 10.482412             -58.435825  78.761420  53.677236 -22.184166   \n",
       " 10.714996             -58.431329  78.761389  53.688721 -22.179378   \n",
       "\n",
       "                      NewLeague[N]  \n",
       "negative log(lambda)                \n",
       "-12.310855                0.000000  \n",
       "-12.078271                0.000000  \n",
       "-11.845686                0.000000  \n",
       "-11.613102                0.000000  \n",
       "-11.380518                0.000000  \n",
       "...                            ...  \n",
       " 9.784658               -12.401324  \n",
       " 10.017243              -12.390685  \n",
       " 10.249827              -12.382160  \n",
       " 10.482412              -12.375344  \n",
       " 10.714996              -12.369904  \n",
       "\n",
       "[100 rows x 19 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soln_path = pd.DataFrame(soln_array.T,\n",
    "                         columns=D.columns,\n",
    "                         index=-np.log(lambdas))\n",
    "soln_path.index.name = 'negative log(lambda)'\n",
    "soln_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9c70aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_fig, ax = subplots(figsize=(8,8))\n",
    "soln_path.plot(ax=ax, legend=False)\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Standardized coefficients', fontsize=20)\n",
    "ax.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b0729ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25.53538897200662,\n",
       " AtBat           5.468249\n",
       " Hits            6.266161\n",
       " HmRun           4.611820\n",
       " Runs            5.919867\n",
       " RBI             6.236741\n",
       " Walks           6.320869\n",
       " Years           5.331340\n",
       " CAtBat          7.195275\n",
       " CHits           7.591160\n",
       " CHmRun          7.230796\n",
       " CRuns           7.781849\n",
       " CRBI            7.844434\n",
       " CWalks          6.635644\n",
       " League[N]       0.035258\n",
       " Division[W]    -3.126570\n",
       " PutOuts         4.636988\n",
       " Assists         0.371734\n",
       " Errors         -0.126797\n",
       " NewLeague[N]    0.143604\n",
       " Name: -3.240065292879872, dtype: float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_hat = soln_path.loc[soln_path.index[39]]\n",
    "lambdas[39], beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "802b6ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.331320564843033"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12b90141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24374766133488554, 160.90961591542953)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_hat = soln_path.loc[soln_path.index[59]]\n",
    "lambdas[59], np.linalg.norm(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5432442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.446e+07, tolerance: 5.332e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;ridge&#x27;, ElasticNet(alpha=0.24374766133488554, l1_ratio=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=steps,-list%20of%20tuples\">\n",
       "            steps\n",
       "            <span class=\"param-doc-description\">steps: list of tuples<br><br>List of (name of step, estimator) tuples that are to be chained in<br>sequential order. To be compatible with the scikit-learn API, all steps<br>must define `fit`. All non-last steps must also define `transform`. See<br>:ref:`Combining Estimators <combining_estimators>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">[(&#x27;scaler&#x27;, ...), (&#x27;ridge&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=transform_input,-list%20of%20str%2C%20default%3DNone\">\n",
       "            transform_input\n",
       "            <span class=\"param-doc-description\">transform_input: list of str, default=None<br><br>The names of the :term:`metadata` parameters that should be transformed by the<br>pipeline before passing it to the step consuming it.<br><br>This enables transforming some input arguments to ``fit`` (other than ``X``)<br>to be transformed by the steps of the pipeline up to the step which requires<br>them. Requirement is defined via :ref:`metadata routing <metadata_routing>`.<br>For instance, this can be used to pass a validation set through the pipeline.<br><br>You can only set this if metadata routing is enabled, which you<br>can enable using ``sklearn.set_config(enable_metadata_routing=True)``.<br><br>.. versionadded:: 1.6</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=memory,-str%20or%20object%20with%20the%20joblib.Memory%20interface%2C%20default%3DNone\">\n",
       "            memory\n",
       "            <span class=\"param-doc-description\">memory: str or object with the joblib.Memory interface, default=None<br><br>Used to cache the fitted transformers of the pipeline. The last step<br>will never be cached, even if it is a transformer. By default, no<br>caching is performed. If a string is given, it is the path to the<br>caching directory. Enabling caching triggers a clone of the transformers<br>before fitting. Therefore, the transformer instance given to the<br>pipeline cannot be inspected directly. Use the attribute ``named_steps``<br>or ``steps`` to inspect estimators within the pipeline. Caching the<br>transformers is advantageous when fitting is time consuming. See<br>:ref:`sphx_glr_auto_examples_neighbors_plot_caching_nearest_neighbors.py`<br>for an example on how to enable caching.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>If True, the time elapsed while fitting each step will be printed as it<br>is completed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"scaler__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>If False, try to avoid a copy and do inplace scaling instead.<br>This is not guaranteed to always work inplace; e.g. if the data is<br>not a NumPy array or scipy.sparse CSR matrix, a copy may still be<br>returned.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_mean',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_mean,-bool%2C%20default%3DTrue\">\n",
       "            with_mean\n",
       "            <span class=\"param-doc-description\">with_mean: bool, default=True<br><br>If True, center the data before scaling.<br>This does not work (and will raise an exception) when attempted on<br>sparse matrices, because centering them entails building a dense<br>matrix which in common use cases is likely to be too large to fit in<br>memory.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_std',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_std,-bool%2C%20default%3DTrue\">\n",
       "            with_std\n",
       "            <span class=\"param-doc-description\">with_std: bool, default=True<br><br>If True, scale the data to unit variance (or equivalently,<br>unit standard deviation).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ElasticNet</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"ridge__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=alpha,-float%2C%20default%3D1.0\">\n",
       "            alpha\n",
       "            <span class=\"param-doc-description\">alpha: float, default=1.0<br><br>Constant that multiplies the penalty terms. Defaults to 1.0.<br>See the notes for the exact mathematical meaning of this<br>parameter. ``alpha = 0`` is equivalent to an ordinary least square,<br>solved by the :class:`LinearRegression` object. For numerical<br>reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.<br>Given this, you should use the :class:`LinearRegression` object.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.24374766133488554</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=l1_ratio,-float%2C%20default%3D0.5\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.5<br><br>The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For<br>``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it<br>is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a<br>combination of L1 and L2.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Whether the intercept should be estimated or not. If ``False``, the<br>data is assumed to be already centered.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('precompute',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=precompute,-bool%20or%20array-like%20of%20shape%20%28n_features%2C%20n_features%29%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DFalse\">\n",
       "            precompute\n",
       "            <span class=\"param-doc-description\">precompute: bool or array-like of shape (n_features, n_features),                 default=False<br><br>Whether to use a precomputed Gram matrix to speed up<br>calculations. The Gram matrix can also be passed as argument.<br>For sparse input this option is always ``False`` to preserve sparsity.<br>Check :ref:`an example on how to use a precomputed Gram Matrix in ElasticNet<br><sphx_glr_auto_examples_linear_model_plot_elastic_net_precomputed_gram_matrix_with_weighted_samples.py>`<br>for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=max_iter,-int%2C%20default%3D1000\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=1000<br><br>The maximum number of iterations.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=copy_X,-bool%2C%20default%3DTrue\">\n",
       "            copy_X\n",
       "            <span class=\"param-doc-description\">copy_X: bool, default=True<br><br>If ``True``, X will be copied; else, it may be overwritten.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>The tolerance for the optimization: if the updates are smaller or equal to<br>``tol``, the optimization code checks the dual gap for optimality and continues<br>until it is smaller or equal to ``tol``, see Notes below.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>See :term:`the Glossary <warm_start>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=positive,-bool%2C%20default%3DFalse\">\n",
       "            positive\n",
       "            <span class=\"param-doc-description\">positive: bool, default=False<br><br>When set to ``True``, forces the coefficients to be positive.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>The seed of the pseudo random number generator that selects a random<br>feature to update. Used when ``selection`` == 'random'.<br>Pass an int for reproducible output across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('selection',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=selection,-%7B%27cyclic%27%2C%20%27random%27%7D%2C%20default%3D%27cyclic%27\">\n",
       "            selection\n",
       "            <span class=\"param-doc-description\">selection: {'cyclic', 'random'}, default='cyclic'<br><br>If set to 'random', a random coefficient is updated every iteration<br>rather than looping over features sequentially by default. This<br>(setting to 'random') often leads to significantly faster convergence<br>especially when tol is higher than 1e-4.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;cyclic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('ridge', ElasticNet(alpha=0.24374766133488554, l1_ratio=0))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = skl.ElasticNet(alpha=lambdas[59], l1_ratio=0)\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('ridge', ridge)])\n",
    "pipe.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20134d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.4237101772592"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d378ed5",
   "metadata": {},
   "source": [
    "Estimating Test Error of Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48b73d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.486e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([134214.00419204])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = skm.ShuffleSplit(n_splits=1,\n",
    "                              test_size=0.5,\n",
    "                              random_state=0)\n",
    "ridge.alpha = 0.01\n",
    "results = skm.cross_validate(ridge,\n",
    "                             X,\n",
    "                             Y,\n",
    "                             scoring='neg_mean_squared_error',\n",
    "                             cv=validation)\n",
    "-results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1b8baa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([231788.32155285])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.alpha = 1e10\n",
    "results = skm.cross_validate(ridge,\n",
    "                             X,\n",
    "                             Y,\n",
    "                             scoring='neg_mean_squared_error',\n",
    "                             cv=validation)\n",
    "-results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e41d4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.127e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.113e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.107e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.081e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.977e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.744e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.494e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.234e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.968e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.704e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.448e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.204e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.977e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.769e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.581e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.412e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.261e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.127e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.008e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.900e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.803e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.714e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.632e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.554e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.480e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.342e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.276e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.214e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.154e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.097e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.043e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.991e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.943e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.898e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.856e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.817e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.780e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.746e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.715e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.687e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.661e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.637e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.616e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.596e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.579e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.563e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.550e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.538e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.528e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.519e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.512e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.506e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.500e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.496e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.493e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.490e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.488e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.486e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.485e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.483e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.483e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.482e+06, tolerance: 2.272e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e+07, tolerance: 5.332e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;ridge&#x27;, ElasticNet(alpha=0.005899006046740856, l1_ratio=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=steps,-list%20of%20tuples\">\n",
       "            steps\n",
       "            <span class=\"param-doc-description\">steps: list of tuples<br><br>List of (name of step, estimator) tuples that are to be chained in<br>sequential order. To be compatible with the scikit-learn API, all steps<br>must define `fit`. All non-last steps must also define `transform`. See<br>:ref:`Combining Estimators <combining_estimators>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">[(&#x27;scaler&#x27;, ...), (&#x27;ridge&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=transform_input,-list%20of%20str%2C%20default%3DNone\">\n",
       "            transform_input\n",
       "            <span class=\"param-doc-description\">transform_input: list of str, default=None<br><br>The names of the :term:`metadata` parameters that should be transformed by the<br>pipeline before passing it to the step consuming it.<br><br>This enables transforming some input arguments to ``fit`` (other than ``X``)<br>to be transformed by the steps of the pipeline up to the step which requires<br>them. Requirement is defined via :ref:`metadata routing <metadata_routing>`.<br>For instance, this can be used to pass a validation set through the pipeline.<br><br>You can only set this if metadata routing is enabled, which you<br>can enable using ``sklearn.set_config(enable_metadata_routing=True)``.<br><br>.. versionadded:: 1.6</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=memory,-str%20or%20object%20with%20the%20joblib.Memory%20interface%2C%20default%3DNone\">\n",
       "            memory\n",
       "            <span class=\"param-doc-description\">memory: str or object with the joblib.Memory interface, default=None<br><br>Used to cache the fitted transformers of the pipeline. The last step<br>will never be cached, even if it is a transformer. By default, no<br>caching is performed. If a string is given, it is the path to the<br>caching directory. Enabling caching triggers a clone of the transformers<br>before fitting. Therefore, the transformer instance given to the<br>pipeline cannot be inspected directly. Use the attribute ``named_steps``<br>or ``steps`` to inspect estimators within the pipeline. Caching the<br>transformers is advantageous when fitting is time consuming. See<br>:ref:`sphx_glr_auto_examples_neighbors_plot_caching_nearest_neighbors.py`<br>for an example on how to enable caching.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>If True, the time elapsed while fitting each step will be printed as it<br>is completed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"scaler__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>If False, try to avoid a copy and do inplace scaling instead.<br>This is not guaranteed to always work inplace; e.g. if the data is<br>not a NumPy array or scipy.sparse CSR matrix, a copy may still be<br>returned.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_mean',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_mean,-bool%2C%20default%3DTrue\">\n",
       "            with_mean\n",
       "            <span class=\"param-doc-description\">with_mean: bool, default=True<br><br>If True, center the data before scaling.<br>This does not work (and will raise an exception) when attempted on<br>sparse matrices, because centering them entails building a dense<br>matrix which in common use cases is likely to be too large to fit in<br>memory.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_std',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_std,-bool%2C%20default%3DTrue\">\n",
       "            with_std\n",
       "            <span class=\"param-doc-description\">with_std: bool, default=True<br><br>If True, scale the data to unit variance (or equivalently,<br>unit standard deviation).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ElasticNet</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"ridge__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=alpha,-float%2C%20default%3D1.0\">\n",
       "            alpha\n",
       "            <span class=\"param-doc-description\">alpha: float, default=1.0<br><br>Constant that multiplies the penalty terms. Defaults to 1.0.<br>See the notes for the exact mathematical meaning of this<br>parameter. ``alpha = 0`` is equivalent to an ordinary least square,<br>solved by the :class:`LinearRegression` object. For numerical<br>reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.<br>Given this, you should use the :class:`LinearRegression` object.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.005899006046740856</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=l1_ratio,-float%2C%20default%3D0.5\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.5<br><br>The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For<br>``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it<br>is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a<br>combination of L1 and L2.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Whether the intercept should be estimated or not. If ``False``, the<br>data is assumed to be already centered.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('precompute',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=precompute,-bool%20or%20array-like%20of%20shape%20%28n_features%2C%20n_features%29%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DFalse\">\n",
       "            precompute\n",
       "            <span class=\"param-doc-description\">precompute: bool or array-like of shape (n_features, n_features),                 default=False<br><br>Whether to use a precomputed Gram matrix to speed up<br>calculations. The Gram matrix can also be passed as argument.<br>For sparse input this option is always ``False`` to preserve sparsity.<br>Check :ref:`an example on how to use a precomputed Gram Matrix in ElasticNet<br><sphx_glr_auto_examples_linear_model_plot_elastic_net_precomputed_gram_matrix_with_weighted_samples.py>`<br>for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=max_iter,-int%2C%20default%3D1000\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=1000<br><br>The maximum number of iterations.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=copy_X,-bool%2C%20default%3DTrue\">\n",
       "            copy_X\n",
       "            <span class=\"param-doc-description\">copy_X: bool, default=True<br><br>If ``True``, X will be copied; else, it may be overwritten.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>The tolerance for the optimization: if the updates are smaller or equal to<br>``tol``, the optimization code checks the dual gap for optimality and continues<br>until it is smaller or equal to ``tol``, see Notes below.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>See :term:`the Glossary <warm_start>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=positive,-bool%2C%20default%3DFalse\">\n",
       "            positive\n",
       "            <span class=\"param-doc-description\">positive: bool, default=False<br><br>When set to ``True``, forces the coefficients to be positive.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>The seed of the pseudo random number generator that selects a random<br>feature to update. Used when ``selection`` == 'random'.<br>Pass an int for reproducible output across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('selection',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=selection,-%7B%27cyclic%27%2C%20%27random%27%7D%2C%20default%3D%27cyclic%27\">\n",
       "            selection\n",
       "            <span class=\"param-doc-description\">selection: {'cyclic', 'random'}, default='cyclic'<br><br>If set to 'random', a random coefficient is updated every iteration<br>rather than looping over features sequentially by default. This<br>(setting to 'random') often leads to significantly faster convergence<br>especially when tol is higher than 1e-4.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;cyclic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-2');</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('ridge', ElasticNet(alpha=0.005899006046740856, l1_ratio=0))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'ridge__alpha': lambdas}\n",
    "grid = skm.GridSearchCV(pipe,\n",
    "                        param_grid,\n",
    "                        cv=validation,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid.fit(X, Y)\n",
    "grid.best_params_['ridge__alpha']\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "175eba9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.230e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.219e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.097e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.229e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.219e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.096e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.875e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.095e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.211e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.225e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.872e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.212e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.870e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.210e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.867e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.200e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.864e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.203e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.196e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.077e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.208e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.197e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.190e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.855e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.071e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.191e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.849e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.063e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.841e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.054e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.163e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.043e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.149e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.820e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.806e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.012e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.139e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.789e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.992e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.117e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.087e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.968e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.081e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.058e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.745e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.939e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.060e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.051e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.718e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.907e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.686e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.869e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.975e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.939e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.938e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.929e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.783e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.568e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.734e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.834e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.826e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.772e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.684e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.770e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.478e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.633e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.721e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.713e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.646e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.655e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.520e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.494e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.404e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.403e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.177e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.098e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.126e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.110e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.982e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.804e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.894e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.713e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.808e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.627e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.727e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.548e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.650e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.474e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.579e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.406e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.514e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.343e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.454e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.286e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.402e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.234e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.355e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.969e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.187e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.314e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.966e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.914e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.145e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.279e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.865e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.249e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.843e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.824e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.075e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.223e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.790e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.790e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.047e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.202e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.743e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.761e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.022e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.184e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.700e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.990e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.737e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.000e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.169e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.663e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.971e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.717e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.982e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.156e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.630e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.956e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.701e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.966e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.146e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.601e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.943e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.688e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.953e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.138e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.575e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.933e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.677e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.942e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.132e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.554e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.924e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.668e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.933e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.126e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.535e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.917e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.661e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.122e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.520e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.911e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.655e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.920e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.119e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.507e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.906e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.651e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.915e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.116e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.496e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.647e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.911e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.114e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.487e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.899e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.644e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.907e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.112e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.480e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.897e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.642e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.905e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.111e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.474e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.895e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.640e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.903e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.110e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.469e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.893e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.639e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.901e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.109e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.465e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.892e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.638e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.900e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.462e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.891e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.637e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.899e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.460e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.636e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.898e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.107e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.458e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.636e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.897e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.107e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.456e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.889e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.635e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.897e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+07, tolerance: 5.332e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-3.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-3.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;ridge&#x27;, ElasticNet(alpha=0.01185247763144249, l1_ratio=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=steps,-list%20of%20tuples\">\n",
       "            steps\n",
       "            <span class=\"param-doc-description\">steps: list of tuples<br><br>List of (name of step, estimator) tuples that are to be chained in<br>sequential order. To be compatible with the scikit-learn API, all steps<br>must define `fit`. All non-last steps must also define `transform`. See<br>:ref:`Combining Estimators <combining_estimators>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">[(&#x27;scaler&#x27;, ...), (&#x27;ridge&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=transform_input,-list%20of%20str%2C%20default%3DNone\">\n",
       "            transform_input\n",
       "            <span class=\"param-doc-description\">transform_input: list of str, default=None<br><br>The names of the :term:`metadata` parameters that should be transformed by the<br>pipeline before passing it to the step consuming it.<br><br>This enables transforming some input arguments to ``fit`` (other than ``X``)<br>to be transformed by the steps of the pipeline up to the step which requires<br>them. Requirement is defined via :ref:`metadata routing <metadata_routing>`.<br>For instance, this can be used to pass a validation set through the pipeline.<br><br>You can only set this if metadata routing is enabled, which you<br>can enable using ``sklearn.set_config(enable_metadata_routing=True)``.<br><br>.. versionadded:: 1.6</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=memory,-str%20or%20object%20with%20the%20joblib.Memory%20interface%2C%20default%3DNone\">\n",
       "            memory\n",
       "            <span class=\"param-doc-description\">memory: str or object with the joblib.Memory interface, default=None<br><br>Used to cache the fitted transformers of the pipeline. The last step<br>will never be cached, even if it is a transformer. By default, no<br>caching is performed. If a string is given, it is the path to the<br>caching directory. Enabling caching triggers a clone of the transformers<br>before fitting. Therefore, the transformer instance given to the<br>pipeline cannot be inspected directly. Use the attribute ``named_steps``<br>or ``steps`` to inspect estimators within the pipeline. Caching the<br>transformers is advantageous when fitting is time consuming. See<br>:ref:`sphx_glr_auto_examples_neighbors_plot_caching_nearest_neighbors.py`<br>for an example on how to enable caching.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>If True, the time elapsed while fitting each step will be printed as it<br>is completed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"scaler__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>If False, try to avoid a copy and do inplace scaling instead.<br>This is not guaranteed to always work inplace; e.g. if the data is<br>not a NumPy array or scipy.sparse CSR matrix, a copy may still be<br>returned.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_mean',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_mean,-bool%2C%20default%3DTrue\">\n",
       "            with_mean\n",
       "            <span class=\"param-doc-description\">with_mean: bool, default=True<br><br>If True, center the data before scaling.<br>This does not work (and will raise an exception) when attempted on<br>sparse matrices, because centering them entails building a dense<br>matrix which in common use cases is likely to be too large to fit in<br>memory.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_std',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_std,-bool%2C%20default%3DTrue\">\n",
       "            with_std\n",
       "            <span class=\"param-doc-description\">with_std: bool, default=True<br><br>If True, scale the data to unit variance (or equivalently,<br>unit standard deviation).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ElasticNet</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"ridge__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=alpha,-float%2C%20default%3D1.0\">\n",
       "            alpha\n",
       "            <span class=\"param-doc-description\">alpha: float, default=1.0<br><br>Constant that multiplies the penalty terms. Defaults to 1.0.<br>See the notes for the exact mathematical meaning of this<br>parameter. ``alpha = 0`` is equivalent to an ordinary least square,<br>solved by the :class:`LinearRegression` object. For numerical<br>reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.<br>Given this, you should use the :class:`LinearRegression` object.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.01185247763144249</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=l1_ratio,-float%2C%20default%3D0.5\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.5<br><br>The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For<br>``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it<br>is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a<br>combination of L1 and L2.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Whether the intercept should be estimated or not. If ``False``, the<br>data is assumed to be already centered.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('precompute',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=precompute,-bool%20or%20array-like%20of%20shape%20%28n_features%2C%20n_features%29%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DFalse\">\n",
       "            precompute\n",
       "            <span class=\"param-doc-description\">precompute: bool or array-like of shape (n_features, n_features),                 default=False<br><br>Whether to use a precomputed Gram matrix to speed up<br>calculations. The Gram matrix can also be passed as argument.<br>For sparse input this option is always ``False`` to preserve sparsity.<br>Check :ref:`an example on how to use a precomputed Gram Matrix in ElasticNet<br><sphx_glr_auto_examples_linear_model_plot_elastic_net_precomputed_gram_matrix_with_weighted_samples.py>`<br>for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=max_iter,-int%2C%20default%3D1000\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=1000<br><br>The maximum number of iterations.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=copy_X,-bool%2C%20default%3DTrue\">\n",
       "            copy_X\n",
       "            <span class=\"param-doc-description\">copy_X: bool, default=True<br><br>If ``True``, X will be copied; else, it may be overwritten.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>The tolerance for the optimization: if the updates are smaller or equal to<br>``tol``, the optimization code checks the dual gap for optimality and continues<br>until it is smaller or equal to ``tol``, see Notes below.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>See :term:`the Glossary <warm_start>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=positive,-bool%2C%20default%3DFalse\">\n",
       "            positive\n",
       "            <span class=\"param-doc-description\">positive: bool, default=False<br><br>When set to ``True``, forces the coefficients to be positive.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>The seed of the pseudo random number generator that selects a random<br>feature to update. Used when ``selection`` == 'random'.<br>Pass an int for reproducible output across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('selection',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=selection,-%7B%27cyclic%27%2C%20%27random%27%7D%2C%20default%3D%27cyclic%27\">\n",
       "            selection\n",
       "            <span class=\"param-doc-description\">selection: {'cyclic', 'random'}, default='cyclic'<br><br>If set to 'random', a random coefficient is updated every iteration<br>rather than looping over features sequentially by default. This<br>(setting to 'random') often leads to significantly faster convergence<br>especially when tol is higher than 1e-4.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;cyclic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-3');</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('ridge', ElasticNet(alpha=0.01185247763144249, l1_ratio=0))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = skm.GridSearchCV(pipe,\n",
    "                        param_grid,\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid.fit(X, Y)\n",
    "grid.best_params_['ridge__alpha']\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01e2d1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuAAAAK+CAYAAADjWquOAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAijNJREFUeJzs3XlYlXX+//HXYTsCyhFENnOrzFTUXMqt0kxBBzXbrDTKFpqpzHHU+U22mjNpi1ozNq3TqpZ9G9MsjVBLzVFcUFLcN8QFxIVFUfb79wdx6xFU9MA5LM/HdZ2rc+77fd/3GxB68eFzPrfFMAxDAAAAAJzCzdUNAAAAAHUJARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwohoZwKdMmaIbb7xRDRo0UFBQkIYOHaodO3bY1YwcOVIWi8Xu0b17d7uavLw8PfPMMwoMDJSvr6+GDBmigwcP2tVkZGQoOjpaNptNNptN0dHRyszMtKtJSUnR4MGD5evrq8DAQI0ePVr5+fl2NZs3b1bv3r3l7e2tJk2aaNKkSTIMo/I+KQAAAKgRamQAX758uZ5++mnFx8dr8eLFKiwsVEREhHJycuzqBgwYoNTUVPOxaNEiu/1jxozRvHnzNGfOHK1cuVKnTp3SoEGDVFRUZNYMHz5ciYmJio2NVWxsrBITExUdHW3uLyoqUlRUlHJycrRy5UrNmTNHc+fO1bhx48ya7Oxs9e/fX2FhYVq3bp1mzJihqVOnavr06VX0GQIAAEB1ZTFqwTDs0aNHFRQUpOXLl+vWW2+VVDICnpmZqfnz55d7TFZWlho3bqyZM2fqvvvukyQdPnxYTZs21aJFixQZGalt27apbdu2io+PV7du3SRJ8fHx6tGjh7Zv367WrVvrxx9/1KBBg3TgwAGFhYVJkubMmaORI0cqPT1dfn5+eu+99zRhwgQdOXJEVqtVkvTaa69pxowZOnjwoCwWSxV/hgAAAFBdeLi6gcqQlZUlSQoICLDbvmzZMgUFBalhw4bq3bu3Xn31VQUFBUmSEhISVFBQoIiICLM+LCxM4eHhWrVqlSIjI7V69WrZbDYzfEtS9+7dZbPZtGrVKrVu3VqrV69WeHi4Gb4lKTIyUnl5eUpISNBtt92m1atXq3fv3mb4Lq2ZMGGCkpOT1bJlyzIfU15envLy8szXxcXFOnHihBo1akRgBwAAqIYMw9DJkycVFhYmN7cLTzSp8QHcMAyNHTtWN998s8LDw83tAwcO1L333qvmzZtr3759evHFF9W3b18lJCTIarUqLS1NXl5e8vf3tztfcHCw0tLSJElpaWlmYD9XUFCQXU1wcLDdfn9/f3l5ednVtGjRosx1SveVF8CnTJmiV1555TI/GwAAAHC1AwcO6Kqrrrrg/hofwEeNGqVNmzZp5cqVdttLp5VIUnh4uLp27armzZtr4cKFuuuuuy54PsMw7EaYyxttroya0pk/FxrNnjBhgsaOHWu+zsrKUrNmzXTgwAH5+fldsH8AAAC4RnZ2tpo2baoGDRpctK5GB/BnnnlGCxYs0IoVKy76W4YkhYaGqnnz5tq1a5ckKSQkRPn5+crIyLAbBU9PT1fPnj3NmiNHjpQ519GjR80R7JCQEK1Zs8Zuf0ZGhgoKCuxqSkfDz72OpDKj56WsVqvdlJVSfn5+BHAAAIBq7FLThWvkKiiGYWjUqFH69ttv9fPPP5c7heN8x48f14EDBxQaGipJ6tKlizw9PbV48WKzJjU1VUlJSWYA79Gjh7KysrR27VqzZs2aNcrKyrKrSUpKUmpqqlkTFxcnq9WqLl26mDUrVqywW5owLi5OYWFhZaamAAAAoHarkaugPPXUU/ryyy/13XffqXXr1uZ2m80mb29vnTp1ShMnTtTdd9+t0NBQJScn67nnnlNKSoq2bdtm/lngySef1A8//KDPPvtMAQEBGj9+vI4fP66EhAS5u7tLKplLfvjwYX3wwQeSpCeeeELNmzfX999/L6lkGcIbbrhBwcHBevPNN3XixAmNHDlSQ4cO1YwZMySVTB9p3bq1+vbtq+eee067du3SyJEj9dJLL9ktV3gx2dnZstlsysrKYgQcAACgGqpwXjNqIEnlPj799FPDMAzj9OnTRkREhNG4cWPD09PTaNasmfHwww8bKSkpduc5c+aMMWrUKCMgIMDw9vY2Bg0aVKbm+PHjxogRI4wGDRoYDRo0MEaMGGFkZGTY1ezfv9+IiooyvL29jYCAAGPUqFFGbm6uXc2mTZuMW265xbBarUZISIgxceJEo7i4uMIfc1ZWliHJyMrKqvgnCgAAAE5T0bxWI0fA6yJGwAEAAKq3iua1GjkHHAAAAKipCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAE9XIAD5lyhTdeOONatCggYKCgjR06FDt2LHD3F9QUKC//e1vat++vXx9fRUWFqaHHnpIhw8ftjtPnz59ZLFY7B7333+/XU1GRoaio6Nls9lks9kUHR2tzMxMu5qUlBQNHjxYvr6+CgwM1OjRo5Wfn29Xs3nzZvXu3Vve3t5q0qSJJk2aJMMwKvcTU0lO5xeqxbML1eLZhTqdX3jBbZe7vTLOUd37q6yPEQAA1F41MoAvX75cTz/9tOLj47V48WIVFhYqIiJCOTk5kqTTp09rw4YNevHFF7VhwwZ9++232rlzp4YMGVLmXDExMUpNTTUfH3zwgd3+4cOHKzExUbGxsYqNjVViYqKio6PN/UVFRYqKilJOTo5WrlypOXPmaO7cuRo3bpxZk52drf79+yssLEzr1q3TjBkzNHXqVE2fPr2KPkOoyQjxAADUbh6ubuBKxMbG2r3+9NNPFRQUpISEBN16662y2WxavHixXc2MGTN00003KSUlRc2aNTO3+/j4KCQkpNzrbNu2TbGxsYqPj1e3bt0kSR999JF69OihHTt2qHXr1oqLi9PWrVt14MABhYWFSZKmTZumkSNH6tVXX5Wfn59mz56t3NxcffbZZ7JarQoPD9fOnTs1ffp0jR07VhaLpTI/PYCkkmDe9qWfJElbJ0XKx8uj3G0AAMC5auQI+PmysrIkSQEBARetsVgsatiwod322bNnKzAwUO3atdP48eN18uRJc9/q1atls9nM8C1J3bt3l81m06pVq8ya8PBwM3xLUmRkpPLy8pSQkGDW9O7dW1ar1a7m8OHDSk5OLrffvLw8ZWdn2z2AqsLoOgAAzlPjh78Mw9DYsWN18803Kzw8vNya3NxcPfvssxo+fLj8/PzM7SNGjFDLli0VEhKipKQkTZgwQb/99ps5ep6WlqagoKAy5wsKClJaWppZExwcbLff399fXl5edjUtWrSwqyk9Ji0tTS1btixzjSlTpuiVV16p4GcBcB5G0QEAcEyN/z/nqFGjtGnTJq1cubLc/QUFBbr//vtVXFysd999125fTEyM+Tw8PFytWrVS165dtWHDBnXu3FmSyp0eYhiG3fYrqSl9A+aFpp9MmDBBY8eONV9nZ2eradOm5dYCAACg5qjRU1CeeeYZLViwQL/88ouuuuqqMvsLCgo0bNgw7du3T4sXL7Yb/S5P586d5enpqV27dkmSQkJCdOTIkTJ1R48eNUewQ0JCzJHuUhkZGSooKLhoTXp6uiSVGT0vZbVa5efnZ/cAqjOmqwAAUDE1MoAbhqFRo0bp22+/1c8//1zuFI7S8L1r1y4tWbJEjRo1uuR5t2zZooKCAoWGhkqSevTooaysLK1du9asWbNmjbKystSzZ0+zJikpSampqWZNXFycrFarunTpYtasWLHCbmnCuLg4hYWFlZmaAtQ2BHMAAOzVyAD+9NNPa9asWfryyy/VoEEDpaWlKS0tTWfOnJEkFRYW6p577tH69es1e/ZsFRUVmTWlIXjPnj2aNGmS1q9fr+TkZC1atEj33nuvOnXqpF69ekmS2rRpowEDBigmJkbx8fGKj49XTEyMBg0apNatW0uSIiIi1LZtW0VHR2vjxo1aunSpxo8fr5iYGHPUevjw4bJarRo5cqSSkpI0b948TZ48mRVQAAAA6qAaGcDfe+89ZWVlqU+fPgoNDTUfX3/9tSTp4MGDWrBggQ4ePKgbbrjBrqZ09RIvLy8tXbpUkZGRat26tUaPHq2IiAgtWbJE7u7u5rVmz56t9u3bKyIiQhEREerQoYNmzpxp7nd3d9fChQtVr1499erVS8OGDdPQoUM1depUs6Z0WcSDBw+qa9eueuqppzR27Fi7Od5AXcKoOACgLquRb8K81B0kW7Roccmapk2bavny5Ze8VkBAgGbNmnXRmmbNmumHH364aE379u21YsWKS14PAAAAtVuNHAEHAAAAaioCOIBqg6kpAIC6gAAOAAAAOBEBHAAAAHAiAjiAao+pKQCA2oQADgAAADgRARwAAABwIgI4AAAA4EQEcAA1FnPDAQA1EQEcAAAAcCICOAAAAOBEBHAAAADAiQjgAGoV5oUDAKo7AjgAAADgRARwAAAAwIkI4AAAAIATEcABAAAAJyKAAwAAAE5EAAdQJ7A6CgCguiCAAwAAAE5EAAcAAACciAAOAAAAOBEBHAAAAHAiAjgAAADgRARwAAAAwIkI4ADqNJYnBAA4GwEcAAAAcCICOAAAAOBEBHAAAADAiQjgAAAAgBMRwAEAAAAnIoADAAAATkQABwAAAJyIAA4AAAA4EQEcAM7DzXkAAFWJAA4AAAA4EQEcAAAAcCICOAAAAOBEBHAAAADAiQjgAAAAgBMRwAEAAAAnIoADAAAATkQABwAAAJyIAA4AAAA4EQEcACqIO2QCACoDARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwIgI4AAAA4EQerm4A1U9BUbH5PCevUMWGdOac227n5BXKMEqen3s77tLnFll0Jr/I3J5bUCQ3i0V5BWe35RcWy92tSBZZlF949nqFRcUqKi45efHv/wUAAKhNCOAoY+m2dPP5ja8uLbO/vG2S1PUf5W/v/PclZbbdMGlxubUdXil/e9uXfpIkWSzn1U+MK7Oty9+XyGKR3M7b0fO1n+VmscjNIp0b7ftOWy53i8XuPFH/WikPN0vJOc7Z/sCH8fJ0d5Obm+XczXp69gZ5edj/QemF+Uny9nSXp7ubjHOu+P6yPfK1esjT3c3u3Iu3HpFfPU+d292+Yzny9/GSj5e7DINfSKqr0/mF5r/RrZMi5ePFj1YAwIXxfwnUKOdn0MJyRsnPnDPSfq7M0wXlbk/Lyi2zbd+xnHJrfzuYVe72X3YcLbPt2w2Hyq3918+7y93+5zmJZbZF/WtlubW931ymBlYP+Vo95O15Nvi/unCbGvl6yc/bU/U83c3te46eUpOGPvJyt5R3OgAA4EQEcJTRv22w+Xzji/3k7eWhM/mF6vT7SPaGF/vJx8tDhlEy8tflHyXb179wuznydzq/0BwRX/f87fL28tDpvELdNLlk25rn+qqe59naHlN+liStevY2eXt6yFDJtJder/8iSfr1//VRPU8PGTJ0Jr9Ivd9cJkn6eVxv1fN01+n8QvWbvkKSFPeXW2T1cC/pr6BQf/hnSYj9/pleZ7fnF+rOd1dJkr75U3d5urvrTH6hHvhojSTp80dulKeHm4qLpTMFhYr5IkGSNOOBTvJ0t6iouOQcf/3vJknSpDvayc1i0ZmCQr26cLsk6c+3t5LFIhUWGTpTUKiPVyZLku7tcpWKDSm/qFi5BYVavLXkLw6dmzVUQZGhMwVF2p1+SpLkV89DuQXFyj9nWpAkHT2Zp6Mn88p87WavSSn3azp4xv8kSW7n5O/HPluv0Ib1FOxXTw19PM3tx0/lydvfXZbz/7QAAAAqBQEcZbifk9Ksnu6q5+mu4nOGnuv9vk2S3dQKHy+Pcv/07mst2X5u+GtQz9Os9TxnVLahj9fZEH/OyG6j+la7cF8qxFZPPl4edtuu8vcpt/aaxvXL3d4uzFbmHDe2DCi39vY2QXbbSwP4PV2uMs9RGsD/2Ptqu9rSAP7KHe3stpdOXZj1eDfzHKXb4p8r+aWmoKhYGTn55i8w/32yh4qKDOXkF+pETr7Gf1PSxx9vvVqn84uUnVugjJx8rdh1TFJJkM/OLZnPX2r13uMqzy1vLJO3p7uu8vdWWENvc/uq3cfUrolNfvX4sQEAgCP4PylQA3i6u6n+OcG3baifXYgvDeB/7teq3HAf/9zt8nR30+HMM+ZfD167q70yThfoSHauDmedUdyWI5JK5tmfKSjSrvRT2vX7SLwkPf77XwF8rWentsyM368uzfzVNsyvij5yAABqHwI4UEd4urupcQOr+XrIDWHlhvWNL/ZXxukCHcw4rT1HT2nigq2SpJaBvko5cVo5eWfn2E9ZVDLa72aRrm5c39y+O/2U2jexMY0FAIByEMAB2PHycFPLQF+1DPRVl+b+ZgBfOPpmebi5aXtatoa8UzKn/LbWjbXlcLbST+aZ89Ylacg7/1NgfS91u7qRujRr6IoPAwCAaosADqDCvDzcdG3Q2ZHuf4/oLB8vDx3JztX65BN6+suNkiSrh5uOncrXwk2pWrgp1ayfsmib/tA+TO3CGji9dwAAqgsCOACHBfvV023XB5mv1zx3u3YeOaX4vcf1v93HtGbfCUnSzPgUzYxPsVt1Jb+wWD5eTm8ZAACX4Vb0ACqdl4ebbmoZoNG3t9Knj9xobh/aKUz+Pp52a7L3nbZckxdts5vCAgBAbVYjA/iUKVN04403qkGDBgoKCtLQoUO1Y8cOuxrDMDRx4kSFhYXJ29tbffr00ZYtW+xq8vLy9MwzzygwMFC+vr4aMmSIDh48aFeTkZGh6Oho2Ww22Ww2RUdHKzMz064mJSVFgwcPlq+vrwIDAzV69Gjl5+fb1WzevFm9e/eWt7e3mjRpokmTJnFnQ9Q5k+9sr3XP99Nn54TyEzn5+nDFXvWbvlwP/meNC7sDAMA5amQAX758uZ5++mnFx8dr8eLFKiwsVEREhHJyzt698I033tD06dP1zjvvaN26dQoJCVH//v118uRJs2bMmDGaN2+e5syZo5UrV+rUqVMaNGiQiorOrvIwfPhwJSYmKjY2VrGxsUpMTFR0dLS5v6ioSFFRUcrJydHKlSs1Z84czZ07V+PGjTNrsrOz1b9/f4WFhWndunWaMWOGpk6dqunTp1fxZwqofjzcS0bHS/17eCf1axMsdzeLNqRknt3+y25lXeDupQAA1GQ1cg54bGys3etPP/1UQUFBSkhI0K233irDMPT222/r+eef11133SVJ+vzzzxUcHKwvv/xSf/zjH5WVlaWPP/5YM2fOVL9+/SRJs2bNUtOmTbVkyRJFRkZq27Ztio2NVXx8vLp16yZJ+uijj9SjRw/t2LFDrVu3VlxcnLZu3aoDBw4oLCxMkjRt2jSNHDlSr776qvz8/DR79mzl5ubqs88+k9VqVXh4uHbu3Knp06dr7NixLNWGOu2264MU1SFMR7Jz9eWaFP1z6S5J0r9/2aPPV+3XQz2aa3i3Zi7uEgCAylMjR8DPl5WVJUkKCCgZVdu3b5/S0tIUERFh1litVvXu3VurVpXcfjwhIUEFBQV2NWFhYQoPDzdrVq9eLZvNZoZvSerevbtsNptdTXh4uBm+JSkyMlJ5eXlKSEgwa3r37i2r1WpXc/jwYSUnJ5f7MeXl5Sk7O9vuAdRmwX719MfeV5uvrwuur1N5hXp32R71n77ChZ0BAFC5anwANwxDY8eO1c0336zw8HBJUlpamiQpODjYrjY4ONjcl5aWJi8vL/n7+1+0JigoSOcLCgqyqzn/Ov7+/vLy8rpoTenr0przTZkyxZx3brPZ1LRp00t8JoDa5dsne+rD6C5q38SmMwVnp4V9sSpZhUXFLuysYk7nF6rFswvV4tmFOp1f6Op2AADVSI0P4KNGjdKmTZv01Vdfldl3/tQOwzAuOd3j/Jry6iujpvQNmBfqZ8KECcrKyjIfBw4cuGjfQG3j5mZRRLsQLRjVSx9Edza3vxa7Q4NmrNS65BMu7A4AgCtXowP4M888owULFuiXX37RVVddZW4PCQmRVHZ0OT093Rx5DgkJUX5+vjIyMi5ac+TIkTLXPXr0qF3N+dfJyMhQQUHBRWvS09MllR2lL2W1WuXn52f3AOoii8WiW1o1Nl/bvD21Pe2k7n1/tSZ8u9mFnQEAcGVqZAA3DEOjRo3St99+q59//lktW7a029+yZUuFhIRo8eLF5rb8/HwtX75cPXv2lCR16dJFnp6edjWpqalKSkoya3r06KGsrCytXbvWrFmzZo2ysrLsapKSkpSaevZuf3FxcbJarerSpYtZs2LFCrulCePi4hQWFqYWLVpU0mcFqBt+/PPNeuCmprJYpO8SD7u6HQAALluNDOBPP/20Zs2apS+//FINGjRQWlqa0tLSdObMGUklI2ZjxozR5MmTNW/ePCUlJWnkyJHy8fHR8OHDJUk2m02PPfaYxo0bp6VLl2rjxo168MEH1b59e3NVlDZt2mjAgAGKiYlRfHy84uPjFRMTo0GDBql169aSpIiICLVt21bR0dHauHGjli5dqvHjxysmJsYctR4+fLisVqtGjhyppKQkzZs3T5MnT2YFFOAKNPTx0pS7OujbJ3uqXdjZvww9N28zc60BADVCjQzg7733nrKystSnTx+Fhoaaj6+//tqs+X//7/9pzJgxeuqpp9S1a1cdOnRIcXFxatCggVnz1ltvaejQoRo2bJh69eolHx8fff/993J3dzdrZs+erfbt2ysiIkIRERHq0KGDZs6cae53d3fXwoULVa9ePfXq1UvDhg3T0KFDNXXqVLPGZrNp8eLFOnjwoLp27aqnnnpKY8eO1dixY6v4MwXUXp2a+WvOE93N1/M3HtbgGSu188jJixwFAIDr1ch1wCtyB0mLxaKJEydq4sSJF6ypV6+eZsyYoRkzZlywJiAgQLNmzbrotZo1a6YffvjhojXt27fXihUspQZUJne3s39BCmpg1Z6jObrvg3gXdgQAwKXVyBFwADjft0/1VO/rGiuv8OwShWfyiy5yBAAArkEAB1ArBPh66dORN2pc/+vMbTFfrOd29gCAaocADqDWcHOz6LFbzq6KtCElU/d+sEppWbku7AoAAHsEcAC1VlADq3YeOaW731ulvUdPubodAAAkEcAB1GKzH++mqwN9dSjzjB78eO2lDwAAwAkI4ABqrSb+3vrmTz3U4SqbMpkLDgCoJgjgAGq1RvWt+iqmu3pe08jctj45w4UdAQDqOgI4gFrP1+qhd0d0Nl+P+nKDdqRxwx4AgGsQwAHUCV4eZ3/cZecW6uFP1upQ5hkXdgQAqKsqHMDvuusu3X333Tp48GC5+0+fPq0VK1Zc8m6P27dvV0BAgBo1anTROgCoKtc09lVadq4e+niNMk/nO/Xap/ML1eLZhWrx7EKdzi906rUBANVDhQP4/PnzNX/+fGVnZ5e7f9++ferTp4/69u170fMUFRUpMzNTmZmZl9UoAFSWDx/qolBbPe05mqMnZ21wdTsAgDqm0qegGIZR2acEgEoVavPWF4/eJJu3p347mOXqdgAAdQxzwAHUSa2CG+iTkV1Vz5MfgwAA5+L/PADqrC7NAzT13o7m69ikNBd2AwCoKwjgAOq0vtcHmc9f/C5J+4/nuLAbAEBdQAAHgN/l5BXp6S83KL+w2NWtAABqMQI4APyuoY+nkg5l642fdri6FQBALUYAB4DfvXZXe0nSl2tSXNwJAKA2I4ADwO9uva6xnuxzjavbAADUch6Xe8ALL7yghg0bltl+7o11Hn300Qsezw14AFRn4/pfpzV7j2tDSqYkKb+wWD5eru0JAFC7XHYA/+677y64z2KxSJI+//zzK+8IAFzIw91Nb97bQbdPWyFJ+mDFXv1twPUu7goAUJtc1hQUwzAq5QEA1Vmozdt8/tGve7U7/aQLuwEA1DYVHgHft29fVfYBANVSYZGh575N0pwnuru6FQBALVHhAN68efOq7AMAqiVvT3etTT6hbxIOaHDHMFe3AwCoBVgFBQAu4pm+10qSJi/aruOn8lzcDQCgNiCAA8BFPNi9mdqF+SnrTIFej+UGPQAAx132KigVlZKSonnz5mn37t1yc3NTy5YtNXjwYF1zDWvsAqg5PNzdNOWu9hr67//ph02pVXad0/mFavvST5KkrZMi5eNVZT+eAQAuVuGf8IWFhfrkk08kSe3bt1ePHj0uWDtp0iS9+uqrKiwstNv+17/+VaNHj9a0adOusF0AcL4OVzXUwz1b6NP/Jbu6FQBALVDhAL5+/Xr96U9/ksViUVxc3AXr3nzzTU2cOLHcfUVFRXr77bfl5uamN99887KbBQBXGRfRWj9uTlNadq6rWwEA1HAVngO+fPlySVKzZs10++23l1tz+PBhvfzyy+brXr166eOPP9aPP/6oSZMmyWazyTAMvf3229q1a5eDrQOA89S3euiFQW3M1yknTruwGwBATVbhAP7rr7/KYrHojjvuuGDNJ598otzcXFksFg0dOlQrVqzQI488osjISL3wwgtatmyZrFariouL9cUXX1TKBwAAztL3+iDz+Yyfd7uwEwBATVbhAJ6SkiJJF537/f3335vP33jjDfPW9KU6duyohx56SIZhaOXKlZfbKwBUGws3pWrL4SxXtwEAqIEqHMDT09MlSS1atCh3/+nTp7Vx40ZZLBa1b99e1157bbl1AwYMkCTt2MFyXgBqtjdYlhAAcAUqHMAzMjIkSd7e3uXuX79+vbnqSa9evS54ntI7amZmZlb00gBQ7Xi4WbR851Gt3nPc1a0AAGqYCgdwHx8fSdLRo0fL3b9mzRrz+Q033HDB85ROSykqKqropQGg2rm361WSpNdjt8swDBd3AwCoSSocwEunnqxevbrc/cuWLTOfX2yeeGmAt9lsFb00AFQ7f+p9jbw93ZV4IFNLt6W7uh0AQA1S4QB+8803yzAMvf/++zp58qTdvv3792vx4sWyWCwKCwtTeHj4Bc+TmJgoSWrZsuWVdQwA1UDjBlY9fkvJz7G3l7KsKgCg4iocwB977DFZLBalpqaqT58+io2N1a5du7RgwQINGDDAnP/98MMPX/Q8S5culcViUceOHR3rHABcLObWq+Xv46m9R3Nc3QoAoAapcAC/4YYb9OSTT8owDCUmJioqKkrXX3+97rzzTu3cuVOSFBQUpHHjxl3wHKmpqfr5558lSbfeequDrQOAa/nV89TTt5W/4hMAABdS4QAuSf/617/05JNPSpIMw7B7hISEaMGCBfL397/g8W+//baKiork7u6ugQMHOtY5AFQDD3ZvrhBbPVe3AQCoQTwup9jNzU3//ve/9fTTT2vBggXav3+/vLy81KlTJ917773y9fW96PE+Pj4aN26cQkND1ahRI4caB4DqoJ6nu56+7Rq9OH+LJCmvoEg+Xpf1oxUAUMdc0f8l2rZtq7Zt2172cS+//PKVXA4AqrUhHcPMAP79plQ91KOFaxsCAFRrlzUFBQBQlqf72R+ln6zcp+Ji1gUHAFwYARwAKlHy8dNavO2Iq9sAAFRjBHAAqGTvL9/D3TEBABdU4Tngffv2rdQLWywWLV26tFLPCQCu5uXhpo0pmdqQkunwuU7nF6rtSz9JkrZOiuTNnQBQS1T4p/myZctksVgklSxBWPr8Sjh6PABUV3fcEKZv1h/UJyv3uboVAEA1ddnDKfXq1VNQUFBV9AIANd4jPVvovwkH9cuOo65uBQBQTV12AM/NzVVoaKiio6N13333KSAgoCr6ggv5eHko+bWoS2673O2VcY6LbQeqgxaBvopsG6LYLWmubgUAUE1VOID//e9/1+zZs7V9+3bFx8drzZo1+stf/qI//OEPio6O1qBBg+Tp6VmVvQIXVF1+QXDFOVD9/LH31QRwAMAFVTiAP//883r++ee1fv16ffHFF/r666919OhRzZ8/X999950aNmyoYcOG6cEHH1SvXr2qsmcA56iMcI/K1amZv7o299f6/RmubgUAUA1d9jKEXbt21b/+9S8dPnxYCxYs0D333COr1aqMjAx9+OGHuvXWW3XNNddo4sSJ2rVrV1X0DKCSlQbz5NeiWGmjkjx2c0vz+cncAhd2AgCobq54HXB3d3cNGjRI//d//6e0tDR99NFHuuWWWyRJ+/bt09///nddf/316tGjh9577z2dOHGi0poG4BzlBXPCesXc0irQfP7thkMu7AQAUN1Uyo14/Pz89Nhjj2nZsmXat2+fJk2apFatWskwDK1du1ajRo3S1VdfXRmXAlBNEcztubmdXWr163UHuDEPAMBU6XfCbNasmV544QVt375dM2bMkNVqlWEYys/Pr+xLAUCNkHz8tFbvPe7qNgAA1USlD1OlpKRo9uzZmjlzpnbs2GFu9/LyquxLAagBeONniS/XpKjnNYGXLgQA1HqVEsCzs7P1zTffaNasWfr1119lGIb559YePXqYa4YDgFQ3Q/lPW9J09GSefK3urm4FAOBiVxzAi4qK9OOPP2rmzJn6/vvvlZeXZ4buq6++Wg8++KCio6N1zTXXVFqzAFATdbzKpt8OZumbhAMa2bOFq9sBALjYZQfwdevWaebMmZozZ46OHy+Z02gYhrkOeHR0NOuAA7gitXVkfNiNTfXbwSx9uSZFD3Vv7up2AAAuVuEA/uqrr2rmzJnm2t6GYcjT01MDBw5UdHS0Bg8ezDxvACjHgHYhev3H7TqYcUb/23PM1e0AAFyswgH8xRdflMVikWEY6tatmx566CHdf//98vf3r8r+AKDG8/Zy191drtKn/0vW/60/6Op2AAAudtlTULy9vXXkyBG9+eabevPNN6/4whaLRXv27Lni4wHUHbVhasqIbs306f+StWzHUVe3AgBwscsO4GfOnFFycrLDF7ZYLJcuAoBa4tqgBrqpZYDW7uOuwABQ11U4gN96662EZgBwwIhuzQjgAICKB/Bly5ZVYRsAcPlq2tSUAeEh8vfxVMbpAle3AgBwoUq/FT0AoHxWD3fd1bmJw+c5nV+oFs8uVItnF+p0fmEldAYAcKYaGcBXrFihwYMHKywsTBaLRfPnz7fbb7FYyn2c+6bRPn36lNl///33250nIyND0dHRstlsstlsio6OVmZmpl1NSkqKBg8eLF9fXwUGBmr06NHKz8+3q9m8ebN69+4tb29vNWnSRJMmTTJvWgSgbrmny1Xm88OZZ1zYCQDAVSrlVvTOlpOTo44dO+qRRx7R3XffXWZ/amqq3esff/xRjz32WJnamJgYTZo0yXzt7e1tt3/48OE6ePCgYmNjJUlPPPGEoqOj9f3330squRtoVFSUGjdurJUrV+r48eN6+OGHZRiGZsyYIUnKzs5W//79ddttt2ndunXauXOnRo4cKV9fX40bN87xTwYAO9V9WkrzRr7m8x82pWpMvwYu7AYA4Ao1MoAPHDhQAwcOvOD+kJAQu9ffffedbrvtNl199dV22318fMrUltq2bZtiY2MVHx+vbt26SZI++ugj9ejRQzt27FDr1q0VFxenrVu36sCBAwoLC5MkTZs2TSNHjtSrr74qPz8/zZ49W7m5ufrss89ktVoVHh6unTt3avr06Ro7dixvbAXqsAWJh/Xn21vxcwAA6pgaOQXlchw5ckQLFy7UY489Vmbf7NmzFRgYqHbt2mn8+PE6efKkuW/16tWy2Wxm+Jak7t27y2azadWqVWZNeHi4Gb4lKTIyUnl5eUpISDBrevfuLavValdz+PDhiy7nmJeXp+zsbLsHgNpl77EcbT6U5eo2AABOVusD+Oeff64GDRrorrvusts+YsQIffXVV1q2bJlefPFFzZ07164mLS1NQUFBZc4XFBSktLQ0syY4ONhuv7+/v7y8vC5aU/q6tKY8U6ZMMeee22w2NW3a9DI+agA1xbcbDrm6BQCAk9XIKSiX45NPPtGIESNUr149u+0xMTHm8/DwcLVq1Updu3bVhg0b1LlzZ0nl3yzIMAy77VdSU/oGzIv92XnChAkaO3as+To7O5sQDtRC3/92WM9HtXF1GwAAJ6rVAfzXX3/Vjh079PXXX1+ytnPnzvL09NSuXbvUuXNnhYSE6MiRI2Xqjh49ao5gh4SEaM2aNXb7MzIyVFBQYFdz/kh3enq6JJUZGT+X1Wq1m7YCwDHV8c2ZjXy9dDwnXyt2HlWPaxq5uh0AgJPU6ikoH3/8sbp06aKOHTtesnbLli0qKChQaGioJKlHjx7KysrS2rVrzZo1a9YoKytLPXv2NGuSkpLsVl2Ji4uT1WpVly5dzJoVK1bYLU0YFxensLAwtWjRojI+TAA1VFSHkp83325kGgoA1CU1MoCfOnVKiYmJSkxMlCTt27dPiYmJSklJMWuys7P1zTff6PHHHy9z/J49ezRp0iStX79eycnJWrRoke6991516tRJvXr1kiS1adNGAwYMUExMjOLj4xUfH6+YmBgNGjRIrVu3liRFRESobdu2io6O1saNG7V06VKNHz9eMTEx8vPzk1SylKHVatXIkSOVlJSkefPmafLkyayAAkBDbih5A/firUeUfYa7YwJAXVEjA/j69evVqVMnderUSZI0duxYderUSS+99JJZM2fOHBmGoQceeKDM8V5eXlq6dKkiIyPVunVrjR49WhEREVqyZInc3d3NutmzZ6t9+/aKiIhQRESEOnTooJkzZ5r73d3dtXDhQtWrV0+9evXSsGHDNHToUE2dOtWssdlsWrx4sQ4ePKiuXbvqqaee0tixY+3mdwOom9qENNB1wfWVX1isuK1lp7wBAGqnGjkHvE+fPpe8k+QTTzyhJ554otx9TZs21fLlyy95nYCAAM2aNeuiNc2aNdMPP/xw0Zr27dtrxYoVl7wegLrFYrHozk5X6fXY7VqQeNjV7QAAnKRCAfzcqR2VqVmzZlVyXgCoKYZ2CtMbP23X+v0Zrm4FAOAkFQrgLVu2rPQLWywWFRYWVvp5AeByuHp1lFCbt3pe00j/233cZT0AAJyrQnPADcOokgcAQLqz01WubgEA4EQVGgH/9NNPL7r/3Xff1bp16+Tp6amIiAjddNNNCg4OlmEYSk9P17p16xQXF6eCggLdeOONevLJJyuleQCoDQaEh+jF+Uk6U1Dk6lYAAE5QoQD+8MMPX3Df448/rvXr1ysiIkIff/yxmjRpUm7doUOHFBMTo59++knt27fXRx99dGUdA0AtU9/qodvbBOmHTamXLgYA1HgOLUP43//+V5988om6du2qhQsXXjB8S1KTJk30/fffq0uXLvrkk0/0f//3f45cGgBqlSEdw8znhUXFLuwEAFDVHArgH3zwgSwWi8aOHWu3fvaFuLu7a9y4cTIMQx9++KEjlwaAWqXb1QHm83XJrIgCALWZQ+uAb9q0SZJ03XXXVfiY0trNmzc7cmkAqDKuWBnF0/3seEjsljTd3ibYqdcHADiPQyPgJ0+elCSlp6dX+JjS2tJjAQD2Fm89wjQUAKjFHArgzZs3lyR98cUXFT6mtJab8ABA+TJPF2j13stfF/x0fqFaPLtQLZ5dqNP53GcBAKorhwL4HXfcIcMwNGfOHL3xxhuXrJ86daq++uqrktsv33mnI5cGgFptISuiAECt5VAAf/bZZxUSEiJJmjBhgjp16qS3335b//vf/7Rr1y7t3r1b//vf//T222+rS5cu+tvf/iZJCgkJMZ8DAMqK3ZKmAqahAECt5NCbMBs2bKglS5YoMjJShw4d0qZNmzRu3LgL1huGoauuukqxsbFq2LChI5cGgFqrka+Xjufka83eE65uBQBQBRwaAZektm3basuWLfrLX/6ihg0bXvC28w0bNtTYsWOVlJSktm3bVkbvAFArRbQrWQEldkuaizsBAFQFh0bAS/n5+WnatGmaMmWKEhIStHnzZmVkZMgwDAUEBKh9+/bq0qWLvLy8KuNyAFCrDWgXoq/WHtCSrUdc3QoAoApUSgAv5eXlpR49eqhHjx6VeVoAqBactT545+b+CmpgVfrJvCq/FgDA+RyeggIAqFzubhb9oX2oq9sAAFSRSh0B37t3r1avXq20tDSdPn1aTz75pAIDAyvzEgBQJ0R1CNVnq5Jd3QYAoApUSgDfuHGjxowZo5UrV9ptv/vuu+0C+L///W+98sorstls2rp1qzw9PSvj8gBQ63RpxjQUAKitHJ6CsnDhQvXs2VMrV660W/WkPA8//LDOnDmjvXv36ocffnD00gBQa7m5WRT5+2ooAIDaxaEAnpaWpgceeEB5eXlq27atfvzxR508efKC9fXr19fQoUMlST/++KMjlwaAWm9AeIj5PK+gyIWdAAAqk0MB/K233tKpU6fUvHlz/frrr4qMjJSvr+9Fj+nTp48Mw1BCQoIjlwaAWq/jVQ3N5yt3H3ddIwCASuVQAP/pp59ksVg0bty4Ct/ZsnXr1pKk5ORkRy4NALWem5vFfL6YNcEBoNZwKIDv27dPknTTTTdV+JgGDRpIkk6dOuXIpQGgTlm2I10FRcWubgMAUAkcCuAFBQWSdFmrmWRmZkrSJaeqAADOys4tVPxepqEAQG3gUAAPCSl5g1DpSHhFrF69WpJ01VVXOXJpAKg2Su+QmfxalHy8KvX2CnZik9Kq7NwAAOdxKID36tVLkjRv3rwK1Z8+fVrvv/++LBaLbr31VkcuDQB1zk9bjqiouPxlXgEANYdDAfzhhx+WYRj66quvFBcXd9HaU6dOadiwYUpJSZEkPfbYY45cGgDqlAb1PHTsVJ42pmS4uhUAgIMcCuD9+vXT0KFDVVxcrCFDhuivf/2r1q5da+4/ceKE1qxZo7///e9q3bq1fvzxR1ksFj300EPq1KmTw80DQF3Rp3VjSdJPW5iGAgA1ncN3wpw1a5b69Omj/Px8TZ8+XT169JDFUrJ0Vu/evdWzZ09NnDhRqampMgxDffv21fvvv+9w4wBQl/RrU3JXzNgtaRe82zAAoGZwOID7+PhoyZIlevPNNxUSEmJ3O/pzHwEBAZo8ebJ++uknWa3WyugdAOqMXtc2Uj1PNx04cUbb0y58x+HynM4vVItnF6rFswt1Or+wijoEAFRUpbxd383NTePGjdOf//xnrV27VuvXr1d6erqKiorUqFEjderUSTfffDPBGwCukI+Xh3pf11g/bTmiJdyUBwBqtEpdL8vDw0M9e/ZUz549K/O0AABJA8JD9NOWI1q8Ld3VrQAAHOBQAF+xYoUk6cYbb5S3t3eFjsnNzTXfqMlShABQcX1bB8vDzaLd6dxJGABqMocCeJ8+feTm5qZNmzapbdu2FTrm0KFD5nGFhcxFBICKsvl4qsc1jfTrrmOubgUA4ACHp6Bc6bvxeRc/gNqs9O6YlW1AeAgBHABqOIdXQblcxcXFkiR3d3dnXxoAarz+bYP1+0qvAIAayukBPDk5WZJks9mcfWkAqPGCGtRTp6YNXd0GAMABlzUFpfQ28udLTU1V/fr1L3psXl6e9uzZoxdffFEWi0Xt2rW7nEsDAH7Xr02wNqRkuroNAMAVuqwA3rJlyzLbDMNQRETEZV/4oYceuuxjAABSv7ZBeuOnHZKkEzn58vGq1BVlAQBV7LKmoJx/d8sLbb/Yw2q16q9//aseffTRSv9gAKAuuMrfx3y+bMdRF3YCALgSlzVs8umnn9q9fuSRR2SxWPT3v/9dTZo0ueBxFotF9erVU2hoqDp16nTJ6SoAgIpZuv2IHuze3NVtAAAuw2UF8Icfftju9SOPPCJJGjp0aIXXAQcAVJ5Vu4/rdH4h01AAoAZx6Cf2L7/8Iqn8ueEAgKqXV1isFTuPaUB4iKtbAQBUkEMBvHfv3pXVBwDgCsVtTSOAA0AN4vR1wAEAlWvptnQVFhW7ug0AQAVV2qRBwzCUmJio3377TceOHdOZM2cuebv5l156qbIuDwB1kr+PpzJOF2jtvhO6oVlDV7cDAKiASgngn3/+uV555RXt37//so4jgAOAY267PkjfbjikuK1HCOAAUEM4PAXl+eef16OPPqrk5ORLrgEuqdx1xAGgrvDx8lDya1FKfi2qUlYuuf36IElS3JY0fq4CQA3hUABfs2aNpkyZIknq37+/EhMTtWHDBkkla38XFRXp2LFjio2N1R133CHDMHTzzTcrNTVVxcXMVwQAR/W4ppG8Pd11OCtX21JPVvi40/mFavHsQrV4dqFO5xdWYYcAgPM5FMDfe+89SVLz5s21cOFCdejQQZ6enuZ+i8WigIAARUREaN68efr3v/+tlStXasCAAcrPz3escwCA6nm6q/d1jSVJS7cdcXE3AICKcCiAr1q1ShaLRaNHj5aHx6X/lPrkk0/q7rvv1qZNm/Tuu+86cmkAwO8i2gVLkpZuT3dxJwCAinAogKempkqS2rVrd/aEbmdPWVBQUOaY6OhoGYahr7/+2pFLAwB+d/v1wXJ3s2jnkVOubgUAUAEOBfDSgB0UFGRuq1+/vvn86NGjZY5p2rSpJGn37t2OXBoA8Dubj6e6Xx3g6jYAABXkUABv3Lhk3mF2dra5LTg4WO7u7pKkbdu2lTmmdNT85MmKv1kIAHBxEW25EyYA1BQOBfDSqSfbt283t3l5eZnby5tmMnv2bElSWFiYI5cGAJyjf9tgV7cAAKgghwL4LbfcIsMw9Msvv9htv++++2QYhj755BO99NJL2rJli9atW6dRo0bpq6++ksVi0cCBAx1qHABwVlhDb7UL83N1GwCACnAogA8dOlSS9MMPP9hNQ/nzn/+sFi1aqLi4WK+++qo6dOig7t27m8sW+vv7a8KECY5cGgBwntvbBF26CADgcg5PQfnll180b948FRaevZGDj4+PfvnlF/Xq1avM3TDDw8O1dOlSXXXVVQ43DwA46/Y2Z6eh5ORxcx0AqK4cvg9y7969y93evHlz/frrr9qxY4e2bNmiwsJCtWrVSp06dXL0kgCAclzb2Nd8vmLXMd3dmYEOAKiOHA7gl9K6dWu1bt26qi8DAHWexWIxny/ddoQADgDVVJUHcADApfl4eSj5tahKO9/ynUeVV1gkq4d7pZ0TAFA5HJoDDgConnLyirRq93FXtwEAKEeFRsAnTZpUJRd/6aWXquS8AADppy1puu16VkYBgOqmQgF84sSJdnMLKwsBHACqzuKtR/TqnYar2wAAnKfCU1DOX07w/MeV1AAAqoaft4eO5+RrffIJV7cCADhPhQJ4cXHxBR979+7VjTfeKMMwNHDgQH3zzTfav3+/cnNzlZubq/379+u///2vBg4cKMMwdOONN2rfvn0qLi6+4qZXrFihwYMHKywsTBaLRfPnz7fbP3LkSFksFrtH9+7d7Wry8vL0zDPPKDAwUL6+vhoyZIgOHjxoV5ORkaHo6GjZbDbZbDZFR0crMzPTriYlJUWDBw+Wr6+vAgMDNXr0aOXn59vVbN68Wb1795a3t7eaNGmiSZMm8QsIgCrVt3XJ1JOfthxxcScAgPM59CbMrKwsRUREaMOGDfriiy+0cOFC3X333WratKm8vLzk5eWlpk2b6q677tLChQs1c+ZMJSQkqF+/fsrKyrri6+bk5Khjx4565513LlgzYMAApaammo9FixbZ7R8zZozmzZunOXPmaOXKlTp16pQGDRqkoqIis2b48OFKTExUbGysYmNjlZiYqOjoaHN/UVGRoqKilJOTo5UrV2rOnDmaO3euxo0bZ9ZkZ2erf//+CgsL07p16zRjxgxNnTpV06dPv+KPHwAupfSmPD9tSbusX/hP5xeqxbML1eLZhTqdz818AKAqOLQM4VtvvaXdu3frT3/6kx588MFL1o8YMUIrV67UBx98oGnTpl3xmzsHDhyogQMHXrTGarUqJCSk3H1ZWVn6+OOPNXPmTPXr10+SNGvWLDVt2lRLlixRZGSktm3bptjYWMXHx6tbt26SpI8++kg9evTQjh071Lp1a8XFxWnr1q06cOCAwsLCJEnTpk3TyJEj9eqrr8rPz0+zZ89Wbm6uPvvsM1mtVoWHh2vnzp2aPn26xo4dWyVz6wGg17WN5O3prkOZZ7Qt9aSr2wEAnMOhEfC5c+fKYrHo3nvvrfAxw4YNkyR9++23jlz6kpYtW6agoCBdd911iomJUXp6urkvISFBBQUFioiIMLeFhYUpPDxcq1atkiStXr1aNpvNDN+S1L17d9lsNrua8PBwM3xLUmRkpPLy8pSQkGDW9O7dW1ar1a7m8OHDSk5OvmD/eXl5ys7OtnsAQEXV83RXn9aNJZW8GRMAUH04FMBLA6TNZqvwMaW1+/fvd+TSFzVw4EDNnj1bP//8s6ZNm6Z169apb9++ysvLkySlpaXJy8tL/v7+dscFBwcrLS3NrAkKKrt8V1BQkF1NcHCw3X5/f395eXldtKb0dWlNeaZMmWLOPbfZbGratOnlfAoAQJHtSv4KuGQbARwAqhOHArinp6ekkjcZVlRpbemxVeG+++5TVFSUwsPDNXjwYP3444/auXOnFi5ceNHjDMOwmxJS3vSQyqgpnY95seknEyZMUFZWlvk4cODARXsHgPPddn2QPNws2nM0x9WtAADO4VAA79ixowzD0Ouvv67Tp09fsv706dN6/fXXZbFY1KFDB0cufVlCQ0PVvHlz7dq1S5IUEhKi/Px8ZWRk2NWlp6ebo9MhISE6cqTsqNHRo0ftas4fxc7IyFBBQcFFa0qnw5w/Mn4uq9UqPz8/uwcAXA6bt6d6Xhvo6jYAAOdxKIA//vjjkqQdO3aoT58+SkxMvGDtb7/9pttuu03bt2+XJD3xxBOOXPqyHD9+XAcOHFBoaKgkqUuXLvL09NTixYvNmtTUVCUlJalnz56SpB49eigrK0tr1641a9asWaOsrCy7mqSkJKWmppo1cXFxslqt6tKli1mzYsUKu6UJ4+LiFBYWphYtWlTZxwwAkhTZ7sK/6AMAXMOhVVBGjBihefPm6dtvv1VCQoK6dOmi9u3b68Ybb1RQUJAsFouOHDmidevW2U1TueuuuzR8+PArvu6pU6e0e/du8/W+ffuUmJiogIAABQQEaOLEibr77rsVGhqq5ORkPffccwoMDNSdd94pqWQe+mOPPaZx48apUaNGCggI0Pjx49W+fXtzVZQ2bdpowIABiomJ0QcffCCp5JeGQYMGqXXr1pKkiIgItW3bVtHR0XrzzTd14sQJjR8/XjExMeaI9fDhw/XKK69o5MiReu6557Rr1y5NnjxZL730EiugAKhy/dsG64X5SeLWAwBQfTgUwCXp66+/1pgxY/Tee++puLhYmzZtKndOeOm86FGjRjm8Bvb69et12223ma/Hjh0rSXr44Yf13nvvafPmzfriiy+UmZmp0NBQ3Xbbbfr666/VoEED85i33npLHh4eGjZsmM6cOaPbb79dn332mdzd3c2a2bNna/To0eZqKUOGDLFbe9zd3V0LFy7UU089pV69esnb21vDhw/X1KlTzRqbzabFixfr6aefVteuXeXv76+xY8eaPQNAVQpqUE+dmjbUhpRMV7cCAPidwwHc3d1dM2bM0BNPPKH3339fS5Ys0e7du+1u/NCqVSv169dPf/zjHytl7nefPn0uemOJn3766ZLnqFevnmbMmKEZM2ZcsCYgIECzZs266HmaNWumH3744aI17du314oVKy7ZEwCcy8fLQ8mvRTl8nn5tggngAFCNOBzAS7Vv317//ve/JZWsYZ2ZmSnDMOTv72+3BjYAwLki2gXrjZ92SJKOnsxT80aV9qMfAHAFHHoT5oVYrVYFBwcrJCSE8A0ALhbW0Nt8Hrf1wvcfAAA4R5UEcABA9fRTEjflAQBXI4ADQB2SkJKhI9m5rm4DAOq0Ck0E7Nu3r6SSOzcuXbq0zPYrcf65AABVzzCkHzenatiNTV3dCgDUWRUK4MuWLZNU9tbpy5Ytk8ViueiKJOcrrWcNbABwjUWb0y47gJ/OL1Tbl0pWmNo6KVI+XryREwCuVIV+gt56663lBuYLbQcAVF/r9p9gGgoAuNBljYBXdDsAoHrq1LShNh7IVNxW3owJAK7CmzABoA4ZEB4iSfopieUIAcBVCOAAUIf0bxssSdwZEwBciAAOAHVIiK2eujb3d3UbAFCnEcABoI6J6hDq6hYAoE6rUAB3d3ev9IeHB0tYAYArDAwngAOAK1UogBuGUSUPAIDzhdjqqXOzhq5uAwDqrAoNQ7/88stV3QcAwIkGhIfwRkwAcBECOADUMD5eHkp+Lcqhc0S0DdbkRdslSYczz+jaoAaV0RoAoAJ4EyYA1EFBfvXM54s2p7qwEwCoewjgAFDHfZd4mPflAIATEcABoI7bczRHWw5nu7oNAKgzKnUtwIyMDP322286duyYzpw5c8kRlYceeqgyLw8AuEJzNxxUeBPbZR1zOr9QbV/6SZK0dVKkfLxYXhYAKqJSflouW7ZML7/8slauXFnhYywWCwEcAKqJBYmH9dwf2ri6DQCoExyegvLee++pX79+WrlyJeuAA0AN1MjXS8dz8vXrrqOubgUA6gSHAvi2bds0evRoGYah9u3ba/78+Vq4cKGkkhHuPXv2aP369Xr//ffVuXNnSdLNN9+sLVu2aO/evY53DwBwWOmt6eduOOTiTgCgbnAogM+YMUNFRUUKDAzUr7/+qiFDhqhZs2bm/pYtW6pz58564okntG7dOv31r3/VypUr9cwzz6h58+YONw8AcNyQjmGSpMVbjyj7TIGLuwGA2s+hAL58+XJZLBaNHj1aDRpc/CYOFotFr7/+uvr27atffvlFn3zyiSOXBgBUkjahDXRdcH3lFxYrbusRV7cDALWeQwH84MGDkmROL5FKgnapgoKyIylPPPGEDMPQrFmzHLk0AKCSWCwW3dX5Kkkla4IDAKqWQwE8NzdXkhQWFmZu8/X1NZ9nZGSUOebaa6+VJG3dutWRSwMAKtEdN4TJYpES9pf9uQ0AqFwOBfCAgABJUk5OjrmtcePG5ij4zp07yxxz7NgxSVJmZqYjlwYAVKJQm7d6XRPo6jYAoE5wKIBff/31kqRdu3aZ23x8fNSqVStJ0oIFC8ocU7qtcePGjlwaAFDJ7urcxNUtAECd4FAAv/nmm2UYhlasWGG3/a677pJhGPrXv/6lTz75RDk5OTp69KimTp2qDz/8UBaLRX379nWocQBA5YpsFyJvT3dXtwEAtZ5DAXzQoEGSpO+++86cDy5J48aNU0BAgAoKChQTEyM/Pz+FhITob3/7mwoLC1WvXj09++yzjnUOALDj4+Wh5NeilPxa1BXdFt7X6qH+bYMd7uN0fqFaPLtQLZ5dqNP5hQ6fDwBqG4cCeLdu3fTpp5/q9ddft3vDZaNGjfTTTz+pRYsWZe5+GRQUpHnz5qlNG255DADVzZAbzr6p/kx+kQs7AYDa6/KHSM7z8MMPl7u9S5cu2r59u37++Wdt2bJFhYWFatWqlSIjI+Xj4+PoZQEAVaBbywDz+Y9JaXqwOzdNA4DK5nAAvxhPT09FRkYqMjKyKi8DAKgk7m5n7+UwZ20KARwAqoBDU1AAALVX0uFsJR7IdHUbAFDrOBTAb7zxRv3zn/9UWlpaZfUDAKhGZq7e7+oWAKDWcSiAJyQkaOzYsWratKkiIiL0+eef6+TJk5XVGwDAxb7fdFgZOfmubgMAahWHAnibNm1kGIaKioq0dOlSPfroowoJCdF9992nBQsWqLCQ5acAoKZqG+qn/MJifZNwwNWtAECt4lAA37JlizZu3Kjx48erSZMmMgxDZ86c0X//+1/deeedCg4O1pNPPqlff/21svoFADjJAzc1lSTNik9RcbHh4m4AoPZw+E2YHTt21BtvvKGUlBT98ssviomJUcOGDWUYhjIyMvThhx+qT58+at68uZ577jklJSVVRt8AgCr2h/ah8qvnoZQTp7Vy9zGHz8cNegCgRKWugtK7d2998MEHSktL07x583TvvffKarXKMAwdOHBAr7/+ujp27KgOHTrojTfeqMxLAwAqmbeXu+7tWjIKPmct01AAoLJUyTKEnp6euuOOO/T1118rPT1dn376qfr16yc3NzcZhqGkpCRNmDChKi4NAKhEI7o1kyQt33XUxZ0AQO1R5euA169fXw8//LB++uknff7552rYsGFVXxIAUEmublxft7QKlMEUcACoNFV6J0xJ2rBhg7788kvNmTNHqampVX05AEAli+7eXL/ucnwOOACgRJUE8D179ujLL7/Ul19+qZ07d0qSjN+HTxo0aKA777xTI0aMqIpLAwAqWd/rgxRiq6e0rFxXtwIAtUKlBfD09HR9/fXX+vLLL7V27VpJZ0O3p6enIiMjNWLECN1xxx2qV69eZV0WAFDFPNzddF/Xpvrn0l2SVKlLEp7OL1Tbl36SJG2dFCkfryr/wywAuJxDP+lycnL07bffavbs2fr5559VVFQk6Wzw7tmzpx588EENGzZMAQEBjncLALhsPl4eSn4tyqFz3HfjVWYA/2XHUQ3uGFYZrQFAneRQAA8ODtaZM2cknQ3dbdq00YgRIzR8+HC1aNHC4QYBAK7X0MfLfP7+8j0a1CHUhd0AQM3mUAA/ffq0JCksLEz333+/RowYoU6dOlVKYwCA6mnL4Wwt23lU3Vryl00AuBIOBfCRI0fqwQcf1G233SaLxVJZPQEAqrkZS3fppsducnUbAFAjORTAP/nkk8rqAwBQQ1g93LQhJVPxe09U2TV4cyaA2qxKbsSTnJysvn376vbbb6+K0wMAXOieLldJKpkLDgC4fFUypJCTk6Nly5YxLQUAaqHHbm6pb9Yf1LrkDFe3AgA1UpXfih4AULuE2Orp3q5XuboNAKixCOAAgMv2ZJ9r5OHm/L9yns4vVItnF6rFswt1Or/Q6dcHUP2U93Ohuv+sIIADAC7bVf4+GnIDN+MB4JjLCc/VPVRfDgI4AOCKxNzS0ny+6WCmy/qoTf9TBmq6uhCeKwMBHABwRZo38jWfT160XcXFhgu7AVBVauIUj+quSlZBCQoK0ssvv1wVpwYAVEObDmbpvwkHNezGpq5uxcRa4sDl4XvGearkM9u4cWMCOADUMa/FbldkuxB5elTvJWgJGajr+B5wPaagAEAd5OPloeTXopT8WlSl/M/3msa+OpGTr+mLd1RCd67Bn9lRG/FvuHqq8gD+/fffKzo6WgMHDtRTTz2ljRs3VvUlAQBO9nxUG0nSzPj92paa7eJuqh5vNAPgCIcC+C+//KKgoCA1a9ZMmZmZZfa/+OKLGjp0qL788kvFxcXpgw8+ULdu3TR79mxHLgsAqGa6X91IUR1CVWxIry7c5up2qhVCOZyBf2c1i0MBfNGiRTp27Ji6d++uhg0b2u3btGmTJk+eLMMwZBiGGjZsKMMwVFhYqCeeeEL79+935NIAgGrmhag28vZ014aUTFe3UiMQmHAl+HdTOzgUwFeuXCmLxaL+/fuX2ffee+/JMAz5+/srISFBx48f19q1axUQEKDc3Fy9//77jlwaAFDNhNq89czt17q6jRqPgAXUfg4F8LS0NEnS9ddfX2bfDz/8IIvFoqefflqdOnWSJHXt2lWjRo2SYRhasmSJI5cGAFRDj93cUi0a+bi6jVqHUF438XWvvRwK4Onp6ZIkm81mt33Pnj06dOiQJOmuu+6y23fLLbdIknbv3n3F112xYoUGDx6ssLAwWSwWzZ8/39xXUFCgv/3tb2rfvr18fX0VFhamhx56SIcPH7Y7R58+fWSxWOwe999/v11NRkaGoqOjZbPZZLPZFB0dXWaue0pKigYPHixfX18FBgZq9OjRys/Pt6vZvHmzevfuLW9vbzVp0kSTJk2SYXDDCgC1j9XDXc/9oY35en3yCRd2AwDVk0MBvDREZmVl2W3/9ddfJZUE8xtuuMFuX6NGjSRJp0+fvuLr5uTkqGPHjnrnnXfK7Dt9+rQ2bNigF198URs2bNC3336rnTt3asiQIWVqY2JilJqaaj4++OADu/3Dhw9XYmKiYmNjFRsbq8TEREVHR5v7i4qKFBUVpZycHK1cuVJz5szR3LlzNW7cOLMmOztb/fv3V1hYmNatW6cZM2Zo6tSpmj59+hV//ABQnd3cKtB8Pv6bTTp2Ks+F3dRujJDWDnwd6x6HFn8NCQnR/v37tW3bNnNkW5J++qlkcfdevXqVOSYnJ0eS5O/vf8XXHThwoAYOHFjuPpvNpsWLF9ttmzFjhm666SalpKSoWbNm5nYfHx+FhISUe55t27YpNjZW8fHx6tatmyTpo48+Uo8ePbRjxw61bt1acXFx2rp1qw4cOKCwsDBJ0rRp0zRy5Ei9+uqr8vPz0+zZs5Wbm6vPPvtMVqtV4eHh2rlzp6ZPn66xY8fKYqneN6wAAEekn8zTX75O1OeP3OTqVuoUbrQCVG8OjYB3795dhmHovffeM0e09+7dq+++++6Cb87cuXOnJF0w+FaFrKwsWSyWMiu1zJ49W4GBgWrXrp3Gjx+vkydPmvtWr14tm81mhm+p5OO12WxatWqVWRMeHm6Gb0mKjIxUXl6eEhISzJrevXvLarXa1Rw+fFjJyckX7DkvL0/Z2dl2DwCoaep5uunXXcf03vI9rm4FcDlGulHKoQD++OOPSypZcjA8PFz33HOPunfvrtzcXHl7e2v48OFljlmxYoUkqW3bto5cusJyc3P17LPPavjw4fLz8zO3jxgxQl999ZWWLVumF198UXPnzrWbr56WlqagoKAy5wsKCjLffJqWlqbg4GC7/f7+/vLy8rpoTenr0pryTJkyxZx7brPZ1LRp08v8yAHA9V6IKvlZPy1uh9YnZ7i4m7qN8AdUHw79Tapv374aM2aM3n77bSUnJ2v//v3mvPA333xTgYGBdvW5ubkXHR2vbAUFBbr//vtVXFysd999125fTEyM+Tw8PFytWrVS165dtWHDBnXu3FmSyp0eYhiG3fYrqSn9HF1s+smECRM0duxY83V2djYhHECNc2enMG1IydC3Gw5p/De/ubodwGmYBoSLcfhfw/Tp09W3b1998803SktLU2hoqB566CH17du3TO2CBQvk5+cnm81W5QG8oKBAw4YN0759+/Tzzz/bjX6Xp3PnzvL09NSuXbvUuXNnhYSE6MiRI2Xqjh49ao5gh4SEaM2aNXb7MzIyVFBQYFdz/kh36eox54+Mn8tqtdpNWwGAmshisegfQ8O16WCWdqefcnU7KAdB0TF8/nAlHJqCUmrQoEH6/PPP9dNPP+mzzz4rN3xL0rBhw5ScnKx9+/bpqquuqoxLl6s0fO/atUtLliwxV165mC1btqigoEChoaGSpB49eigrK0tr1641a9asWaOsrCz17NnTrElKSlJqaqpZExcXJ6vVqi5dupg1K1assFuaMC4uTmFhYWrRokVlfLgAUK35eHno38M7q55npfwvB07ClBWg6tTIn4anTp1SYmKiEhMTJUn79u1TYmKiUlJSVFhYqHvuuUfr16/X7NmzVVRUpLS0NKWlpZkheM+ePZo0aZLWr1+v5ORkLVq0SPfee686depkrtzSpk0bDRgwQDExMYqPj1d8fLxiYmI0aNAgtW7dWpIUERGhtm3bKjo6Whs3btTSpUs1fvx4xcTEmCPuw4cPl9Vq1ciRI5WUlKR58+Zp8uTJrIACoFry8fJQ8mtRSn4tqlJH8lqHNDDng0vSp/9LrrRzA87ALySoTE4J4Hv27NGaNWvKndJxJdavX69OnTqZd9gcO3asOnXqpJdeekkHDx7UggULdPDgQd1www0KDQ01H6Wrl3h5eWnp0qWKjIxU69atNXr0aEVERGjJkiVyd3c3rzN79my1b99eERERioiIUIcOHTRz5kxzv7u7uxYuXKh69eqpV69eGjZsmIYOHaqpU6eaNaXLIh48eFBdu3bVU089pbFjx9rN7waAuuCuzk3M52/+tEOf/W+fC7vBlartQbS2f3yoHhwa3jh69Ki++eYbSSWripx/R8zdu3frvvvuM0eqLRaLhg4dqv/85z9llgS8HH369LnonSQvdZfJpk2bavny5Ze8TkBAgGbNmnXRmmbNmumHH364aE379u3N1V8AACUmfr9V3BO4dmAeNHB5HPoOmTt3rkaNGqXWrVvrqaeestuXl5engQMHau/evWYgNgxD8+bN07Fjx7Rs2TJHLg0AqMEe7dVCn/wvWa98v9XVraAKVZdgfqE+qkt/uDDDMJRXWKT8wmJlnSkwt+87liN3N4sKCg2dyju7feWuY3J3sygn7+xfL1JOnNb1IRdfjMPZHPqXFhcXJ4vForvvvrvMvs8++0x79uyRxWLRkCFDdPvtt2vJkiX6/vvv9euvv+r//u//NGzYMEcuDwCoocZFXCdDzAWvq8oLvpcbki/nHKh6hmHoVF6h0rJzzW3LdqSroKhk+4mcs4tRvLxgiwoKi3U6v0inzgnKg2asVH5hsc4UFJnb2r0cV+71ov61stztT8xMKLNtXfKJ2hXAd+zYIUm66aaytxj+6quvJJWsFT5//nxJ0jPPPGPOtf7qq68I4ABQR1ksFr00qK3O5BdpzroDkqSZ8fv1xC1X8wZ1oBooLCpWenau0k/m6UDGaXP7G7E7dDK3UMdO5Znbekz5WSdzC1R83pyyp2ZvLPfc36w/WO72vUdzKtyfn7eHvNzd5OnuJg83iw5knJEktQltIC93N7lZLNp4IFOSFFi/+i3r7PAccEl2t2KXpDNnzmj16tWyWCx64okn7PY9+uijWrJkiTZs2ODIpQEANZzFYtELUW3MAD5l0XZtOpil1+/uIDcyOFBlzn2v3KLNqTp+Kl+pWblKOXE2aN8waXGZQC1Jn61KLrPt3Kkhnu4WFRSVHBge5ic/b0/5Wj3k7emuBb8dliSNuu0a2by95O3lLg83i579dnPJuR+5UX7enpIM3fXuaknSiv/XRw19vOTl7qbComKFTywZEY+fcHu5fw2Z+2TPMn8N6X1d4yv5NFUphwJ4ZmamJMnNzX4xlfj4eBUUFMjNzU39+vWz29eyZUtJZ29GAwCou9zOSdoebhYt3JSqbanZemtYRxd2BdR8hmEo/WSekg5lmdue/nKDDmfYB+3x32wq9/hiQ3KzlIweN6rvpW2pJyVJj/RqoaAG9VTf6q4Xv9siSVowqpeC/erJ5u2pouJic9rI//2ph11ILg3gT912rd320gB+U8sAMzyXCqxvPVt7iUU2ahKHAnj9+vWVlZVV5k6PpW+wbNu2rfz9/e32eXp6llzYg3lZAICzvnj0Jo375jftPZqj+z6Md3U7QI1gGIaOnspTYkqmue2+D+KVfCxHJ/Psl1H8ZfvRMsd3ae6vpv7eCm3orcb1vTTph22SSkaemzT0kbubxW40+a+Rrc2QXBrArw2qf06grj0huSo5lIKvv/56rVmzRrGxsfrDH/5gbp87d64sFot69+5d5pjSsH6x27ADAOqeG5o11A/P3KwxXyfq113HzO0ZOfm8mQ6QVFxsKPnY2XnSj322XjuPnNTxc97gKEmbfx/1drNITQN8tP94yYj3i4Pa6JrG9RXkZ9Uf/lnyJsaZj91kNxpdGsAD61vlzlywKuPQT7SoqCjFx8frww8/VJs2bXTLLbfos88+09atW2WxWHTXXXeVOaZ07ndV3ooeAFAzNapv1WeP3KRpcTv07rI9kqQB//xVT992rUb2bOHa5gAnMgxDhzPPmK9HfrJW21JP2o1qr957XFJJ0G7RyFd7fw/nb93XUe3CbGreyEdFxYY5ev3ATc3KTPGAazgUwEeNGqV3331XqampGjVqlN2+Hj166LbbbitzzPfffy+LxaJbbrnFkUsDAJyo9Bb1zuDuZtGovteaAfxkbqFe+3G7Zq7er9G3X+uUHgBX+WTlPiUdytaGlAylnzy70sja5AxJUj1PN+UWFEuS/n5HO3Vs2lCtghrI0NmgHdkuxG5UG9WPQwHcZrNpyZIlio6OtlvV5JZbbjGXITzXb7/9pnXr1slisah///6OXBoAUEdMuStc/1yyW4cyz+hvczeb2wuLil3YFeCYrDMFit97XGv3ZWjtvuPm9qlxO83n7m4WFf2+FMnfh7ZT1+YBatKwnjq8sliSdHeXqwjaNZTDk+ratGmj9evXa9++fUpLS1NoaKhatGhxwfpPP/1UktSzZ09HLw0AqAPuuKGJht5wlT753z69u2y3cvJKbtLRd9py3dOlqYZ0DHVxh8ClpZ/MtXtvQ8/XflZ5i3r0vT5IN7YIUOdmDXVtUH11+ccSSdLdna9i+kgtUmnvamnZsqW5xOCFdOzYUR07srQUAODyeHu56+nbrtWQjqG65Y1lkqRjp/L1/vI9en/5HrPu6Mk8NW/EGzbheufO3/7DP39V8vHTdvsNQ7o60FddW/irY9OGen5ekiTpneGdGNWuA/gpBQCoMRqdc0e7f95/g75LPKxlO9LNG4b0fnOZrmnsqx7XNFKnZv4XOAtQNeYmHNTGlEyt2XdCh84J4MnHT8tikVoHN9D2tJL1tFf8vz5qFuArqSRolwZw1A2VGsCPHDmiZcuWKSkpSSdOnJAkBQQEKDw8XH369GHpQQBApenfNlh33NBE+46d0m1Tl0uSLBZpz9Ec7Tmao1nxKWbt019u0HXBDXRNYH2FNaznqpZRSxQWFWvzwSytSz6h+HPmb5euiy3Zz99+d0Qn9bq2sTzdLeYbJavj7dHhPJUSwFNTUzV27Fh9++23Kiws/88l7u7uuueeezRt2jSFhjJfDwBQOYL9zgbq//3tNm0+lK34vce1avcx7ThySlLJDUjKuwlJ/+krFNjAqkBfL9l8PM3tn69Kls3bS+7n3Oh59Z7j8rV6yNPdosJz7tG9O/2UfK0ecrdYlF9UZG4/kZOvgiJD+YVnt6FmyjpdoDXnBO3uU37W6fyyX9cuzf3V4+pG6nZ1gK4PaaAbX10qSerTOoj527DjcAD/7bff1K9fP504cULGRW4RWlhYqK+//lpLlizR0qVL1b59e0cvDQCAnYY+XopsF6LIdiF2d+97IaqNDpw4rb3HcrQr/ZTSsnIlSYcyz9hNFSj1euyOMtse+3x9udcc8s7/yt1+8+u/lNnW8ZU41fN0Vz1Pd1k9zqb7Rz5dJ5u3p+rX81A9T3dz+7yNhxTcoJ58vM5uu9j/a+G4/MKzq+s8Py9Jmw5mas/RHLua0/lFalDPQ12bl8zffnvJLkllb2oDXIhDATwnJ0dRUVE6frzkt8J+/fopJiZG3bp1U0hIiKSSO1+uXbtW//nPfxQXF6djx44pKipK27dvl4+Pj+MfAQAAlzC8WzO7YFQazL98vJty8ot0/FSeUrNy9c+lJUEqqkOo8guLdSq30LzZSaug+io2DBUWGyooKtbhzJIQ39DHU8XFhooNqajY0JmCC494FxQZKigq1Mlc+3C2Zt+JcuvLmxd8w6TFCmpQT4ENrGrk62Vu/3bDITVv5KNQWz3ZvD3LHIey8s75Wr3y/VZtT83W1tRsc9u8jYfM580CfJRyouSNlPOe6qkOVzU0b9NeGsCBinIogL/zzjs6fPiw3Nzc9MEHH+ixxx4rU9OsWTM1a9ZM99xzjz755BPFxMTo0KFD+ve//62//vWvjlweAACH3NCsoV0wLw3gb97TwZwyUBrWvxvVq9wQv+rZvuVuT5oYIS8Pd53MLTCXkls67lZZZFFuQbGyzuTrgY/WmNfLLyoJ/Bmn8/X+8r2SpJuvDVR2boGOn8o3R+oLioxyR+5fmF/+m/ienLVBTQO81ficOcepWWfUPMBXHufOsanFis6ZMvTB8r3ac/SUtqed1L5zbuv+9boDZY77461X66aWAbqhaUN5e7mbX9vWIQ24TTsc4lAA/+6772SxWDRy5Mhyw/f5Hn30Ua1atUqffPKJ5s2bRwAHgBrMmXfHrInc3Czy8nCT9znTR0Jt3uVOUYjqEGq3vTSAf/hQlzK/CCwee6tO5hbq6Mk8Hco4rUk/bJMk3XxtI6WfLBnJP3eEffnOsnPfb5+2Qu5uFoX41VOI7ewc+jlrU9QswFchtnpq6FOzRtELiop1MOPsUn/T43Yq5cRp7TuWo+TjZ4N26S9Z53u0Vwt1bu6va4Pqa8Dbv0qS/tyvFVNKUCUcCuA7d5bcren++++v8DEPPPCAPvnkE/NYAABQcU0a2of40gD+4UNdze1HT+aabwB8ZUhbHTuVr/3HT2vBb4clSR5uJW8kPX8kvfRc53vgw3gF+9VT4wZWu2Aev/e4gv3q2c1nr0xFxYayzxSYr1fsPKqTuYU6dipfaVln++47bbnSs3N1zkC3/rNyX7nnHNQhVOFNbGod0kAtGvmYK+iMj2zNGyXhNA4F8FOnSt5dHhAQUOFj/P1L1mXNycm5RCUAALgSvtaz/3u/t2tTM1iWBvCNL/VXTl6RDmWWjBCP/2aTpJK7MB79fRT92Kk88xy/HcySlFXmOo9+VvaNqTe9ulQ+Xu7y8Sr7RlMvDze5Weynbjz62ToVF0u556wWc9vUZTqVW6ic81Ya+dOsDeV+vKVvqvXycDPfRPnATU11XXADXd24vkJtVkW8VTKq/cbv04skRrXhOg4F8MaNG+vw4cPatm2bOnfuXKFjtm0r+e06MDDQkUsDAIAr5O5mUYitZPpJm1A/M4CfexfGzNP5umHSYknSv+6/QVm/T3tJzTqjb9YflCRd09hX2b/PWy8sKhl+PpVXqFN5ZYPthd5oGr+37PYj2XnlVErXhzRQkF89Bdb3UkNvT33yv2RJ0lcx3XRNUH35eLorfGKcJOnFQW0J2qi2HArg3bt319y5czV9+nTdd9998vC4+OkKCgo0bdo0WSwWde/e3ZFLAwCAKuR1zuh1v7bBdmG2NIB//8zN8vHyUE5egdq9XBJ8F42+WcWGdKagSBk5+XpiZoIk6Y172svDze33fYV6cX7JTWvevKeDfK0eKjYMjfpyoyTpv3/qocD6VjWo5yF3N4v5i8C3T/W066M0gHds2pDpI6hRHArgDz30kObOnavExERFRUXp008/VVhYWLm1hw4d0qOPPqrExETzjZsAAKDms5wzraRFoG+5I8+DOoTZbS8N4KVvQD23tm2YH6PXqNUcCuCDBw/W0KFDNX/+fC1ZskRXX321+vfvr27duik4OFgWi0VpaWlas2aNFi9erIKCkjdS3HnnnYqK4p3zAAAAqHscvhPmV199pYceekjffPON8vPztWjRIi1atKhMXemdu+6991598cUXjl4WAAAAqJEcDuBWq1Vff/21HnroIb377rtavny5Tp8+bVfj4+Oj3r176+mnn9Yf/vAHRy8JAKjGWB8cwPku9HOhvO2XU3u556guHA7gpaKiohQVFaWioiLt3btXJ06UvKs5ICBAV199tdzd3S9xBgAAAFS1qgy41T34VhcOBfC+fftKkqKjo/XII49Iktzd3dWqVSvHOwMAAECFEIhrFocC+K+//qri4mK9+OKLldUPAAAAVDOnVqBiHArgQUFBSktLU8OGDSupHQAAgLqFUF33OBTAO3bsqLS0NO3cuVOdOnWqrJ4AAABqHYI2SrlduuTCHn/8cRmGoffff7+y+gEAAKjxSsN28mtR5k2FgFIO/Yu466679OCDD2rWrFl69NFHNWPGDPn6+lZWbwCAWoTRP9RG/LvGlXAogH/xxRe6/fbbtWnTJn3++ef67rvvNHjwYHXo0EH+/v6XXHrwoYcecuTyAAAATkHQRmVyKICPHDlSFovFfJ2RkaGZM2dW6FiLxUIABwAA1QpBG87g8KSk0lvMX+g1AABAdUTYhqs4FMD37dtXWX0AAABUCYI2qhuHAnjz5s0rqw8AQB1EMEJl4t8TagrWxQEAADUOYRs1GQEcAABUWwRt1EaXdSOeH3/8UZ07d1bnzp315ZdfXtaFZs+ebR67ZMmSyzoWAFC3cBOTuoevOeqSCgdwwzD0l7/8Rb/99psaNWqk4cOHX9aFhg8frkaNGikxMVHjxo277EYBAEDtQNhGXVfhf/U///yzdu7cKXd3d7399tuXfSGLxaJ//vOf6tixo5KSkrRs2TL16dPnss8DAACqlwtNE2H6CFC+CgfwuXPnSpL69++vdu3aXdHF2rZtq8jISP3444+aO3cuARwAcFkIdJXvcsMzXwPAcRUO4GvXrpXFYtHgwYMduuCgQYO0aNEixcfHO3QeAADqussJyQRnoPqocADfv3+/JKl169YOXfC6666TJCUnJzt0HgAApNoXLAnPQO1X4QCelZUlSQoICHDogqXHZ2dnO3QeAAAuxhWh9XLCM6EaqLsqHMD9/PyUkZGhzMxMhy5YenyDBg0cOg8AAFeiMqZtEJ4BOKLCyxAGBQVJkrZu3erQBbdt22Z3PgAAAKAuqXAAv+mmm2QYhhYsWODQBb/77jtZLBbdeOONDp0HAAAAqIkqHMAHDhwoSVq8eLFWrFhxRRdbsWKF4uLi7M4HAAAA1CUVDuB33323rr76ahmGoWHDhmnHjh2XdaGdO3dq2LBhslgsatGihe65557LbhYAAACo6SocwD08PDRt2jRZLBYdPXpUXbt21VtvvaVTp05d9LhTp07p7bffVteuXZWeni5JmjZtmjw8uPUsAAAA6h6LYRjG5RwwZcoUPf/887JYLJIkX19f3XLLLercubOCg4Pl6+urnJwcHTlyRBs2bNCvv/6qnJwclV5m0qRJeuGFFyr/I6nlsrOzZbPZlJWVJT8/P1e3AwAAgPNUNK9ddgCXpJkzZ+qpp55STk5OyUl+D+PlKT29j4+P3nnnHY0cOfJyLwcRwAEAAKq7iua1Ck9BOVd0dLR27typcePGqXHjxjIM44KPwMBAjR8/Xjt37iR8AwAAoM67ohHw823dulW//fabjh07ppMnT6pBgwYKDAxUx44d1bZt28ros85jBBwAAKB6q2heq5R3QrZt25agDQAAAFTAFU1BAQAAAHBlCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwohoZwFesWKHBgwcrLCxMFotF8+fPt9tvGIYmTpyosLAweXt7q0+fPtqyZYtdTV5enp555hkFBgbK19dXQ4YM0cGDB+1qMjIyFB0dLZvNJpvNpujoaGVmZtrVpKSkaPDgwfL19VVgYKBGjx6t/Px8u5rNmzerd+/e8vb2VpMmTTRp0iRVwv2PAAAAUAPVyACek5Ojjh076p133il3/xtvvKHp06frnXfe0bp16xQSEqL+/fvr5MmTZs2YMWM0b948zZkzRytXrtSpU6c0aNAgFRUVmTXDhw9XYmKiYmNjFRsbq8TEREVHR5v7i4qKFBUVpZycHK1cuVJz5szR3LlzNW7cOLMmOztb/fv3V1hYmNatW6cZM2Zo6tSpmj59ehV8ZgAAAFDtGTWcJGPevHnm6+LiYiMkJMR47bXXzG25ubmGzWYz3n//fcMwDCMzM9Pw9PQ05syZY9YcOnTIcHNzM2JjYw3DMIytW7cakoz4+HizZvXq1YYkY/v27YZhGMaiRYsMNzc349ChQ2bNV199ZVitViMrK8swDMN49913DZvNZuTm5po1U6ZMMcLCwozi4uIKf5xZWVmGJPO8AAAAqF4qmtdq5Aj4xezbt09paWmKiIgwt1mtVvXu3VurVq2SJCUkJKigoMCuJiwsTOHh4WbN6tWrZbPZ1K1bN7Ome/fustlsdjXh4eEKCwszayIjI5WXl6eEhASzpnfv3rJarXY1hw8fVnJy8gU/jry8PGVnZ9s9AAAAUPPVugCelpYmSQoODrbbHhwcbO5LS0uTl5eX/P39L1oTFBRU5vxBQUF2Nedfx9/fX15eXhetKX1dWlOeKVOmmHPPbTabmjZtevEPHAAAADVCrQvgpSwWi91rwzDKbDvf+TXl1VdGjfH7GzAv1s+ECROUlZVlPg4cOHDR3gEAAFAz1LoAHhISIqns6HJ6ero58hwSEqL8/HxlZGRctObIkSNlzn/06FG7mvOvk5GRoYKCgovWpKenSyo7Sn8uq9UqPz8/uwcAAABqvloXwFu2bKmQkBAtXrzY3Jafn6/ly5erZ8+ekqQuXbrI09PTriY1NVVJSUlmTY8ePZSVlaW1a9eaNWvWrFFWVpZdTVJSklJTU82auLg4Wa1WdenSxaxZsWKF3dKEcXFxCgsLU4sWLSr/EwAAAIBqrUYG8FOnTikxMVGJiYmSSt54mZiYqJSUFFksFo0ZM0aTJ0/WvHnzlJSUpJEjR8rHx0fDhw+XJNlsNj322GMaN26cli5dqo0bN+rBBx9U+/bt1a9fP0lSmzZtNGDAAMXExCg+Pl7x8fGKiYnRoEGD1Lp1a0lSRESE2rZtq+joaG3cuFFLly7V+PHjFRMTY45YDx8+XFarVSNHjlRSUpLmzZunyZMna+zYsZecEgMAAIBaqOoXZKl8v/zyiyGpzOPhhx82DKNkKcKXX37ZCAkJMaxWq3HrrbcamzdvtjvHmTNnjFGjRhkBAQGGt7e3MWjQICMlJcWu5vjx48aIESOMBg0aGA0aNDBGjBhhZGRk2NXs37/fiIqKMry9vY2AgABj1KhRdksOGoZhbNq0ybjlllsMq9VqhISEGBMnTrysJQgNg2UIAQAAqruK5jWLYXBLxpogOztbNptNWVlZzAcHAACohiqa12rkFBQAAACgpiKAAwAAAE5EAAcAAACciAAOAAAAOBEBHAAAAHAiAjgAAADgRARwAAAAwIkI4AAAAIATEcABAAAAJyKAAwAAAE5EAAcAAACciAAOAAAAOBEBHAAAAHAiAjgAAADgRARwAAAAwIkI4AAAAIATEcABAAAAJyKAAwAAAE5EAAcAAACciAAOAAAAOBEBHAAAAHAiAjgAAADgRARwAAAAwIkI4AAAAIATEcABAAAAJyKAAwAAAE5EAAcAAACciAAOAAAAOBEBHAAAAHAiAjgAAADgRARwAAAAwIkI4AAAAIATEcABAAAAJyKAAwAAAE5EAAcAAACciAAOAAAAOBEBHAAAAHAiAjgAAADgRARwAAAAwIkI4AAAAIATEcABAAAAJyKAAwAAAE5EAAcAAACciAAOAAAAOBEBHAAAAHAiAjgAAADgRARwAAAAwIkI4AAAAIATEcABAAAAJyKAAwAAAE5EAAcAAACciAAOAAAAOBEBHAAAAHAiAjgAAADgRARwAAAAwIkI4AAAAIATEcABAAAAJyKAAwAAAE5EAAcAAACciAAOAAAAOBEBHAAAAHAiAjgAAADgRARwAAAAwIkI4AAAAIATEcABAAAAJyKAAwAAAE5UawN4ixYtZLFYyjyefvppSdLIkSPL7OvevbvdOfLy8vTMM88oMDBQvr6+GjJkiA4ePGhXk5GRoejoaNlsNtlsNkVHRyszM9OuJiUlRYMHD5avr68CAwM1evRo5efnV+nHDwAAgOqp1gbwdevWKTU11XwsXrxYknTvvfeaNQMGDLCrWbRokd05xowZo3nz5mnOnDlauXKlTp06pUGDBqmoqMisGT58uBITExUbG6vY2FglJiYqOjra3F9UVKSoqCjl5ORo5cqVmjNnjubOnatx48ZV8WcAAAAA1ZHFMAzD1U04w5gxY/TDDz9o165dslgsGjlypDIzMzV//vxy67OystS4cWPNnDlT9913nyTp8OHDatq0qRYtWqTIyEht27ZNbdu2VXx8vLp16yZJio+PV48ePbR9+3a1bt1aP/74owYNGqQDBw4oLCxMkjRnzhyNHDlS6enp8vPzq1D/2dnZstlsysrKqvAxAAAAcJ6K5rVaOwJ+rvz8fM2aNUuPPvqoLBaLuX3ZsmUKCgrSddddp5iYGKWnp5v7EhISVFBQoIiICHNbWFiYwsPDtWrVKknS6tWrZbPZzPAtSd27d5fNZrOrCQ8PN8O3JEVGRiovL08JCQkX7DkvL0/Z2dl2DwAAANR8dSKAz58/X5mZmRo5cqS5beDAgZo9e7Z+/vlnTZs2TevWrVPfvn2Vl5cnSUpLS5OXl5f8/f3tzhUcHKy0tDSzJigoqMz1goKC7GqCg4Pt9vv7+8vLy8usKc+UKVPMeeU2m01Nmza9oo8dAAAA1YuHqxtwho8//lgDBw60G4UunVYiSeHh4eratauaN2+uhQsX6q677rrguQzDsBtFP/e5IzXnmzBhgsaOHWu+zs7OJoQDAADUArV+BHz//v1asmSJHn/88YvWhYaGqnnz5tq1a5ckKSQkRPn5+crIyLCrS09PN0e0Q0JCdOTIkTLnOnr0qF3N+SPdGRkZKigoKDMyfi6r1So/Pz+7BwAAAGq+Wh/AP/30UwUFBSkqKuqidcePH9eBAwcUGhoqSerSpYs8PT3N1VMkKTU1VUlJSerZs6ckqUePHsrKytLatWvNmjVr1igrK8uuJikpSampqWZNXFycrFarunTpUmkfJwAAAGqGWr0KSnFxsVq2bKkHHnhAr732mrn91KlTmjhxou6++26FhoYqOTlZzz33nFJSUrRt2zY1aNBAkvTkk0/qhx9+0GeffaaAgACNHz9ex48fV0JCgtzd3SWVzCU/fPiwPvjgA0nSE088oebNm+v777+XVLIM4Q033KDg4GC9+eabOnHihEaOHKmhQ4dqxowZFf5YWAUFAACgemMVFElLlixRSkqKHn30Ubvt7u7u2rx5s+644w5dd911evjhh3Xddddp9erVZviWpLfeektDhw7VsGHD1KtXL/n4+Oj77783w7ckzZ49W+3bt1dERIQiIiLUoUMHzZw50+5aCxcuVL169dSrVy8NGzZMQ4cO1dSpU6v+EwAAAIBqp1aPgNcmjIADAABUb4yAAwAAANUQARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwIgI4AAAA4EQEcAAAAMCJCOAAAACAExHAAQAAACcigAMAAABORAAHAAAAnIgADgAAADgRARwAAABwoloZwCdOnCiLxWL3CAkJMfcbhqGJEycqLCxM3t7e6tOnj7Zs2WJ3jry8PD3zzDMKDAyUr6+vhgwZooMHD9rVZGRkKDo6WjabTTabTdHR0crMzLSrSUlJ0eDBg+Xr66vAwECNHj1a+fn5VfaxAwAAoHqrlQFcktq1a6fU1FTzsXnzZnPfG2+8oenTp+udd97RunXrFBISov79++vkyZNmzZgxYzRv3jzNmTNHK1eu1KlTpzRo0CAVFRWZNcOHD1diYqJiY2MVGxurxMRERUdHm/uLiooUFRWlnJwcrVy5UnPmzNHcuXM1btw453wSAAAAUP0YtdDLL79sdOzYsdx9xcXFRkhIiPHaa6+Z23Jzcw2bzWa8//77hmEYRmZmpuHp6WnMmTPHrDl06JDh5uZmxMbGGoZhGFu3bjUkGfHx8WbN6tWrDUnG9u3bDcMwjEWLFhlubm7GoUOHzJqvvvrKsFqtRlZW1mV9TFlZWYakyz4OAAAAzlHRvObh2vhfdXbt2qWwsDBZrVZ169ZNkydP1tVXX619+/YpLS1NERERZq3ValXv3r21atUq/fGPf1RCQoIKCgrsasLCwhQeHq5Vq1YpMjJSq1evls1mU7du3cya7t27y2azadWqVWrdurVWr16t8PBwhYWFmTWRkZHKy8tTQkKCbrvttgv2n5eXp7y8PPN1VlaWJCk7O7tSPj8AAACoXKU5zTCMi9bVygDerVs3ffHFF7ruuut05MgR/eMf/1DPnj21ZcsWpaWlSZKCg4PtjgkODtb+/fslSWlpafLy8pK/v3+ZmtLj09LSFBQUVObaQUFBdjXnX8ff319eXl5mzYVMmTJFr7zySpntTZs2vehxAAAAcK2TJ0/KZrNdcH+tDOADBw40n7dv3149evTQNddco88//1zdu3eXJFksFrtjDMMos+1859eUV38lNeWZMGGCxo4da74uLi7WiRMn1KhRo0sei0vLzs5W06ZNdeDAAfn5+bm6HVQhvtZ1A1/nuoGvc91RU7/WhmHo5MmTdrMfylMrA/j5fH191b59e+3atUtDhw6VVDI6HRoaatakp6ebo9UhISHKz89XRkaG3Sh4enq6evbsadYcOXKkzLWOHj1qd541a9bY7c/IyFBBQUGZkfHzWa1WWa1Wu20NGzas2AeMCvPz86tR39i4cnyt6wa+znUDX+e6oyZ+rS828l2q1q6Ccq68vDxt27ZNoaGhatmypUJCQrR48WJzf35+vpYvX26G6y5dusjT09OuJjU1VUlJSWZNjx49lJWVpbVr15o1a9asUVZWll1NUlKSUlNTzZq4uDhZrVZ16dKlSj9mAAAAVE+1cgR8/PjxGjx4sJo1a6b09HT94x//UHZ2th5++GFZLBaNGTNGkydPVqtWrdSqVStNnjxZPj4+Gj58uKSS31wee+wxjRs3To0aNVJAQIDGjx+v9u3bq1+/fpKkNm3aaMCAAYqJidEHH3wgSXriiSc0aNAgtW7dWpIUERGhtm3bKjo6Wm+++aZOnDih8ePHKyYmpsb9NgcAAIDKUSsD+MGDB/XAAw/o2LFjaty4sbp37674+Hg1b95ckvT//t//05kzZ/TUU08pIyND3bp1U1xcnBo0aGCe46233pKHh4eGDRumM2fO6Pbbb9dnn30md3d3s2b27NkaPXq0uVrKkCFD9M4775j73d3dtXDhQj311FPq1auXvL29NXz4cE2dOtVJnwlciNVq1csvv1xmmg9qH77WdQNf57qBr3PdUdu/1hbjUuukAAAAAKg0dWIOOAAAAFBdEMABAAAAJyKAAwAAAE5EAAcAAACciACOOufVV19Vz5495ePjc8GbG6WkpGjw4MHy9fVVYGCgRo8erfz8fOc2ikrXokULWSwWu8ezzz7r6rbgoHfffVctW7ZUvXr11KVLF/3666+ubgmVbOLEiWW+d0NCQlzdFirBihUrNHjwYIWFhclisWj+/Pl2+w3D0MSJExUWFiZvb2/16dNHW7ZscU2zlYgAjjonPz9f9957r5588sly9xcVFSkqKko5OTlauXKl5syZo7lz52rcuHFO7hRVYdKkSUpNTTUfL7zwgqtbggO+/vprjRkzRs8//7w2btyoW265RQMHDlRKSoqrW0Mla9eund337ubNm13dEipBTk6OOnbsaLeM87neeOMNTZ8+Xe+8847WrVunkJAQ9e/fXydPnnRyp5XMAOqoTz/91LDZbGW2L1q0yHBzczMOHTpkbvvqq68Mq9VqZGVlObFDVLbmzZsbb731lqvbQCW66aabjD/96U92266//nrj2WefdVFHqAovv/yy0bFjR1e3gSomyZg3b575uri42AgJCTFee+01c1tubq5hs9mM999/3wUdVh5GwIHzrF69WuHh4QoLCzO3RUZGKi8vTwkJCS7sDJXh9ddfV6NGjXTDDTfo1VdfZWpRDZafn6+EhATzZmilIiIitGrVKhd1haqya9cuhYWFqWXLlrr//vu1d+9eV7eEKrZv3z6lpaXZfY9brVb17t27xn+P18o7YQKOSEtLU3BwsN02f39/eXl5KS0tzUVdoTL8+c9/VufOneXv76+1a9dqwoQJ2rdvn/7zn/+4ujVcgWPHjqmoqKjM92twcDDfq7VMt27d9MUXX+i6667TkSNH9I9//EM9e/bUli1b1KhRI1e3hypS+n1c3vf4/v37XdFSpWEEHLVCeW/QOf+xfv36Cp/PYrGU2WYYRrnb4VqX87X/y1/+ot69e6tDhw56/PHH9f777+vjjz/W8ePHXfxRwBHnf1/yvVr7DBw4UHfffbfat2+vfv36aeHChZKkzz//3MWdwRlq4/c4I+CoFUaNGqX777//ojUtWrSo0LlCQkK0Zs0au20ZGRkqKCgo81s4XM+Rr3337t0lSbt372YUrQYKDAyUu7t7mdHu9PR0vldrOV9fX7Vv3167du1ydSuoQqUr3aSlpSk0NNTcXhu+xwngqBUCAwMVGBhYKefq0aOHXn31VaWmpprf8HFxcbJarerSpUulXAOVx5Gv/caNGyXJ7gc7ag4vLy916dJFixcv1p133mluX7x4se644w4XdoaqlpeXp23btumWW25xdSuoQi1btlRISIgWL16sTp06SSp578fy5cv1+uuvu7g7xxDAUeekpKToxIkTSklJUVFRkRITEyVJ1157rerXr6+IiAi1bdtW0dHRevPNN3XixAmNHz9eMTEx8vPzc23zuGKrV69WfHy8brvtNtlsNq1bt05/+ctfNGTIEDVr1szV7eEKjR07VtHR0eratat69OihDz/8UCkpKfrTn/7k6tZQicaPH6/BgwerWbNmSk9P1z/+8Q9lZ2fr4YcfdnVrcNCpU6e0e/du8/W+ffuUmJiogIAANWvWTGPGjNHkyZPVqlUrtWrVSpMnT5aPj4+GDx/uwq4rgYtXYQGc7uGHHzYk/f/27j+mqvqP4/jrivyaAwtQwCSohhRpP4ACcsakH5LWbFRipcIfDpbiaml/tAxwbLo2bWuamtaEIJcyRjg3NGuQNisFFoq4DEuIEpAkAwZGl/P9g3F2Ee7lXqPL13w+NrYzzud8Pp/zF697eN/3GfFTWVlpjmlqajIWLVpk+Pr6GgEBAUZ2drbR19c3cZvGP1ZTU2PEx8cbU6dONXx8fIyoqCgjNzfX6Onpmeit4R96//33jfDwcMPLy8uIiYkxvvrqq4neEsZZWlqaERoaanh6ehozZswwUlNTjTNnzkz0tjAOKisrR/2bnJ6ebhjGYCvC3NxcIyQkxPD29jYeffRR4/Tp0xO76XFgMQzDmKjwDwAAANxs6IICAAAAuBEBHAAAAHAjAjgAAADgRgRwAAAAwI0I4AAAAIAbEcABAAAANyKAAwAAAG5EAAcAAADciAAOAAAAuBEBHAAAAHAjAjgAYISCggJZLBZZLBZduHBhorfjlP7+fkVFRclisWjfvn12xxmGIX9/f02aNEnBwcFasmSJmpqaxpx/1apVslgsSk9PH89tA7gJEcABAP8JW7du1blz53TPPffohRdesDvu/Pnz6urqkmEYam9vV0lJiRYuXDjm/G+++aa8vLxUVFSkkydPjufWAdxkCOAAgBted3e3Nm3aJEnKycnRpEn2/7yFhobq9OnTOnTokO644w5JUkNDg2pqahyuERYWpvT0dBmGofXr14/f5gHcdAjgAIAb3o4dO9TR0aGwsDAtWbLE4dgpU6Zo9uzZWrBggfLz883ff//992Ous3btWknS559/zlNwANeNAA4AuKFZrVZt27ZNkvTiiy86fPp9rUceecQ8rq+vH3N8VFSUYmJiJEnvvfeeizsFgEEEcADADe3IkSNqbm6WJC1btsylayMiIuTn5yfJuQAuSS+//LIkqbS0VFeuXHFpPQCQCOAAgOv0119/afv27Zo/f76mTZsmLy8vhYSEaOHChSouLtbAwMCYc3R0dOiNN97QrFmz5Ovrq+DgYD3xxBMqKyuT5Fw3lv3790uSIiMjNWfOHJfuwWKxKDIyUpLzAfy5556TJPX19am8vNyl9QBAIoADAK5DU1OTHnjgAa1evVpVVVXq6OhQf3+/2traVFFRoeXLlyspKUmXL1+2O0ddXZ2io6O1efNm/fjjj+rr61N7e7u++OILpaamKisry6m9VFZWSpISEhJcvo+amhqz9ru1tVW///77mNeEh4crNDRUklRVVeXymgBAAAcAuKS7u1vJyck6e/asJOnZZ5/VgQMHVF1drZKSEiUlJUmSvv76az399NOyWq0j5ujs7FRKSoouXbokabCso6KiQtXV1fr000+VmJioXbt2aefOnQ730tLSYj4Zf+ihh1y6D6vVqszMzGFP6s+cOePUtUNrHTt2zKU1AUAigAMAXLRhwwb99NNPkqT169errKxMzzzzjGJjY/X888+rsrLSrJP+5ptvtGvXrhFz5OXlqbW1VZK0efNmFRcXKyUlRbGxsUpLS9OxY8e0ePFifffddw73cvz4cfP4wQcfdOk+tm7dqtra2mG/c7YMJTY2VpLU2Nio9vZ2l9YFAAI4AMBpV69e1YcffihJio6OVl5e3ogxFotF27dvV2BgoCSZHUqG9PX1qbCwUJIUExOj119/fcQcHh4e+uCDD+Tj4+NwPy0tLebx9OnTnb6PlpYWvf3225Jc74Ry7Vq//vqr0+sCgEQABwC4oKamRn/88YckKSMjQx4eHqOO8/f3N/txNzQ06OLFi8PmGOoesmLFClksllHnCA4O1oIFCxzuZ6iERZJuvfVWp+9jzZo16u7ulp+fn/bt26dbbrlFkvMBPCAgYNQ9AIAzCOAAcIP6+++/zQ4h/+SnoKDA6TVtA2p8fLzDsbbnba+zPR4q5bAnLi7O4XnbL3k6G8APHDigzz77TJK0ceNGzZw50+ye4mwAt13LmS9uAoAtAjgAwGm2gTc4ONjh2JCQkFGv6+zsNI/HKhuZNm2aw/O2JSq9vb0Ox0pST0+P1qxZI2nwA8KqVaskyQzgnZ2d+u2338acx3YtX1/fMccDgK3JE70BAMD1mTx5stmJ5J8YaqnnKnulI0MMw7iueV1hG9AvX75svlTHnpycHDU3N8vT01O7d+8235pp2z+8vr5eM2bMcDiP7QeKsT4kAMC1COAAcAO7++673bqebe1za2urZs2aZXdsW1vbqNfZlm+0t7c7nGOs+mrb8NvZ2anw8HC7Y+vq6szXx69bt25Y6L7vvvvM4/r6ej355JMO17V9ik8AB+AqSlAAAE6bPXu2eTxWi8ATJ06Met29995rHldXVzucY6zztiH63LlzdscNDAwoMzNTVqtVd911l9kBZbT9OVMHPrTWlClTdOedd445HgBsEcABAE6LjY01O4YUFhaO+pIdSerq6jJfER8dHT2szCUuLk5Tp06VJBUVFdktVWlra9Phw4cd7icuLs6swT558qTdcTt27DA/EOzcuXNE3ba/v7/59NyZAD60VkJCgiZP5p/JAFxDAAcAOM3b21srV66UNPjWyA0bNowYYxiGsrOz1dHRIUnKzs4edt7Hx0crVqyQJNXW1urdd98dMcfAwICysrLU19fncD9eXl56+OGHJQ1/4m7r4sWLeuuttyQNtj18/PHHRx039DS9oaHBYf361atXderUKUnSvHnzHO4PAEZDAAcAuCQnJ8csu8jPz1dqaqoOHjyo2tpalZaWKjk5WR9//LEkKTExUZmZmSPmyMvLM7ukrFu3TsuWLdPhw4dVW1ur/fv3a968eSovLzfDtWT/S5+LFi2SNBjAu7q6Rpx/9dVXdeXKFQUFBWnLli1272uoDrynp0c///yz3XFHjx5Vf3//sLUBwBUEcACAS/z8/PTll1+aXwC99lX0VVVVkqS5c+fq4MGDo76sJyAgQIcOHTK/wPjJJ58MexX98ePHlZGRoaysLPMae2/FfOmll+Th4aG+vj6VlZUNO1dRUaGSkhJJ0pYtWxQUFGT3vq7thGLP3r17JUlRUVFj9ikHgNEQwAEALouIiFBdXZ22bdumpKQkBQYGytPTU8HBwUpJSVFRUZGOHj06rPvJte6//341NDRo7dq1ioyMlLe3t4KCgjR//nzt3btXe/bs0Z9//mmOH6obv9Ztt92mxYsXSxoM8kN6e3u1evVqSdJjjz1mlr3Y40wAtw35Qz3EAcBVFsMdjVoBALgOK1eu1EcffaSZM2fql19+sTvu22+/VWJiojw8PNTY2KiIiIh/ZT/FxcVavny5AgICdOHChTH7jgPAaHgCDgD4v9Tb26vy8nJJg91GHElISNBTTz0lq9WqTZs2/Sv7GRgY0MaNGyUN1q0TvgFcLwI4AGBCnD9/3m63EavVqldeecXspJKenj7mfO+88448PDy0Z88eNTc3j+teJamkpERnz55VWFiYXnvttXGfH8DNg+alAIAJkZ+frxMnTmjp0qWKj4/X9OnT1dvbq1OnTmn37t2qra2VNFi/7Uy3kTlz5qigoECNjY1qbm7W7bffPq77tVqtys3NVXJy8og+4gDgCmrAAQATIiMjQ4WFhQ7HzJ07V+Xl5QoMDHTTrgDg30cABwBMiB9++EGlpaU6cuSImpqadOnSJfX39yswMFBxcXFKS0vT0qVLNWkS1ZIA/lsI4AAAAIAb8VgBAAAAcCMCOAAAAOBGBHAAAADAjQjgAAAAgBsRwAEAAAA3IoADAAAAbkQABwAAANyIAA4AAAC4EQEcAAAAcCMCOAAAAOBG/wP11GJtDJqnqAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ridge_fig, ax = subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(lambdas),\n",
    "            -grid.cv_results_['mean_test_score'],\n",
    "            yerr=grid.cv_results_['std_test_score'] / np.sqrt(K))\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d93be681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.230e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.219e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.097e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.229e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.219e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.096e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.875e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.095e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.211e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.225e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.872e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.212e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.870e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.210e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.867e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.200e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.864e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.203e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.196e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.077e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.208e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.197e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.190e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.855e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.071e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.191e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.849e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.063e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.841e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.054e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.163e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.043e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.149e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.820e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.806e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.012e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.139e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.789e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.992e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.117e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.087e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.968e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.081e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.058e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.745e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.939e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.060e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.051e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.718e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.907e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.686e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.869e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.975e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.939e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.938e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.929e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.783e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.568e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.734e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.834e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.826e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.772e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.684e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.770e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.478e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.633e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.721e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.713e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.646e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.655e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.520e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.494e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.404e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.403e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.177e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.098e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.126e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.110e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+07, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+07, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.982e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.804e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.894e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.713e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.808e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.627e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.727e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.548e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.650e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.474e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.579e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.406e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.514e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.343e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.454e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.286e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.402e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+07, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.234e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.355e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+07, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.969e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.187e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.314e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.966e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.914e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.145e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.279e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.865e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.249e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.843e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.824e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.075e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.223e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.790e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.790e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.047e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.202e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.743e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+07, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.761e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.022e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.184e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.700e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.990e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.737e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.000e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.169e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.663e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.971e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.717e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.982e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.156e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.630e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.956e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.701e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.966e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.146e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.601e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.943e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.688e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.953e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.138e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.575e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.933e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.677e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.942e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.132e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.554e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.924e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.668e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.933e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.126e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.535e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.917e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.661e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.122e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.520e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.911e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.655e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.920e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.119e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.507e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.906e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.651e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.915e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.116e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.496e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.647e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.911e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.114e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.487e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.899e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.644e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.907e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.112e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.480e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.897e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.642e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.905e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.111e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.474e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.895e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.640e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.903e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.110e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.469e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.893e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.639e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.901e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.109e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.465e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.892e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.638e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.900e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.462e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.891e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.637e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.899e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.460e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.636e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.898e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.107e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.458e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.636e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.897e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.107e+06, tolerance: 3.759e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.456e+06, tolerance: 4.201e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.889e+06, tolerance: 4.466e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.635e+06, tolerance: 4.445e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.897e+06, tolerance: 4.437e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+07, tolerance: 5.332e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-4.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-4.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;ridge&#x27;,\n",
       "                                        ElasticNet(alpha=10000000000.0,\n",
       "                                                   l1_ratio=0))]),\n",
       "             param_grid={&#x27;ridge__alpha&#x27;: array([2.22093791e+05, 1.76005531e+05, 1.39481373e+05, 1.10536603e+05,\n",
       "       8.75983676e+04, 6.94202082e+04, 5.50143278e+04, 4.35979140e+04,\n",
       "       3.45506012e+04, 2.73807606...\n",
       "       4.67486141e-03, 3.70474772e-03, 2.93594921e-03, 2.32668954e-03,\n",
       "       1.84386167e-03, 1.46122884e-03, 1.15799887e-03, 9.17694298e-04,\n",
       "       7.27257037e-04, 5.76338765e-04, 4.56738615e-04, 3.61957541e-04,\n",
       "       2.86845161e-04, 2.27319885e-04, 1.80147121e-04, 1.42763513e-04,\n",
       "       1.13137642e-04, 8.96596467e-05, 7.10537367e-05, 5.63088712e-05,\n",
       "       4.46238174e-05, 3.53636122e-05, 2.80250579e-05, 2.22093791e-05])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">Pipeline(step...l1_ratio=0))])</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;ridge__alpha&#x27;: array([2.2209...22093791e-05])}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">KFold(n_split... shuffle=True)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___scaler__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>If False, try to avoid a copy and do inplace scaling instead.<br>This is not guaranteed to always work inplace; e.g. if the data is<br>not a NumPy array or scipy.sparse CSR matrix, a copy may still be<br>returned.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_mean',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_mean,-bool%2C%20default%3DTrue\">\n",
       "            with_mean\n",
       "            <span class=\"param-doc-description\">with_mean: bool, default=True<br><br>If True, center the data before scaling.<br>This does not work (and will raise an exception) when attempted on<br>sparse matrices, because centering them entails building a dense<br>matrix which in common use cases is likely to be too large to fit in<br>memory.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_std',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_std,-bool%2C%20default%3DTrue\">\n",
       "            with_std\n",
       "            <span class=\"param-doc-description\">with_std: bool, default=True<br><br>If True, scale the data to unit variance (or equivalently,<br>unit standard deviation).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ElasticNet</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___ridge__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=alpha,-float%2C%20default%3D1.0\">\n",
       "            alpha\n",
       "            <span class=\"param-doc-description\">alpha: float, default=1.0<br><br>Constant that multiplies the penalty terms. Defaults to 1.0.<br>See the notes for the exact mathematical meaning of this<br>parameter. ``alpha = 0`` is equivalent to an ordinary least square,<br>solved by the :class:`LinearRegression` object. For numerical<br>reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.<br>Given this, you should use the :class:`LinearRegression` object.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.01185247763144249</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=l1_ratio,-float%2C%20default%3D0.5\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.5<br><br>The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For<br>``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it<br>is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a<br>combination of L1 and L2.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Whether the intercept should be estimated or not. If ``False``, the<br>data is assumed to be already centered.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('precompute',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=precompute,-bool%20or%20array-like%20of%20shape%20%28n_features%2C%20n_features%29%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DFalse\">\n",
       "            precompute\n",
       "            <span class=\"param-doc-description\">precompute: bool or array-like of shape (n_features, n_features),                 default=False<br><br>Whether to use a precomputed Gram matrix to speed up<br>calculations. The Gram matrix can also be passed as argument.<br>For sparse input this option is always ``False`` to preserve sparsity.<br>Check :ref:`an example on how to use a precomputed Gram Matrix in ElasticNet<br><sphx_glr_auto_examples_linear_model_plot_elastic_net_precomputed_gram_matrix_with_weighted_samples.py>`<br>for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=max_iter,-int%2C%20default%3D1000\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=1000<br><br>The maximum number of iterations.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=copy_X,-bool%2C%20default%3DTrue\">\n",
       "            copy_X\n",
       "            <span class=\"param-doc-description\">copy_X: bool, default=True<br><br>If ``True``, X will be copied; else, it may be overwritten.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>The tolerance for the optimization: if the updates are smaller or equal to<br>``tol``, the optimization code checks the dual gap for optimality and continues<br>until it is smaller or equal to ``tol``, see Notes below.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>See :term:`the Glossary <warm_start>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=positive,-bool%2C%20default%3DFalse\">\n",
       "            positive\n",
       "            <span class=\"param-doc-description\">positive: bool, default=False<br><br>When set to ``True``, forces the coefficients to be positive.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>The seed of the pseudo random number generator that selects a random<br>feature to update. Used when ``selection`` == 'random'.<br>Pass an int for reproducible output across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('selection',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNet.html#:~:text=selection,-%7B%27cyclic%27%2C%20%27random%27%7D%2C%20default%3D%27cyclic%27\">\n",
       "            selection\n",
       "            <span class=\"param-doc-description\">selection: {'cyclic', 'random'}, default='cyclic'<br><br>If set to 'random', a random coefficient is updated every iteration<br>rather than looping over features sequentially by default. This<br>(setting to 'random') often leads to significantly faster convergence<br>especially when tol is higher than 1e-4.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;cyclic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-4');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('ridge',\n",
       "                                        ElasticNet(alpha=10000000000.0,\n",
       "                                                   l1_ratio=0))]),\n",
       "             param_grid={'ridge__alpha': array([2.22093791e+05, 1.76005531e+05, 1.39481373e+05, 1.10536603e+05,\n",
       "       8.75983676e+04, 6.94202082e+04, 5.50143278e+04, 4.35979140e+04,\n",
       "       3.45506012e+04, 2.73807606...\n",
       "       4.67486141e-03, 3.70474772e-03, 2.93594921e-03, 2.32668954e-03,\n",
       "       1.84386167e-03, 1.46122884e-03, 1.15799887e-03, 9.17694298e-04,\n",
       "       7.27257037e-04, 5.76338765e-04, 4.56738615e-04, 3.61957541e-04,\n",
       "       2.86845161e-04, 2.27319885e-04, 1.80147121e-04, 1.42763513e-04,\n",
       "       1.13137642e-04, 8.96596467e-05, 7.10537367e-05, 5.63088712e-05,\n",
       "       4.46238174e-05, 3.53636122e-05, 2.80250579e-05, 2.22093791e-05])})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_r2 = skm.GridSearchCV(pipe,\n",
    "                           param_grid,\n",
    "                           cv=kfold)\n",
    "grid_r2.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5adb3b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r2_fig, ax = subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(lambdas),\n",
    "            grid_r2.cv_results_['mean_test_score'],\n",
    "            yerr=grid_r2.cv_results_['std_test_score'] / np.sqrt(K)\n",
    "            )\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated $R^2$', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e96be72",
   "metadata": {},
   "source": [
    "Fast Cross-Validation for Solution Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a0418b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.875e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.874e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.872e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.870e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.868e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.865e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.861e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.857e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.851e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.844e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.835e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.824e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.811e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.795e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.776e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.753e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.726e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.696e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.661e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.622e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.491e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.445e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.399e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.314e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.276e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.241e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.210e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.049e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+07, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.998e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.908e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.822e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.740e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.662e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.590e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.524e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.464e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.410e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.363e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.321e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.285e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.254e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.228e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.205e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.187e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.171e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.159e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.148e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.140e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.133e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.127e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.123e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.119e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.116e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.114e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.112e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.111e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.110e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.109e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.107e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.107e+06, tolerance: 3.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.097e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.096e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.095e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.078e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.072e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.064e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.044e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.031e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.014e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.971e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.911e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.875e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.834e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.789e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.741e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.691e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.639e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.589e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.492e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.407e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.104e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.081e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.049e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.040e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e+07, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.989e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.924e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.864e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.810e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.761e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.716e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.677e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.643e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.612e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.586e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.563e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.543e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.526e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.512e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.501e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.491e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.483e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.476e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.471e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.467e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.463e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.461e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.458e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.457e+06, tolerance: 4.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.230e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.229e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.225e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.193e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.170e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.155e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.136e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.114e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.088e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.056e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.020e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.933e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.882e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.772e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.714e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.657e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.601e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.548e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.499e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.340e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.309e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.282e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.179e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.163e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.107e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.094e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+07, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.988e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.969e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.954e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.942e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.931e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.923e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.915e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.910e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.905e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.901e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.898e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.895e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.893e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.892e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.889e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.889e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.888e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.887e+06, tolerance: 4.466e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.219e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.212e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.206e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.196e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.190e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.171e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.144e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.125e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.103e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.076e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.045e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.009e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.967e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.921e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.871e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.817e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.761e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.647e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.592e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.489e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.401e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.363e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.298e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.246e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.026e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e+07, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.959e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.904e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.858e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.818e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.784e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.756e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.733e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.714e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.698e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.685e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.675e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.666e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.660e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.654e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.650e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.646e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.643e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.641e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.639e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.638e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.637e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.636e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.635e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.635e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.634e+06, tolerance: 4.445e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.212e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.211e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.200e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.189e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.147e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.085e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.020e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.980e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.934e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.883e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.826e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.766e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.576e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.514e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.399e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.348e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.301e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.221e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.107e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.023e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.000e+07, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.896e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.799e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.708e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.624e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.545e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.471e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.403e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.340e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.283e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.231e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.184e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.143e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.105e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.073e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.044e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.019e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.998e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.980e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.965e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.952e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.941e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.932e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.924e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.918e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.913e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.909e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.906e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.903e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.901e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.900e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.898e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.897e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.896e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.896e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.895e+06, tolerance: 4.437e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+07, tolerance: 5.332e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-5.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-5.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;ridge&#x27;,\n",
       "                 ElasticNetCV(alphas=array([2.22093791e+05, 1.76005531e+05, 1.39481373e+05, 1.10536603e+05,\n",
       "       8.75983676e+04, 6.94202082e+04, 5.50143278e+04, 4.35979140e+04,\n",
       "       3.45506012e+04, 2.73807606e+04, 2.16987845e+04, 1.71959156e+04,\n",
       "       1.36274691e+04, 1.07995362e+04, 8.55844774e+03, 6.78242347e+03,\n",
       "       5.37495461e+03, 4.25955961e+03,...\n",
       "       1.84386167e-03, 1.46122884e-03, 1.15799887e-03, 9.17694298e-04,\n",
       "       7.27257037e-04, 5.76338765e-04, 4.56738615e-04, 3.61957541e-04,\n",
       "       2.86845161e-04, 2.27319885e-04, 1.80147121e-04, 1.42763513e-04,\n",
       "       1.13137642e-04, 8.96596467e-05, 7.10537367e-05, 5.63088712e-05,\n",
       "       4.46238174e-05, 3.53636122e-05, 2.80250579e-05, 2.22093791e-05]),\n",
       "                              cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "                              l1_ratio=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=steps,-list%20of%20tuples\">\n",
       "            steps\n",
       "            <span class=\"param-doc-description\">steps: list of tuples<br><br>List of (name of step, estimator) tuples that are to be chained in<br>sequential order. To be compatible with the scikit-learn API, all steps<br>must define `fit`. All non-last steps must also define `transform`. See<br>:ref:`Combining Estimators <combining_estimators>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">[(&#x27;scaler&#x27;, ...), (&#x27;ridge&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=transform_input,-list%20of%20str%2C%20default%3DNone\">\n",
       "            transform_input\n",
       "            <span class=\"param-doc-description\">transform_input: list of str, default=None<br><br>The names of the :term:`metadata` parameters that should be transformed by the<br>pipeline before passing it to the step consuming it.<br><br>This enables transforming some input arguments to ``fit`` (other than ``X``)<br>to be transformed by the steps of the pipeline up to the step which requires<br>them. Requirement is defined via :ref:`metadata routing <metadata_routing>`.<br>For instance, this can be used to pass a validation set through the pipeline.<br><br>You can only set this if metadata routing is enabled, which you<br>can enable using ``sklearn.set_config(enable_metadata_routing=True)``.<br><br>.. versionadded:: 1.6</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=memory,-str%20or%20object%20with%20the%20joblib.Memory%20interface%2C%20default%3DNone\">\n",
       "            memory\n",
       "            <span class=\"param-doc-description\">memory: str or object with the joblib.Memory interface, default=None<br><br>Used to cache the fitted transformers of the pipeline. The last step<br>will never be cached, even if it is a transformer. By default, no<br>caching is performed. If a string is given, it is the path to the<br>caching directory. Enabling caching triggers a clone of the transformers<br>before fitting. Therefore, the transformer instance given to the<br>pipeline cannot be inspected directly. Use the attribute ``named_steps``<br>or ``steps`` to inspect estimators within the pipeline. Caching the<br>transformers is advantageous when fitting is time consuming. See<br>:ref:`sphx_glr_auto_examples_neighbors_plot_caching_nearest_neighbors.py`<br>for an example on how to enable caching.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>If True, the time elapsed while fitting each step will be printed as it<br>is completed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"scaler__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>If False, try to avoid a copy and do inplace scaling instead.<br>This is not guaranteed to always work inplace; e.g. if the data is<br>not a NumPy array or scipy.sparse CSR matrix, a copy may still be<br>returned.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_mean',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_mean,-bool%2C%20default%3DTrue\">\n",
       "            with_mean\n",
       "            <span class=\"param-doc-description\">with_mean: bool, default=True<br><br>If True, center the data before scaling.<br>This does not work (and will raise an exception) when attempted on<br>sparse matrices, because centering them entails building a dense<br>matrix which in common use cases is likely to be too large to fit in<br>memory.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_std',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_std,-bool%2C%20default%3DTrue\">\n",
       "            with_std\n",
       "            <span class=\"param-doc-description\">with_std: bool, default=True<br><br>If True, scale the data to unit variance (or equivalently,<br>unit standard deviation).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ElasticNetCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html\">?<span>Documentation for ElasticNetCV</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"ridge__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=l1_ratio,-float%20or%20list%20of%20float%2C%20default%3D0.5\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float or list of float, default=0.5<br><br>Float between 0 and 1 passed to ElasticNet (scaling between<br>l1 and l2 penalties). For ``l1_ratio = 0``<br>the penalty is an L2 penalty. For ``l1_ratio = 1`` it is an L1 penalty.<br>For ``0 < l1_ratio < 1``, the penalty is a combination of L1 and L2<br>This parameter can be a list, in which case the different<br>values are tested by cross-validation and the one giving the best<br>prediction score is used. Note that a good choice of list of<br>values for l1_ratio is often to put more values close to 1<br>(i.e. Lasso) and less close to 0 (i.e. Ridge), as in ``[.1, .5, .7,<br>.9, .95, .99, 1]``.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=eps,-float%2C%20default%3D1e-3\">\n",
       "            eps\n",
       "            <span class=\"param-doc-description\">eps: float, default=1e-3<br><br>Length of the path. ``eps=1e-3`` means that<br>``alpha_min / alpha_max = 1e-3``.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_alphas',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=n_alphas,-int%2C%20default%3D100\">\n",
       "            n_alphas\n",
       "            <span class=\"param-doc-description\">n_alphas: int, default=100<br><br>Number of alphas along the regularization path, used for each l1_ratio.<br><br>.. deprecated:: 1.7<br>    `n_alphas` was deprecated in 1.7 and will be removed in 1.9. Use `alphas`<br>    instead.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alphas',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=alphas,-int%2C%20default%3D100\">\n",
       "            alphas\n",
       "            <span class=\"param-doc-description\">alphas: array-like or int, default=None<br><br>Values of alphas to test along the regularization path, used for each l1_ratio.<br>If int, `alphas` values are generated automatically.<br>If array-like, list of alpha values to use.<br><br>.. versionchanged:: 1.7<br>    `alphas` accepts an integer value which removes the need to pass<br>    `n_alphas`.<br><br>.. deprecated:: 1.7<br>    `alphas=None` was deprecated in 1.7 and will be removed in 1.9, at which<br>    point the default value will be set to 100.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">array([2.2209...22093791e-05])</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Whether to calculate the intercept for this model. If set<br>to false, no intercept will be used in calculations<br>(i.e. data is expected to be centered).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('precompute',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=precompute,-%27auto%27%2C%20bool%20or%20array-like%20of%20shape%20%20%20%20%20%20%20%20%20%20%20%20%20%28n_features%2C%20n_features%29%2C%20default%3D%27auto%27\">\n",
       "            precompute\n",
       "            <span class=\"param-doc-description\">precompute: 'auto', bool or array-like of shape             (n_features, n_features), default='auto'<br><br>Whether to use a precomputed Gram matrix to speed up<br>calculations. If set to ``'auto'`` let us decide. The Gram<br>matrix can also be passed as argument.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=max_iter,-int%2C%20default%3D1000\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=1000<br><br>The maximum number of iterations.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>The tolerance for the optimization: if the updates are smaller or equal to<br>``tol``, the optimization code checks the dual gap for optimality and continues<br>until it is smaller or equal to ``tol``.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross-validation,<br>- int, to specify the number of folds.<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For int/None inputs, :class:`~sklearn.model_selection.KFold` is used.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">KFold(n_split... shuffle=True)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=copy_X,-bool%2C%20default%3DTrue\">\n",
       "            copy_X\n",
       "            <span class=\"param-doc-description\">copy_X: bool, default=True<br><br>If ``True``, X will be copied; else, it may be overwritten.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=verbose,-bool%20or%20int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool or int, default=0<br><br>Amount of verbosity.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of CPUs to use during the cross validation.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=positive,-bool%2C%20default%3DFalse\">\n",
       "            positive\n",
       "            <span class=\"param-doc-description\">positive: bool, default=False<br><br>When set to ``True``, forces the coefficients to be positive.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>The seed of the pseudo random number generator that selects a random<br>feature to update. Used when ``selection`` == 'random'.<br>Pass an int for reproducible output across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('selection',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.ElasticNetCV.html#:~:text=selection,-%7B%27cyclic%27%2C%20%27random%27%7D%2C%20default%3D%27cyclic%27\">\n",
       "            selection\n",
       "            <span class=\"param-doc-description\">selection: {'cyclic', 'random'}, default='cyclic'<br><br>If set to 'random', a random coefficient is updated every iteration<br>rather than looping over features sequentially by default. This<br>(setting to 'random') often leads to significantly faster convergence<br>especially when tol is higher than 1e-4.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;cyclic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-5');</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('ridge',\n",
       "                 ElasticNetCV(alphas=array([2.22093791e+05, 1.76005531e+05, 1.39481373e+05, 1.10536603e+05,\n",
       "       8.75983676e+04, 6.94202082e+04, 5.50143278e+04, 4.35979140e+04,\n",
       "       3.45506012e+04, 2.73807606e+04, 2.16987845e+04, 1.71959156e+04,\n",
       "       1.36274691e+04, 1.07995362e+04, 8.55844774e+03, 6.78242347e+03,\n",
       "       5.37495461e+03, 4.25955961e+03,...\n",
       "       1.84386167e-03, 1.46122884e-03, 1.15799887e-03, 9.17694298e-04,\n",
       "       7.27257037e-04, 5.76338765e-04, 4.56738615e-04, 3.61957541e-04,\n",
       "       2.86845161e-04, 2.27319885e-04, 1.80147121e-04, 1.42763513e-04,\n",
       "       1.13137642e-04, 8.96596467e-05, 7.10537367e-05, 5.63088712e-05,\n",
       "       4.46238174e-05, 3.53636122e-05, 2.80250579e-05, 2.22093791e-05]),\n",
       "                              cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "                              l1_ratio=0))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgeCV = skl.ElasticNetCV(alphas=lambdas,\n",
    "                           l1_ratio=0,\n",
    "                           cv=kfold)\n",
    "pipeCV = Pipeline(steps=[('scaler', scaler),\n",
    "                         ('ridge', ridgeCV)])\n",
    "pipeCV.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "939b1bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuned_ridge = pipeCV.named_steps['ridge']\n",
    "ridgeCV_fig, ax = subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(lambdas),\n",
    "            tuned_ridge.mse_path_.mean(1),\n",
    "            yerr=tuned_ridge.mse_path_.std(1) / np.sqrt(K))\n",
    "ax.axvline(-np.log(tuned_ridge.alpha_), c='k', ls='--')\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "217f0bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115526.70630987742"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(tuned_ridge.mse_path_.mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a12dab02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-222.80877051,  238.77246614,    3.21103754,   -2.93050845,\n",
       "          3.64888723,  108.90953869,  -50.81896152, -105.15731984,\n",
       "        122.00714801,   57.1859509 ,  210.35170348,  118.05683748,\n",
       "       -150.21959435,   30.36634231,  -61.62459095,   77.73832472,\n",
       "         40.07350744,  -25.02151514,  -13.68429544])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_ridge.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09223eb8",
   "metadata": {},
   "source": [
    "Evaluating Test Error of Cross-Validated Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf132e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_valid = skm.ShuffleSplit(n_splits=1,\n",
    "                               test_size=0.25,\n",
    "                               random_state=1)\n",
    "inner_cv = skm.KFold(n_splits=5,\n",
    "                     shuffle=True,\n",
    "                     random_state=2)\n",
    "ridgeCV = skl.ElasticNetCV(alphas=lambdas,\n",
    "                           l1_ratio=0,\n",
    "                           cv=inner_cv)\n",
    "pipeCV = Pipeline(steps=[('scaler', scaler),\n",
    "                         ('ridge', ridgeCV)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fae7e65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.596e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.595e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.594e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.592e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.590e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.587e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.579e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.574e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.568e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.550e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.507e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.487e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.464e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.407e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.339e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.302e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+07, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.885e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.687e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.507e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.341e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.189e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.046e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.912e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.783e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.659e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.536e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.415e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.295e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.176e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.059e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.944e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.833e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.726e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.625e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.530e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.442e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.361e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.287e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.221e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.161e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.107e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.059e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.016e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.979e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.945e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.916e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.891e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.869e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.849e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.833e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.819e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.807e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.798e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.790e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.783e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.777e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.773e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.769e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.767e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.764e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.762e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.761e+06, tolerance: 3.201e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.516e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.516e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.516e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.515e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.515e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.514e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.513e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.512e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.511e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.509e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.507e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.501e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.497e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.491e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.477e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.467e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.441e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.223e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.113e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+07, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.870e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.617e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.388e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.183e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.999e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.835e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.687e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.554e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.432e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.320e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.215e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.116e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.020e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.928e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.837e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.749e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.664e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.581e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.427e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.357e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.293e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.235e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.183e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.137e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.097e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.062e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.031e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.005e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.982e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.962e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.946e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.931e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.919e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.909e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.900e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.893e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.887e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.882e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.878e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.874e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.872e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.870e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.868e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.866e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.865e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.864e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.864e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.863e+06, tolerance: 3.035e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.596e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.595e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.594e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.593e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.591e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.588e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.585e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.577e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.571e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.564e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.555e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.544e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.515e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.495e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.473e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.267e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.103e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.066e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e+07, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.750e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.505e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.287e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.093e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.920e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.766e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.627e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.503e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.389e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.286e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.190e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.100e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.016e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.937e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.862e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.790e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.722e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.658e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.598e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.542e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.491e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.445e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.405e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.368e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.337e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.309e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.285e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.264e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.246e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.231e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.217e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.205e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.195e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.186e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.179e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.172e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.167e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.162e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.158e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.155e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.152e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.150e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.148e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.147e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.146e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.145e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.144e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.143e+06, tolerance: 3.200e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.375e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.375e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.375e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.373e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.372e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.369e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.367e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.365e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.358e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.340e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.320e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.307e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.173e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.075e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.042e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+07, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.778e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.486e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.217e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.972e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.751e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.553e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.377e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.219e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.079e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.953e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.839e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.735e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.639e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.550e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.465e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.384e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.306e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.232e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.160e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.090e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.024e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.962e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.903e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.848e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.798e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.752e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.712e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.645e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.618e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.595e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.575e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.559e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.545e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.534e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.525e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.517e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.511e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.505e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.501e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.498e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.495e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.492e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.491e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.489e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.488e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.487e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.486e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.486e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.485e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.485e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.484e+06, tolerance: 2.753e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.610e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.609e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.609e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.608e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.605e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.603e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.601e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.594e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.589e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.583e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.576e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.567e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.556e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.542e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.525e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.505e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.340e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.245e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+07, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.848e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.380e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.947e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.550e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.188e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.861e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.564e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.296e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.052e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.831e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.628e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.441e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.270e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.111e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.964e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.829e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.703e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.588e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.481e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.384e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.295e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.215e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.142e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.077e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.020e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.924e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.885e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.851e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.822e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.797e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.775e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.756e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.740e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.725e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.713e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.702e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.693e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.684e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.677e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.672e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.667e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.662e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.659e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.656e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.654e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.652e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.650e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.649e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.648e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.647e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:701: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.647e+06, tolerance: 3.225e+03\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 3.855e+03\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([132393.84003227])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = skm.cross_validate(pipeCV,\n",
    "                             X,\n",
    "                             Y,\n",
    "                             cv=outer_valid,\n",
    "                             scoring='neg_mean_squared_error')\n",
    "-results['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396090d7",
   "metadata": {},
   "source": [
    "The Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "540db925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Oladokun\\AppData\\Local\\anaconda3\\envs\\islp_clean\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1663: FutureWarning: 'n_alphas' was deprecated in 1.7 and will be removed in 1.9. 'alphas' now accepts an integer value which removes the need to pass 'n_alphas'. The default value of 'alphas' will change from None to 100 in 1.9. Pass an explicit value to 'alphas' and leave 'n_alphas' to its default value to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1472370031649866"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassoCV = skl.ElasticNetCV(n_alphas=100,\n",
    "                           l1_ratio=1,\n",
    "                           cv=kfold)\n",
    "pipeCV = Pipeline(steps=[('scaler', scaler),\n",
    "                         ('lasso', lassoCV)])\n",
    "pipeCV.fit(X, Y)\n",
    "tuned_lasso = pipeCV.named_steps['lasso']\n",
    "tuned_lasso.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea590f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas, soln_array = skl.Lasso.path(Xs,\n",
    "                                     Y,\n",
    "                                     l1_ratio=1,\n",
    "                                     n_alphas=100)[:2]\n",
    "soln_path = pd.DataFrame(soln_array.T,\n",
    "                         columns=D.columns,\n",
    "                         index=-np.log(lambdas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79733176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAK5CAYAAAB5bnIwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Xdc1dX/wPHXh703CggICi7UXGmOVNxajrJfppVSNjTTyJGZDbW08lu5SivTrKwss8xRrpxpbnHkyAHiAFHZ814un98fH7iKE7zAZbyfj8fncT/7nI9e4H3PPed9FFVVVYQQQgghhBBFZmHuCgghhBBCCFHRSBAthBBCCCFEMUkQLYQQQgghRDFJEC2EEEIIIUQxSRAthBBCCCFEMUkQLYQQQgghRDFJEC2EEEIIIUQxSRAthBBCCCFEMVmZuwJVSV5eHhcvXsTZ2RlFUcxdHSGEEEIIcQNVVUlLS8PPzw8Li9u3N0sQXYYuXrxIQECAuashhBBCCCHu4ty5c/j7+9/2uATRZcjZ2RnQ/lNcXFzMXBshhBBCCHGj1NRUAgICjHHb7UgQXYYKunC4uLhIEC2EEEIIUY7dreutDCwUQgghhBCimCSIFkIIIYQQopgkiBZCCCGEEKKYpE90OaKqKrm5uRgMBnNXRVQilpaWWFlZSVpFIYQQogRJEF1O6HQ64uLiyMzMNHdVRCXk4OCAr68vNjY25q6KEEIIUSlIEF0O5OXlER0djaWlJX5+ftjY2EiroSgRqqqi0+m4fPky0dHRhIaG3jFxvBBCCCGKRoLockCn05GXl0dAQAAODg7mro6oZOzt7bG2tubs2bPodDrs7OzMXSUhhBCiwpMmqXJEWghFaZH3lhBCCFGy5C+rEEIIIYQQxSRBtBBCCCGEEMUkQbQQQgghhBDFJEG0KBE7duzA0tKSHj16FNo/adIkmjRpctP5QUFBKIqCoijGrCRDhw4lKSmpWOV27NiRyMhIE2ouhBBCCFF8EkSLErFw4UJGjhzJ33//TWxsbJGumTJlCnFxccTGxvL999+zdetWRo0aVco1FUIIIYQwnQTR5ZSqqmTqcs2yqKparLpmZGTw888/M3z4cB5++GEWLVoEwKJFi5g8eTIHDx40tjoXHANwdnbGx8eHGjVqEB4ezuDBg9m/f7/x+NWrVxk4cCD+/v44ODjQqFEjfvzxR+PxiIgItmzZwqxZs4z3j4mJMeWfXQghhBCiSCRPdDmVpTfQ4O21Zin76JTuONgU/a3x008/UbduXerWrctTTz3FyJEjeeuttxgwYABHjhxhzZo1bNiwAQBXV9db3uPChQusWrWKVq1aGfdlZ2fTvHlzxo8fj4uLC6tXr+bpp5+mVq1atGrVilmzZvHff//RsGFDpkyZAoC3t7cJTy6EEEIIUTTSEi1MtmDBAp566ikAevToQXp6On/99Rf29vY4OTlhZWWFj48PPj4+2NvbG68bP348Tk5O2Nvb4+/vj6IofPLJJ8bjNWrUYOzYsTRp0oRatWoxcuRIunfvztKlSwEtILexscHBwcF4f0tLy7J9eCGEEEJUSdISXU7ZW1tydEp3s5VdVCdOnGD37t38+uuvAFhZWTFgwAAWLlxIly5d7njtuHHjiIiIQFVVzp07xxtvvMFDDz3E1q1bsbS0xGAw8MEHH/DTTz9x4cIFcnJyyMnJwdHR0aTnE0IIIYQwlQTR5ZSiKMXqUmEuCxYsIDc3lxo1ahj3qaqKtbX1XTNteHl5ERISAkBoaCgzZ86kdevWbNq0iS5duvDxxx8zY8YMZs6cSaNGjXB0dCQyMhKdTleqzySEEEIIcTflP0oT5VZubi7ffvstH3/8Md26dSt0rH///nz//ffY2NhgMBiKdL+CrhhZWVkAbNu2jb59+xq7iuTl5XHy5Enq169vvKY49xdCCCGEKCkSRIt7tmrVKpKSkhg6dOhNAwYfe+wxFixYwLhx44iOjiYqKgp/f3+cnZ2xtbUFIC0tjfj4eGN3jtdeew0vLy/atGkDQEhICMuWLWPHjh24u7vzySefEB8fXyiIDgoKYteuXcTExODk5ISHhwcWFtLVXwghhBClS6INcc8WLFhAly5dbplxo3///kRFRVG7dm169OhBeHg43t7ehVLUvf322/j6+uLn58fDDz+Mo6Mj69evx9PTE4C33nqLZs2a0b17dzp27IiPjw/9+vUrVM7YsWOxtLSkQYMGeHt7FzlHtRBCCCGEKRS1uEmBxT1LTU3F1dWVlJQUXFxcjPuzs7OJjo4mODgYOzs7M9ZQVFbyHhNCCCGK5nbx2o2kJVoIIYQQQohikj7RQgghhBCiXFBVlSy9gaRMPUkZOpIz9SRl6mgS4EaAh4O5q1eIBNFCCCGEEKJUGPJUkjN1XM3QcTVdx9WMHK6m60jM0JGUvz8p49p2UqYeXW7eTff532ONJYgWQgghhBAVl6qqpGTpSUjLISE1h4S0bC6n5XA5LYcr6TlcSdflv+aQmKEj7x5G31lbKrg52ODuYI2bgw2u9tYl/yAmkiBaCCGEEEIAkJNr4FJKDnEpWcSnZhOfkk18ajYJqTnEp2ZzKTWbhLScW7YW34mbgzWejjZ4Otni5WSDu4MNno42uDva4OGobbs72ODuqAXNjjaWKIpSSk9ZMiSIFkIIIYSoInS5eVxIziI2MZPYqxmcvZrJuaRMLiZnE5eSzZX0nCLfy9XemmrOtlRzscXbyRZvZ1u8nPIXZy1Y9nayxd3RBmvLypfLQoJoIYQQQohK7OSlNH6PusifR+KIvpJx1+4VNlYW+LnaUd3FDh9XO3xctHVt25ZqznZ4O9tiZ21ZNg9QTkkQLYQQQghRyZxLzGTloYusiLrI8fi0QsfsrC2o6eFIgIcDNT0dCPRwwM/NHl9XO3xd7fBwtCn3XSnKAwmiRalbtGgRkZGRJCcnm7sqQgghRKV25EIKH645zraTV4z7rC0V2od606eJH61reeLtbCtBcgmQIFqYJCIiguTkZJYvX15o/+bNmwkPDycpKYkBAwbQq1cv47FJkyaxfPlyoqKiyrayQgghRCV1LjGTj9ad4PeoiwAoCjwQ7EmfJn70bOiDm4ONmWtY+UgQLUqdvb099vb25q6GEEIIUekkZej4dNMpvvvnLDqDljGjXxM/RnetS6Bn+cqrXNlUvqGSotxZtGgRbm5uxvXJkydz8OBBFEVBURQWLVoEaC3UgYGB2Nra4ufnx6hRo8xXaSGEEKIc0+XmMX/rGdr/bxML/o5GZ8ijXYgXq0a2Y+YTTSWALgPSEl1eqSroM81TtrWD9j1QKRgwYABHjhxhzZo1bNiwAQBXV1d++eUXZsyYwZIlSwgLCyM+Pp6DBw+WSh2EEEKIimzziQSmrDrKmcsZANT3dWFCz3q0r+Nt5ppVLRJEl1f6TJjmZ56y37gINo5FPn3VqlU4OTkV2mcwGG55rr29PU5OTlhZWeHj42PcHxsbi4+PD126dMHa2prAwEBatmx5b/UXQgghKqGYKxm8t/ooG44lAODlZMNr3evxWHN/LCxkoGBZkyBamCw8PJx58+YV2rdr1y6eeuqpIt/j//7v/5g5cya1atWiR48e9OrVi969e2NlJW9RIYQQVVumLpc5G0+xYJvWbcPKQiGiTRCjuoTiYlf+psOuKiRCKa+sHbQWYXOVXQyOjo6EhIQU2nf+/Pli3SMgIIATJ06wfv16NmzYwEsvvcT//vc/tmzZgrW1/IIQQghRNW04eol3VvzLheQsANrX8ebthxsQUs3pLleK0iZBdHmlKMXqUlGR2NjY3LK7h729PX369KFPnz6MGDGCevXqcfjwYZo1a2aGWgohhBDmczE5i8kr/2Xtv5cAqOFmz6Q+YXSpX01yPJcTEkSLMhcUFER0dDRRUVH4+/vj7OzMjz/+iMFgoFWrVjg4OPDdd99hb29PzZo1zV1dIYQQoszkGvJYtCOGGev/I0NnwMpC4bkHazGqcwgONhK2lSfyvyHKXP/+/fn1118JDw8nOTmZr7/+Gjc3Nz744ANGjx6NwWCgUaNGrFy5Ek9PT3NXVwghhCgT+84m8dbyIxyNSwWgeU13pj7SkHo+LmaumbgVRVVV1dyVqCpSU1NxdXUlJSUFF5drPxDZ2dlER0cTHByMnZ2dGWsoKit5jwkhRPl1NT2HD9cc5+e92ngiV3trJvSsx+MtAiTrhhncLl67kbRECyGEEEKYgSFPZcmeWKavOUFKlh6Ax1v4M75HPTydbM1cO3E3EkQLIYQQQpSx4/GpvPbLIQ6dTwG0CVPe6xdG85oeZq6ZKCoJooUQQgghytC6f+OJ/CmKTJ0BZ1srRnerw9MP1MTK0sLcVRPFIEG0EEIIIUQZUFWVL7ae4cM1x1FVeDDUi48fv49qzjJWpSKSIFoIIYQQopTpcvOY+Nthlu7TBg8+/UBN3undQFqfKzAJooUQQgghSlFiho5hi/exOzoRCwXe6R3GkDZB5q6WMJEE0UIIIYQQpeTM5XQivt5DbGImzrZWzBnUlI51q5m7WqIESBAthBBCCFEKos4l8+yiPSRm6AjwsGfhkPsJre5s7mqJEiJBtBBCCCFECdvy32WGL95Hps5AY39XFkbcj5fkfq5UJIgWQgghhChByw9cYOzSg+TmqTwY6sW8p5rjZCshV2UjQ0KFSSIiIujXr99N+zdv3oyiKCQnJ9/zvTt27IiiKCiKgo2NDbVr12bChAnk5OTce4WFEEKIUvTVtjNE/hRFbp5Kn/v8WDDkfgmgKyn5XxXl2vPPP8+UKVPQ6XTs2bOHZ555BoD333/fzDUTQgghrlFVlQ/WHOeLLWcAeLZtMG8+VB8LC8XMNROlRVqiRalbtGgRbm5urFq1irp16+Lg4MBjjz1GRkYG33zzDUFBQbi7uzNy5EgMBkOhax0cHPDx8SEwMJD+/fvTtWtX1q1bZzweFBTEzJkzC13TpEkTJk2aZNxWFIWvvvqKRx55BAcHB0JDQ1mxYkVpPrIQQogqJC9P5e3f/zUG0ON71OOthyWAruykJbqcUlWVrNwss5Rtb2WPopTsD35mZiazZ89myZIlpKWl8eijj/Loo4/i5ubGH3/8wZkzZ+jfvz/t2rVjwIABt7zHwYMH2b59O0FBQcUuf/LkyUyfPp3//e9/zJkzhyeffJKzZ8/i4eFh4pMJIYSoygx5KhN/O8ySPedQFHj/kUY80TLQ3NUSZUCC6HIqKzeLVj+0MkvZuwbtwsHaocjnr1q1Cicnp0L7bmxR1uv1zJs3j9q1awPw2GOP8d1333Hp0iWcnJxo0KAB4eHhbNq0qVAQPXfuXL766iv0ej06nQ4LCws+++yzYj9TREQEAwcOBGDatGnMmTOH3bt306NHj2LfSwghhADINeTx2i+H+PXABSwU+Oj/7uPRZv7mrpYoIxJEC5OFh4czb968Qvt27drFU089Zdx2cHAwBtAA1atXJygoqFDwXb16dRISEgrd58knn2TixImkpqby4Ycf4uLiQv/+/Ytdx8aNGxvXHR0dcXZ2vqksIYQQoqj0hjxe/SmKVYfisLRQmPVEEx5u7GfuaokyJEF0OWVvZc+uQbvMVnZxODo6EhISUmjf+fPnC21bW1sX2lYU5Zb78vLyCu1zdXU13nvx4sWEhYWxYMEChg4dCoCFhQWqqha6Rq/X31THopQlhBBCFEVOroGRPxxg3dFLWFsqfDqoGd3DfMxdLVHGJIgupxRFKVaXiqrA2tqaN954gwkTJjBw4EAcHBzw9vYmLi7OeE5qairR0dFmrKUQQojKTJebx4jv97PhWAI2VhZ8/lQzOtWrbu5qCTOQ7ByiQhk0aBCKojB37lwAOnXqxHfffce2bds4cuQIQ4YMwdLS0sy1FEIIURnpDXmM+vEAG44lYGtlwYIhLSSArsKqXBD9/vvvoygKkZGRxn2qqjJp0iT8/Pywt7enY8eO/Pvvv4Wuy8nJYeTIkXh5eeHo6EifPn1u6rIgSp+NjQ0vv/wy06dPJz09nQkTJtC+fXsefvhhevXqRb9+/Qr1vRZCCCFKgiFPZfTPB1nzbzw2lhZ8ObgFD4Z6m7tawowU9cYOpZXYnj17ePzxx3FxcSE8PNyYX/jDDz9k6tSpLFq0iDp16vDee++xdetWTpw4gbOzMwDDhw9n5cqVLFq0CE9PT8aMGUNiYiL79u0rcstnamoqrq6upKSk4OLiYtyfnZ1NdHQ0wcHB2NnZlfhzCyHvMSGEuHd5eSrjfjnEsv3nsbJQ+OLp5nSuLy3QldXt4rUbVZmW6PT0dJ588knmz5+Pu7u7cb+qqsycOZOJEyfy6KOP0rBhQ7755hsyMzP54YcfAEhJSWHBggV8/PHHdOnShaZNm7J48WIOHz7Mhg0bzPVIQgghhChlqqoycflhlu0/j6WFwqeDmkoALYAqFESPGDGChx56iC5duhTaHx0dTXx8PN26dTPus7W1pUOHDuzYsQOAffv2odfrC53j5+dHw4YNjefcSk5ODqmpqYUWIYQQQlQMqqoyacW//Lj7HBYKzBjQhB4Nfc1dLVFOVInsHEuWLGH//v3s2bPnpmPx8fGAlqP4etWrV+fs2bPGc2xsbAq1YBecU3D9rbz//vtMnjzZ1OoLIYQQwgw+WneCb/45i6LA9Mfuo899kgdaXFPpW6LPnTvHK6+8wuLFi+/YF/TGaa5VVb3r1Nd3O2fChAmkpKQYl3PnzhWv8kIIIYQwi6+3R/PZptMAvNevIY81l5kIRWGVPojet28fCQkJNG/eHCsrK6ysrNiyZQuzZ8/GysrK2AJ9Y4tyQkKC8ZiPjw86nY6kpKTbnnMrtra2uLi4FFqEEEIIUb6tOHiRKauOAjC2Wx2ebFXTzDUS5VGlD6I7d+7M4cOHiYqKMi4tWrTgySefJCoqilq1auHj48P69euN1+h0OrZs2UKbNm0AaN68OdbW1oXOiYuL48iRI8ZzhBBCCFHx/X3yCmN+jkJVYUjrmowID7n7RaJKqvR9op2dnWnYsGGhfY6Ojnh6ehr3R0ZGMm3aNEJDQwkNDWXatGk4ODgwaNAgQJt6eujQoYwZMwZPT088PDwYO3YsjRo1ummgohBCCCEqpsPnU3jxu73oDSoPNfbl7d5hd+3aKaquSh9EF8Vrr71GVlYWL730EklJSbRq1Yp169YZc0QDzJgxAysrKx5//HGysrLo3LkzixYtktnxhBBCiEog+koGEV/vJkNnoE1tTz55/D4sLSSAFrdXpSZbMTeZbEWYi7zHhBDi9q6k5/Do3B3EJmYS5ufCkhcewNnO2tzVEmYik60IIYQQQtxFtt7Ai9/tIzYxk0APBxY901ICaFEkEkQLk0RERKAoCoqiYGVlRWBgIMOHD78pk4kQQghR3qiqyuvLDrHvbBIudlYsjLgfb2dbc1dLVBASRAuT9ejRg7i4OGJiYvjqq69YuXIlL730krmrJYQQQtzRpxtPsTzqIpYWCvOeak5INSdzV0lUIBJEC5PZ2tri4+ODv78/3bp1Y8CAAaxbtw6Ajh07EhkZWej8fv36ERERYdwOCgpi2rRpPPvsszg7OxMYGMiXX35pPK7T6Xj55Zfx9fXFzs6OoKAg3n///bJ4NCGEEJXUqkMX+Xj9fwC827chbUO8zFwjUdFIdo5ySlVV1Kwss5St2Nvfc0qfM2fOsGbNGqyti9ef7OOPP+bdd9/ljTfe4JdffmH48OG0b9+eevXqMXv2bFasWMHPP/9MYGAg586dk9kfhRBC3LMDsUmM+fkgAM+1C2ZQq0Az10hURBJEl1NqVhYnmjU3S9l19+9DcXAo8vmrVq3CyckJg8FAdnY2AJ988kmxyuzVq5exC8j48eOZMWMGmzdvpl69esTGxhIaGkq7du1QFIWaNWXmKCGEEPfmQnIWz3+7j5zcPDrXq8aEXvXNXSVRQUl3DmGy8PBwoqKi2LVrFyNHjqR79+6MHDmyWPdo3LixcV1RFHx8fEhISAC0wYtRUVHUrVuXUaNGGbuKCCGEEMWRpTPw3Dd7uZKeQz0fZ2YNbCq5oMU9k5bockqxt6fu/n1mK7s4HB0dCQnRpkWdPXs24eHhTJ48mXfffRcLCwtuTEWu1+tvuseN3T8URSEvLw+AZs2aER0dzZ9//smGDRt4/PHH6dKlC7/88kux6imEEKLqUlWVN347zLG4VLycbFgQcT9OthIGiXsn755ySlGUYnWpKE/eeecdevbsyfDhw/H29iYuLs54zGAwcOTIEcLDw4t1TxcXFwYMGMCAAQN47LHH6NGjB4mJiXh4eJR09YUQQlRC3/5zlt8OXMDSQuHTQc2o4Va8BiMhbiRBtChxHTt2JCwsjGnTptGpUydGjx7N6tWrqV27NjNmzCA5OblY95sxYwa+vr40adIECwsLli5dio+PD25ubqVSfyGEEJXLnphE3l11FIAJPevxQC1PM9dIVAYSRItSMXr0aJ555hlOnTrFwYMHGTx4MFZWVrz66qvFboV2cnLiww8/5OTJk1haWnL//ffzxx9/YGEhXfqFEELcWUJqNi99v5/cPJXe9/kxtF2wuaskKglFvbHDqig1t5uLPTs7m+joaIKDg7GzszNjDUVlJe8xIURVpMvNY9D8new9m0Td6s78NqINDjbSfiju7Hbx2o2kKU8IIYQQldLU1UfZezYJZzsrvni6uQTQokRJEC2EEEKISmf5gQt8889ZAGYOaEKQl6OZayQqGwmihRBCCFGpnLmczhu/HQZgVOdQOtevbuYaicpIgmghhBBCVBo5uQZG/niATJ2BB2p58ErnUHNXSVRSEkQLIYQQotL44M/j/HsxFQ9HG2Y9ITMSitIjQbQQQgghKoX1Ry/x9fYYAD76v8ZUd5FsRKL0SBAthBBCiArvYnIW4345CMBz7YLpVE/6QYvSJUG0EEIIISq0XEMekUuiSM7U06iGK6/1qGfuKokqQIJoIYQQQlRoszeeYndMIk62VswZ2BQbKwlvROmTd5kQQgghKqw9MYnM2XgSgKmPNJR80KLMSBAtTBIREYGiKCiKgpWVFYGBgQwfPpykpCTjOUFBQcZzLC0t8fPzY+jQoYXO2bx5M4qikJycbIanEEIIURGl5+Qy+ucoVBUea+5P3yY1zF0lUYVIEC1M1qNHD+Li4oiJieGrr75i5cqVvPTSS4XOmTJlCnFxccTGxvL999+zdetWRo0aZaYaCyGEqAymrj7GucQsarjZ807vBuaujqhiZBJ5YTJbW1t8fHwA8Pf3Z8CAASxatKjQOc7OzsZzatSoweDBg1myZElZV1UIIUQlselEAj/ujgXgo/+7D2c7azPXSFQ1EkSXU6qqkqvLM0vZVjYWKMq9Jac/c+YMa9aswdr69r/MLly4wKpVq2jVqtW9VlEIIUQVlpypY/wvhwB4tm0wrWt7mrlGoiqSILqcytXl8eUrW8xS9guzOmBta1nk81etWoWTkxMGg4Hs7GwAPvnkk0LnjB8/njfffNN4TqtWrW46RwghhCiKt37/l4S0HGp7O/Jaj7rmro6ooqRPtDBZeHg4UVFR7Nq1i5EjR9K9e3dGjhxZ6Jxx48YRFRXFoUOH+OuvvwB46KGHMBgM5qiyEEKICmrlwYusPHgRSwuFGQOaYGdd9EYfIUqStESXU1Y2Frwwq4PZyi4OR0dHQkJCAJg9ezbh4eFMnjyZd99913iOl5eX8ZzQ0FBmzpxJ69at2bRpE126dCm5ygshhKi0ElKzeev3IwCMCA+hsb+beSskqjQJosspRVGK1aWiPHnnnXfo2bMnw4cPx8/P75bnWFpqz5aVlVWWVRNCCFFBqarK678eJjlTT8MaLozsFGLuKokqTrpziBLXsWNHwsLCmDZtmnFfWloa8fHxxMXFsXv3bsaNG4eXlxdt2rQxY02FEEJUFCsOXmTj8QRsLC2Y8XgTrC0lhBHmJe9AUSpGjx7N/PnzOXfuHABvv/02vr6++Pn58fDDD+Po6Mj69evx9JQR1UIIIe4sMUPH5JVHARjVOYTQ6s5mrpEQoKiqqpq7ElVFamoqrq6upKSk4OLiYtyfnZ1NdHQ0wcHB2NnZmbGGorKS95gQoiIb/XMUv+6/QD0fZ1a83A4bK2kDFKXndvHajeRdKIQQQohya+t/l/l1/wUUBd5/tJEE0KLckHeiEEIIIcqlTF0uE5cfBiCiTRBNA93NXCMhrpEgWgghhBDl0oz1/3EuMYsabvaM7SaTqojyRYJoIYQQQpQ7h84ns+DvaADee6QhjraSlVeULxJECyGEEKJc0RvyGL/sMHkq9LnPj/C61cxdJSFuIkG0EEIIIcqVBX9HcywuFTcHa97u3cDc1RHiliSIFkIIIUS5EZeSxawNJwGY2Ks+Xk62Zq6RELcmQbQQQgghyo33Vh8jS2+gRU13Hmvub+7qCHFb0ktfCCGEEOXCjlNXWH0oDgsFpvRtiKIo5q6SMCdVhdxs0GeBtb22lCMSRItyZfPmzYSHh5OUlISbmxuLFi0iMjKS5ORkc1dNCCFEKdIb8nhnxb8APP1ATRr43X6mOFFOqCroMvKXdO1Vn5m/npm/naGt67NuWL/xNQtys66t67O0AJr8ibX7fQ5NBpr1cW8kQbS4Z59//jnjxo0jKSkJKyvtrZSeno67uzsPPPAA27ZtM567bds22rdvz4kTJ6hTp465qiyEEKKc+mZHDCcT0vF0tGF0V8kJXary8iAnFbKTISsJspIhJ+2GJVV71aVDTnr+a/6x64PmgiC3tOkzy6acYpAgWtyz8PBw0tPT2bt3Lw888ACgBcs+Pj7s2bOHzMxMHBwcAK2F2c/PTwJoIYQQN0lIzWZm/mDC8T3q4epgbeYaVQIGPVw9DZePQUL+cvkEZCRAdgqoeSVYmAI2jtcW64J1B7B2yN9XsO5wbd3a/rrX6xYre7C2045Z2Wn7LMvfe0KCaHHP6tati5+fH5s3bzYG0Zs3b6Zv375s2rSJHTt20KVLF+P+8PBwFi9ezMyZMzlx4gSOjo506tSJmTNnUq1a0XKAXr16lZ49e+Lj48PPP/9MVlYWL7/8MuvWrSM9PR1/f3/eeOMNnnnmmVJ7biGEECXr/T+Pk56TS5MANxlMeK9y0iF2J8RshehtEH8Y8vR3vsbKHuzdwM4N7FzA1jl/uX7dGWycwNYJbJzzX52uvRYEyFWw/7oE0eWUqqrk5uSYpWwrW9siD+bo2LEjmzZt4vXXXwdg06ZNvPbaa+Tl5bFp0ya6dOmCTqfjn3/+Yc6cOeh0Ot59913q1q1LQkICr776KhEREfzxxx93Lev8+fN069aNFi1asHDhQqysrBg7dixHjx7lzz//xMvLi1OnTpGVlWXS8wshhCg7u6MT+e3ABRQFpvQNw8Ki6gVj9yRXB+f3wJlNEL0VLuyDvNzC59g4gXc9qFYPqjXQ1l1qXAucre3MUfNKQ4Locio3J4fZQx4zS9mjvvkFa7ui/WB17NiRV199ldzcXLKysjhw4ADt27fHYDAwe/ZsAHbu3ElWVhbh4eHUqlXLeG2tWrWYPXs2LVu2JD09HScnp9uW899//9G1a1f69u3LrFmzjEF+bGwsTZs2pUWLFgAEBQXd41MLIYQoa7mGPN7+/QgAT9wfSGN/N/NWqDxTVa17xumN2hKzTeuXfD3XQAhuD8EPQuAD4FazSrYQlxUJooVJwsPDycjIYM+ePSQlJVGnTh2qVatGhw4dePrpp8nIyGDz5s0EBgZSq1YtDhw4wKRJk4iKiiIxMZG8PK1PVmxsLA0a3HpWqqysLNq1a8fAgQOZNWtWoWPDhw+nf//+7N+/n27dutGvXz/atGlT6s8thBDCdD/uOcfx+DTcHKx5rbsMJryJPkvrmnFyLZxcB8mxhY87eEGtjlCrgxY8uweZo5ZVlgTR5ZSVrS2jvvnFbGUXVUhICP7+/mzatImkpCQ6dOgAgI+PD8HBwWzfvp1NmzbRqVMnMjIy6NatG926dWPx4sV4e3sTGxtL9+7d0el0ty3D1taWLl26sHr1asaNG4e//7X+cj179uTs2bOsXr2aDRs20LlzZ0aMGMFHH3107/8AQgghSl1atp6Z6/8D4NUudXB3tDFzjcqJlPPwX37QfGaLlvatgIW11sIc0hlqd4LqjcBC5s0zFwmiyylFUYrcpcLcwsPD2bx5M0lJSYwbN864v0OHDqxdu5adO3fyzDPPcPz4ca5cucIHH3xAQEAAAHv37r3r/S0sLPjuu+8YNGgQnTp1Mmb6KODt7U1ERAQRERE8+OCDjBs3ToJoIYQo5z7fcpqrGTpqeTkyqFWguatjPqoKl47A8T/gxGqIO1j4uEsNCO0Gdbprrc02juapp7iJBNHCZOHh4YwYMQK9Xm9siQYtiB4+fDjZ2dmEh4djZ2eHjY0Nc+bMYdiwYRw5coR33323SGVYWlry/fffM3DgQGMg7ePjw9tvv03z5s0JCwsjJyeHVatWUb9+/dJ6VCGEECXgYnIWX22LBuD1nvWwtqxiran6bDi7XWttPv4HpFzfTUOBgJb5gXMPqB4m/ZrLKQmihcnCw8PJysqiXr16VK9e3bi/Q4cOpKWlUbt2bWPL86JFi3jjjTeYPXs2zZo146OPPqJPnz5FKsfKyooff/yRAQMGGANpGxsbJkyYQExMDPb29jz44IMsWbKkVJ5TCCFEyfho7QlycvNoFexB1wbV735BRaeqcPUUnNqgLTHbC3fTsLKH2uFQt5cWODt5m6+uosgUVVXLaKoZkZqaiqurKykpKbi4XJvONDs7m+joaIKDg7GrIF04RMUi7zEhRHlx5EIKD8/5G4AVL7etvBk5cnO0DBon1mgDA28cFOjsp/VtrttLGxxo42CWaoqb3S5eu5G0RAshhBCiTKiqynurjwLQr4lf5Qug0xO0Lhr/rYHTmwqnoLO0gZptIKSLtnjXk24aFVypB9GXLl1i1apVXLlyheDgYHr37o29vX1pFyuEEEKIcuavYwnsPJOIjZUFYytDSjt9FpzdoU14cnozXDpc+LiTjzYgsG5PGRRYCZkURB87dox33nkHRVH44osvcHNzK3R8xYoVDBo0qNAMcgEBAaxYsYLGjRubUrQQQgghKhC9IY9pfx4DYGi7YPzdK2D3BYMeLh6AmL8heguc/QcMN8wu7Hsf1OkJdXuAz32Sgq4SMymIXr58Ob/88gvt27e/KYBOSEjgqaeeIjMzs9D+2NhYevfuzdGjR3F0lE9kQgghRFWwZM85zlzOwMPRhuEda5u7OkVj0MOF/Vrf5pi/4dxu0GcUPsfZTxsUWCtc69ssgwKrDJOC6L/++gtFUXj44YdvOjZ37lzS09OxsrJi+vTpdO7cmbVr1/L6669z/vx55s+fT2RkpCnFCyGEEKICSM/JNU6sEtklFBc7azPX6DZUFRKOaa3MZzZrgfONU2vbu0PNthDUTgucvetK3+YqyqQgOjZWG2l633333XTs119/RVEUBg8ebAyWGzVqxMmTJ5k/fz4rVqyQIFoIIYSoAhZtj+Zqho5gL0cGtixnE6tkXIXTG+HUei1wTr9U+Li9hxYwFyze9aWLhgBMDKIvX74MaDPGXe/KlSv8+++/AAwaNKjQsT59+jB//nzjcSGEEEJUXimZer7YegbQWqHNPrFKXp7Wr/nUeji5Hi7sA67L9mtlp2XRqNVRW2RqbXEbJgXRBf2ds7OzC+3/+++/UVUVW1tb2rZtW+iYr68vAMnJyaYULYQQQogK4Mttp0nLzqVudWd6N/YzTyV0mVor84nV8N9ayLhc+Hi1MAjtArU7Q0ArsJZ8+uLuTPpo5eHhAVzr1lHgr7/+AqBFixbY2toWOpabmwuAk5OTKUUX2bx582jcuDEuLi64uLjQunVr/vzzT+NxVVWZNGkSfn5+2Nvb07Fjx5tayXNychg5ciReXl44OjrSp08fzp8/Xyb1F0IIISqqK+k5fL09BoDR3epgYVGGfYczrsD+b+GHJ2B6MCwZCAcWawG0rQvU7w29Z8OrR+GlHdB1CtTqIAG0KDKTguiCvtA//PCDcV9WVhZLly5FURQ6dep00zVnz54FKDQ9dGny9/fngw8+YO/evezdu5dOnTrRt29fY6A8ffp0PvnkEz799FP27NmDj48PXbt2JS0tzXiPyMhIfvvtN5YsWcLff/9Neno6Dz/8MAaDoUyeQQghhKiI5m0+TabOwH3+rnQri+m90y7Bnq/gm97wUSisGAn//Qm52eAaCC1fhMG/w7jTMGAxNB8CrjVKv16iUjKpO8cTTzzBunXrWLlyJU888QTt2rXjp59+IiEhAQsLCwYOHHjTNbt27QKgVq1aphRdZL179y60PXXqVObNm8fOnTtp0KABM2fOZOLEiTz66KMAfPPNN1SvXp0ffviBF198kZSUFBYsWMB3331Hly5dAFi8eDEBAQFs2LCB7t27l8lzlEeqqtK1a1csLS1Zu3ZtoWNz585lwoQJHD58mMDAcjaIRAghRKmLT8nmu51aw9mYbnVRSiuDRdolOLocjv6uTXxyff9m3/ugXm9tspPqYZJFQ5Qok4LowYMHs3DhQv7++2+WLl3K0qVLjceeeeYZ6tWrd9M1BVk7btVKXdoMBgNLly4lIyOD1q1bEx0dTXx8PN26dTOeY2trS4cOHdixYwcvvvgi+/btQ6/XFzrHz8+Phg0bsmPHjjsG0Tk5OeTkXEvCnpqaWjoPZiaKovD111/TqFEjvvjiC1588UUAoqOjGT9+PHPmzCnxAFqv12NtXU5TIwkhhDCas/Ekutw8WgZ58GCoV8nePDsFjq2Cw0u1dHRq3rVjNVpAg77QoA+4B5VsuUJcx6TuHBYWFvz555+MHj0af39/rKysCAgI4K233mLevHk3nb9y5UpiYmIA6Nq1qylFF8vhw4dxcnLC1taWYcOG8dtvv9GgQQPi4+OBm7uWVK9e3XgsPj4eGxsb3N3db3vO7bz//vu4uroal4CAgBJ8qvIhICCAWbNmMXbsWKKjo1FVlaFDh9K5c2datmxJr169cHJyonr16jz99NNcuXLFeO2aNWto164dbm5ueHp68vDDD3P69Gnj8ZiYGBRF4eeff6Zjx47Y2dmxePFizp49S+/evXF3d8fR0ZGwsDD++OMPczy+EEKIWziXmMlPe84BMLZ7CbVC5+q0wPnnwfC/UPj9JW26bTUP/O+H7tMg8gg8/xe0HSUBtCh1JrVEAzg6OvLRRx/x0Ucf3fXcdu3aER0dDUDNmjVNLbrI6tatS1RUFMnJySxbtowhQ4awZcsW4/Ebf7hVVb3rD3xRzpkwYQKjR482bqemphY5kFZVFVWfd/cTS4FibVGsX3hDhgzht99+45lnnqF///4cOXKEPXv20KJFC55//nk++eQTsrKyGD9+PI8//jgbN24EICMjg9GjR9OoUSMyMjJ4++23eeSRR4iKisLiunRC48eP5+OPP+brr7/G1taWF154AZ1Ox9atW3F0dOTo0aNlNlBVCCHE3c3ccJLcPJX2dbxpGexh2s3iD0PUD3DoJ8i8em2/Vx1o9Dg06g8eZdNFVIjrmRxEF4e7u/tNLbplwcbGhpCQEEDLGLJnzx5mzZrF+PHjAa21uSD1HmhTlhe0Tvv4+KDT6UhKSipU94SEBNq0aXPHcm1tbW/KTlJUqj6Pi2/vuKdrTeU3pQ2KjWWxrvnyyy9p2LAh27Zt45dffmHBggU0a9aMadOmGc9ZuHAhAQEB/Pfff9SpU4f+/fsXuseCBQuoVq0aR48epWHDhsb9kZGRxj7roGWD6d+/P40aNQLKrn+9EEKIuzuVkMZvB7QMVmO71bm3m2QmwqGfIWqxFkQXcKoOjR/XgmefRtLHWZiVSd05OnXqROfOnY0ZN4ri4sWLxuvMRVVVcnJyCA4OxsfHh/Xr1xuP6XQ6tmzZYgyQmzdvjrW1daFz4uLiOHLkyF2D6KqkWrVqvPDCC9SvX59HHnmEffv2sWnTJpycnIxLQR/5gi4bp0+fZtCgQdSqVQsXFxeCg4OBm1MmtmjRotD2qFGjeO+992jbti3vvPMOhw4dKoMnFEIIURQzN5wkT4VuDarT2N+t6BeqKsTuhF9fgI/rwZrxWgBtaaP1cR70s5aOrtt74NtYAmhhdia1RG/evBlFUcjIyCjyNVlZWcbrysIbb7xBz549CQgIIC0tjSVLlrB582bWrFmDoihERkYybdo0QkNDCQ0NZdq0aTg4OBhnWnR1dWXo0KGMGTMGT09PPDw8GDt2LI0aNTJm6ygNirUFflPME6Qr1vf22crKygorK+0tlZeXR+/evfnwww9vOq+g1b93794EBAQwf/58/Pz8yMvLo2HDhuh0ukLnOzo6Ftp+7rnn6N69O6tXr2bdunW8//77fPzxx4wcOfKe6i2EEKJknL6czurDcQC82rWIrdDZKXDwJ9j3NSQcvbbfpxE0HQyNHgMHE7uECFEKyrQ7hzlcunSJp59+mri4OFxdXWncuDFr1qwxDmx87bXXyMrK4qWXXiIpKYlWrVqxbt06nJ2djfeYMWMGVlZWPP7442RlZdG5c2cWLVqEpWXxujwUh6Ioxe5SUZ40a9aMZcuWERQUZAysr3f16lWOHTvGF198wYMPPghoM10WVUBAAMOGDWPYsGFMmDCB+fPnSxAthBBmNnfTaVQVujaoTn1flzuffPkE7PocDi4BvTYDMlb2Wh/n5s9CjWbS2izKtTIPogtare3symZGoAULFtzxuKIoTJo0iUmTJt32HDs7O+bMmcOcOXNKuHaV14gRI5g/fz4DBw5k3LhxeHl5cerUKZYsWcL8+fNxd3fH09OTL7/8El9fX2JjY3n99deLdO/IyEh69uxJnTp1SEpKYuPGjdSvX7+Un0gIIcSdnEvMZHnUBQBeDg+59Ul5eXBqA+yaB6c3XtvvXR9aPAONB4C9W+lXVogSUOZBdMGU2/7+/mVdtChDfn5+bN++nfHjx9O9e3dycnKoWbMmPXr0wMJCy/6xZMkSRo0aRcOGDalbty6zZ8+mY8eOd723wWBgxIgRnD9/HhcXF3r06MGMGTNK/6GEEELc1udbTmPIU3kw1Iv7AtwKH9RlQtT3sHMeJBakMlWg3kPQahgEtZNWZ1HhKKqqqnc/TfPss88W2l60aBGKotC3b1/c3NzueG1OTg6nT59mz549AAwdOpQvv/yy+DWuwFJTU3F1dSUlJQUXl2tfc2VnZxMdHU1wcHCZtdCLqkXeY0KI0hSfkk376ZvQGfL4+cXW19LaZSbC7vmw+4tr6elsXaHZ09DyecnlLMql28VrNypWS3RB0Hw9VVX5/fffi3R9Qbzu4eHBhAkTilO0EEIIIcqpL7eeQWfIo2WwhxZAJ5+Dfz6D/d+CPj/5gFsgtB4JTQaBreT2FxVfsYLowMDAQkH02bNnURQFX1/fO07FrCgKdnZ2+Pr60qZNG4YPH46fn9+911oIIYQQ5cKV9Bx+2K2lun25hSMsHwGHlkBernZC9UbQLhIa9APLSp/PQFQhxXo3F0zZXaBgVrl169bRoEGDEquUEEIIISqGBX9Hk63P4z7HZB5c+TRg0A4EPagFz7U7S39nUSmZ9JGwffv2KIpyUx5fIYQQQlR+KRf+47ttxwFrXtZ9hWJpgJAu0OF1CLjf3NUTolSZPNmKEEIIIaoIVdVmETy5Fv5by6KYANINj1FPiaVzHU8I/wv8W9z9PkJUAtI5SQghhBC3l3YJzu2C03/Bf+sg7SIA6aodC3OfB2BEt0ZYhA83Zy2FKHMlHkSnpqaSlpaGwWC467mBgYElXbwQQggh7lWeAeIPwbk9cH63FjwnxxY+x9oBanXkG0M/Uo44UcvLkV4d2pqnvkKYUYkE0evXr2fu3Lls27aNpKSkIl2jKAq5ubklUbwQQgghTJF0Fg4s1pb8luZrFKjWAILaQmh3CGpHit6SL6ZvBHIZ2TkESwsZOCiqHpOD6FGjRvHZZ58B1/JACyGEEKKcy82BE3/Avm/gzGYg/2+4rQsEtAT/ltprjeZgV3jCiS83Hic1O5c61Z3oc1+NMq+6EOWBSUH0Dz/8wKeffgqAnZ0d/fr1o3nz5nh4eBjT3wkhhBCiHNFlwK7PtclQCmYRBKgVDs0Ga1NxW9ne9vLLaTks/DsGgDHd6kortKiyTAqiv/jiCwACAgLYuHEjtWvXLpFKiYonPj6eqVOnsnr1ai5cuEC1atVo0qQJkZGRdO7c2XjetGnTeOutt5g6dSqvv/56oXt07NiRJk2aMHPmTOO+mJgYgoODjdvW1tYEBgYSERHBxIkTb5pB804UReG3336jX79+9/ycQghRYemzYd/XsO1jyLis7XP2haZPaUsRp+D+bNMpsvQG7vN3pVuD6qVXXyHKOZOC6EOHDqEoCu+8844E0FVYTEwMbdu2xc3NjenTp9O4cWP0ej1r165lxIgRHD9+3Hju119/zWuvvcbChQtvCqLvZMOGDYSFhZGTk8Pff//Nc889h6+vL0OHDi2NRxJCiMrDoNf6Om/9H6Re0Pa5B0P4GxD2aLFmETyflMkPu7SBhuO61ytWQ4YQlY1JfS70ej0ATZs2LZHKiIrppZdeQlEUdu/ezWOPPUadOnUICwtj9OjR7Ny503jeli1byMrKYsqUKWRkZLB161bjsYiICLZs2cKsWbNQFAVFUQrNkOnp6YmPjw81a9bkySefpE2bNuzfv994fM+ePXTt2hUvLy9cXV3p0KFDoeNBQUEAPPLIIyiKYtwWQohKS1Xh6Ar4rCWsitQCaJca0HsWvLwHGj9e7Gm4Z/91Ep0hj9a1PGkb4lk69RaigjApiC4IRNLT00uiLuI6qqqi0+nMshRngGhiYiJr1qxhxIgRt5y50s3Nzbi+YMECBg4ciLW1NQMHDmTBggXGY7NmzaJ169Y8//zzxMXFERcXR0BAwC3L3Lt3L/v376dVq1bGfWlpaQwZMoRt27axc+dOQkND6dWrF2lpaYAWZIPWEh4XF2fcFkKISuniAVj0EPz8NCSeAUdv6PEBjNwPzSPA0rrYtzx9OZ1l+7WW7LHd60ortKjyTOrO8eijjzJ16lT++usvHnzwwZKqk0Br5Z82bZpZyn7jjTewsbEp0rmnTp1CVVXq1at3x/NSU1NZtmwZO3bsAOCpp56ibdu2zJkzBxcXF1xdXbGxscHBwQEfH5+brm/Tpg0WFhbodDr0ej0vvPACgwcPNh7v1KlTofO/+OIL3N3d2bJlCw8//DDe3t6AFtTf6v5CCFEppF6Ev96Fgz8CKljZQZuR0DYSbJ1MuvWM9f9hyFPpUr8azWu6l0h1hajITGqJHjNmDIGBgcycObNQv1dRdRS0Wt+tReKHH36gVq1a3HfffQA0adKEWrVqsWTJkiKV89NPPxEVFcXBgwf56aef+P333wv1qU5ISGDYsGHUqVMHV1dXXF1dSU9PJzY29g53FUKISiI3B7b8D+Y0h4M/ACo0ehxG7oNOb5ocQP97MYVVh+IALSOHEMLElmhXV1fWrFlDnz59aNu2Le+++y4DBw7E3V0+oZrK2tqaN954w2xlF1VoaCiKonDs2LE7Zr1YuHAh//77L1ZW195yeXl5LFiwgBdeeOGu5QQEBBASEgJA/fr1OXPmDG+99RaTJk3Czs6OiIgILl++zMyZM6lZsya2tra0bt0anU5X5GcRQogK6fQmWD0GEk9r2wGtoPv74N+8xIr4eN1/APS5z4/6vi53OVuIqsGkILpWrVoAZGZmkpSUxMiRIxk1ahReXl44ODjc8VpFUTh9+rQpxVdqiqIUuUuFOXl4eNC9e3c+++wzRo0adVO/6OTkZM6dO8fevXvZvHkzHh4ehY61b9+eI0eO0LBhQ2xsbIo0XTyApaUlubm56HQ67Ozs2LZtG3PnzqVXr14AnDt3jitXrhS6xtrausj3F0KIci81Dta+Af/+qm07VYfu06BhfyjB/sr7ziax8XgClhYKr3atU2L3FaKiMymIvj57Amhf7auqSkJCwl2vlQEJlcfcuXNp06YNLVu2ZMqUKTRu3Jjc3FzWr1/PvHnz6N69Oy1btqR9+/Y3Xdu6dWsWLFjAjBkzCAoKYteuXcTExODk5FQo4L569Srx8fHk5uZy+PBhZs2aRXh4OC4uWotISEgI3333HS1atCA1NZVx48Zhb29fqKygoCD++usv2rZti62trXxjIoSomAy5sOcr2Pge6NJAsYCWL2gp6+xcS7y4Geu1VujHmvkT7HXzAHIhqiqTgughQ4aUVD1EBRYcHMz+/fuZOnUqY8aMIS4uDm9vb5o3b86sWbMYNGgQ48ePv+W1/fv35/333+fDDz9k7NixDBkyhAYNGpCVlUV0dLTxvC5dugBaC7Svry+9evVi6tSpxuMLFy7khRdeoGnTpgQGBjJt2jTGjh1bqKyPP/6Y0aNHM3/+fGrUqHHTh0AhhCj3Lv0Lv4/Qsm+ANiX3Q5+AX5NSKW7Xmav8feoK1pYKL3cKKZUyhKioFLU4+cyESVJTU3F1dSUlJcXYggqQnZ1NdHQ0wcHB2NnZmbGGorKS95gQFVyuDrZ9pM02mJcLtq7QdRI0iwALk3IE3NETX/7DzjOJPNkqkKmPNCq1coQoT24Xr93IpJZoIYQQQpSy8/u01ufLx7Ttug/BQx+Di2+pFrvj9BV2nknExtKCEeHSCi3EjSSIFkIIIcojfZbW73nnXFDzwMELek3Xpuou5XFFqqoa+0IPbBmAn5v9Xa4Qouop0SA6Ozubffv2ER8fT2ZmJn379r1jM7gQQgghbiHuEPz6PFzOn4Oh0ePajIOOZTPV9t+nrrAnJgkbKwteklZoIW6pRILoc+fO8eabb/LTTz+h1+uN+w8fPkyDBg2M2wsWLOCLL77A1dWVdevWSYYOIYQQ4np5BtgxGzZOhTw9OFaDPnOgbo8yq4KqqnyS3wr9VKuaVHeRcRRC3IrJQfTu3bvp1asXSUlJXD9G8VYBcp8+fRgxYgR6vZ5169bRvXt3U4sXQgghKofkWPhtGJzdrm3Xexh6zwJHrzKtxub/LnMgNhk7awuGdaxVpmULUZGYNKQ3JSWFvn37kpiYiI+PD3PnzuXw4cO3Pd/b25uePXsCsHr1alOKFkIIISqPQz/DvLZaAG3tqLU+D1hc5gH09X2hB7cOopqztEILcTsmtUTPmTOHS5cu4eXlxT///ENgYOBdr+natSu///47u3fvNqVoIYQQouLTZcKf4+DAYm3bvyU8+gV4mKcFeMOxBA6dT8HBxpIX20srtBB3YlIQvXLlShRFYfTo0UUKoAHCwsIAZMpvIYQQVdvl/2DpEEg4CijQ8XV4cCxYmidx1pX0HKas+heAIW2C8HSyNUs9hKgoTPpJPXnyJMAtp3O+HTc3N0BLZC2EEEJUSYd+hpWRoM/QBg/2/wpqdTBbdTJ1uQxdtIdziVkEeNgzrH1ts9VFiIrCpCA6KysLAEdHxyJfk56eDiCzpolbioiIIDk5meXLl5u7KkIIUfL0WfDna7D/W2076EHovwCcq5utSrmGPF7+4QAHz6fg7mDNN8+0xNXB2mz1EaKiMGlgobe3N6CluCuqffv2AeDrW7ozLYmyFR8fz8iRI6lVqxa2trYEBATQu3dv/vrrLwCCgoKYOXPmTddNmjSJJk2aGLdnzZrFokWLjNsdO3YkMjKydCsvhBBlIfkcLOiWH0Ar0OF1GPy7WQNoVVV56/cjbDyegK2VBV8NuZ9a3k5mq48QFYlJQXTLli0B+PPPP4t0vsFg4Msvv0RRFNq1a2dK0aIciYmJoXnz5mzcuJHp06dz+PBh1qxZQ3h4OCNGjCjWvVxdXY1dfoQQotKI2Q5fdoT4Q+DgCU//BuETwMLSrNX6bNMpftx9DkWB2QOb0rymu1nrI0RFYlIQPXDgQFRVZeHChRw4cOCO5+bl5TFs2DCOHj0KwFNPPWVK0aIceemll1AUhd27d/PYY49Rp04dwsLCGD16NDt37izWvSIiIujXr59xfcuWLcyaNQtFUVAUhZiYGJKSknjyySfx9vbG3t6e0NBQvv7661J4MiGEMJGqwu758G0fyLwCPo3hhc1QO9zcNeOXfef5aJ2Wzm5ynzC6h/mYuUZCVCwm9Ynu378/bdq0YceOHXTu3Jl3332X//u//zMeVxSFS5cusW7dOmbMmMHBgwdRFIUePXrQsWNHU+teqamqSl5ellnKtrCwL/JskomJiaxZs4apU6fesm+8Ka3Ks2bN4r///qNhw4ZMmTIF0LoQvfLKKxw9epQ///wTLy8vTp06ZeyfL4QQ5UZuDqweAwe+07YbPqblf7ZxMGu1DHkq3+86y5SVWqPWix1qMbh1kFnrJERFZHIeneXLl9O+fXuOHz/OqFGjGDVqlDEAa9asGTqdzniuqqo0atSI77//3tRiK728vCw2b2lklrI7djiMpWXRfsmfOnUKVVWpV6/eXc8dP348b775ZqF9Op2u0NTw13N1dcXGxgYHBwd8fK61kMTGxtK0aVNatGgBaP2thRCiXElPgCVPwvndoFhAl0nQZhQUsYGitOyPTeLt349w5IKWIatvEz/Gd7/7728hxM1M6s4B4OXlxd69exkxYgS2traoqmpccnJyjOtWVla88MIL7NixQ/q8ViIFU70XpeV63LhxREVFFVqGDRtW7DKHDx/OkiVLaNKkCa+99ho7duwo9j2EEKLUJByHrzprAbSdKzy5FNq+YtYAOjFDx+vLDvHo3B0cuZCKs50Vk/uE8cnjTbCwMG9gL0RFVSIZ3R0cHJgzZw6TJk1i7dq17N27l4SEBAwGA56enjRt2pSePXvi5+dXEsVVCRYW9nTscPsp1Eu77KIKDQ1FURSOHTtm7Mt8O15eXoSEhBTa5+HhUez69ezZk7Nnz7J69Wo2bNhA586dGTFiBB999FGx7yWEECXqzBb46WnISdFmHXzyF/A0X87lvDyVH/fEMn3NCVKy9AA81tyf8T3q4e0sk6kIYYoSnRbJ09OTQYMGMWjQoJK8bZWkKEqRu1SYk4eHB927d+ezzz5j1KhRN/WLTk5ONumbBxsbGwwGw037vb29iYiIICIiggcffJBx48ZJEC2EMK+oH2DFSMjLhYAH4IkfwNHTbNU5eSmN1389zL6zSQDU93Xh3b5htAgqfuOFEOJm5plbVFQqc+fOpU2bNrRs2ZIpU6bQuHFjcnNzWb9+PfPmzePYsWP3fO+goCB27dpFTEwMTk5OeHh4MGnSJJo3b05YWBg5OTmsWrWK+vXrl+ATCSFEMagqbH4ftnyobYc9Cv3mgbV5JhXLyTXw2abTzNt8Cr1BxdHGkjHd6jK4dU2sLE3uxSlE6VJVyEmD7GTIToGs/Fff+8AtwNy1K0SCaGGy4OBg9u/fz9SpUxkzZgxxcXF4e3vTvHlz5s2bZ9K9x44dy5AhQ2jQoAFZWVlER0djY2PDhAkTiImJwd7engcffJAlS5aU0NMIIUQxGPTw+8twKP93ULtXodPbYGGeYHV3dCKv/3qIM5czAOhSvxpT+jbEz63o3fSEKBGqqgXCmYnakpUEWQXrBdvJ+a9J2rlZSVrArObdfL++c6Hpk2X8EHemqAUjw+4gNjbWuB4YGHjL/ffi+ntVBampqbi6upKSkoKLi4txf3Z2NtHR0QQHB8t06KJUyHtMiFKgy4SlEXByLSiW8PAn0DzCLFVJz8nl/T+O8f0u7e+yt7Mtk/uE0bOhT5FTlgpxR6qqBbkZl69brmhL5hVtOzMxf/uqtqg3d8csMksbsHPTBufau2mDc+v3LqmnuaPbxWs3KlJLdHBwMKD1083Nzb1p/7248V5CCCFEhZGdAj88AbE7wMoOHv8W6nQ3S1V2nLrCuF8OcSFZy5c/sGUAr/eoj6uDtVnqIyqYXB2kX4K0eEiPz38t2E7Q1jMua+t5+uLf38YJ7D3AwR3s3fPXPfLXb1js3LSA2c4VrMv/tydFCqJv11hdhEZsIYQQonJJT4DFj0L8YbB1hUE/Qc3WZV6NjJxcPlxznG//OQuAv7s90x9rTJvaXmVeF1FO6bMg5QKkns9/LVjiIC1/ybhcvHvauoKTNzh6g6MXOHhdt+557dXBUwuYzTQ2oCwUKYi+3ZTKMtWyEEKIKiU5Fr7tB4mntcDhqV/Bt3GZV2PXmauM++UQsYmZADz1QCATetbH0VaGOlUp2SnaezI5FpLPaa8p+dsp57UuFUVhaQNOPuBcHZzyF2ef/PVq2uJYTXvPV+KguLiK9NM2ZMiQYu0XQgghKp3LJ7QAOu0iuAbC4OVlngM6U5fL9DUnWLQjBoAabvZ82L8x7UKl9blSyjNoLceJ0ZB4BpJiIPms9poUo/VRvhtrR3CtAa7+4FIjf/EFZ79rrw4eZp9NsyKSj6xCCCHE3SQcg0UPawOovOvB07+BS9lOILYnJpFxSw8Sc1VrfX7i/gAmPlQfZzvp+1zhZVyBK/9pH9Su/AdXT2tBc/JZMOjufK2DJ7gFgmuA9mpcD9ACZzs3CZBLiQTRQgghxJ1cOgrf9NYCaJ/G8PTyMp1EJVtv4KO1J1iwPRpVBR8XOz58rDEd6niXWR1ECcvLg6jFEPUjXD6upXy7HQtrcA8Cj2BwDwb3mtq2exC41QRbpzKqtLiRBNFCCCHE7VwfQPvepwXQDmU349++s0mMW3qQM1e0vM//19yfNx9ugKu9tD5XWJdPwMpXIPafwvvdAsGrDnjV1boJedbWgmZXf7CwNE9dxR0VKYj+9ttvjeuDBw++5f57cf29hBBCiHLl0r/5AfRV8G2i9YG2dy+TolVV5fMtZ/jf2uPkqVDdxZYPHm1MeL1qZVK+KAX6bNj2Mfw9Q0sVZ+0A7cdBSGfwDAUbB3PXUBRTkSZbsbCwQFGUm3I7F+y/p4KrYJ5omWxFmIu8x4QopvgjWgCdlQh+TbU+0GUUQKdl6xm39BBr/o0HoF8TPyb3aSh5nyuy6K2wMlLL6gIQ2h0e+khrfRblTolOtgKSK1oIIUQVUdACbQygl2sTQJSBUwnpvPjdXk5fzsDaUmFSnzAGtQyUWQcrqpw0WPcW7MtPCezkAz0/hAZ9ZbBfJVCkIDo6OrpY+0XVEx8fz9SpU1m9ejUXLlygWrVqNGnShMjISDp37kxQUBCRkZFERkYWum7SpEksX76cqKgok8q//g+Mo6MjtWvX5tVXXyUiIsKk+wohqpirp+G7R/ID6Gb5LdBuZVL0miNxjPn5IBk6Az4udsx9qhnNAsum9VuUguit8PsILWczQIuh0OUdbTY+USkUKYiuWbNmsfaLqiUmJoa2bdvi5ubG9OnTady4MXq9nrVr1zJixAiOHz9eJvX4+uuv6dGjBxkZGfz0008888wz+Pr60r27eabiFUJUMCkXtDzQ6ZegekN4+tcyCaANeSofrTvBvM3aV/2tgj34dFAzvJ1tS71sUQp0GbBhEuz+Utt2C4S+cyH4QbNWS5Q8C3NXQFR8L730EoqisHv3bh577DHq1KlDWFgYo0ePZufOncW6V0REBP369WPatGlUr14dNzc3Jk+eTG5uLuPGjcPDwwN/f38WLlx407Vubm74+PhQu3Zt3njjDTw8PFi3bh2gBfqKohRq8U5OTkZRFDZv3gzA5s2bURSFv/76ixYtWuDg4ECbNm04ceLEPf/bCCEqiIwr8F0/bbY3j1pl1gc6KUNHxNe7jQH0c+2CWfxcKwmgK6qz/8Dn7a4F0M2fgeE7JICupCTFXTmlqiqZeXlmKduhGANGExMTWbNmDVOnTsXR0fGm425ubsUuf+PGjfj7+7N161a2b9/O0KFD+eeff2jfvj27du3ip59+YtiwYXTt2pWAgICbrjcYDCxbtozExESsrYs/EGfixIl8/PHHeHt7M2zYMJ599lm2b99e7PsIISqI7BRY/Kg2yYWLPwz+XZvmuJT9ezGFF7/bx/mkLOysLfiwf2P6NqlR6uWKUpAap7U+H1qibbvUgD5ztMwbotIyKYhOS0tjxowZALzwwgv4+Pjc8fy4uDjmz58PwLhx47C3tzel+EotMy+P2lsPm6Xs0+0b4WhZtJyUp06dQlVV6tWrd9dzx48fz5tvvllon06no0GDBoX2eXh4MHv2bCwsLKhbty7Tp08nMzOTN954A4AJEybwwQcfsH37dp544gnjdQMHDsTS0pLs7GwMBgMeHh4899xzRXqO602dOpUOHToA8Prrr/PQQw+RnZ0tWS2EqIx0mfDDExB3EBy8tDR2ZZAxYfmBC7z+6yGy9XkEejjwxdPNqe97+ywAopzSZ8M/n8K2T0CfASjQ7Gno9p70fa4CTAqily9fzqRJkwgNDeXtt9++6/k+Pj58//33nDp1inr16vH444+bUrwoBwqysxSl5XrcuHE3DfSbPXs2W7duLbQvLCwMC4trPY2qV69Ow4YNjduWlpZ4enqSkJBQ6LoZM2bQpUsXzp07x+jRo3n11VcJCQkp7iPRuHFj47qvry8ACQkJBAZKKiIhKhWDHpYOgdgdYOuq9YH2Ci3VIvWGPKb9cYyvt8cA0KGON7OeaIKbg02plitKmKrC8VWwdqI2NTeAf0st80aNZuatmygzJgXRv/76K4qiFDkYVhSFJ554gnfffZelS5dKEH0HDhYWnG7fyGxlF1VoaCiKonDs2DH69et3x3O9vLxuCmo9PG6e+evGLhiKotxyX94N3V18fHwICQkhJCSEpUuX0rRpU1q0aEGDBg2MQfn1KRn1ev0t63l9WQUfDm4sSwhRwakqrIqEk+vAyh6e/FmbkbAUpWbreWnxfv4+dQWAl8NDeLVrHSwtJNVZhaGqWtaNzR9oH74AnH2h6xRo9H+Stq6KMWlgYUHWhTZt2hT5mtatWwNw9OhRU4ousvfff5/7778fZ2dnqlWrRr9+/W4aKKaqKpMmTcLPzw97e3s6duzIv//+W+icnJwcRo4ciZeXF46OjvTp04fz58+XWr0VRcHR0tIsS3HykXp4eNC9e3c+++wzMjIybjqenJxcgv8qRRcSEkL//v2ZMGECAN7e3oDWpaiAqWn1hBAV2Nb/wYHFoFjA/y2CwAdKtbi4lCwe//wf/j51BQcbSz5/qjlju9eVALqiUFU4swW+7gXf9tECaEtbeHAsvLwXGj8uAXQVZFIQXRBEFnzlXRQF/aYvXLhgStFFtmXLFkaMGMHOnTtZv349ubm5dOvWrVDAN336dD755BM+/fRT9uzZg4+PD127diUtLc14TmRkJL/99htLlizh77//Jj09nYcffhiDwVAmz1GezZ07F4PBQMuWLVm2bBknT57k2LFjzJ492/ihyRzGjBnDypUr2bt3L/b29jzwwAN88MEHHD16lK1bt97UP1sIUUVE/QCbpmrrvT6Cuj1KtbijF1N55LMdHI9Pw9vZlp9fbE2PhnceQyTKidsFzy1fhFeioPNbYOtk7loKMzGpO0fBV+SZmZlFvqbg3LKa8nvNmjWFtr/++muqVavGvn37aN++PaqqMnPmTCZOnMijjz4KwDfffEP16tX54YcfePHFF0lJSWHBggV89913dOnSBYDFixcTEBDAhg0bqnwe4uDgYPbv38/UqVMZM2YMcXFxeHt707x5c+bNm2e2ejVq1IguXbrw9ttv88cff7Bw4UKeffZZWrRoYRyw2K1bN7PVTwhhBmc2w4qR2nrbSLh/aKkWt+3kZYYv3k96Ti4h1ZxY9Mz9+Ls7lGqZooRc2Kdl3IjOH7djaQvNI6BdJLj4mbFiorxQVBPm7a5Xrx4nT55kxowZjBo1qkjXzJ49m8jISGrVqsWpU6futeh7durUKUJDQzl8+DANGzbkzJkz1K5dm/3799O0aVPjeX379sXNzY1vvvmGjRs30rlzZxITE3F3v5Y39L777qNfv35Mnjy5SGXfbi727OxsoqOjCQ4OlgwQolTIe0wItOm8F/aAnFRo2B8e/QqKMQakuH7ee443fj1Mbp7KA7U8+OKpFrg6FD/tpihjV07Bxilw9Hdt29JGy/cswXOVcbt47UYm/fZ48MEHUVWVuXPn3naQ1vX0ej1z585FURTatWtnStH3RFVVRo8eTbt27YzZHuLj4wEtA8T1qlevbjwWHx+PjY1NoQD6xnNuJScnh9TU1EKLEEIIM0i9CN//nxZAB7aBfvNKNYCeu/kUr/1yiNw8lb5N/Pjm2ZYSQJd3qXGw8hX4rGV+AK3AfYNg5D7oNV0CaHETk36DPPPMMwCcPHmSQYMG3bFbR2ZmJgMHDuS///4rdG1Zevnllzl06BA//vjjTcduHEynqupdB9jd7Zz3338fV1dX43KriUGEEEKUMl0m/DAAUi+AZyg88T1Ylc6MgKqq8sGfx5m+RhvAPrxjbWYOaIKtVdFy7wsz0GXC5g9hTjPYtwhUA9Tpqc00+Mi8MskbLiomk/pEt2nThieeeIIlS5bw66+/smvXLp5//nnat2+Pr68viqJw8eJFtm7dyldffcX58+dRFIXHHnvMOJlFWRk5ciQrVqxg69at+Pv7G/cXDHSMj48vNEAyISHB2Drt4+ODTqcjKSmpUGt0QkLCHTOTTJgwgdGjRxu3U1NTJZAWQoiypKrw+wiIPwQOnvDUL+Bwc2rNkpCXp/LW70f4flcsAG/0qscL7WuXSlmiBKgq/PsrrH8HUs5p+/xbaunqappvULyoOEye9nvhwoVcuXKFDRs2cOHCBSZNmnTL8wq6Xnft2pVvvvnG1GKLTFVVRo4cyW+//cbmzZsJDg4udDw4OBgfHx/Wr19v7BOt0+nYsmULH374IQDNmzfH2tqa9evXG3Nbx8XFceTIEaZPn37bsm1tbbG1LZ3WDiGEEEXw9ydaoGRhBY9/B+5BpVKM3pDH2KUH+T3qIooC0x5pxMCW0oJZbl08AGsmQOw/2raLP3SbAmGPSqo6UWQmB9F2dnasXbuW2bNn89FHH902dV1AQADjxo1jxIgRxcpDbKoRI0bwww8/8Pvvv+Ps7Gzsw+zq6oq9vT2KohAZGcm0adMIDQ0lNDSUadOm4eDgwKBBg4znDh06lDFjxuDp6YmHhwdjx441Zn8QQghRDp34E/56V1vvOR2C2pZKMdl6AyO+389fxxOwslCYMaAJve+T/rPlUmYibHgH9n8HqNpEO+1ehTYjwUaypojiMTmIBq0/8SuvvMKoUaOIioriwIEDXLmizcjk5eVFs2bNuO+++8o0eC5QkGKtY8eOhfZ//fXXximoX3vtNbKysnjppZdISkqiVatWrFu3DmdnZ+P5M2bMwMrKiscff5ysrCw6d+7MokWLsLSUfm5CCFHuJByHZc8DKrR4ttRS2WXqchm6aC//nLmKrZUFnz/VnPB61UqlLGECVYWo72HdW5CVqO1r9H/QZRK4+t/xUiFux6QUd6J4JMWdMBd5j4kqJSsJ5neCxDNQsy08vRysbEq8mExdLs8u2sPOM4k42VqxYEgLWtXyLPFyhIkSjsGq0dem6a7WAB76RPo9i9sqaoq7EmmJFkIIIcoFQy788qwWQLsGwuPflkoAnaUzMHTRXmMA/e3QljQLdL/7haLs6DJhy4fwz6eQlwvWDtDxdXjgJbCUdIPCdBJECyGEqDw2vgunN2oB08AfwNGrxIvI0hkY+s0e/jlzFSdbK755VgLocifmb/j9ZUiK1rbrPQw9PgA3yZAlSk6Rguhvv/3WuD548OBb7r8X199LCCGEMMmJNbB9prbe9zPwaVTiRWTrDTz/7V52nL6Ko40l3zx7P81rSgBdbuSka1N175mvbbvUgIc+hro9zVotUTkVqU+0hYUFiqKgKAq5ubk37b+ngm+4V1VQmftEx8fHM3XqVFavXs2FCxeoVq0aTZo0ITIyks6dOxMUFMTZs2cBLaNLzZo1GTp0KGPHjjXLgNOqpjK8x4S4o6Sz8EV7yE6GVsOg54clXkRBAL3t5BUcbCz59tmWtAgqnZzT4h6c2QwrRkKylqeb5hHQ9V2wu32fViFupcT7RN8u1pZxiSImJoa2bdvi5ubG9OnTady4MXq9nrVr1zJixAiOHz8OwJQpU3j++efJzs5mw4YNDB8+HBcXF1588UUzP4EQokLLzYGlQ7QAukYLLXAqYbrcPIYt3mcMoL+RALr8yEmHdW/Cvq+1bddA6DMbaoebt16i0itSEB0dHV2s/aJqeemll1AUhd27d+Po6GjcHxYWxrPPPmvcdnZ2Ns4Q+dxzzzFv3jzWrVtnDKIVReG3336jX79+xmvc3NyYOXMmERERxMTEEBwczLJly5gzZw67du0iNDSUzz//nNattVHWZ8+e5eWXX+bvv/9Gp9MRFBTE//73P3r16lUG/xJCCLNY96Y2eYa9O/zfohIfSGjIUxmz9CCbT1zGztqCryPu534JoMuH83th2XPX+j7f/5yWts7W+Y6XCVESihRE16xZs1j7helUVSVLbzBL2fbWlkXuYpGYmMiaNWuYOnVqoQC6gJub2037VFVly5YtHDt2jNDQ0GLXb+LEiXz00UeEhoYyceJEBg4cyKlTp7CysmLEiBHodDq2bt2Ko6MjR48excnJqdhlCCEqiCPLYPeX2vojX5T4wDFVVXlnxRFWHryItaXC5081lzR25YEhF7Z9rGXfUA3ajIOPzIPg9uaumahCihREN2vWDEVR+OWXXwpNmx0bq/U7qlGjhkw6UsKy9AYavL3WLGUfndIdB5ui9fQ5deoUqqpSr169u547fvx43nzzTXQ6HXq9Hjs7O0aNGlXs+o0dO5aHHnoIgMmTJxMWFsapU6eoV68esbGx9O/fn0aNtAFFtWrVKvb9hRAVxJWTsCL/d0i70VCne4kX8cn6/1i8MxZFgU8eb0LHujKRitklRsOvL8D53dp2w/7a4EF7GeApylaRIqWoqCgURSErK6vQ/qCgICwsLDh06BANGjQolQqK8q2gT3xRWq7HjRtHREQEly9fZuLEiXTq1Ik2bdoUu8zGjRsb1319fQFISEigXr16jBo1iuHDh7Nu3Tq6dOlC//79C50vhKgk9Fnw8xDQpUPNdhA+scSL+GrbGeZsPAXAu30bylTe5UHUj/DHWO3/3dYFen0EjR8HGaAuzKBIQXRBgJSXl3fTMRlYWDrsrS05OqXkW1WKWnZRhYaGoigKx44dK9SX+Va8vLwICQkhJCSEZcuWERISwgMPPECXLl0A7X124/tJr9ffdB9r62tJ8m98bz733HN0796d1atXs27dOt5//30+/vhjRo4cWeRnEkJUAOvegoR/wbEaPLYALEt22oNf9p3nvdXHABjbrQ5PPSDdF81Klwl/joMDi7XtwNZa9x13+X8R5mNRlJNcXV0BOHfuXKlWRlyjKAoONlZmWYqTcs7Dw4Pu3bvz2WefkZGRcdPx5OTkW17n7u7OyJEjGTt2rDFw9vb2Ji4uznjOyZMnyczMLN4/HBAQEMCwYcP49ddfGTNmDPPnzy/2PYQQ5dh/667lAX7kc3D2KdHb/3XsEuOXHQLguXbBjAgPKdH7i2K6cgq+6pIfQCvQcQJErJYAWphdkYLogv6l7733HsePH8dgKDzgTfL8Vm1z587FYDDQsmVLli1bxsmTJzl27BizZ882Zs24lREjRnDixAmWLVsGQKdOnfj000/Zv38/e/fuZdiwYYVanYsiMjKStWvXEh0dzf79+9m4cSP169c36fmEEOVI+mX4/SVt/YGXIKRzid7+yIUUXv7hAIY8lf7N/Jn4UH35G2dO//4GX3bM/9bBGwYv16butpBxWML8ihREP/fcc6iqys6dOwkLC8PGxsY4kFBVVRo2bIilpWWxFisrmXG8sggODmb//v2Eh4czZswYGjZsSNeuXfnrr7+YN2/eba/z9vbm6aefZtKkSeTl5fHxxx8TEBBA+/btGTRoEGPHjsXBwaFYdTEYDIwYMYL69evTo0cP6taty9y5c019RCFEeaCq8PsIyLgM1cKg8zslevuLyVk8u2gPWXoDD4Z68UH/RhJAm0tuDvwxDpZGgC4NaraFF7dBrY7mrpkQRkWasRDgtddeY8aMGTe1Qt9zwYpSYveqKCrzjIWifJP3mKgUds/XBpVZ2sILm6B6WIndOjVbz//N+4cTl9KoW92ZpcNb42JXvG/CRAlJi4efnr6WfaPdaG3gaAn3exfidkp8xsLp06czatQoNm3axIULF8jJyWHy5MkoisKwYcOoVk3S/gghhCgll09ok6oAdJ1SogG03pDHiO/3c+JSGt7Otix85n4JoM3l/D746UlIiwM7V3h0fqmkLhSiJBTrY52/vz9PP/20cXvy5MmA1rdVUtwJIYQoFbk5sGwo5GZD7c7Q6sUSu7Wqqry1/AjbTl7B3tqShUPup4abfYndXxRD1I+w8hUw5IBXXRj4I3jWNnethLitIgXRqampADc1aQcGBmJhYYGNTclOsSqEEEIYbXwP4g+Dgyf0m1uiOYHnbTnNkj3nUBSYPbApjfxdS+zeoogMubDhHfjnU227bi8tfZ3d7b9GF6I8KFIQ7ebmdstJVQq6c0hXDiGEEKUiZjvsmKOt95lTouns1v0bz/Q1JwB45+EGdG1QvcTuLYooKwmWPgNnNmnb7V/TUthZFCnvgRBmVeTuHLcaf/jMM89gYWFBixYtpDuHEEKIkpWTBsuHASo0Gwz1HiqxW5+8lMarP0UBMLh1TSLaBpfYvUURJcfC4sfgygmwdoB+8yCsn7lrJUSRFSmItrS0JC8vD51Od9MxmbFQCCFEqVj7hhZouQVC92kldtuULD0vfLePDJ2BVsEevPWwNAKVuYsH4IcBkH4JnP1g0E/g29jctRKiWIr0fYmXlxcAR48eLdXKCCGEEACcWAP7vwUUrYXS1rlEbmvIU3llyQGir2RQw82euU82w9pSug6Uqf/WwdcPaQF0tTB4boME0KJCKlJLdOvWrVm+fDnjx48nJSWFOnXqFJpJbs+ePVy5cqXYhbdv377Y1wghhKjkMq7CipHaeusRENSuxG79yfoTbD5xGVsrC754ujmeTrYldm9RBHsXwuoxoOZpE6c8/q2Wyk6ICqhIQfSYMWNYuXIlFy9e5OWXXy50TFVVnn322WIXrCgKubm5xb5OCCFEJaaqsPpVyEgA73rQ6a0Su/XqQ3F8tuk0ANMfa0zDGhK8lRlVhb+mwN+faNtNnoTes8BS8nGLiqtI32G1bduWX3/9ldq1a6OqqnEpcP2+4ixCCCFEIYd/gaO/g4UVPPI5WJfMDJvH4lIZu/QgAC+0r0XfJjVK5L6iCPIMWv7nggC64xvQ9zMJoEWFV+TsHL1796Z3796cO3eOCxcukJ2dTadOnVAUhQULFhAcLCObq7L4+HimTp3K6tWruXDhAtWqVaNJkyZERkbSuXNngoKCOHv2LAB2dnbUrFmToUOHMnbsWJT8nK8xMTGF3kfW1tYEBgYSERHBxIkTjedNmjSJ5cuXExUVVebPKYQoRSkX4I8x2nr718CvaYncNjVbz7DF+8jSG3gw1IvXutctkfuKIsjVwW8vwL+/gWKhtT43G2zuWglRIoo9EX1AQAABAQGF9rVs2VJS3FVhMTExtG3bFjc3N6ZPn07jxo3R6/WsXbuWESNGcPz4cQCmTJnC888/T3Z2Nhs2bGD48OG4uLjw4ouFZx/bsGEDYWFh5OTk8Pfff/Pcc8/h6+vL0KFDzfF4QoiyoKqwKhKyU8CvGTw4uoRuqzJh2WHOXs2khps9s59oipUMJCwbukz4+Wk4tQEsrKH/V5LCTlQqxQ6irzd48GAURcHd3b2k6iMqoJdeeglFUdi9ezeOjo7G/WFhYYX6yzs7O+Pjo02U8NxzzzFv3jzWrVt3UxDt6elpPK9mzZosXLiQ/fv3SxAtRGV2eCmcXAeWNlo3jhL6qn/xzrOsPhyHtaXCp4Oa4u4oM+yWiaxkLYXduZ1aDugBiyGks7lrJUSJMimIXrRoUQlVQ9xEVUGfaZ6yrR2KPK1uYmIia9asYerUqYUC6AJubm437VNVlS1btnDs2DFCQ0PveP+9e/eyf/9+hgwZUqT6CCEqoIwr8Od4bb3Da+BdMt0tDp9P4d1VxwB4vWd9mgZKg0+ZSL8Mix/Rpmq3c4VBSyGwlblrJUSJMymIvpULFy4QHx9PZmYmLVq0wN7evqSLqBr0mTDNzzxlv3ERbG4OiG/l1KlTqKpKvXr17nru+PHjefPNN9HpdOj1euzs7Bg1atRN57Vp0wYLCwvjeS+88AKDB0sfOiEqrT/HQ1YiVG8IbSNL5Jap2XpG/LAfnSGPrg2q82zboBK5r7iLtEvwTW9tFkLHavD0b+DT0Ny1EqJUlEgQnZaWxkcffcTChQu5ePGicf/hw4cL9ZVesmQJv/76K66ursyfP78kihZmVpBlRSlCy/W4ceOIiIjg8uXLTJw4kU6dOtGmTZubzvvpp5+oX78+er2ew4cPM2rUKNzd3fnggw9KvP5CCDM78Scc+UUbdNb30xLpxqGqKq8vO0RsotYP+qPH7ivS7yhhousDaBd/GLICPGubu1ZClBqTg+hTp07Rs2dPzpw5Uyht3a1+YbVu3Zqnn36avLw8hgwZQrt2JZdAv9KxdtBahM1VdhGFhoaiKArHjh2jX79+dzzXy8uLkJAQQkJCWLZsGSEhITzwwAN06dKl0HkBAQGEhIQAUL9+fc6cOcNbb73FpEmTsLMrmXRXQohyIDsFVuUPIGz9coll4/hu51n+OByPtaXCZ082w9VBUqmVuhsD6IiV4FHL3LUSolSZNEQ5JyeHhx56iNOnT+Pg4MBrr73GqlWrbnt+zZo1CQ8PB2DFihWmFF35KYrWpcIcSzFabDw8POjevTufffYZGRkZNx1PTk6+5XXu7u6MHDmSsWPH3jVnuKWlJbm5ueh0uiLXSwhRAax/B9IuasFWxwklcssjF1J477p+0E0C3ErkvuIOCgXQNSSAFlWGSUH0559/zsmTJ3F0dGTbtm188MEH9OrV647X9OzZE1VV+eeff0wpWpQjc+fOxWAw0LJlS5YtW8bJkyc5duwYs2fPpnXr1re9bsSIEZw4cYJly5YV2n/16lXi4+M5f/48f/75J7NmzSI8PBwXF5fSfhQhRFmJ+Rv2fa2t954NNkX/Bux2snQGRi05gM6QRzfpB102bgqgV0kALaoMk7pz/PrrryiKwiuvvEKTJk2KdE3jxo0BOHnypClFi3IkODiY/fv3M3XqVMaMGUNcXBze3t40b96cefPm3fY6b29vnn76aSZNmsSjjz5q3F/QvcPS0hJfX1969erF1KlTS/05hBBlRJ8FK0Zq682fgeAHS+S20/44xpnLGVR3sWX6Y42lH3RpS78sAbSo0hTVhPm3vb29SUxMZNOmTbRv396438LCAkVRbhpYCBAVFUWzZs2wsbEhOzv73mteAaWmpuLq6kpKSkqhVtXs7Gyio6MJDg6WPr+iVMh7TJQrG9+Drf8DZz8YsVNLg2aiTccTeGbRHgC+G9qSB0O9Tb6nuAN9Fix6GC7s1QLoIStlEKGoNG4Xr93IpO4caWlpALi6Fv0XYEHgbG0tAz2EEKLKuXoats/S1nt+UCIB9NX0HMb9cgiAZ9oGSQBd2vLy4LdhWgBt5waDf5cAWlRJJgXRnp6eAFy6dKnI1xw+fBiA6tWrm1K0EEKIikZV4Y+xYNBB7c5Qv08J3FJlwq+HuZKeQ2g1J8b3uHvOemGiTe/B0eXaVN4DFoPXnSfNEqKyMimILugH/ddffxX5moULF6IoCq1ayexFQghRpRz9HU5vBEtb6PW/YmUCup2le8+z7uglrC0VZj7RBDtryxKoqLitA9/Dto+19T6zS6w/uxAVkUlB9KOPPoqqqnzxxRecPXv2rudPnjyZXbt2ATBgwABTihZCCFGR5KTDmvw0du0iS+Tr/7NXM5i08l8AxnSrS5if6V1DxB1Eb4OVr2jrD46FJoPMWx8hzMyk7BwRERF88sknHD9+nA4dOvDZZ58VSnGnKAp5eXls376d6dOn88cff6AoCvfffz99+pj+NZ4QQlRIBj1kJUNWEmQna5OOZKcUXtdnQ55e6/pgyNVe83LByk5LB2ftANb22mLrCi6+2kA9Fz9wqgYW5axFdsuHWk5ot5rQ7lWTb5dryOPVn6LI1BloGezB8w9KVohSdeUk/PSU9p4MexTCJ5q7RkKYnUlBtKWlJStWrKBt27bExsbSp08fHByu5frs3bs3ly5dIjMzE9D6rvn5+bF06VLTai2EEOWBqkJOKmQm5i9XISv/NTMxf73gNela0KxLL916KZbg7APOvte9Vr+27eQDTtXBwRMsTPpCsmgSjsHOudp6r/9pgb+JFvwdzf7YZJxtrfjk8fuwtJB0dqUmKwm+/z/tvet/P/SbWzbvGyHKOZOn/a5duzZRUVE8//zzrF692jhrnaqqnDlzptC53bp14+uvv8bX19fUYoUQouQZ9FoAnHEZMq7kr1+BzPz1guDYuH5Vax2+V3au+YvbzevW9mBpA5ZW+a82oFhAbo6WXkyfeW3JSoa0OEi9CGnxoBog9YK23IliqbVaO1XTgmpH72uLUzVw9AKvOuDqf+/PqKqweqz271T3IajT/d7vle/M5XQ+Wf8fAG893AB/d9MnahG3oaqw/CVIiga3QHjixxL5ECREZWByEA3g4+PDypUr+ffff/n999/Zu3cvCQkJGAwGPD09adq0KX379qVFixYlUZwQQhSdIVcLgtMvabOrpRcsCZCRoE0YkZGgBc5ZSfdWhrWD1qpr7w4OHvnrHtq6vcd1x9y1INneXQuUS6PLRZ5Be7bUi1pgnRanBdZp8dfW0y9p/yaq4do5d+JVB0K6aBk1gtoWDqIMuVqwnhwLKefyg/eCgP4iJEZrrfUA5/fArPu0gYVWNmDtCDaOYOsENvmLrZP271Po389DC+rtXMnLU3l92WFycvN4MNSL/2thQoAv7m7HbDjxh/Z/9vh34CTpA0XRqKpKniGXXJ0eg15Hrl5Hrk5bDHo9uXodBp2O3NxcDPrr9un12pKbS65ejyFX267Xtj2+IXXN/ViFlEgQXSAsLIywsLCSvKUQQtxaQVeK1Lj8wO26oDE17tp6xmVQ84p+X8VCC3odvLSWWAfP/Nf89YIguWDd3qNEpqwuMRaWWv9ol7t842fQa63s6dd9sMi4nP+hIn9JT9Bmo7vyn7bsnKsFU4EPaP+myWch5YIWjBdFRgJkmPBsDp5csfFnwFUX2tn4MigsHOWiNbgHaYG3zFBYsmK2w4bJ2nrPD8GviVmrI0qOmpeHPicbXXY2+uws9Dk56LOz0edoS25OjrYvJ4dcXcFrtvaak4Nel6MFxDn5r7r8fXq9FiTnB8tqcX733oVXQM3KHUQLUZYmTZrE8uXLiYqKArSBrsnJySxfvtys9RIlJDcHUs7fsJzTXguC5qL2LVYsrnVRcKqe3yfYGxzzuzIYuy9U04KxqtDf09K6aMF2VjJEb4FTG+DURkg9r20XupcNuAaAWwC4+Off1w9id8Khn7QZ7QYuAVTt/7Vg0Wdq/4e6DO01Jx1y0rRvBLKu72eelN/3/CrVMq/Sv6ABf83P1+pg6wruNcEjWBu86F5Te3UL1OpWnj7oVATpCfDLs9oHpMZPQPMIc9dI3EBVVXIyMshKSyErLZWstLT811Sy01LJTk8nOzODnIx0cjIzyMnIICczA11WFrm6nDKvr6W1NVbWNtqrjQ2W1jZYWVsX2m9pZXVt3doaS6uC49Z4BwaVeZ3vplSC6NzcXJKStK9F3d3dsbKSWL2yi4+PZ+rUqaxevZoLFy5QrVo1mjRpQmRkJPPnzyclJYU///zTeP6ff/5Jr169ePPNN3n33XeN+999913mzZvHxYsXzfEYoizl5V37uj8pRmvVTI6FpLPaelo8oN79PnZuWpDm4qsNnHPxyx9M53dtUJ2jV/nLVlFR2LtBg77aoqpw+QTE7tC6XrgFaouTz80fPDITYf0kbb3LJPBtbFI11OxU3l60iquxx2jnkcLA2nqUxDPaeyc9HnJSIP6QttyKo3d+QO2vBdWu/tr7xtVfWxy8qsaHp6LIM2gBdHo8eNeHhz+RVv4ykqvXk5mSREZyEpkpKWSmJBuXjJRkslJTyEpNITMtlazUVPIMJozJAFAUbOzssLYtWGyxsrtu3cb22rqtLdY2tljZ2GBta4eVjY22XLdubWObHyRr51lZ22BpY42VlTVKJfz5KrHo9tixY8ydO5cNGzZw8uRJVFX746coCqGhoXTt2pVhw4bRoEGDkipSlBMxMTG0bdsWNzc3pk+fTuPGjdHr9axdu5YRI0bw6quvMnbsWHJzc40fqDZv3kxAQACbNm0qdK/NmzcTHh5ujscQpcGQqwXEiWe06Z4Tz2gDlBKjtf0G3Z2vt7LXWjcLAh1j8ON3rcXTxrFsnkVogVS1etpyN9tnaYFt9YbQ8DGTi172byrfxbhiY9WGMUMeRPF2unZQl5n/ASz/A1lSjLZdsOSkXuuicmHfrQuwKGiZr5H//vIr/EGs4NXazuRnKfc2TYOYbVqf9ce/lZ8xExW0GGckJ5KemKi9JiWSkZxERlIiGSlJZCYnk5GSRE5G8fs7WdvZY+/soi0uLtg7OWPv7IKdkzO2jo7YOjhi6+iEnYMjNg4O2Do4YG1nj7WdHVbWNijyAemelUgQPWHCBD766CPy8vKMwXMBVVU5ceIE//33H/PmzWPcuHFMmzatJIoV5cRLL72Eoijs3r0bR8drv2zDwsJ49tlnSUhIID09nb179/LAAw8AWrD8+uuv8+qrr5KZmYmDgwM6nY5//vmH2bNnAzB+/Hh+++03zp8/j4+PD08++SRvv/021tbWRarXvn376NmzJ6+88goTJ07k4MGDREZGsnfvXuOHuy+++EIGvJaEzEQtj6yx/+xJbUk+e+fsFRZWWuuge9B1X8EHgluQ9uroJS1gFVFqHOz6XFvv9JbJLbwJqdlMyZ9U5dUudah9fQANWleNOwX3WcnXAurUC9e6BRUsafFa/uOCc+7Ezi0/oM5PFehc/brX6te6CNm5Vsz37rGVsO0jbb3PbPCuY976lHP67GzSkxPJSEzUXpOSSE+6Snri1WuviYnF6j5haWWFvasbjq5uOLi64eDihoObGw4urtq2swv2Lq7Yu7ji4OKKlY1NKT6huBOTg+iRI0cyd+5cY/Bcv359WrVqhY+PD6qqcunSJXbv3s3Ro0cxGAx8+OGHZGRkMGvWLJMrX5mpqkpWbpZZyra3si/yJ9PExETWrFnD1KlTCwXQBdzc3HBzc8PPz49NmzbxwAMPkJaWxv79+1m1ahWffvop27dvp2vXruzcuZOsrCxjS7SzszOLFi3Cz8+Pw4cP8/zzz+Ps7Mxrr71213pt3ryZfv368f777zN8+HAAnnzySZo2bcq8efOwtLQkKiqqyAG5yJd+GS4f077ST8h/vXxcy/RwO1Z24FFLWzxra6/uQeAerLX6WUp3r0pn63TIzYaAViWS0u7t3/8lNTuXRjVcef7B4OLfwN5NW27XpcSg1wZWpl681t8+5cJ1mU3yB6nmZudPiJOsve/vxNL2uv721Qv3wXeqpn1o9AjW+uCXB2nxsO4tOJzfz7zlC9DI9G8QKiI1L4+stNTCrcXJSWSkJJGRnExmstbdIiM5EV1W0f9O2zk64ejugaObO47uHjgVrLu54+Dqbly3dXSU1uEKwqS/Xtu3b+ezzz5DURQaNGjAl19+SZs2bW557j///MOwYcM4fPgwn376KQMGDLjtuQKycrNo9UMrs5S9a9AuHKyLNgjn1KlTqKpKvXp3/nq3Y8eObN68mQkTJrBt2zbq1KmDt7c3HTp0YPPmzXTt2tXYxaN2bW064DfffNN4fVBQEGPGjOGnn366axD9+++/8/TTT/PFF18wcOBA4/7Y2FjGjRtnrGtoaGiRnrFK0mVqQcKlf7UlIf818+rtr3ENAK9QLR2aZ4i27lFbC5QrYV84cRtXT8P+b7X1LpNMbo1d+288a/6Nx8pC4cP+jbGyLIX3kqX1tS5Dt6Oq2kyS16cJNL7GaQPxClIn5qSCISe/xfvcncu2c83/UBmkBdyKxbUFRfv3c/C81sXEpYbWraSkBkoa9LDrC9j8AejStDJbPAvd3iuZ+5czuXo96VevkHb1MumJV0lLLGgtvkpa4hXSkxLJTE4iz1DEjDOAla1tfkDsYQyOnTw8cfLwxNlde3X08MDaxrYUn0yYg0lB9BdffAFAcHAw27dvx9XV9bbntm7dmq1bt9K8eXOio6P5/PPPJYiuBK7v+34n4eHhREZGotfr2bx5Mx07dgSgQ4cOzJkzB9Bajzt16mS85pdffmHmzJmcOnWK9PR0cnNzcXFxuWM5u3btYtWqVSxdupRHHnmk0LHRo0fz3HPP8d1339GlSxf+7//+zxiwV2mZiRB3UBuQFXdIW088fZu0cIr2x947/6tz7/rgXVcLmKXfpACtP21eLoR0hZqm/Y5Py9bzzu9aN44X2teigd+df/5LlaJca9GuVv/O5+qzCgfV1+cjT0/Qgu/ks9rx7BTtZy7uYPHqY+emdXcqyEPukJ9P284NbJ21n8eC3Ns2jmBlq31YsLDOf7XSfs7XvKF9uwRQozn0+ghqNCv+v085oKoq2elppF5O0JYrBa+XScsPnDNTkot8P3sXVy04LmgxdnXTWo3drrUaO7p5YGNf9G9vReViUhC9bds2FEXh9ddfv2MAXcDV1ZXx48fz4osvsm3bNlOKrvTsrezZNWiX2couqtDQUBRF4dixY/Tr1++254WHh5ORkcGePXvYtGkT48aNA7QgevDgwSQmJvLPP/8wZMgQAHbu3MkTTzzB5MmT6d69O66urixZsoSPP/74jvWpXbs2np6eLFy4kIceegib6/qKTZo0iUGDBrF69Wr+/PNP3nnnHZYsWXJTsF2pZafAhR1w8QBc2K/94b5dS5mDF1QP0waGVQ+D6g3Aq66kChO3F3cIjvyirXd+2+TbfbT2BPGp2dT0dGBU5wr0zZG1vda/373mnc/TZeQPiIzRBttmJQGq9gFWLXg1aB90r+9mos+41q2kJDh4at8aNHmq3H9rpNflkJpwieRL8aQkxJNyKZ6Uy5fyXxPQZ9+9e4WVjS3Onp44eXhprcX5rcYFi6ObB45ublhaSXc/cWcmBdHx8fEANG3atMjXNGumfcK9dOmSKUVXeoqiFLlLhTl5eHjQvXt3PvvsM0aNGnVTv+jk5GTc3NyoXbs2AQEBrFixgqioKDp06ACAr68vQUFBfPzxx2RnZxv7Q2/fvp2aNWsyceJE473Onj171/p4eXnx66+/0rFjRwYMGMDPP/9cqN9znTp1qFOnDq+++ioDBw7k66+/rrxBtJqntYjpMiA9TRvstfr/IP0WQbN7MPjep/UZ9bkPfBppA6WEKI6N+ekqG/Y3OaXd/tgkvt2p/cxPe6QRdtaVMEWhjaPWqn23lu3rXT/JUMHU81mJ16akz0q+Lvd2fv5tXTrk6rTBkwadljUnT69N+37fE9DpTa0Vu5zI1elIir9IUtwFkuPjSI6/SHJ8HEmX4ki/eofxF/kc3dxx8aqGi3c1nL28tVdPb5w9vXDx8sbOyVlajkWJMCmItrOzQ6fTkVGMlCzp6drkCLa20jeospg7dy5t2rShZcuWTJkyhcaNG5Obm8v69euZN28ex45pXxWGh4czd+5cQkJCqF79WoBW0KWjVq1aBAYGAhASEkJsbCxLlizh/vvvZ/Xq1fz2229Fqk+1atXYuHEj4eHhDBw4kCVLlqDX6xk3bhyPPfYYwcHBnD9/nj179tC/f/+S/wcxF4M+/w9mpvbHU5+JMc9yrqr90QQtYPZrqn1l69dUC5jt7v5NkhB3dHYHnFynBWbhE+9+/h3oDXlMWHYYVYX+zfxpG+JVQpWsBBRF+3mt4D+zqqqSmZJM4oVzXD1/jsS48yRdvEDixQukXknQPizcho29A27VfXGtXh3Xaj75i7bu4uUt2SpEmTEpiA4ODubgwYOsWLGC9u3bF+malStXAlCrVi1TihblSHBwMPv372fq1KmMGTOGuLg4vL29ad68OfPmzTOeFx4ezrfffmvsD12gQ4cOfPXVVzz++OPGfX379uXVV1/l5ZdfJicnh4ceeoi33nqLSZMmFalOPj4+bNy4kY4dO/Lkk0/y7bffcvXqVQYPHsylS5fw8vLi0UcfZfLkySXxT1D2VFUbuJSTca3VyXCLFEqKpdbaZWsDjgoM3QDuPmVfX1H5bcpPXdpssJaFxQRfbj3DiUtpeDjaMPGhYrTSinIpMyWZy7ExXIk9y9ULsVrQfOEc2elpt73G1sERd78auPv44ebji5uPn3FdWpJFeaGoNyZ2LoY333yTadOmYWNjw+rVq+ncufMdz//rr7/o1asXubm5vPHGG4VmqqsKUlNTcXV1JSUlpdAAuezsbKKjowkODsbOrgok8hfFp6ra17A5ademRy5oWb6elX3+gCJHre+ypS0oirzHROmK3QkLu2uD1l6JunOWi7uIvpJB95lb0eXmMWPAfTzS9N7vJcpWrl7P1fOxXI45w+Wz0Vw5F8Pl2LNkpabc+gJFwbVadTxrBOBRIwB33xp4+NbA3a8GDq5uEigLs7ldvHYjk1qiIyMj+fTTT0lLS6Nnz548//zzPPvsszRt2hSL/MEJeXl5HDhwgAULFvDVV1+Rm5uLq6srkZGRphQtROVn0GtBc8FyU9CsaIFyweh7G0dtxL0QZW1r/uQcTQaaFECrqsrE3w6jy83jwVAv+jWpUUIVFCUlL89ARlJSfraLK6ReSeDK2WgSzkaTeOHcrVPDKQpu1X3wCqiJV0BNPPwD8awRgLtfDUn7Jio0k/7ienl58fPPP9OnTx90Oh2ff/45n3/+OTY2Nnh4eKAoClevXkWn06b2VVUVGxsbli5diqenZ4k8gBCVRl5efitzftB802Q7BUGzM9g6aVPylvOR9KIKuHgATq3X8hq3e9WkW/26/wI7Tl/FztqCqf0aSUtkGctKS+XquViSE+LJSk0hMzWFrNRUstK09fSkRDKSElHzbpX+UmPn6IR3UC28awbjHRiEV0BNPP0DsZZvwEQlZHKzVbdu3di5cycvvPACe/fuBSAnJ4e4uLibzr3//vv58ssvue+++0wtVojKITdHG2mfnaoFztzQu8raPj/na37eV4tKmKFAVGzb8tNONnxMm43yHqVk6Zn2hzYI+ZXOdQj0LP/ZiSoqQ66eK7FnuXTmFFfOneXq+bNcORdb5BzKioWFlhrO0xtnD088AwKpFlQL75q1cPb0kg8/osooke9+mzRpwu7du9mzZw8bNmzgyJEjJCYmAloKtIYNG9KlSxfuv//+kihOiIrLkKtlzchJ04Ln3OzCxy2staC5YLGUPKWiHEs4Bse0weI8OMakW81Y/x9XM3TU9nZkaLt7mNpb3JKqqiTFXST+9H/En9KWhLNnMOhvMaYCcPGuhruv1ifZwcUFe2dX7F1ccXBxxdHNHWdPLxzc3LCQD/RClEwQXeD++++XQFmIAnkGLU+zPlNLO6fP0AYH3sjGCWxdwM4FrOxMniZZiDKz7RPttX5vbQbLe3T0Yirf/hMDwJS+DbGxkm5K90qXnUX8qf+4+N9x4k4e5+LJE2Snpd50np2jE9Vrh+JdMxjPGgF4Bmj9lG3s5RsAIYpKRiEJURKuD5gLXm9sZS5gaat1zbBz0VqbZTCgqIiunr42O+GDY+/5Nqqq8s6KI+Sp8FAjX8kJXUyZKcmcP/4vF479y/lj/3L5bDSqWrjPsqW1NdWCa+MbUhefkDr41A7FrbqvdLsQwkRV4q/31q1b+d///se+ffuIi4vjt99+KzRFtaqqTJ48mS+//JKkpCRatWrFZ599RlhYmPGcnJwcxo4dy48//khWVhadO3dm7ty5+PtL+qUqp2AmQGML8x0CZgtrsHbQBgQWvErQLCqD7TO1n4WQruDX5J5v89uBC+yJScLe2lJyQhdB6pUEzh89wvljRzh//ChJF8/fdI6zlzd+ofXwq1MP3zr1qBZUS6awFqIUmPTX/MCBA7Ro0QIbGxtOnTpFjRp3Tkd04cIFateuTW5uLocOHaJBgwamFF9kGRkZ3HfffTzzzDO3nKFu+vTpfPLJJyxatIg6derw3nvv0bVrV06cOIGzszOgpfNbuXIlS5YswdPTkzFjxvDwww+zb98+LC2lb1ilZtBdN4VuhhZA3zgAEG4ImO21denTLCqjlPMQ9aO23n7cPd8mNVvPtD+OAzCycwh+bvYlUbtKJTk+jnNHD2tB87EjpF5OKHyCouAVUJMa9cLwr9eAGvXCcPaU1nwhyoJJQfRPP/2Eqqo8/PDDdw2gAWrUqEGfPn345ZdfWLJkCVOmTDGl+CLr2bMnPXv2vOUxVVWZOXMmEydO5NFHHwXgm2++oXr16vzwww+8+OKLpKSksGDBAr777ju6dOkCwOLFiwkICGDDhg107969TJ5DlBGDPj9jRtrt+zErlvnBsuO1VmYJmEVVsX22lrc86EEIbHXPt5m5/iRX0nOo5eXIc+1kFlsAvS6H80ePEB21l+gDe0mOL5zpSrGwwKdWKDXqh+FfvyE16jbAzsnJTLUVomozKYjevHkziqLcNkC9lYceeohffvmFDRs2lFkQfSfR0dHEx8fTrVs34z5bW1s6dOjAjh07ePHFF9m3bx96vb7QOX5+fjRs2JAdO3bcNojOyckhJ+faVMypqTcP7hDlQ0HfQFcXZ5KPbbn5hNvMBHjT9a6uJCcnl0WVhTCP1DjY/4223v7e+0Ifj0/lm/zBhJP6hFXpwYTJ8XFa0By1j3P/HiZXd+3vhoWlFb6hdfCv3wj/Bg3xq1MPGztpsReiPDApiD537hxAsbpl1K1bF4Dz52/ux2UO8fHxAFSvXr3Q/urVq3P27FnjOTY2Nri7u990TsH1t/L+++8zefLkEq5x+RIREUFycjLLly83d1WKT1UhKwnSLwHw9SeT6NW5nXbM2p5Fv6zhmZdepXu3bqxZu9Z4WXJyMv/P3nnHx1Fdf/uZ2ZntXV223HsBm2bANFMNoZcQIAmkENIIvCaUFAjkl0AqNaGGXgIJBEIg9NimmGIDptgGd8u2urS9Tnv/mNVKsiVbtmRZsufhc7l37twpux7NfufMueeEQi7mz5/PUUcdBUB9fT1PPfUUv/rVrwb6U1hYDBzZGDzxVXMOwPADYfSRO7UbwzC47rllaLrB3KmVHDGhrJ9PdHCj5HNsWvYZ6z75kPVLPyRSX9dlvbeklNEz9mf0zAMYOW1fK2KGhcUgpU8iurW1FQDnDmQicjjMFJ9NTU3bGTmwbDlL2TCM7c5c3t6Yn/3sZ8ybN6+4HI/Hqamp6duJWvQdwzDdNeL1XbICBkvLKR+7DzgCINnB9R6SJPHG//7H/PnzmTNnTo+7rKysJBAIDMTZW1jsHvJpeOJcaPgUPGVw+t07HY7xhU/r+WB9G05Z5NpTBmZuzO4mHY+x9sMPWLX4XWo/XYqqdLiJiTYb1RMnM3rGAYyeeQClNSOtyBkWFkOAPr0/a7fM1tbW9nqbdgu03+/vy6H7jcrKSoCtLMpNTU1F63RlZSX5fJ5IJNLjmO5wOBz4/f4uZW9i+fLlnHTSSXi9XioqKvjGN75BS0tLcf3LL7/MYYcdRjAYpKSkhJNPPpk1a9Z02ceiRYuYMWMGTqeTAw44gOeeew5BEFi6dCkADz30EMFgsMs27WM685///If9998fp9PJmNEjuOGXV6NmE6Zvs6/KHOSrMsWBZC9u5/F4+Na3vsU111zTf1+MhcVQQ83DP74Jte+aD5lf/xeUjtupXWUVjd+9ZE4m/MGR4xi2B08mjDc38dF//81TN1zD3d/7Bq/cfRtrP/wAVcnjLSll+jEncOoVP+eHf/s75/7qdxx02tmUjRhlCWgLiyFCnyzRU6ZMoampieeff55TTz21V9s8++yzQIdbx+5m9OjRVFZW8tprrzFz5kwA8vk8Cxcu5Pe//z0A+++/P7Is89prr/HVr34VMF/ff/755/zhD3/YJedlGAZGJrP9gbsAweXq8028vr6eI488kosvvpibb76ZTCbD1VdfzVe/+lX+97//AWbUlHnz5jF9+nRSqRTXXXcdZ5xxBkuXLkUURRKJBKeccgonnXQSTzzxBBs2bODyyy/f4XN55ZVX+PrXv87tN/6Sw/ebxJoNm/jeVb8Bu4df/d/vwbbtP4Prr7+ecePG8fTTT3P22WfvzNdhYTF00TV49nuw+jVzbsAF/4CqfXZ6dw++s57N0QyVfiffO2LPm0wYb2lm5Xtv8+W7b9GwemWXdWWjxjD+wEMYd+DBlFpi2cJiyNMnEX3SSScxf/58HnnkES688EIOP/zwbY5/8803efTRRxEEgZNPPrkvh94hkskkq1evLi6vW7eOpUuXEg6HGTFiBJdffjk33ngj48ePZ/z48dx444243W7OP/98wJws9p3vfIcrrriCkpISwuEwP/3pT5k+fXoxWkd/Y2QyfLnf/rtk39tj4kcfIrj75oN31113sd9++3HjjTcW+x544AFqampYuXIlEyZM2Crc4P333095eTnLly9n2rRpPP744wiCwH333YfT6WTKlCls3ryZiy++uPcnoqv89obruOaH3+TCM8x/qzGT9+X/8i6uuubn/OrGP293F9XV1Vx22WX84he/6BJf3MJij8cw4IX/B8ueNUM4fu0xGHHwTu+uJZnjr/PNe/FVcyfisu8Z4UGTkTZTOC96i7qVKzpWCALDJ01lXEE4B8p7fnNpYWEx9OiTiL7kkkv4/e9/T2trKyeddBI33ngjF1988VY+0tlslnvvvZdf/OIXaJpGOBzmBz/4QZ9OfEdYsmRJF3/Wdj/lCy+8kIceeoirrrqKTCbDD3/4w2KylVdffbUYIxrglltuQZIkvvrVrxaTrTz00ENWjOge+PDDD5k/fz7ebkIvrVmzhgkTJrBmzRquvfZa3nvvPVpaWtB1M8tWbW0t06ZN48svv2Sfffbpcj0ddNBBvT+JVDPE6/lw6acs/vgTfnvHA4Bp+dE0jWw2Szqdxt2LB4arr76ae+65hwceeKD4NsLCYo9CyUCioVDqzQm3Gz+AZf8CQYSz7oNxfTMa3PLaSpI5lenDApw+Y/thUQczSjbLqsXvsvzN/1H72ScdWQIFgWETpzDx0MOZMGs2nmBo2zuysLAYsvRJRHu9Xp544glOOukk0uk0l19+OT//+c854IADqKoyU4rW1dWxZMkS0uk0hmEgyzJ///vfB9Q/+KijjsIwukmOUUAQBK6//nquv/76Hsc4nU7uuOMO7rjjjl1wht2ck8vFxI8+HJBjdXfsvqLrOqecckrRJaYzVVWmD/Ipp5xCTU0N9913H9XV1ei6zrRp08jnzQk33U3c3PLfURTFrfqUdCGUYMz0v9cNgxt++XPOPPf8rc6lt5Nig8EgP/vZz7jhhhsG9C2KhUW/kEtCfDPENkJsM8TrIFFn1vF6c1022vP2p9wGU8/o0ymsbEzw9w/M+TO//MpkRHHouTLoukbt55+y4s3/seqDd1FyHZlKqyZMYtIhhzP+4Nn4wlayEwuLvYE+5x8+9thjiz6n9fX1pFIp3nzzzS5j2kXOsGHDePTRR4thwSx6RhCEPrtU7E72228/nnnmGUaNGoUkbX2Ztba2smLFCu65556iG9Dbb7/dZcykSZN4/PHHyeVyxaguS5Ys6TKmrKyMRCJBKpXC47RDbDNL3yvEeRZs4K9iv/3258u1Gxg3bucmQrVz6aWXcvvtt3Pbbbf1aT8WFv2KYUC6FaK1HSW2sVBvMsu2BHJnJCf4Ks1Jtr5K8FbC2KNhwvHb33Y7/PbFFegGnDC1glljSvq8v4Ek1tTI5wte5/MFr5Fs7ZgcHayoYvLhc5hy+ByClVW78QwtLCx2B30W0QBz5sxhzZo1PPLII7z44ot8/PHHxSgMpaWl7Lfffpxyyil8/etfL4ohiz2HWCxWjJbRziWXXMJ9993Heeedx5VXXklpaSmrV6/mySef5L777iMUClFSUsK9995LVVUVtbW1W0XAOP/88/nFL37B9773Pa655hpqa2v505/+BHSEJJw1axZut5ufX/n/uPTrp/LBx5/y0D//Y+6gYgqIEtdddx0nn3wyNTU1nHPOOYiiyKeffspnn33Gb37zm15/TqfTyQ033MCPfvSjnf+yLCx2BiUDkQ0QWd9Rou3LG8zMmtvDEYDAMPAPM2tfNfirwV9VaFeBM7jTYeu2xcKVzSxc2YxsE7jmxMn9vv9dgaoorFnyPp/97xU2fLbUfFgBnB4vEw89gilHzKFq/CRrcqCFxV5Mv4hoMAXG9773Pb73ve/11y4thggLFiwoRjZp58ILL+Sdd97h6quv5oQTTiCXyzFy5Ejmzp2LKIoIgsCTTz7JT37yE6ZNm8bEiRO5/fbbu7yl8Pv9/Oc//+EHP/gBM2bMYPr06Vx33XWcf/75RTeMsNfBY3/5HVfe8AfuffARjj3iEK6/7ld874c/BtG8vE844QReeOEFfv3rX/OHP/wBWZaZNGkS3/3ud3f4s1544YX8+c9/Zvny5Tv/hVlYtKPmIN1mWpK3LNGNEFkHbetM14vt4auCQA0ER0CwUAdqIDDcFM7O3RNiU9V0fvui+ffyzUNGMbrUs1vOo7fEmhr55LX/8vn818gkOrLMjpg+g+lzjmPcgYcg2e3b2IOFhcXegmBsy1nYol+Jx+MEAgFisVgXn/BsNsu6desYPXr0DiWu2Rt5/PHH+da3vkUs0oZLjZqTB6HouoG7dKcsaYIg8Oyzz/Yp+sZDDz3E5ZdfPijTflvX2ACh5iDVAukW89pMtdft7ZaCSG6BVCvkE73ft8MPoZEQGtVRgu11DUiD8y3fE+/X8vNnPyPolln40zkE3PLuPqWtMHSd9Z9+zNJXXmDtx0uKVmdvKMy0Occx9ajjCFZU7uaztLCwGCh60mtb0m+WaAuLXcEjjzzCmDFjGDZsGJ988okZa/qsM3AlN4BWyPjlCpuvpW19+3E+77zzKCkp2amU9F6vF1VVLYG6J2AYkE+ZfsSZCGSiZjsb6yiZwnKmYEVOtZgW5R0Rxe0INnCHwV3SqYTBP9wUyOHREBpt9g0x14HldXF+/7KZWOWyY8YPOgGdS6f5fP5rLH31BaIN9cX+kfvMZMbxX2HMfgciWhGYLCwsesAS0RaDmoaGBq677joaGhqoqqrinFPn8tsrvm0KaJvdfF3dD6+pV61aBbDTIQvbfcKtkIeDDF0zxW2mO5eJtoJIjnRqt5kCWVd2/piCDTylZvZLTyl4ygvtEvNNiae0IJRLTWHsDILYp+Sxg5IvGxJ8/f73iWUUZo4IcsGskbv7lIrEW5r5+OX/8OnrL5PPpAFwuD1MPfIY9j3+K4Srh3b4PQsLi4HBcucYQCx3jj6QjZk+ou3ixl1qWp9FS7T2hj3qGsslzRjG7W4SyaZOLhOd3SYK1mF28hYnyuAKgStoCl1XEJyBLUqwIIoLwthTYk7g2wNF8Y6wqjHB1+59j9ZUnn2GB3j0O7MIuHa/Fbpx7WqWvPAsX777FkYhLn24ejj7nXQaUw6fgzzU/zYsLCz6Bcudw2LPQNfMGLbpVnPZ5jAnTDm2TuJiMcTJxguJPurMOl6ok40dJdHYu0gUW+IMbu0u4QoV6s7tUEeR3UPOfWIwsLopyXn3vU9rKs/Uaj+Pfnv3CmjDMNi47FPef/Ypaj//tNhfM3UfDjj5DEbP2B9hL3/oGaoYhmEmuTHAMHQMfYtlwzD7MIoPTYZu9mMYhe3b2zpGYbuu6zr1FbZvP3a773xxHxhdntm72iiNTv1dPkTXcy229U6fqfC5tlpvbNE2x4NR3K54XlsdGBAEhEICMgSh0+1OKHQJnRY79Ql02a7L2OKut1jf6Zgdx+56Lltti9BldcWYcQTKB9fcBEtEWwxe8ikzfJeWM5c9ZWYEAsv6PPTIxgsxizeaD0Xx9kQfndr5ZO/3J3vAW1ZwkygvtLtxm/CUmSLZZt3qBoJ1LSnOv+89WpI5Jlf5eew7s3abH7RhGKz9aDHvP/sU9au+BEC02Zh46BHs/5XTqRg9drec1+7AMAxUJY+ay6Hkcqj5PGrebGtKvrisKopZ5xWzX8mjKQqqYi5rimIWVS0Us23oelH06e1tvbMQ7E4YFsYaBmwpCLcQhR1i2egiNi32Lo6/5CdMP9oS0RYW28YwClbHwkQfUTajEjh8297OYvdgGKY/cbTWjF0crTUffmIbTeEc3Qi5WO/25QiYST78VV0TfnjLC+0Ks1hvIgYdXzYkuPCBD2hK5JhY4ePx784i5Bn4UHC6rrHq/UW8/+w/aN6wDgBJtjPt6OM58NQz8ZeWD/g57Qi6rqFks+QzGfKZdKHOkM9lUNrb2QxKLouSzZDPZs3x2QxK1uxTCmJZyWVRclnUXG53f6zBQ7v1VQBBEBFEAUEQi9ZVQRSgUAsIIIoFQ6xgJkEThA4rarHdvr/CtkLX4xWbnW2vnZuirbhvoRAC1jy39vNrP0ehGCJWEAUQxK22o33b4rl2OnbnE2u3ohet1J0t50Yno3VXa3tniuOL+9pi39sc37Nlvst5ddqxJxhisGGJaIvBhZrrmjzCGTTDd4nWpbpb0TVTELetNWMXR9ab8Ysj68x/r1x8u7vAFTIjTgSGF5J+VJvxi/3VHck+7IM7hrDF1qxuSnLH/1bx/Cd1GAaML/fy+MWzCA+wgDYMg9UfvMs7/3iM1k1menHZ6WLG8Sex/1dOH5AfYMMwUHJZsskkuVSSXCpFNp0y2+mUWVIpcuk0+XSKXCZNLp0in06Ty6TJp9NdUonvCmyShGR3IDkcSHY7kmw3l+1yobZjk+TiOptdNmvZrEVJwlYoZltGEEVT3BUFnikKO/q2EITtolEUEAtvFoXO27ePF+gytl0ctovJDmFriuAt+7YSxO3C0sKin7CUicXgIRM1rZiGZkY4CAw3hZd10xsYDMOcmNeyElpWQdsaaF0LratNsdweUrAnPOXmG4PgCAiONB9+AiMKonm4ZT3ew9hSPAMcP6WC35wxjVLvwMWsNgyD9Us/5O2nHqVp3RoAHB4P+514GjNPPAWXd8ffYLWL4Uw8TjaZIJOIk0kmisvZVIJsMmm2kx3tXDqFrmn98rlEmw2704XscuFwuZGdTuwut9nndCI7XdhdLuwOsy07ndidTnOdwyySw1FoO5AdDiS7wwrZZ2HRj1gi2mL3Y+imT2x74hTZY4qxQZo8Ysij6xBdD01fQMuXpmBuWWmW7DbcLmz2QpKP0V3jF4dGmcLZ7h6Y87cYUPKqTmM8y+ZohrpCWVYX5+VlDV3E80+OGc+0YYEBPbfazz/lnacepW7lCsC0PO9/0qnsf/IZOD1dH9qUXJZ0LEo6FiMdj5KKRsnEY2ZfPEYmES/WmXgMTdn5MIeiTcLp9eJwe3B6vDg8HuxuD063B7vbjcPtweHx4HC5sbs9OFyuQu02hbHLjU2WLauphcUgxxLRFgNCjxkB1ZzpGqCYsVrxlIO/ilGjx3D55Zdz+eWXb3ffo0aN6vXY3nLUUUexcOFCAD7++GNmzJix0/t66KGH+Na3vgXAZZddxq233toPZ9gLDMMMCahkIRU3I5w8dS1sfBvUTPfbCKJpRS4ZVyhjITzGbAeGW5M6hzhZRSOSztOWyhNNK0TSeSKpPJFCO5ZWiGYUouk8sYxCNK3Qls5vNam/nd0lnls2buDNxx9k3cdLANNFYcz+sxg+eSpKNss7Tz1GOhohFYuQjkVJRSPkMz1c89vAJsu4fH5cXh/OYu3D5fPj8Hhxer04vT5cHh8OrxenxyySw2EJYAuLvYBeieja2tpdcvARI0bskv1aDBwXXXQRDz/8MACSJBEOh9lnn30477zzuOiii0wfNaC+vp5QaAufxEzMnIjW7r4RGmnG3gUWL16Mx9M7/9gdGbsjXHzxxfz617+mtLQUgKqqKi6//HKuvvrq4pirr76aP/zhD7z++uscc8wxxf5jjjmGiooKnnjiCc4991zmzp3LmWee2e/nWMTQTbGsZEyBrBSKUXi1rBay8DV/Ya63OaB0ApRPgtKJUDreXA6PAdmKlTvY0XWDjKKRyqtk8hrxjEprKkdrMl+sWwrtSCpPa8oUy6n8zrka2CWRYUEX1UEn1QEX1UEXx02p2CXiWdc0sqlkh7tEwXUiHYsSqd/Mhk+XEmtq6LKNpqqsev8dVr3/zjb3Lcl23MEgbn8AdyCIq1C7fX6z7Q/g8gdw+fy4/QFLDFtYWGyTXono0aNH9/uBBUFAVdV+36/FwDN37lwefPBBNE2jsbGRl19+mcsuu4ynn36a559/HkmSqKzsFJbGMMzIG8lGc1l2my4Bndw3ysrKen38HRm7I7jd7i7nfdRRRzF//vwuInrBggXU1NQwf/78oojO5/O8++673HbbbQC4XC5cLhd2ez9NtNL1glBOmyWfATVLj0lFJKcZ4cSZhxP/CJUTzO/bsirvErSCwM3kNbKKVmxnCu1soZ1V9ELduehmrepk8irpvFYoZjuTN4VzVtn58F6SKBDy2Am5ZYJusw657cV20C0TcNkJFtolHgelXnuvxaSqKOTTKbKpFLl0sjCRzpxQl22fYFfsS5JLpzsm3aXTKNkdtxi7/AG8wRCeUBhPMIwnFDLrYAhPIIg7GMITDGF3uSxRbGFh0W/0SkRbSQ0ttoXD4SiKzWHDhrHffvtx8MEHc8wxx/DQQw/x3e9+t8Od49STOWTWgRw5awa/+/lPzDi+/mqaW1qprq7m1VdfZc6cOVu5aFx//fU88MADNDY2UlJSwtlnn83tt98ObO3OUVtby6WXXsobb7yBKIrMnTuXO+64g4qKiuK+nnvuOa644gquvfZaIpEIJ554Ivfddx8+X8+TkObMmcMVV1yBqqpIkkQikeDjjz/m1ltv5YknniiOe//998lkMsyZM6fvX65hmII53y6Y0z0LZsEGsqujSK6CgBYhm4WIAqNngJWVrQuqppPKacSzCsmc2lGyXetUTiVVELSpnEoqV2gXxG270M2pAxu/1m234XVIlHhNsVvisVPidVDitVPqcRDy2Al7zP6w147PIfUoJA3DQFOUYmi1XCZKpiXF6lSSbDpJLpkk2y6GC4I4m+oklJNJVGU7E1B7icPtwen1YugGyWgbesHo4i8tY9rRJzBy+r54wyV4giFs0u7PhmhhYbH30SsR/eCDD25z/Z133snixYuRZZnjjz+egw46iIqKCgzDoKmpicWLF/Pqq6+iKAoHHnggP/jBD/rl5PdkDMNAze+eYPKSXeyzteboo49m33335V//+hff/e53zU41Dy0rueD04/njXY9w0+//hOApAeCpp56ioqKCI488cqt9Pf3009xyyy08+eSTTJ06lYaGBj755JNuj2sYBqeffjoej4eFCxeiqio//OEPOffcc1mwYEFx3Jo1a3juued44YUXiEQifPWrX+V3v/sdv/3tb3v8THPmzCGZTLJ48WIOOeQQ3nrrLSZMmMDZZ5/N//t//490Oo3b7Wb+/PkMHz6ccePG7fgXpykFwZwy3S+UtOmqsSWiZFrwZVdHbbPvlZFMVE0nnlWLfrzxrGrWGaWwrBDPqCSy5rp4RiGRVUhkVRJZlYzSP9EUusMl23DbbThlGy67DZdswymLOOVC3xbLTknEabfhlMzxbrsNt13Cbe9Y9tglXIXaKXf9W1UVhVwq2SFyU1FykRS5zSma0mk2drL85jNpM9RapzqfSfdbdInOk+ccHq/pQ+zxdPS7u2kXJt45PV7qvlzB/EfuK0bcCJRXcPj5FzHh4MMsa7KFhcWgoFci+sILL+xx3Xe/+12WLFnC8ccfz/3338+wYcO6Hbd582YuvvhiXnnlFaZPn8599923c2e8l6Dmde69bOFuOfb3bjsS2dH3V/2TJk3i00870uwSrwN1POee9hX+3/U38/ZHyzn88MMBeOKJJzj//POLPtSdqa2tpbKykmOPPRZZlhkxYgQHHXRQt8d8/fXX+fTTT1m3bh01NTUAPProo0ydOpXFixdz4IEHAqDrOg899FDR8vyNb3yDN954Y5sievz48QwbNowFCxZwyCGHsGDBAo488kjKy8sZM2YM77zzDscddxwLFizonRXaMMxsjLmUma0vn+rIztiZdguz3W1GLpHdYJP3SMHcPvGtNZnvMgHOrDsmwEXTCtGMWSey/eMW5pBEvA4Jn1PC65Tw2Atth4THYdZuu4THYcNT6HPLNtyODqHbWfQ6pJ17GDUMg3wmQzYZJ5tMmtEiImYotUgyQX0hBnEmmTAFczJZtAar+f5LqiE7nGYkCZe7y6S54oQ6j7cogtv7HW5TMNtdrmL83x0l2lDP6/f9lVUfLALA7nJz8JnnMvPEU5Fky+JsYWExeOhTdI6nn36aBx54gAMPPJAXX3wR2zbiTw4bNoz//Oc/HHLIITzwwAMcd9xxfPWrX+3L4S0GOYZhmCKi3fcZHWQPZZOncdxxx/H4449z+OGHs27dOt59913uuuuubvdzzjnncOuttzJmzBjmzp3LSSedxCmnnIIkbX35rlixgpqamqKABpgyZQrBYJAVK1YURfSoUaO6uG5UVVXR1NS03c901FFHsWDBAn72s5+xYMECrrzySgCOPPJIFixYwBFHHMF7773HnXfe2f0OdM0M5ZdLmKJZ70YASs4OwWz3mMtDVDAbhkEso9CcyJklmTMnvCVztCQLE+BS5nJbKk96Jye+AfgcEn6XjN8lE3BJ+J1m2++UCbhkfM7C+kLtdZhjvAWhbJe2foDrDwzDIJtKkm4PqRZvD7MW6xJSLZOIF9pxdK0PDwaCYIpZd7vQdXex9trdnsJ6D3aXG4fb3aW2u8yYwzsrgncWJZvlvX89yYcvPoemqgiCyD7HnsCh51yAOxAc0HOxsLCw6A19EtH33HMPgiAwb968bQrodmw2G1dccQXnnXce9957ryWit4FkF/nebVu7NgzUsfuDFStWMHp4pWmBBjNtd+k4EEQuuOACLrvsMu644w6eeOIJpk6dyr777tvtfmpqavjyyy957bXXeP311/nhD3/IH//4RxYuXIi8hWWqKNy3YMv+LbcTBAFd3777zJw5c7jssstobW3l448/5ogjjgBMEX3HHXdw/PHHd/WH1jVTLOfipptGutXM/NdxZFMw272F4h4S2Rl13aA1lacxnqUhlqUpkaMxbtbNifbaFMqKtmNzKtonvoXddkIembDH3mUCXKjQX5z85jJFsmTbNSK4J3RdIx2NkmxrJRlpIxlpIxVpJdHWWgivFi3GJd4ZUSzZHWY4NY8Xp89fDKfm9PpMq3C7ddjrK/oPOzxeHC43QjdvdAYrhmGw8r13WPDo30i2tgAwcp+ZHPWN71A6YtTuPTkLCwuLbdCnX+v2V/UTJkzo9TbtYz/77LO+HHqPRxCEfnGp2F387/XX+Oyzz/h/3/pVR6enzIxDDJx++ulccsklvPzyyzzxxBN84xvf2Ob+XC4Xp556Kqeeeio/+tGPmDRpEp999hn77bdfl3FTpkyhtraWjRs3Fq3Ry5cvJxaLMXny5D5/rjlz5pBKpbj55psZP358cbLikUceyYUXXsiLL77I6NGjGVnqgdY1psW5OAmwINLtXvOBwu41XTMGmeAxDIOWZJ76WIa6aJa6aMZsx0zBbIrm7A6J44BLpsxnTnwr9ToKpTABzmOnxGunpDAJzu/seeLbQKJrGonWZqKNDcSbm4i3NHWqm0m2teyQ/7DD7cEdCODyF0Ks+QPmciG8WntoNbP4kB17/gTQ1s0b+d8Dd1P7uTnHwV9WwZyLvsfY/Q8aFNeAhYWFxbbok4hOJBIAvXoN3k772PZtLYY+uVyOhoaGjhB3/32Rm373O04+9nC+ec6pZuzhLfB4PJx22mlce+21rFixgvPPP7/H/T/00ENomsasWbNwu908+uijuFwuRo4cudXYY489ln322YcLLriAW2+9tTix8Mgjj+SAAw7o82cdM2YMI0aM4I477uCCCy4o9leXhRlZM5y777qTc04+FmIbOzYSZXD6TbcMT6kZk3k3ousGTYkcGyNpNral2RTJsDmSYXO0o+R7EWFCEKDU66DS76Tc56Dc76Dc5yzWZT4H5T4zSoRDGpwPhLl0mmhjPbHGeiINZh1raiDa2EiitRljO28nBFHEEwzhDZfgDYXxhEqKodbcgWAhvFoQtz+I1F8hDvcAlGyWd5/5Ox+++G90TcUmyxx02tkceNrZyHYrU6mFhcXQoE8ieuTIkaxcuZJHHnmEE044oVfbPPLII4CVaGVP4uWXX6aqqgpJkgiFQuw7eSy3/9+VXHjuGYil40y/3m644IIL+MpXvsIRRxyxzeshGAzyu9/9jnnz5qFpGtOnT+c///kPJSUlW40VBIHnnnuOSy+9lCOOOKJLiLv+Ys6cOTz88MMcddihkGiATBTUDEfO2pf7//4ccw49wLQwOwNmafdpFqWiJX5XoxsGeVUnr+rkVJ10JktLMscND37AR5tT2xXJggBlXgfVnRJsVAVdVAWcVPidVAZM4SwPsAvFzqDkc8Qa6onU19FWt4lIfR2R+s1EGurIxLeR5hwzY52/rIJAeQX+0jL8peX4y8qLtScUGnDf4aHO+k8/5vX7/kKsyZwrMWb/g5hz4fcIVlRuZ0sLCwuLwYVg9CEI9DXXXMMf/vAHBEHgpptu4qqrrtrm+D/96U9cddVVCILAVVddxU033bSzhx6SxONxAoEAsVgMv99f7M9ms6xbt47Ro0fjHMoxfHMJaFtnZsmzOcyU0dLQtCodddRRzJgxY+sU3WrWFM0F4dyBYLpnuALgCIC0tdWxx33uJIZhoGimSC4WRSOv6iia3iWStKHmaarbxPXzm9ic0LCJAtVBJzUhN8NDLoYF3QwLmYJ5eNBNZcC5yyba7SqyySStmzfStnljR71pI/GWJnrMW42ZqCNYWUWooopARRXBikr85RUEyyvxBENDyr94MJNJxFn46P0sW/gGAL6SMo75zvcZu/+s3XxmFhYWFl3pSa9tSZ9EdDQaZcqUKTQ2mhaFffbZhwsvvJADDzyQ8vJyBEGgsbGRxYsX8+ijj7J06VIMw6Cqqoply5YRDAZ39tBDkj1aRKdbIboRMEzLc2gM2Ab/BLmeOOqoo1i0aBF2u513336T6eOGQyZixm0uIoDDC86QaXHu4fM+/vjjXHLJJWQyGS699NIdFtG6bhREspnII6toRdG8rT9fURBwSCJ2SUTQFZo2b0RxlTK8LEBVwDngE/H6CyWbpXVTLS0bNxRL68YNJCNtPW7jcHsIVQ8jVDWMUFU14erhBCuqCFZW43C7B/Ds9z4Mw+DLRW/yv4fuNS3/gsDMuSdz2LnfwO6yvnsLC4vBx4CIaDAnbZ1wwgls3rx5uxNBDMNg+PDhvPzyy0yZMqUvhx2S7JEiessU3s4gBEcOuslyO8rmjbVkok2QjTGizIfd3imah8O3XeHcmUQiUXzQDAaDlJaWdjvOKLhgtKd9bk8DnVe1nhJ6IwgCDpuIQzbFskOyFYWzJArFv8mheI0ZhkGitYXmDevMsn4tzbXriDTU92hZ9paUUjKshvCw4YW6hpJhNbj8AWui2gCTS6dZvfhdPp//GptWfA5AyfARHH/JpVRP6PskXwsLi72HeOJz/L5pA3e8XoroPpsKp0yZwrJly7jhhht46KGHiEQi3Y4LhUJ861vf4rrrrtvmCVkMIXQdohsgGzWXvRXgqxqyMY0B010j1cIwKQolNiBs9stucIXMYtuxhA8+n2+rdOKabhREskamIJaziobegzi0iQIOycxo55ALYlkWsdv6nl1yMGAYBrGmRhrXrqZp3Woa162hcd0asol4t+PdgSClNSMprRlJSXs9fIRlVd7NaKrK+k8+YsVb81nz4QfF5C+iTeLgM8/loNPPtlJ0W1hY9JpMZjMrV/2alpbXmTnzMcKhQ3b3KXWhX963+/1+/vznP3PTTTfx4Ycf8tlnnxGJRDAMg3A4zPTp09l///2xW7PT9xw0xfR/VlKAAMEacG890W9IYBhmHOf2JCjt2OzgCoM7ZE4O7NMhTNHcnna6p1TToiDgkEWcUiENdCEldGer8p5AKhqhfvVKGlavpGGNWXKp1FbjRJuN8LAaykaOLpbykaOt5BuDgEwyQdumjbTVbTLL5o3Urfqyy4NPqHo4Uw47iilHHI2/rHw3nq2FhcXuxDAM0AwMVcfI6xiKhqHoHUXt1Kfq6HmFtpb3iDS/D5qfMv08Uv4NhA/YA0V0O3a7nUMOOYRDDhlcH9Kin1Gy0LYGtLyZkjo82nRxGGoYhunnnKg3P0s7Dr8Zis7h75NVXTcMUjmVeEYlnlVQtK4RMWSbiKuTUHbJNtN/eQ8SywCaqtC0bi11K1dQ9+UK6levJNHavNU4myRROmI0FWPGUjF6HBVjxlFSM3KPSPVsGAa6pqEpeVRFQc3ni20tn0dVFTSlo6hKHl3TMHQdXdcxdK1QG2CYvvCGYUB73RM9XEs9XmHdjFey2Y7sirEo6XiMVCy6zbcEkw49gsmHz6FizLg97noeSsQUlTXpHGsyOTZn8zTkVRpzCg05hca8QkRRGe9xcqDfw4EBswxzWsauvRlDMzDyGnpOw8ipGHndbOe1jv68ZgrhvIbeqW0ohT6l67IplLViqoTeYqOSUk4rLof2373hYbtj6M78stg95FPQttZMV22zQ3gsyEPDx7YLuSTEN3dMFBRspiXdU9qniCKGYZDJa0QyCrG0gtopzrAoCPicEj6nmYJ6KISH2xmyySSbv1zG5i+WU7dyBY1rVqMq+a6DBIHS4SOoHDeByrETqBw3gdKakdi6SeU+EBiGgZrLkc9mULLZLeoM+WwWJZdF2aJWczmUfA41n0fNmbW5nOsQy/k8aj6PYezgL8gQwFdSRnjYcLNU11BaM4LqCZMRe5HB1qL/yOk6y5NZlibSLE9mWJ3Osjqdozm//UyZnyYyfJrIcP9mM1tktUNmdsjL/xtZyRj30IyutDdhWnYLYjZnCtqOdrsY7truqFWMbGHbrNlPL3IE9BkBBFlEkG0Iklhoixg2naxaS1atwxDzIIn4Q1Nw+8cgyCJSxeBz1+vXX6y1a9fy7rvv0tDQQDqd5gc/+EGPk6gshiDZOETWgaGD7DIF9A76B+921KyZhjxbiA8siKYvt6cM+hDvN6doRDMK0XSeXKebkCSK+F0SfqeM1yEhinueVS4VjbD5i2VsWrGMTSs+p7l2/VYT/5w+P9UTJlE9YTLV4ydSMWZcv0RmMAwDJZshl06TSyXNOpMil06TTxfqTLpYmyXTUWcz5DOmYB5IkWuTJGyyHcluxybJSHYZmyRjkztq0WZDtNkQRBFRFM141KL5pqK9IAimVXlHrL09WK57smdLdjtuf7CQbTFQzLYYqKjE7nTt6Ee36COGYbAhm+eDWIqP42k+jpvCOd/Dv2uFXWKs28kIp51Kh0yFQ6bKbtY+SeTzRIYl8RQfxFIsS2aoyyn8syHCvxuj/GBEOT8ZWY7HeijqVwzdMEVsRkXPdhayqilwswWBm9PQswUBnFW7COB2UcwOZI7dIWwCosOGYLchOGyIdhuCXTSX7TZznSwiFMaIcvu6gjhuHyub48T2flkEW1f3RMMwaGr6LytXXo+itAECw6q/xtixP0WWg7vm8/UT/SKiP/74Yy6//HLefvvtLv1nnXVWFxH917/+lRtuuIFAIMDy5cuR94DXtHsNmQhENmCGsPOaWQiHUpIJXTUTo6RaKMoFd4k5EXInHwR03SCWUWhL50nlOiw+oiAQcMkE3aZw3tNeZ2dTSTYt/5zazz+h9vNPaN1Uu9WYUPVwhk+aQvXEKVRPmEyoqrrH76HdCpxJJsh2KUkyyQS5VJJsKkkuadbZVJJcOkUulSKXTm03q+AOIQjYnU5kp8usHS5kp9MsDgd2pwvJYbZlR6Hf7kCy25EcDqT2tt1e7G8Xy1JRNEtW7GmLXqMbBl+msrwXS/FeNMn70RQNeWWrcWHZxr4+N/v43Ix3OxjrdjLW7cC/nWyh49xOTq8IAZDSND6Op/lrbRPz2xLctqGRfza0cd3Yak4rD+5x97K+YigaelpFS6voaQW9vc6o6BkVI9NpOW0KZj1jukn0+NS6s0gFobql6HVIZr+jU79DQnQWlgv9gkMqtkWHaSEeCHK5Jr5c+Suam18FwOOZwORJNxEIzBiQ4/eVPovoF198kbPPPpt8Pt/FN6+7P7YLL7yQa665htbWVl544QXOOOOMvh7eYiBINUNsk9l2BiE0csAy7/WZdr/n+GZTSIPp6+yvNq3pO7w7g4yi0ZbKE0sraIVrXgA8DomQx47fKWPbgyzOmqpSt3IFGz79mA2fLaVxzeqtrLalI0YxfPI0hk+eRvXESYiizfShjcdo3rCWDZ99TCYeIx2Pk0nEySbM2mwntnb32EFEm4TD7cbh8WB3uXG4Peayu33Zjex04XC7sbvaiwu702XWLndREFsC12J3oRkGa9I5Pk9m+DSR5rNEhs+TGWJq14nIdkFgX5+b/QJuZvrczPS7GeG091nkemw2Dgv5mB308kpLnGtXb2ZjNs/3l2/gkbpWfjt+GJO9e+bbB8MwMDIqWlJBTynFur1oKcUUxKmCWE4pGEofH+AlEdFpQ3RKCM52QdtZ4Hbu71xLHRbgdmuxbWj95hiGQUPDv1i56jeoahxBkBg18oeMGvUDRHHo+OX3SUQ3NDRw3nnnkcvlmDp1Kn/605847LDDtgrn1Y7X6+X000/niSee4KWXXrJE9GDHMMz4z4l6c9ldCoHhQyeEnZKB2EbTjxvMLIqB4eDc8RCLmm4QTedpTeXJdoqsYZdEQm47Ibd9yGX42xaxpgbWf/IR65Z+xMZln5DPZLqsdwdD+EvLcfv92CSZXDrJpuWf8eW7b5FJxLeZIbAnRJuE0+vF5fPj9Hpxen04PT6cXg8OjxdnoTi8hdrtxeExxbJkd1hWMoshh2EYrEhl+V9rnPltCT6Kp8l082bFbRM5wO/m4KCXgwNeZvrduHbhnApBEJhbFuDIsI87a5u4o7aRRdEkxyz+kq9VhblydCVVjsEvdAzDdJvQEnn0RB4toaAl8h3LSQU92V4roO+EeVgE0S0juiSzdksdbZdUXBZchX5nRy3Ie85vxo6QyzWx4otraG1dCIDPN5XJk36Pzzf04sf3SUTfcsstJJNJRo4cyVtvvdWrDIRHHXUUjz/+OB9++GFfDm0xECSbOgS0txJ8lVsJ6IsuuoiHH34YAEmSqKmp4cwzz+SGG27A4/Fs9xDbSoX98MMP89e//pVly5YhiiIzZ87kqquu4uSTT972TouuG2YEiIv+36+IpvI895//7rAFPVuwOkdS+aLVWRQE/C6ZsFvGswe4ayjZLLHmRjZ8+jHrP/2YxrWrzcxy2yAdjZCOdh8THgBBwOn14fb5O/xoCz61Lp/fLF4fLn8Ap9eHy+dDdrqG/HdpYbE92hSVN9sSzG9LsKAtTuMWk//cNpGpHhfTfS6m+VxM97qY5HEh74a3Wy6byBWjKzmnMsQNa+p4sTnGE/VtPNsY4ZKacn40ohzfdtxFdhWGZqAl82ixnFmiebREDi2eR4/n0eJ5tHgOI79j1mLBacPmkRE9MqLX3tH2FISxRzb73BKiRzYtwtZ9q9c0Nb/CF1/8AkWJIIp2Ro+6jBEjvosoDs04F30661deeQVBELjiiit6ncJ74sSJAKxfv74vh7bY1aTbIFFntv3V5uS7Hpg7dy4PPvggiqLw1ltv8d3vfpdUKsVdd92104f/6U9/yl/+8hd+85vfcPrpp6MoCo899hinnXYat912Gz/+8Y+73zATNV1P9ILPoDMIjqAZB7qXAlrXDeJZhbZUnmQnX2eHJBL2OAi55SGTMtswDHRVNaNLZLN88vrLJBrqSLQ2E21qJN7ciJrL9Xp/Lp8fTyiMJxjCEwji7lS7A0Hc/gCeYAiXz29FaLCwwIycsTiW4s22BAsjCT5NZLq4w7pEkcNCXo4K+zgs5GOc24FtkImyES4H908bzeJYil+vrmNxPMWtGxp5tK6VK0ZV8I3q0n4X+XpGRY1k0aI5tGgONZpDixaWY6ZY7q1fseCwYfPZEX0yNp8dm9eO6LNj88odtdesB8oXeG9DVZOsXPUb6uv/CYDXO4WpU2/G6xl8Yet2hD6J6HXr1gFw0EEH9XqbdlePZDLZl0Nb7EqycYgWJot5yrcpoAEcDgeVlZUAnH/++cyfP5/nnnuOTCZDNBrlueeeK469/PLLWbp0KQsWLOCiiy5i4cKFLFy4kNtuuw0wr6mGhgb+/Oc/c/vtt3PppZcWt/3tb39LNptl3rx5nHbaadTU1HD99dfz3HPPsfTDxaZ4zka59b7HufVvf2f9qhVc/7ubefjRR4EOP/358+dz6KGHMm/ePJ555hkikQiVlZV86zsX850f/z9iGQVN7/B19jllSrz2QTlJsBh/WFXQFLVQK2atquiqakaw0DQyiTgfvfgc6baWbvclCCKuQIBw1TAqxo4jUF6JNxTGGyopCOeglW3OwqIXrM/keKM1zv9aEyyKJrdy0ZjkcTIn7OPosJ+Dgh4cQ8QP/8CAh+f3G8dLLTF+u6aeNZkcP1+1mbs3NnPFqErOqggh9VJMG4qOGsmitmZQ27JobVnUSA4tYtZGdvvh+RDB5ndgCziw+e0ddaGIfocpnh3WA/3uJBb7iGXLriCTrQUERo68hDGjLxtSvs890ScRrSimtW9HomxEo1GAXr3q35tpj1gw4OTTSMlaBAxwhkwr9A7icrmK18a2uO2221i5ciXTpk3j17/+NQBlZWXccssteL1eLrnkkq22ueKKK7j55pt55plnuPzyy03fW12DphVgFHyVHT4z4obTz09/+lNWrFhBPB7nwQcfBCAcDnP77bfz/PPP89CjT1BSWc3KNRvYuLGWtpQ5wc1uEwm67YQ9Mvbd9LqyHVMoq4UkHJ0TcphiebvRKQQKodK2/nHzl1Uw7oBZjD94NtUTzAmBFhYWO0ZO13kvmuKN1jhvtMZZk+l67y6zSxwZ8nFk2McRIR8VjqH7MCoIAieVBTmuJMDj9a38eX0Dtdk8l31Ry+0bGvnp6EpOKw8iCgJ6XkNtzaK2ZEyxXKi11qxpSd4OokfGFnIgBRzYgg5sQSe2oAMpaApn0St3e1+zGBwYhsa69X9l3bo7AB2no5opU/5MKNR7w+tgp08iurKykg0bNrBu3TpmzpzZq23effddAIYPH96XQ+/xqLkct1949m459k9+dy2yLwyhETs8ifCDDz7giSee4Jhjjtnu2EAggN1ux+12Fy3ZACtXrmTs2LHdpomvrq4mEAiwcuVKUHOQaTOzDRqaGW0jMAKcgeJ4r9eLy+Uik8ni9IfJKBqb4wpLV6ymasRoKifOQBAEpu1fwT4HzCLgkgntJl9nXdfNLHZ5pZDNrpDRTsmbmeq2gRl3uD3GsIQo2tBUtZg0xMx+Z+6jfPRYxh90KOMPOpSS4TUD8dEsLPY4IorK661xXm6JMb8tQbpTRlJJgFkBL0eX+Dk67GOSxzno3mL1FVkUuGhYKWeXB3lqZQPzVzZRsiHBug9jvJqFCRmwJ7dtTBEcNqSwEynsxFbiRAo5sYWcSCEHtpAT0W491A9VcvkWli37f0QiiwCorDidiROvR5KGYHbjbdAnET179mw2bNjAs88+y5lnnrnd8el0mrvvvhtBEDjiiCP6cmiLXYnkNFN599KH+IUXXsDr9aKqKoqicNppp3HHHXdw1VVX7ZLTMwwDQc1B8xcd6br91eApxwAUTUc3oC6aIaNoRNOmb3NtW7q4j1POPo9Lzj+D0446kDnHHMfJJ3+F008+CdsAvFbVdd3McJfPFURzvmhh7hEBMymHLGOT7djkQluSi3GHdV0nl0qRTSbIZ9JdQk5KDgcOr5ezf/l/lA2zhLOFxc6wMZvnpeYoL7fEeT+W7JLnosIucUyJn2NK/BwR8u22CXe7Ej2rojSkUOoLpcEsJ+R1TuhhG9Vhw1XmQi51IRWKrSCcRY+8xz1cWEAk8h6fL7ucfL4ZUXQxadJvqKo8fXef1i6hTyL6wgsv5PHHH+fvf/873/jGNzj++ON7HJtMJvna175GbW0tgiDwne98py+H3uORHA5+8vDTA3Mww4C2NWYoOJsdqWoS7MBM2Tlz5nDXXXchyzLV1dVF9x5RFLsIOaBXbh4TJkzg7bffJp/Pb2WNrtu4gXg8zvhhITB0DMmJKtpp0PykW1JkFI36SBJN12lJ5oofDwHcdgmXLOKUbYw9ejbr1q3j1Vde5vXXX+c73/w6fz/2WJ5+un+/c01VUfM5lFwhFXQuv82YyKLNhiTbsdlls5btBeHc/Y+NmbEva8ZbTiW7uHZIDocZFs7rQ9U0ouksvpKyfv18FhZ7OuszOV5oivJCc4yliXSXdZM9TuaWBjihNMC+vj0ruoyeVclvTqJsSpLfnCC/KYnWlu1+sCgglTiRytxoJQ4W2lQez6X4wikQswuMctn58YgyzqkMDRn/b4sdxzB01q+/k7XrbgN0PJ7xTJ/2Fzyecbv71HYZfRLRxx57LKeffjrPPfccp556KpdeeinnnHNOcX1bWxvvv/8+r776KnfffTcNDQ0IgsA3v/nNXrt/7K0IgoDsdA7MwbJxEBRwOqF0AkiOHdrc4/EwbtzWfyRlZWV8/vnnXfqWLl3axYfebrejaV0TCXzta1/j9ttv55577ukysdDIRPndb36FLMscfNK5fMEotMAI6hsaaYxniz9gXy77HEEQKPU6cMk2SgMe9GyCceXeruftCHDuuedy7rnncvbZZzN37lza2toIh8M79Pnb0TUNJZdDyWVRC7Wmdj85RpSkYga7ztnsehvRQlUUM2FJMtHFgm2TZVxeH06vF8ne8e+obvEdW1hY9Mz6TI5/N0Z5oTnKZ8mOGOkiMCvo4cSCcB7p2rF75WDEMAy0eL5gXU6adV0KtSXT7XhbwI5c5UWu9CBXeZAr3UilLoROEYu+CpygqDy4uYV7NzWzPpPnp19u5M/rG7hkeBkXVJfskZb6vZl8vo1ly+fR1vYWAFWVZzFx4vXYbO7dfGa7lj4H5nvsscc4+eSTWbBgATfffDM333xzUcwceeSRxXHtFsljjjmGu+++u6+HtegvDMOMqQxmMpWdyOLXE0cffTR//OMfeeSRRzjkkEN47LHH+Pzzz7s8QI0aNYr333+f9evX4/V6CYfDHHLIIVx22WVceeWVJNJZjjnhJOLxOP98+mnu/9ujXHn9TbirxpPX4cBDDuPGX17JU/f/hTPPOou3/vcG7y58Hb/fT3XQ/Cxjx4zm9dde5csvv6SkpIRAIMBf/vIXqqqqmDFjBqIo8s9//pPKyspeh2o0DAM1n0fJmaHjlFwWNd+9hdkUyg5kh72QFtqBTdrxPz3DMN010ok4+XSHRUwQRZweM0mJ7NzzfC8tLAaC5rzCv5uiPNsY4cN4x9+XTYDZQS8nlwU5sSxAmX3oTgrU0wpKUxqlMY3amC66Y+jp7h/2bSEH9uE+5GFe7MO9yFVebJ7eff6ALHH5qEourinj8bpW7trYTH1O4fo1dfx5fQMXVJfw3eFlDHcO/QgNezuJxHI+/ez7ZLObEUUnEyfeQHVV/87pMgwDDGPQZZQVjC3ft+8Euq5zyy23cPPNN1NfX9/tmHA4zE9/+lOuuuoqxEH2JQwU8XicQCBALBbD7+/ImpfNZlm3bh2jR4/GOVDW53ZyCWhdDQhQMdWMarEDXHTRRVuFsevMr371K+655x6y2Szf/va3URSFzz77jAULFgDmJMILL7yQTz75hEwmw2dfrKS0cjipnMbjjz7EPx55gDUrvwBBYPK0ffjOD3/CSV85BbdDwmO34bJL3HfvPdx44420tbVx1llnMXHiRO69995iLPLm5mYuuOAC3n33XZLJJPPnz2fVqlXceeedrFq1CpvNxoEHHsgf//jHHt+Q6LpuCuZMhnxBOHcXFcMmy8gOB7LDiexwIDkcfY54oebzxRTZeieLst3txuXz43B7tvs3tVuvMQuLQUpK0/hvc4x/NUZ4M5Io+jiLwGEhL6eXhzihNECJfWglgtCzaodQbkwVhbPeU0QMEaQyd8Gy7MFe7UUe1nvB3Btyus7TDRHu3tjEqrTpamcT4JSyIJfUlDPTv2dbLIcShqZhZLPo+TxGLoeRy6Hnchi5PEa+03JeIdr8HnUbnsTIK9iFEFWlpyMTwMjnO4qidNRKHiPfue6hqGrHeEUFTSNwwy+pPveCAfkOetJrW9IvIrodVVX54IMPWLJkCU1NTWiaRklJCTNnzuSwww7D4Rj6r776wqAU0S2rIJ8ETykEBnbCmW4YZPIayZxKMqeSzmtb+VDLaHjI4hEV3IESnG7vgFhadU0rRrbIZzOoudxW5yaIoimYnU5khwvZ6cBm658fW8MwyKVTpOOxLlZnUZKKGf+kHQgtaYloCwsTwzD4IJbiyYY2nm+KkuoUVWOmz82ZFSFOKw9SPgTC0Ok5DbWpIJQbOyzMWqzn8Ki2gMN0wahwI5cXXDLK3QOWglo3DN5ojXPPxmbejnbkizjQ7+GiYSWcXB60/KY7Yei6KWhzOYxMBj2bw8gW6lwWPZvtELrtfbkcRrGdx8hmMfKF9e37ymbR84VxXfry0Iu5S7uDpkvP4sgf/WZAjtVbEd2vj9eSJHHooYdy6KGH9uduLXYVuaQpoBHAs+2EKv2FbhgksyrRjEIioxRTabcj20S8dhseLYpHacOOiuD0Q3Ak9JNA7Y5294x8JkUunTYtzVucm02SkJ0u7E4nstOFZLf3u6DXC0lR0vFYF19nh9uDy29anS13DQuLHacum+cfDW081dDGukyHRXaUy845FWHOrAgx2j04DT2GpqO2ZAqRMTrcMLRoz2JZ9NuRK9zI5W7kCo8pmivciM7da1UXBYHjSgMcVxrgs0SaezY281xThMXxFIvjKa5bXccFVWG+Oax0yLh6GLqOns6gp1JmSacxMmn0dKeSSqNnMuiZtCmG05nCcsZczmRMQdy5XRDIuxVZRnQ4EOx2BIcD0W4HWSJrNKCQAAkMdxl5ZwU5UScjqmQElbSQJ0WeJDkSZMmKGqoNVBsoEqhiobaZbc0Gqk1AE0EpjNNEsxZkGbfLz/cO2X/3fhfdMLTeUVn0L8l2X+gwSLvuZqUbBqmcSjStEM92ZAMEkEQBj0PCWyh2PYsQXW+GrhME8A8DT9kOx6vuDYZhoOSyZBMJcunUVpMAbbKM3eXC7nQhO11mKLldJGDVfJ50LEomGS/GcxZtIi5fAJc/sENWZwsLCxPNMFjQluCRuhZea4nTbnP22EROLQ9ybmWYWYHB9WCq5zRzgt/mJPm6FEpdEqUpTZd4ep0QfTJyhWlNbhfKcrkb0T347xnTfW7+MmUk146t5vH6Vh6ta6U+p3B7bRN/qW3i+FI/F1SVMCfs73UmxB3BMAyMTAYtkUCPx806kUBLJNGTCfRkstA2i5ZKoidTXZdTaYx0evsH6wcEWUZwuUxR63QiOh0IDieC04HocJp9DntHn90cJzjshfUOc9v2ttNpCmOn0+xz2EmLCq1GkmY1RrMWpSnXQmumlZZMCy2ZFtTcZk52raRU0sjr8GTEzkfpGBDbztmLyKJMyBEi6AwScoTwO/wEHUGCjiABR4CAI4Df7i/W7W2nNHjfnvZJRH/7298GzMlhv/jFL7D1IrJAXV0dv/zlLxEEgfvvv78vh7foC/mU6Q8N203rvbMoqk5rKk9bKo/ayX9YtokEXDIBl4zbbjN/wAwD0i0Q2wwYYLNDaDTY+99PTtc0MskEmXisy2RAQRCwu9w43G7sbjeSvGutIO3h6VKxCLlUqtgv2R24AwGcXt9eO3/AwqIvNOUU/l7fxqP1LWzKdrzROTjg4fzqEr5SGsAzCKJD6HkNpS5JfqMZRk7ZnDSjYnSjlwW7Dbmyw2+53brcn37Lu4sKh8y8UZX8ZEQFr7TGeGhzC29FkrzcEuflljhVDpmvVYb5WlW424goRj6PGo2ix2JosRhaNFqoC8uxGFo8hh6Lo8XN0i6a6c/IRaKI6PEgut1diuB2IboKyy4XottlimFXp2Wns7DsRHC6EF1OU9y6XEWxK/QyelN3aLpGS6aFpnQTTekmGtINNKYbaUo30djWSGO6keZ0M1mthzCGwGi7xndKc3ht0KYKPNzmIWsrY0pJCSXOEsLOMGFXmLAjTMgZIuQMEXYW2o4QLmnPCgMJffSJFkWx+IUcddRRPP3004RCoW1us2zZMqZPn44gCFuFNtvTGVQ+0a1rIBcHVxhCI/ttt4ZhkM5rtCRzxDMqRuHXQBILwtkt42kXzu3oOsQ3QrrNXHYGTPeNfkxB3RFPOUY2mSy6agiCgLMQEk52ugZEtBqGQS6VIhWLoGQ7blgOjwdPIIjs7P8bjeUTbbE38GEsxX2bmnmhOYpa+GULSjbOrQzz9eoSxnt237Vv6AZKY5p8bZx8bYL8pgRqU7pbwSz67ebkvurCJL9qL7agY69IcW0YBnoqzZpNdby8ch0fbtiELRolmIwTTCYYn0szLp8lnEpgxGJokQh6JyPETiFJ2Hw+RJ/PrL1eRJ8Xm9fsE70ebF4vosdrrvN6sHk8pmDuVITdFB0pmU+aYjjdSHOm2WynGouCuSndREu2Bd3YejJ8d/jtfsrd5ZS5yihzl1HqKmU4DYTizyEYKnb3RKZM+ythz6g9ThS3M6A+0YZhsGDBAmbNmsXzzz/PpEmT+mO3FruKfNoU0NCvVuhYRqExniWrdDwceRwSpR47PpeM2N0fm5qHyDpQCq/DfNXgLe839w1d18kmE6TjMdROvmWS3YHb7zetvX14ut8RDMMgm0yQikSKCVcEQcDp8+EJhJC6SXNuYWGxbfK6zgvNMe7b2MzHnZKhHOj38I1hJZxSFsRlG/g3OnpaIVebIL8hbgrnjUmM/NaGI9Fvxz7Ma4aSG+7FXu3F5tvz7gV6Nova3FwoLagtzagtLWgtLeZyaytaaytqa2vRD/i4QumOreKMCAK2QMAswSBisNAOBLH5/dgCfkS/H5s/gC3gx+YvLPt8CK7BayHNqlnqU/XUp+ppSDUUS2O6sVinlN49RNgEG6WuUio8FVS4OxVPBeXu8qJw7uw+YRgGG2rvZc0aMxFZaemxTJt6KzZb/4XDHcr0i4j+9re/zUMPPcTq1as5+OCDefLJJ5k7d25/7NpiV9DuC+0Mgdx3y4xhGDQlcjTGTauqKAgE3TIlHgcu+zYEai4BkfWgqyDYIDQKnD0/8e0ImqKQjse6hIVrtzq7/AFkh2PAbpqGYZBNJEhG24qTBUWbiMsfxO0P7FTMaAuLvZ2IovLQ5hYe2txCY96cz2AXBM6oCPHd4aVM9w1syDQtliO3PkZuXZz8+hhK49ZWZsFuwz7Ch73Gh324D3uNF5t/cE5m7C2GrqO1taE0NKI2NaI0NKA2NKI2NqI2N6E0NaE2t6DHtucz2xXB7UYKh7GFw0ihELZwmLQ/wCeSnUWGzFqHi5jXR9zjwxkOcfyo4ZxZFWaqd/AK4u7IqlnqknVsTm7uUuqSddSn6mnLtvVqPz7ZZ4pgd1lRELeXdrEcdoax7cAbXl1X+HLlr6irewqAmuEXMX78zxGE3e8KNVjol1/vefPmcfrpp3PBBRcQj8c55ZRT+P3vf8+8efP6Y/cW/YmSgWzhZubruxVa1w02RTJEC7PdS70Oyn0OpO1ZftKtEK0125ILwqN3OFNid+SzWdLRCNlUR+gkmyzj9gdw+fwDZnUGMzlKJpEgFY10Es823IEg7kCgz/GjLSz2RjZn89yzsZnH6ltJF8LTldslLhpWyjeqSwYsGYoWz5FbEyO7JkpubazblNhSqQv7SL8pnEf4kSvcg84lwzAMUFWMfN6MC5w3Q6KZESVSHXUqhdoWQW1qMktjI0qzKZB7GxJNcDiQysrMUlqKVFaKrbQUqcRsS+GwuRwOI7q7fwgaB5xZCFP4TGOEfzdF2aRqrN7cwp2bWxjrcnBqeZBTy4NM9g4ua2laSbOibQXLWpaxrNUsG+IbtrudW3JT7a2mwlNBlaeKSnclFZ4KKj2VRYHslvv3oVHTMnz2+Y9obV0ICEwY/0tqai7q12PsCfSbCezkk0/mnXfe4ZRTTmHDhg1ceeWVLFu2jLvvvrtLmmeL3Uyy0aydgT5nJ1Q0nQ2tadJ5FQGBYSEnYU8vhHC6rUNAu0IQGAF98EUuxlSORslnO1LV2l1u3IHAgIeFa3fbSEbauohnTzCEyx+wJgtaWOwEX6Qy/LW2iWcbI0V/56leJz+oKefU8iD2Xfx3pacVUzCvjpJbE9s6LbYAcpUHe40XebgLucKOKOuFhBFp9FiMbIvSNfHEVokoFAxVw1AV0DQMRTWTTqjmOooJKNSOhBSqCpraaaw5ni7LnfbRedvCselrughBMEVxZSVSRTlyRSVSebnZLi832+XliD5fv9yLBUFgVtDLrKCX/xs/jNdb4zzTEOGNtjhrMjlu2dDILRsameB2clp5kJPKAkzyDKy/sm7orI2u5dOWT/mk+RM+bf6UtbG13fole2QPw7zDimW4bzhVniqqvdVUearw2/0Deu6KEuOTT79LLPYRouhk2tRbKSvrybFm76Zf3yNPmzaNJUuWcMYZZ/D222/z0EMPsXLlSv71r39RVlbWn4ey2BnUPGSiZttb2addZRWN9S0p8pqOTRQYGXbjdfbiYSkTgWjhydtdYiZ42cmbg6HrZJIJ0rFoMcpGu8uGOxBEHuDkPqaYT5Nsa0XNmz59pngO4/L7LfFsYbGDxBSV/7bEeLYxwpuRjrdLs4NefjyinKPCW4syQ1GKMXa7JKjIZdEz7UknshjZHHoua2Zhy3VtG/kcWi4PihfDKAVbBUglCELH37Bh6BiperS2VagtX6I2fQnZJEMemw3R4eiIMtGptgWDSBUVBVFchtzeLi1F2E3GMoco8pWyIF8pC5JQNV5tifHvpijz2xKsTGf54/oG/ri+gdEuOyeWmqnb9/e7u5+jsxMYhkFbto0N8Q1siG9gfXw9K1pX8FnLZySVra+Hcnc5U0umMrVkKtNKpzEpPImwMzxoXFByuWaWfnIRyeQXSJKfffe5j2DwgN19WoOWfnfGLCkp4Y033uD73/8+Dz74IIsWLeKggw7i+eefZ/r06f19OIsdIdUMGGD39il0XCKrUNuaRjMMHJLIqBIPDrkXrgmZqOkDDWZs6u0IaEEQePbZZzn99NO79Ou6TjYRN90kCrGdBVHE7Q/gDgSwSQN/M89nMiTaWlEKlnBRFHEHQ7gDQUs8W1hsgWEYGOk0WirVpdbTaTKJJJ81tbGsuZWNbVHs2Sz75rLMyucYg8540cCnKuiZNOvSZlIKPZvByJjZ29gi3vuOIDgC2CqmIVVORyqbjOBw0fkOpcXr0JqXozZ/ida60nSP2xaShGC3I8oy2GUEWUaUzWQVZr/djP1rN2tkCUGSESTJDGcmSwg2yVyW5Y5iN8cgtY+3bbEsIchS1z5ZLvYJcvv2shlX2N6pDKDLW3/jk2ycVRnmrMowMUXl5ZY4/2mO8lYkwbpMnjs3NnHnxibK7BInlAQ4vtTP7JAXTzefWdM1orkoLZkW2rJttGXbiGQjXdqN6UZq47UklES35+OSXEwrnca+ZfsyvXQ600qnUe4u39Vfw06TyWzk46XfJJOpxW4vZcaMh/F5rUAR22KXzGiSZZn777+fqVOncvXVV7NhwwZmz57No48+yrhx43bFIS22h66acZihTxE5ouk8GyMZDMPA45AYGXYj2UQWLVrE4YcfznHHHcfLL7+89YbZWIeAdoVNF47tPHnX19d3CZmo6zqZeIxULIKumpMFbZKEOxDEGwp3K7h3NaqSJ9naWvTBFgQBdyCIJxgaUP9rC4uBwDAM9HgctbXVjLObLGRoSyYLfrNmrXXK3Gb2pzuNMcu2XAiqCqUnepXaQhAKySccXRNUFOr2ZBQ4KxHkagzKQfd13YdNw+bPI4d1pDIBm78cwT4cwf6VjixuW5Z2USxJCNYD9G4jIEucWxXm3KowSVXjf20JXmqO8nprnOa8ymP1rTxW34qETo0tQqWxAW9+OenMOlozrURykV6HhBMQqPZWM9I/khG+EYwPjWffsn0ZGxyLJA6NiePJ5EqWLr2IXL4Rp7OGmTMexu3uv/C3eyq79F933rx5TJ48mfPOO494PM5ZZ53F17/+9V15SIueSLeCoYPkBIdv++O7oTWZY3PUtLwEXTLDwx2vxB544AEuvfRS/va3v1FbW8uIESM6NszGoW0dYJgRQYLbF9AAlZWmy4kpnqOkotFipA2bJJluEj7fbvmh0jWNVLSNdCxWjDnt9gfwhMJWtA2LIYmhKKhNTSgNDSj1DSj1daj1DajNTahNZjgytbnZ9KHtr2MKAnmnk4TdSdrhJON0knU4MNweSgN+hocChPy+HpJUOBFd7cuurokpnE5TyHZznzFUndy6GJllrWSWt6LH83TWSvJwL86JYVyTwsjDvINuIqBF9xiGQTwf3yr8W3u85OZMM43pRhz5NKJzCjnXTPKuGahSGeu0EtZRAtJ+2JybsRufIfMZ9tyXhO1uws4wJa6SLslDSpwllLhKGOkbSY2/Bodt6EZZicU/YenSb6OqUTye8cyc8TAOx65Jwransct/7U888UTeffddTjnlFNauXcujjz66qw+5R2AYBobSu6fg7e9Mh0gT6Aa4S2E7+xVkscuPz5Yh7Eo8DqqDHZM0UqkU//jHP1i8eDENDQ089NBDXHfddQBEGjfx4x98j1cXvksynWH48Bp+/vOf861vfYt8Ps+8efN45plniEQiVFZWcskll/Czn/3MPA9B4MnHHmPOYYeQTWe4/sabePGVV4nF413Gjho1CoAzzjgDgJEjR7J+/Xo++eQTLr/8cpYsWYIgCIwfP5577rmHAw7Yef8uwzDIxOMkI61FQe9wu/GWlCLbh+5N1GLPx8jnUerqyG/ajLJ5M0pdXUddV4fa1GQmPuoFos9nxtn1FpJPeNyFZBQeRHd78gn3FskovMQdDt7MaryU0Xgzp5G2O4oP1GNdDk4qC3BSWZAZvv4NU2YoGtkvI6Q/byH7RRtGtiNes2C34ZwYwjkxjHNiaI+M0bwnoOkazZlmNiU2UZ+qL4aA6xxDOaNux70GEICAupoyNUaJ+jl2eRxRaQKbjGpqVS+aPIyMPIyMfy52QWBy0MORIR+Hh31M87qwDRLf5f4iEnmfTz69GE1L4ffPZMa+f0OWg7v7tIYMA2Iymzx5Mh988AFnnXUWCxcuHIhDDnkMRafuukW7YM9fbHdE9a8PRSjEdzYMg7pYltakOVGuwu+k3Nc1xvJTTz3FxIkTmThxIl//+te59NJLufbaaxF0lWt/diXLV67lpacepHTsPqxes5ZMxrzR3X777Tz//PP84x//YMSIEWzcuJGNGzcWo1sApBMxdFXjgcce57UFC/nn008zcuTI4liAxYsXU15ezoMPPsjcuXOL6ecvuOACZs6cyV133YXNZmPp0qV9ihSTz2SItzQVJzFKdju+klIcbs9O79PCoj/RYjHytbXkN9SSr92AsnETysaN5DdvRm1o2H4UBllGrqxErqxEqqpErqxCqijvCEtWCE0m9jLrpWEY1GbzvNEa54XmGO9FkuiIgAgOmeleV1E4T3D3b+x2Q9HJroyQ/qyZ7PK2LolORK+Ma3IJzqklOMcGEWTL7WIwkMgn2JjYWCybEpuKcZPrU/Wo+vb93cPOcJckIhXuii7xksvcZXhlb7fXWlRReTuSZEFbgvltcTbnFN6KJHkrkoS19QQkG4cEPRwW8jE76GWix9lvExR3By2tC/jssx+i6zlCoUPYZ/o9SJL1e7Yj9ElEz58/H4DRo0dvd2w4HOa1117j//7v/6itre3LYS0GCN0w2NTWEQO6Ouii1Lu1tfX+++8vuunMnTuXZDLJG6+/zrEzR1G7qY6Z06dwwNEngygxavSY4na1tbWMHz+eww47DEEQGDFiBLl0itZNtR3RNkQRf2kZrfEEEyZM4PDDD0cQBEaO7PDVao/8EgwGiy4g7fu/8sorixk0x48fv1Pfg6aqJNtaySTMLI+izYY3FMblDwyaGdUWew9aMkl+/QbyG9aTX7++0N6AsmED2nYSWgguF/bhw5CrhyEPG4Y8rBq5uqPYSkp22j0qp+usy+T4PJHhs2SGzxMZPk9miKlds/TN8Lk5pTzIyWUBRrr69+2NoRnkVkdIL20ms7wVI9dxbFvAgWt6Ka5pJdhH+C03jd1EMp9kQ2IDtfHaYkSL2ngttYlaornoNreVBIkqbxXVnupiXemppMpbZcZP9lT2ya0iKEucXB7k5PIghmGwJpNjQVuChW0J3osmiakaL7fEebnF/C0olSWOCvs4usTPkSEfJfah48rX1PQyny+7HMNQKC09hmlT78A2hF1SdheCYfQ1QKRFb+kpF3s2m2XdunWMHj0aZ8HC02/uHNm4mVZbEKF8MvRikoMgi2i6wYbWNKlCDOiasIuge+vXnF9++SXTpk1j06ZNVFSYPlQ//vGPaWvcxBO3/YqX5i/irIuvZMKECRx//PGcfvrpHHrooQB89NFHHHfccZSUlHD8cccy57DZzD7oIMDM6FcxehzPPPMMZ555Zpexc+fO5eSTT+b444/vOOduInlcf/31/Pa3v+XII4/k2GOP5ZxzzmHs2LG9/uo6XDda0AtJHVx+P75w6ZCbNNjdNWYxeDF0HaWunvy6teTXriW3dh35devIrVuL1tyyzW2l8nLsI0YgjxyBvaYGeXiNKZxrarCF+xZKyzAMNmbzfBhPszadozabZ0Mmx8ZsnrqcsmWCPgBkQWBfn6sQhizAiP4WzoaBsjlJ+uMm0p80oyc7En/YAnZc08tw7VOKvaZ/YhRbbB/DMGhMN7I2tpZ1sXVdSnOmeZvbhp1hanw11PhqGO4bznDvcKq91Qz3DqfcXb5DGff6E1U3+CyZ4e1IgkXRJO9FU2Q6uT8JwEy/mzlhH8eVBNi3n12S+pP6+n+xfMXVgE55+VeYOuXPiKKVz6MzPem1LbFE9A5y55138sc//pH6+nqmTp3KrbfeyuGHH96rbXdERPcbLashnwBPGQSG92qTLWNAjwi78fUQA/qqq67ij3/8Y9GFAswbqCxL1H/0KqHR+9KcVHjxxRd5/fXXeeaZZ/jRj37En/70JwAiba089/TTvP7GG7zw0sscPvtQ/v7YY3iCIWyS1EUYx+NxXnrpJV5//XX++c9/cuyxx/L0008DPYfDW7lyJS+++CIvvfQSCxcu5Mknnyz6Tm+LfCZDorUFJWf6gcsOB77SMuzOwZUBq7dYInrwYeg6akMD+Q0bCqXWrGs3oNRu3OYEPltpKfZRI7GPGoVj1CjkESOwjxyFvWZ4j5nedgbdMFiZzvJ+NMX7sRTvRZPU5XrOTue2iUz1uJjuczHN52K618VEj3OXJELRYjlSHzWS/qgJtbnDF1b0SLj2KcM9o9wUzpbFeZfR7qe8JrqG1dHVrImuMUtsDSkl1eN2YWeYUf5RjPCPYKR/ZDGqxXDfcDzy0HAnyOs6S2Jp/tcW53+tcZanumasHOaQi65KBwU8g8KX2jAMNm1+jJUrrwegquocJk/6rZXGuxssEb0LeOqpp/jGN77BnXfeyezZs7nnnnv429/+xvLly7tGo+iBARfRShqavzTb5VN6lVY7nlGobUujGwb2QgxoZw8xoFVVZfjw4Vx11VUdVmElA5Fazrr4Ci79wcX8+Ke/6LLNPffcw5VXXklba6sZ6zkWwdDNS/CdxUs4+7zzaW1tJVywmPUUtu6VV15h7ty5xbF2u52///3vnHXWWT1+tvPOO49UKsXzzz/f7XrDMMhnMqSibeQLftuCKOILlwx51w1LRO8+9HTatCSvXUNu3Try69aTX7eO/IYNGNmtU0W3I8gy9lGjsI8ejX3MaBxjxpjtUaOw+XY8wo5hGCQ1nVZFpTWv0qqotCkqrYpGW6EdUVQiheWIohFV1WJ2wHYkAaZ73UzyOhnptDPC5SjUdkplaZf+nRiqTvaLNlKLG8iujFA0fUsirilh3PtV4BwfRLBZPs59QdEVItkILZkWWjOttGZbac20mhEuCtEuGtINtGRaegwDJwkSNf4aRvtHMyY4htGB0Yz2j2ZUYBQ++85FiBrM1OfyzG9N8EZbnP+1JrpYqUtkiRNLA5xQ6uewkA/XAF+fmpajsfF5Nm58kGTK1AQ1wy9i/PhfdEkgZNFBb0V0rxx4fv3rXxfb7VEXtuzfGTrvayhw8803853vfIfvfve7ANx666288sor3HXXXdx00027+ey6Idlk1s7QdgW0YRi0JPPUx0zx2DkGdE+88MILRCIRvvOd7xAIBEBToeVLqBjD2aedxP2PP01TPMf+++/P5MmTScVjPPevfzF+7BhaatdzzwMPUlFexowZM/GGS3jp9TeorKwkGAxudaxbbrmFqqoqZsyYgSiK/POf/+wydtSoUbzxxhvMnj0bh8OB0+nkyiuv5Oyzz2b06NFs2rSJxYsXdyuyTfGcJhlpQymIGkEQcPn8Vsg6i+1iGAZ6IoHS0IDa2Fhww1hHbu0a8qvXoNTV9byxJGGvqcE+ciT2kSOQR47EPqLQrq7eZuILwzDI6gZx1RS9zXmV5rxi1opKU16hNa/SUhDNLYpKTt9xm4lLFNjf72FW0MPBAS/7BdzdJqfobwzdQE8raAkFPZEnuypC+qMm9FSHJdw+yo/ngApc00oRndbfaU9oukY8HyeSixDNRonmzNKWbSuK5LZMmymas63b9U3ujE2wMcI/gnHBcYwNjmVscCzjAuMY6R+JbNt7XASqHHbOry7h/OoSMprOwrYEL7ZEebUlTqvSEZfaJQocFvJxXImfY0v8VDt3XTSYXL6FzZseZ9Pmx1GUVgBsNjejRv6QkSO/P6QNQ4OFXlmiRbEj5Jmmad327wyd9zXYyefzuN1u/vnPf3ZxB7jssstYunRpt1FHcrkcuVyuuByPx6mpqRkQS3RL/QYkZ69SEuw0Xzvvh+i6zj+eunurdZ98spyj5pzNz675Mf/613+p3ViH0+ngkEP258bfXsPIkcN5+OF/cv8Df2ft2g2Ioo399pvGr2/4KfvsMwWAUHgKjz16O1/5yrHbHfvSy/P55S9/T21tHVVV5SxZ/F9+8MOf8/77H9Hc3EpJSYiTTz6WX99wJU7n3jd5Ip/X2bSpkca629DUxt19OnslxRutsMXyFgiF/wuAiIiIgA0RodC35X529mR63rzrme3oYWxC305NQEAwbAiG2O3RDUFDlVIoUhJD3PnshBYmgrEj/1oChiGCYQNshVoCQ8IwCsuGRN+ugCGEADabgCiJ2CSx2JZksehGpBoin2mjeFedyGJ1Ai1GoMsuhgktOASlsDuj8M2Zdd++RQNNz9IeBF0Q7TjspchyyZB137h8VAUnlAa2P7Af6Fd3js5pi/VOryj6ms5Y72VM0sFAXV0dw4YN45133ilOjAO48cYbefjhh/nyyy+32ub666/nhhtu2Kp/IER0W8M6JHeyX/ZlMfTJ5w02bmwiGrsBXd+GZdTCwsLCYpdgABsZycfsz8fsz2omYFjuFL3m5ok1nF9dMiDH6ld3jp7E7lASwf3FlpZ3wzB6tMb/7Gc/Y968ecXldkv0QKDjQEm1P9P2jr3EdrA1QvF/u/AAhWJsaV8wQFBB2LV/S4qioeYdNH1xAPlMZJcea29CFwQU2YYq2zD6+dWorhsYmoGh68V5Az1hEwpFNAptA0k0+/qKUohMI4kCcnGHIrJaiCUvGCg2FV00aCFFo2A+vPsNBxONclw7GklVAFVU0MQ8qq3nSYwWPSNiWkJFRERBQBAEBMF8q9GZaC5FXEkjIDDCW4ZH3vbEaV1JoeeiaEocXUthkAa7huHUwFUo4o66DImIghtB8CAKbkTBgyh4EAR3cVnAjSi4CuPchXr3u4poqk42qZBN5ckkFbIJhUxSIZ/e+g2Jt8RBqNLDjEo3cyo9eAJ22rQoX2YldAN0OsK4G/T+d3tbyHIIt2v787WGClO8g29iv+VE1ktKS0ux2Ww0NDR06W9qaiqGdtsSh8OBw7F7XAdKK6t3y3Etto+ZTEYhFc2hF8SR3SnhDTmQ7LvmNVs2myWaUDjtopusiYVDEE3TiEQiNDU10draSktLS7F0dhnbEkEQCAQChEIhwuEwoVCIUChEMBgkGAzidru365L3j8UbueqZTwH4xUmTufgIM9a70pCi9e9foDaabmPeI4YROH4Ur2x8lV+/92sS+QQuqY6fHfQzTh93evE4uq6TSqVIJpMkEgmSyWSXkkqlUPMqqmoWRVFQVRVJkgiHw5SWllJSUlIswWCwS3Qgi96jaRpPP/00K1asYJPNxte+9rUdiqdvaBrZzz+n+S9/JfXWW6YTQkDGfe5cPGccjeZWUfKt5PMt5POt5JVW8vk2lEKtaUlARzeSYCTZEQdPUXQgSX4kKYAsF2opgCT5zCL7C+t9SLZCn+QtrhfFXReCLtGWpX51lLpVZok0pEnWQ8PnHWOcXpnKMQGqR/sJV3kIVboJlLkQrUmxQworOscOMGvWLPbff3/uvPPOYt+UKVM47bTTejWxcLeEuLMYtOi6QTqWI53IF80OTq+MJ+DAJvXvjdS6xvZMDMMgmUzS2tpKa2srbW1ttLW1Fduqum2fYVmWi4I6GAwSCAS6FK/Xi81m464Fa/j9y2a20z+fsy9n7W+GyzQUjcgLa4m8v5G8oKKVy0iHldFktPH0sqdpjDbi0B2MdIykxl5TFM39+bMjiiKBQIBwONyltD8s2O1WGu9t0VlI23ZCSLeT/vBDmm+9jfTixQAITifBr55Dybe/jdwpCVZndD2HokQLwroNRYkWSqe2GkVRYqiFWlGimHbbviIiSV5sNo8prm1ebO21zY1N8iDZPNhs3kLbjc3mMdcV265C26x78jVOx/PUr4nSsDZOw5oYzbUJNHXrzyDaBALlbkKVbkIVbgLlboIVboLlLpxe2ZoIOIBYIe52Ae0h7u6++24OOeQQ7r33Xu677z6WLVvWJYNeT1gi2qI7VEUjFc2RK7wCNCODyLj99n6zSljX2N6Hruskk0kikUiX0tbWRjQaJZnc/pwJQRBwOp3YbDaSeZ14VkNHZFjYjV3QyWQy5HK5nRLFHo8Hn8+H1+st1l6vF4/HgyzLSJLUpeTz+eLDQueyvQcFj8ezlQU+EAgUa1ne/W4BuxtN0/jnP//JF1980SchbRgG6ffeo/nW28h88onZKcsEzziDkou/i70f3BkNQ0fTUgVhHSvUcRTVrFUljqolUJVEoS4sqwlUNYmqJugfEb41ougwRbXoQrS5THEtmrVYaIs2JyJOsimRVEQgFTFIxyEVMVBzEoZmx9AkdM2OocsYmoyuSUh2F/6QD3/Yj6/UT6DUR7Dcjb/UjSdgt+Kh9zOWiN5F3HnnnfzhD3+gvr6eadOmccstt3DEEUf0altLRFtsi3xWJRXNoRRSFQuigNtvx+WzI/bxBmldYxZboigK8XicaDRaLLFYrFji8fgOzXuRbBJ2JJyKhNOQcTlcBMaWsVbawPyG+dhcNv5w3B8oD5Xj8Xj6xQVD13USiUTx4aBziUQi23R1acfj8RAIBPD7/VvVfr8fn8+3V7iLqKrK008/XRTS3//+9ykrK9upfRmGQeqdRbTefTfpJUvMTpsN/1dOovR738Mxblw/nvmOn5umpVG1BJqaQtNSpsDWkmhqElVLdfQX2qqWQtfSqFoaTUujaalCbZb+8WDecXRVxtAlDF1GQEYQZFPIS3ZskgNZdiI7XEiyE5voQBQdiLZCLXbuc2ITncV+UbQX+tqXHWZf+/jC8p4cY7pfRfSYMWP69eTAtHCsWbOm3/c7mLFEtMX2MGNWm2JaLaR9F20Cbr8Dl1feaWuDdY1Z7CjtluxsNouu62iaRk5R+MNLK/h0Y4TqsI87vzkLl8uF0+lElmXT339ZK5Hn16DHzYyL8n5hvmO7mg3JDXxr6reYd8C87Ry5/8hkMkULfDQaJRKJEIvFig8M+W1kheyMx+MpCurOpd2K7vP58Hg8fY5YtbtRVZXHHnuM9evXM2vWLE488cQ+7zP94Ye03H0PqbfeKvZ5jjickm99C/fBBw95FwXDMND1XEFQZ9C0FLqe7VjWM+haptDOmm09i6Zlim1dzxW26Wibdb6w7xy6nsMwene9DhSmaLd3iGzBjiDaC332Tn2FcYXxgigjCvZObRlBkBBF2dxekAv9UvEYgiDh803B6RyY+V67LMTdtmj/Y9hyl931C4IwpOJE9weWiLboLYZhkEuppGK5ou+cKabtOL07bpm2rjGL/iKWVph10+tkFZ1/fv8QDhwV3mqMnlWJvbye1Pv1YMDi0Aquq7wDSZB49rRnGRUYNfAnvgWGYZDJZLpY3rdsJxKJXlvjBUHA7XYXXVI6u6dsWdxu96B1I1m1ahWPP/44TqeTK664ot/OM/P5MlrvuYfE668Xw1A4Jk+m5KIL8Z94IoLlu75dDENH1xUMI4+m59C1HKqaJRlJkIwmSMVSpOIp0vEUmUSKTCpFPptFtCkI7UVUEG0qgi2PYFMQbXlsdg27U0NyqNjsKqKkmtuICoaQwzCUorjfXVZ3gEmTbmRY9bkDcqx+DXF34YUXbnP90qVL+eSTTzAMg2AwyMyZM6moqMAwDJqamli6dCmRSARBENh3333Zd999d+zTWFjsZQiCgNMr4/BIZiSPWB5d00lGcqRjeVNM94Obh4XFjhJwy5wxcxh//2AjDy1a362IFp0SodPH4Z5ZTvTZVRzYMJkDvVNZ7F3GTf+5gb+c8FfkMvduOPsO2kWv2+2mqqqq2zG6rpNOp0kkEsTj8WLdObJIIpEglUqZLgypFKlUqlfHt9vtxeO3C2u3243L5eqxHgjhPXbsWPx+P/F4nC+++ILp06f3y35d06Yy/I7byW/YQNsjjxL917/IrVhB3dXX0PTnmwmdfz7Bc85GKhmYOMBDEUEQsdkcgAOJjtTpPh/QQyQ7VdFItuWIt2SIt2aJt2RIFOpYa5ZscvthJEVJwBt04A058IYkPCEBT1DE5Rdw+sDpNXC4DQwhj6ErBQt6Ht0wa0PPo+sKurFlW0E3FPPBQM8X2nkMQ8Uw1GLbfHBQcdh3zr1oV9Jnn+gHH3yQ73//+1RUVPDnP/+ZM844A2mLNMmapvGvf/2LK6+8koaGBu68806+/e1v9+nEhyKWJdpiZymGxYvn0dX2DFQCbp8dl0/e7gRE6xqz6E+W18U56fa3kESBt68+mspAz9eUoRtkl7ey/K3FfMd1DZqg838bf8RhI47Ad/gw7KP8Q/6VvqZppNPpYui+zqW9v3PZ2RwLkiThcrmKLjRb1lu2Oy/Lcu+jO8yfP5+FCxcyevTo7RrRdhYtGiXy1D+IPPYYanMzAIIs45s7l9D55+GaMWPIXxdDgXxWNUV1a5ZkW5ZEa5ZExKyTbVlS8XyvjM+CAC6/HU/AgTtgx+O34w44cBf6XH47br+My2fH7hz80ZUHZGLhkiVLOPTQQykrK2Px4sVUV2/bV6W+vp7999+f1tZW3nnnHQ444ICdPfSQxBLRFn3FMAyyKYV0LF9082i3Wrt9dmxy92LausYs+puv3v0uH6xv4yfHjGfecRN6tc3v3vgNj296ippcBXeu/SUSNuQqD95DqnHNKEPcRXHSBxOGYZDNZoviOp1OF9uZTIZ0Ot1t3dcYAKIodiuyOxeHw4HT6UTTNP79738D5pvo8vJyHA7HVgay/kDP50m89BJtTzxB9pNPi/2OKZMJn38+/pNOQnTv3rcWezOaqpOK5khGcyQjWZJtOZKRHKlYjlS0UGL57SaE6oxkF4uT5l0FQ5DLZ8fts+P0yuay12w7vTLybrgvDIiIvuCCC3jyySe5/fbb+dGPftSrbf7yl7/wk5/8hK997Ws88cQTO3voIcmeKKIvuugiHn744a36TzjhBF5++eXdcEZ7B4ZhkEurpON51HzH3AKH2wyNJzu63nSG8jVmMTh54dM6fvzEx5R6HSy65mjsvYhtHs/HOeXZU2jLtvFjx7c4edksjMIEWsEl4TmwEu/BVUhh6xrtjGEY5HI5MpkMmUymKMKz2SzZbLbYt2W7fbm/gnCJolhMIma327u0t1VkWe7Sbl9uD2XYPu8q89nnRJ54gviLL2IUJn2KHg/+k08mePbZOKdNtazTgxBdN8gk8qSiprthKpYjHc93bcfzZOL54oT5HUGyizi9MgefNpaJs7qPOd7f9KtPdE+8VZhtO2vWrF5vc/DBBwPw9ttv9+XQFoOIuXPn8uCDD3bp6ylTo6IoW/n1ddfXG3Z2uz0BQRBwemQcbgklq5GO58lnVXJphVxaQXbYcPnsONyS9aNjsUs4YWol5T4HTYkcL31ez2kzhm13G7/dz09m/oTr372eh/WnOWve13F8lif5Xj1aW5bkm5tIvrUJ54QQnoOqcE4KI/RH7vIhTnu8bqfTSSgU2qFtDcMgn89vU3DncrliX3u73ee7M7quF4V8f9IurGVZRh5WjXTJ9xBiMWhsQkilsNXWIv3xD9h9PtzjxuOZOAG717tVPPEtl20221bxxtv7hnoklcGEKAp4Ag48gW1naDYMAyWnFUV1NqGQTuTJJMy06ZlCO5tUySbNPl0zUPM6ybbth6vcHfRJRDcX/Jh6E4uznfax7dtadI9hGCjK9h3+dwU74jsHpmCu7CEjlSAI3HXXXbz00ku8/vrr/PSnP0UQBJ577jl+8pOf8Jvf/Ib169ejaRobN27k0ksv5Y033kAURebOncsdd9xRTKt+/fXXd7vdM888ww033MDq1atxu93MnDmTf//733g8nn75PgYzgiBgd0nYXVLx5pRLKyg5DSWXQbSJuHwygrRrkgtY7L3INpELZo3kltdX8si7G3ologFOH3c6T335FCvaVvCXFXdy/RHX4z1sGNkv2ki+W0duVZTslxGyX0YQ/XY8B1TgOaDSsk7vJIIgFC3GgUCg19upqsrNN99MOp3mq1/9KqNHjyafz5PL5cjlclu1eyqKomy13J7KvZ32vq0IBc3SmVgUPvhgp76LzoiiWBTUnest290tdy7t++mu3rIIgtDt8rbqLdvdLffU13ld5/W7C0EQsDsl7E6JYPn2XXTaRXc2qZBJKvhLBt89oE8iuqysjM2bN/PSSy8xe/bsXm3z3//+F4DS0tK+HHqPR1EUbrzxxt1y7J///Of9mir3V7/6FTfddBO33HILNpuNBx98kNWrV/OPf/yDZ555ppjI4PTTT8fj8bBw4UJUVeWHP/wh5557LgsWLCjua8vtGhoaOO+88/jDH/7AGWecQSKR4K233urXtMJDBdlhI1DmQlMdZJIK2YQZ0SMVzaFoCtmkQvPGBMPHOSzrtEW/cN6sGv4yfxUfbojw+eYY04ZtX6TZRBtXH3Q1F718Ec+seobTx53OjPIZuKaU4JpSgtKSIbW4gfSSRvR4nsT/NpKYvxHH+BCeAypwTSlB6IXriEXfkCSJGTNmsGjRIpYuXcqUKVNwuVz9tn9d14viOZ/Po6pqcblzae/PJxIkl68g+eUX5KMxNJsNzWbDcDqhsgKhtBTd6URV1R7LlsdvP4e9iS2F/LZE//ZKd/vaUrT39MCwow8Poigi+YbhYnBFb+mTiJ4zZw6PPvooN998MyeeeOJ2hfSiRYu45ZZbEASBY445pi+HthhEvPDCC3i93i59V199Nddeey0A559//lbRWPL5PI8++mgxI9Zrr73Gp59+yrp166gppIZ99NFHmTp1KosXL+bAAw/sdruPPvoIVVU588wzi6nX+ysk01DFJol4gw48fjvZtEImoaCk8yg5jVf/tgyP183Uw6uZMKsSh2vwz5K2GLyU+5ycNL2Kfy+t4+FF6/njOb0LX7p/xf6cNvY0/r3m3/zfe//Hkyc/iSyarllyqYvgiaMJHDeSzPJWUh80kFsdJbcyQm5lBNEt4Z5RjvuACuzV3u0cyaIvzJw5k0WLFrFq1Sri8fg2fUN3lM7+1b3muOMAyH7xBbF/P0/shf+gNbcUV8sjRuCfOxf/SSfimDixi7HATIqidxHVmqZtVW/Zbl9uTzjUU2lf3y7Ot1Xaz2XL5c71ttqdS+f+3mBmbNSGZJ6OE2cfR8lxvTPYDhR9+gW95ppreOqpp8jlchxzzDF8//vf56KLLmKfffYp+hsZhsEnn3zCww8/zF133UU+n8fhcHDNNdf0ywfYU5FlmZ///Oe77dg7wpw5c7jrrru69IXDHbFju4vCMnLkyC4pZVesWEFNTU1RQANMmTKFYDDIihUriiJ6y+323XdfjjnmGKZPn84JJ5zA8ccfz9lnn73DfoN7IoIomDOcPTJywqCpzYZNFmndnOTNJ1ey6JnVjDuwgsmHVlE1NmBZpy12im8eMop/L63j35/U8fOTJhPy9O4t1rwD5rFg0wJWRlbyxIonuHBq11BqgiTi3qcM9z5lqK0ZUksaSX/YiBbPk1xUR3JRHfIwL+79ynHvU4bNZyXr6G/KysoYMWIEtbW1LF26lCOOOGJ3nxIAzkmTcE6aRPlPryD17nvEnv83iddeR6mtpfXee2m9917so0fjP/FEU1CPG4cgCEUXjB0S7kOIngR2d/X2RH9369q31TStYz+ajpZT0XIKWl5Fz2noeRVN0dDyGrqioSsqmqphqDq6qqFpZq1rhQcAwaDjP3pse/KDbw5Un0T05MmTeeihh/jmN79JPp/njjvu4I477sButxMOhxEEgdbW1mJqVcMwkCSJBx98kEmTJvXLB9hTEQShX10qdiUej4dx48Ztc/32+gzD6FbEbdm/5XY2m43XXnuNRYsW8eqrr3LHHXfwi1/8gvfff5/Ro0fv6EfZIxEEAdku4fTKnDFvJhs+ibLsrTra6lJ8saieLxbV4y9zMengSiYeXIm/pP9e2Vrs+ew3Isi0YX4+3xznqSUb+f6RY3u1XdgZZt7+8/jVol/x16V/5fiRx1Pl7T7piVTiInDCKPzHjSS3KkJqSSOZ5a0om5PENieJvbgWx7gQnpnlOKeUIDr2/FB5A8V+++1HbW0tH3/8MYcddtigmpAn2Gx4D5uN97DZ6Ok0yQULiL/0EsmFb5Jft46WO++k5c47sY8Zg+/YY/EddyzOadP2WINBX32eDd1ATyvoKbNoWQU9pZrLaQU9raKlFPS0VigKRrbdoi0CO6lZRBAcEqLThuiUEByda5u5zmHDOWnrxE67mz6/y/3a177G6NGj+dGPfsRHH30EmJMH6+vrtxq73377ceedd3LQQQf19bAWexhTpkyhtraWjRs3Fq3Ry5cvJxaLMXny5G1uKwgCs2fPZvbs2Vx33XWMHDmSZ599lnnz5g3EqQ8pHG6ZfebUMP2o4TSsibFiUT2rP2wi3pzhg/+s44P/rGPYxBCTDq5kzIwy7Ja7h8V2EASBbx4yique/pRH393AxYePwdbLTJqnjzudf6/+Nx81fcRNH9zE7Uffvu1jiQLOiWGcE8NoKYXM0iZSS5tRNiaK7h6CLOKcWoJ7nzKcE0KW/3QfmTJlCi+99BKRSIT169czZsyY3X1K3SK63fhPOgn/SSehJZMk//c/4v99ieQ775Bfu7ZooZYqK/Edcwy+Y4/Bvf/+e3S6cUPR0dMKWlrtEMdpUxRryby5nCy0kwp6Rt3prN6Cw4bolhDdMqJLKhbBJSE625cL4rh92WlDcEoIsjhkH2z65Rdy1qxZLFmyhMWLF/P666/z2WefEYlEMAyDcDjM9OnTOfbYY4uv5C32LHK5HA0NDV36JEnaocmjxx57LPvssw8XXHABt956a3Fi4ZFHHrnNpDzvv/8+b7zxBscffzzl5eW8//77NDc3b1d47+0IgkDVuCBV44Icfu4E1n7cxBfvNbDpywibC2XBE18yaloJ4w+sYOT0EiTZsu5ZdM+p+1Zz439XsDma4Y0VjRw/tXexXEVB5NqDr+Wc/5zD/I3z+V/t/zh6xNG92tbmkfHOHoZ39jCUlgzpj5vILG1Cbc2SWdpMZmkzgsNmTlicXopzfAihh2REFj1jt9uZPn06S5Ys4aOPPhq0IrozNq+XwKmnEjj1VLREguTCN0m8/jrJN99EbWgg8vjjRB5/HNHrxTN7Nt4jj8R75BGDMuW4oRvoGbVoCS62Myp6WsXIFPo6l6zZb+xETGbAFMMe2SxuGZtHRvQUBLJb7ljv7iSWt5M1d0+lTyK6trYWAK/XSzgc5sADD7SE8l7Iyy+/TFVV19ewEydO5Isvvuj1PtrD3l166aUcccQRXULcbQu/38+bb77JrbfeSjweZ+TIkfz5z3/mxBNP3KnPsjciO2xMPLiKiQdXEW/NsPL9BlZ+0EikIc2aj5tZ83EzstPG2BlljN2/nJrJYWyWdc+iE07ZxrkH1nDPwrU88u6GXotogHGhcVw49ULu//x+bvrgJg6uOhi3vGMZ6uRSF4HjRuI/dgTKpiTppU1kPmtBi+dJf9xE+uMmU1BPDuOcWoJzQgjRYb1l6S377bcfS5YsYcWKFaRSqSEVPtTm8xE4+SsETv4Kei5HatEiU1AvWIjW2krilVdIvPIKCALO6dPxHnEEntmH4po+HWFXZGjMqWjxPFo8j57IoyUU9EyHKG4XwkbBgmxkd946DIAIoqurCLZ5ZESvKZJtXhnRazfrgjDeWwXxztCnjIXt4UfuuOMOfvjDH/bnee2R7IkZCy2GBjt6jRmGQcumJKsWN7JqSWOXQPd2p41R+5YydmY5I6aEkfaCVM0W22djW5oj/zgf3YDX5x3BuHJfr7fNqBnO+PcZbE5u5qKpF3HFAVf0+XwM3SC/MUHm0+aioC5iE3COC+KcUoJrcgk2/577Sr+/uPfee6mrq+OYY47h8MMP392n02cMXSf7+eckFywkuWAB2eXLu6wX/X48Bx+M57DZeGfPRh627Tjohm6YrhGxnFni+a3reB4jv3NRMbq4S3SyAG/lPuGUtli2DVlXid3JgKT99ng8ZLNZ3nvvPcsC3QssEW2xu+jLNWboBg1rY6xa3Miapc2kYx1iRHLYGDm1hNH7ljJyWglOz+CbPW0xcFz8yBJeW97INw8Zya9Pm7ZD27656U1+9MaPsAk2njr5KSaGJ/bbeRUF9ectZJe3orZmu6yXa3y4JoZwTgwjD/Mi9NKne29i6dKlPPfccwQCAS677LJBNcGwP1Aam0i+uZDU2++Qevdd9Hi8Y6UgIo+dgnvfg7GPn4ZcOQpDlbsK5nge9N7JKcFhw+azY4hR4wQAAHWSSURBVPPbEX32ghhuF76dRHIn0WxZhweWARHREyZMYM2aNbzzzjvFdN4WPWOJaIvdRX9dY+2C2nTzaOpioRZEgepxAUbtU8qofUp7lZHKYs/indUtXPC39/HYbbz382PwOXfsoWregnm8tuE1ppZM5bGTHkMS+/91umEYqE1pMstbySxvQ9mY6LJe9Mo4J5iC2jEuiM16MATMBGA333wzmUyG8847j4kT++8hZ3ej5zS0SBY1kkWL5lDbMuQ3NKE0xNDTBtjcCEIvRKwANr8dm9+BLdBet7ftiH4HNp/dih4zBOitiO7THer444/nrrvu4u2337ZEtIXFXoAgdkxInH32OJo2JFi7tJn1n7bQVpdi88oom1dGeefp1YQq3YyYWsKIqWGqxwetiYl7AYeOLWFcuZfVTUme/nAT35q9Y2Emf3bQz3iv7j2WtS7jseWPcdG0i/r9HAVBQK7wIFd48M8ZgRbPFdKMt5FdFUVPKqQ/aiL9URMIIA/z4hwXxDEuhGOUf6+N9iHLcjH5yuLFi4eUiDY0Ay2aRW3rKFpbQTRHsugptYctPQjtKkkwgBx6qhWtbTNGJoKejRZr+6gK3Afug/fQQ3HNnIK4B0f9sOigT5boVatWMXPmTLxeLx9++CHDtuMztLdjWaItdhcDcY3FmjOs/7SFdZ+2UL8qit7p1aYkiwybGDJF9ZQwgXKX5ae3h/Lou+u59t/LGFPq4fV5RyLuoGvEs6ue5bpF1+GwOfjXqf9ihH/ELjrTrTFUndyGeFFUq43pLusFWcQ+yo9jbBDHmAD2Yd696jV7W1sbt99uhiG89NJLKRlE0SyKQrklg9qSQWnJoLZmUVszaJHcdl0tBJeEFHJgCzmRgg5shSIFndgCDkSvXHTzUSMR0h8sJv3+e6QWvUt+/fot9uXCfdCBeGfPxjN7NvYxY6z73RBjQNw5AJ5//nm+/vWvEwgE+P3vf8/ZZ589ZJKEDDSWiLbYXQz0NZZLK2xcEaF2WSu1y1pJdfKjBvCGHAyfFGL4pDDDJ4XwBPbMDGJ7I6mcysE3vkEip/Lwtw/iyAll29+oE4ZhcPFrF/N+/fscUHEA959wP2JvXqXvArR4juyqKLnVUbKrI+gJpct6wW4zRfWYAI7RBVG9h1uqH3/8cVatWsUhhxzCCSecMODH17MqanMGpSlt1s1p1Oa06eeubUPOSAJSyIlU4kIKO7GFnUghJ7aQAynsRHTu/It5pb6e1LvvkXr3XVLvvovW0tJlvVRZiWf2oXgOPgT3rIOQy8t3+lgWA8OAiOijjzbjeW7YsIF169YVs+yNHz+eUCiEzdbz61tBEHjjjTd29tBDEktEW+wuduc1ZhgGbXUpNnzeSu3yVurXxNDVrredUJWHYROCVI8PMmxCCLcVLWFIc8N/lvHgO+s5elI5D1y045PONyU2cebzZ5JRM1x78LV8deJXd8FZ7hiGYaA2psmujpJbGyO3LoaR2cINQBKx13hxjAyY4nqED9G9Z/lUr1y5kieeeAKn08m8efN2mdFMz6koDWnUpjRKY9oUzY0ptC0eyLsgiUglTqRSF1KpC7nEhVTqxFbiwuazD8iEUcMwyK1cReqdd0i98w7pJUswcrkuY+yjR+OedRCeWbNwH3TQoIxPvbczICK6PcQdmBdObxAEoZjKWdN2LtTLUMUS0Ra7i8F0jSl5jYbVMTZ+0camLyI0b0xsFQc1WOGmekKQ6nFBqsYG8JU4rdehQ4i1zUmO/vNCBAEW/PQoRpbseFzhx5Y/xu8X/x6P7OG5056j0tP72NMDgaEbKI1pcmuj5NbEyG+Ibe1bK4BU5sJe48c+woe9xodc4UGwDd1rWdd1br/9dqLRKKeeeir77bdfn/Zn6AZqawalPoXSkEJpSKM0pNDasj1uI/rsyOUupDI3UpkLuVDbAo5BF1lFz2ZJf/ghqXcWkX7/fTOU3hZ6SR4xAtc++5hlxr44Jk2yfKp3MwMioo866qg+/bDNnz9/p7cdilgi2mJ3MZivsWxSYfPKCJtXRalbGaW1LrmVqPYE7FSONQV11bgAJcO92PYiX9ShyP9v776jo6rWPo5/z5T03hMICYRepCQgRXpVRAEFEQWCiKhwFVGv14odfcVyhStKEVCwgEixgIB06b0TCIQQ0ntvM+f9Y8iQUBNSJuX5rDVrZk59ZkjIb/bss/e4b/eyNSyBJ+9pyBv3tyzz/gajgbHrxnI04Sg96vdgdp/Z1fqDlKqqFCbmkB+RTl5EOvkX0ylMzLluO0WvQV/PAb2vvenmY7rIsSaN2LBjxw42btyIr68vTz31VKn/XdRCo6lVOTqT/OhMCqKzKIjJRM2/8cx6Gkcr9D526L3s0HnbmS4I9bJDY1tzJ8oxpKWRvX8/WXv2kL1nL3lnzly3jaLXY92yBbZt7sL2rjbYtGmDVUAASi0bVrA6q7I+0aL0JEQLS6lJP2O5WQXEnEvl8tlUYs6mkngps8RFigBavQavBo54BTrh3dAJ70Anaa2uZjafjmf8on042ejY/Vpf7KzKHnzCU8MZ8dsICowFfNz9Y+5rdF8lVFp5DJn55EdmkH/p6k3Nu/E3sFo3G6z87LFqcKXVup4DSjUd0SYrK4vPPvsMg8HAk08+Sf369a/bRjWoFCZkm1735UzyozIoiMm6Yb9lRa9B52OP3tvu6gcLH/s6MbygIT2dnKPHyDl6hNwjR8k5cgRDaup122mcnLBt3QqbVq2xadUKm1Yt0devL//nVRIJ0dWQhGhxrV69erF161YADh06RLt27Spl/5r8M1aQbyD+Qjox59OIDU8j9nwaednXD0ll66jHK8AJzwaOeDZwxCvAEXsXa/kjYyFGo0rvT7dwMSmbD4e1YfTddzbKxtdHvuZ/h/+Hq7Urq4auws3GrYIrrTqq8UprdVTG1a4LMVkYM27Qz1ejoPe1x6qBoylYepi6LGgc9NXiZ3rlypUcOXKEtm3bMmzYMAzp+eRHppN3KYP8i+kUXM5ELbi+hVmx1WHlZ4/ezwErPwf09RzQedhWu24YlqKqKgWXLpFz9Bi5x46Sc+w4uSdOXNevGkzB2qZlS2xatcSmeXOsmzXDumFDFH3t//BR2SREV0O1MUSHhoayePFiZsyYwX/+8x/z8lWrVjFs2LBS95Uvi0WLFjF16lRSb/Bpvabp1asXTZs25d1338XDwwOdTkdERAQNGzbE09OT8PBwHB2vTp/crl07hg4dyttvvw2YhpwKDw+nU6dOtTZEX0s1qqTGZxMXkU7chXTiI9Jv2FoNpmDt2cAJD38HPOo74OnviJOnbZmHXRN3Zv7287z/xymaeTuybmr3Owp/BYYCRv0xirCUMO4NvJf/6/l/lVCpZRmyCkx9gi9nkBeZQX5k+nUjgRRRbLSmi+Y87dB5Xenq4GWLzs22yvpaq0aViKPnWLxqKVpFw2NWfbBKu0ELs7UWq3oO6Os7YlXfAav6jmhd5YNtWakFBeSdO2cK1idOkHviBHlhYagF1/+MKFZWWDdujHXz5lg3aYJVQABWAQ3Q+/tLP+syqJLJVoQAsLGx4eOPP2bSpEm4urpaupwax87ODh+f6y+aysjIYObMmbzzzjs33dfNzY304tPT1gGKRsHVxx5XH3uad/YFoLDAQOKlTBIiM4i/mE5CZAbJMdnkZBSYh9krorPS4F7PAff6Drj7OeDuZ497PQdsHKT1pqKNCPHn0/VhnInLYPf5ZLoElX0UAr1Wz7td32X0n6NZG7GWexveS+8GvSuhWsvR2uvRNnbBprELjphaIw2peeauIAXx2RQm5mBIyUXNNVAQlUlBVOY1B1HQe9qi87JD52lnenzlgjuNVfm6haiFRvIvZZB3Ic3c31uXV4iHlSOJmgxOZV6grRKI3tseqwBH84WU0sJcMRS9HpsWLbBp0cK8TM3PJ+/cOXJPnjTdTp8h78wZjFlZ5mUlD6Kg9/XFKjAAna8vOk9P803v5YXO0xOthwcaaxlutCwqPERHRESQmJhITk7ObVshe/ToUdGnrzVUVcVovP6ilKqg0ZRtIox+/fpx7tw5ZsyYwf/9341biXbu3Ml//vMf9u3bh4eHB8OGDWPGjBnY29sza9Ys5s6dy7Fjx4CrrdizZ89m8uTJAAwcOJAOHTowY8aM29aTlpbGyy+/zKpVq8jNzSUkJITPP/+ctm3bAhAeHs60adPYvXs3WVlZtGjRghkzZtCvXz/zMWJiYnjyySfZtGkTPj4+fPDBB7z22mtMnTqVqVOnmluLi7f+pqam4urqyubNm+nVqxcAJ0+e5KWXXmLbtm3Y29szYMAAPv/8czw8PG77Ov71r3/x2WefMXnyZLxkXNFb0um1+DRyxqeRs3lZYb6BxChTsE68nEnipUySL2dSmG8k7oKpFbs4Oycr3PzscfMzBXQ3X3tcfe2wdZDWmzvlbKtnWId6/LAnksU7I+4oRAO08mjFuFbjWHh8Ie/tfo9gn2CcrG7eOlTTKcqVMY1dbbBre3WcbbXAaBrJIiHHNDZyfLbpcXw2aoHxysgW2dcdT+tijc7T9urQb1futa42Nwy5qlGlIDqTvPBUcs+lkh+Rfl3XDI21jjbuTdmcfIAw1wQGTn4Ena38rlQVxcrK1JWj5dWLdlWjkYLLl8k9fZq802fIOx9O/sWLFERcxJidTUF0NAXR0bc8rsbBAa27Gzp3D3Tu7qbHbm5oXd3QurmaHru5oXV1RefiglLHW7crJESfOXOGDz/8kDVr1pS6VUxRFAoLbzbVpjAac9iytY1Fzt2r5zG0WrtSb6/Vavnwww8ZPXo0zz333HUXmRw7doyBAwfy3nvvsWDBAhISEpgyZQpTpkxh4cKF9OrVi+eff57ExEQ8PDzYunWr+X7y5MkUFhayc+dOXnjhhdvWoqoqgwcPxs3NjT///BNnZ2e++eYb+vbtS1hYGG5ubmRmZnLffffx/vvvY2Njw+LFixkyZAhnzpyhQQNTv82xY8eSmJjIli1b0Ov1TJs2jfj4+DK9jzExMfTs2ZOJEyfy2WefkZOTwyuvvMLIkSPZtGnTbfd/9NFH2bBhA++++y6zZ88u07kF6KyuD9ZGo0pafDaJlzJJupxJUnQWydGZpCfmkp2eT3Z6PlGnU0ocx9ZRj6uPPS7edrh42eHiY4ertx2OHjYyQkgpjOsSyA97Ill/MpbLqTnUc7G9o+M82/ZZNkVu4mL6RT7d/ynvdL35NzS1laLXmC+6K041mlquC+KySkxEUpiQjTG7EENqHobUPPLOppY8oEZB0WtM3UC0pntFq2DIKkTNLfn3WWOvN00qE+iEVaAzel97PAsL2PXZCdIy0zl/KYKmTZtW8jsgbkXRaLDy98fK3x/69zcvV1UVQ1IS+Rcvkn8xksK4WAoTEky3+ATzY7WgAGNmJsbMTAouRpbqnBp7e7Surqabi4vp5uxc8t7FGa2TExonJ9NzR0cUXe3oCFHuV7Fq1Soee+wxcnNzK6X/q6gZhg0bRrt27Zg+fToLFiwose6TTz5h9OjRTJ06FYAmTZrw5Zdf0rNnT+bMmUPr1q1xd3dn69atPPTQQ2zZsoUXX3yRzz//HIB9+/aRm5vLPffcc9s6Nm/ezLFjx4iPj8f6ytdSM2fOZNWqVfzyyy889dRTtG3b1twqDfD++++zcuVK1qxZw5QpUzh9+jQbN25k3759hISEADB//nyaNGlSpvdkzpw5dOjQgQ8//NC87Ntvv8Xf35+wsLDb/sFRFIWPPvqIIUOG8MILLxAUFFSm84vraYp1BWnS0du8PD+3kOSYLJKjs0iJySI5JpuU2CwyknLJySggJyOV6GsCiEaj4Ohhg7OnHc6etqabl+ne0d0GXTUdWaGqNfNxpEsjd3adT2LJ7ou8Mqj5HR3HRmfDO13fIXRdKL+e/ZVBgYPo4telgqutmRSNgs7NBp2bDbQouc6QVWBqtU4oNh12Yg6FSTlQqKLmGa4dUdJ0TGutKTQHmbqZ6LztrvuG0srKinbt2rF79272798vIbqaUhQFnYcHOg8P7IKDb7iNqqoYMzIoTErCkJREYWIShclJGBKTKExJxpCcgiE52fQ4KRlDWhoYjRizsjBmZVEQFVWmmjT29micndA6OqF1dDQFbPO9AxoHRzQO9qZlDo5oHR3QBwSgq2ZdRssVoi9dusTjjz9OTk4O9erV4+WXX8bOzs48buTGjRtJSUlh//79fPfdd0RHR3PPPffw9ttv33I2Q2HqUtGr5zGLnftOfPzxx/Tp04cXX3yxxPIDBw5w7tw5li5dal5m6q5i5MKFC7Ro0YIePXqwZcsW+vbty4kTJ3j66aeZOXMmp06dYsuWLXTo0AEHB4fb1nDgwAEyMzNxv2YGqJycHMLDwwHT8EzvvPMOv//+O9HR0RQWFpKTk0NkpOmT95kzZ9DpdCUmEWjcuHGZ+3sfOHCAzZs337Du8PDwUv3BGThwIPfccw9vvvkmP/zwQ5nOL0rPykaHT0NnfBo6l1hekGcgNS6b5JgsUuOzSY27eivMN5IWn0Na/I27Xdk7W+HkYYujhw1O7rY4edjg6GaDo7sNDi42aPV1pxV7XNdAdp1P4qe9kTzftwk2d/gBI9g7mFHNRvHTmZ94Z9c7/PrAr9jpS/+tWV2ktdejtXfGOrDkz7ZqVDFk5EOBEdVgRDWoYFBRDUYUvRa9T+kmhQkJCWH37t2EhYWRkpIi18XUUIqioHVyQuvkBA0b3nZ71WjEmJ5OYUoKhtRUDCmpGFJSMKSlmZ6npZV4bLzy3JiVBWAO34XElLpGn7en4zpq1B2/xspQrhD95Zdfkp2djaOjI3v27MHPz48TJ06Y1/fubbr4Y/jw4bz55ptMmDCBn3/+mQULFpQIVOJ6iqKUqUtFddCjRw8GDhzIa6+9RmhoqHm50Whk0qRJPPfcc9ftU9R9olevXsydO5ft27fTtm1bXFxc6NGjB1u3bmXLli3mPsa3YzQa8fX1ZcuWLdetc3FxAeDll1/mr7/+YubMmTRu3BhbW1sefvhh8vNNw0zd7BuV4ss1Vwa9L76s4JorpY1GI0OGDOHjjz++7li+vr6lej0AH330EV26dOHll18u9T6iYuitteYh84pTVZWs1DxS43NIT8ghLSHbFKgTTaG6IM9AVlo+WWn5xISnXX9gxdQH29HNFKwdXK1xcC1272aNraNVrRlFpF8LL+q52HI5NYffjkQzIsT/jo81NXgqW6O2cjnzMrMOzeKVTq9UYKV1h6JR0DmX/yIyDw8PGjVqxPnz5zlw4ECJa0tE7aVoNObuG2WhFhZiyMgwheqMDAzp6RiL36elY8zMwJCRaXqemYHxymOtW/Ub3rJcIXrjxo0oisKzzz6Ln5/fLbe1tbVlyZIlhIWF8dNPPzF8+HAeeuih8pxeVEMfffQR7dq1K9HK2qFDB06cOEHjxo1vul9Rv+hffvnFHJh79uzJxo0b2blzJ88//3ypzt+hQwdiY2PR6XQEBgbecJvt27cTGhrKsGHDAMjMzCQiIsK8vnnz5hQWFnLo0CGCr3z1de7cuRJD6nl6mi72iYmJoX379gAcPnz4ulpWrFhBYGAgunL0/+rUqRPDhw8vMYSgsCxFUa6EXhtoVrLlTVVVcrMKSE/MJT0xh4wk0316Ui4ZSblkJudSWGAkOy2f7LT86y5wNJ9Do2DnZIW9sxV2ztbYu1ibHjsV3ayxc7bCztGq2rdq67QaHu8cwMfrTrN4VwQPB9/5JBH2enumd5nO0xufZumppQwMHEg7r3YVW7Aok5CQEM6fP8+hQ4fo1atXuf6/E7WbotOZumTUkm8syvWTXhQ8unbtal5W/D/GwsLCEr9MGo2G5557jtDQUL799lsJ0bVQmzZteOyxx5g1a5Z52SuvvELnzp2ZPHkyEydOxN7enlOnTrFhwwbzdkX9opcuXcrq1asBU7Au6hpybX9og8FwXWi1srKiX79+dOnShaFDh/Lxxx/TrFkzoqOj+fPPPxk6dCghISE0btyYX3/9lSFDhqAoCm+++SZG49Urz5s3b06/fv146qmnmDNnDnq9nhdffBFb26ujltja2tK5c2c++ugjAgMDSUxM5I033ihRz+TJk5k3bx6PPvooL7/8Mh4eHpw7d46ffvqJefPmlalL0wcffECrVq3kj1MNoCgKtg5W2DpY4R14/QgSqqqSm1lARrIpVGck55KZmkdmch5ZqblkpuSRlZqHajS1dmel5gEZtzyntZ0OW0crbB312DlamR/bOlph46DHxkF/pSbTY62u6kP3qI7+fLExjOOX0zkYmUJwwJ23KnWr140Hgh5gTfga3vznTZYNWYat7s66oYnya9asGY6OjmRkZHDq1CnatLHMRfFCVLVy/UXOutK3xd//6ldzdnZXuyCkpaVd1ze1VatWABw5cqQ8pxbV2HvvvceyZcvMz++66y62bt3K66+/Tvfu3VFVlaCgIB555BHzNoqi0LNnT1atWkX37t3N+zk7O9OoUaPrBjvPzMw0twAXCQgIICIigj///JPXX3+dJ554goSEBHx8fOjRowfe3qYLyT7//HOeeOIJunbtioeHB6+88sp1o8p89913TJgwgR49euDj48OMGTM4ceJEiYlKvv32W5544glCQkJo1qwZ//d//8eAAQPM6/38/Pjnn3945ZVXGDhwIHl5eQQEBDBo0CBzd5DSatq0KU888QRz584t036i+lEU5UrItcIr4MbDtBkNRnIyCshKyzN1C0nNIystj+zUPLIzCshOyzOPJmI0qORlF5KXXUhqXOlq0NtosbHXm24O+quP7XVY2125v7JMb61FZ6VBZ6VFp9eg02vR6JQytyS72lvxYDs/lu2PYtHOi+UK0QD/7vhvdkfvJiI9gk/3f8obnd+4/U6iUmi1WoKDg9myZQv79u27bYg2XROjohpM90aDimq8sqzouWq6Ny2jxHrVeHW9agSjWmy50TQKj1psmdHI1efq1WOhcvWY6pXzXLOdql6zTDXdU/Tc9IKu3F/zQhUw/5YoSrHHV5YX/Q6VvCv2/Aa/Yzf7tVNussmVcyjXbKtcU4xiXn79gYpqNZerlFxZYpdr/18o/lpK7H+Lba95I4qe12vqiptfyZFpLK1cMxZ6enqSnJzMP//8Q+fOnQHTBBHOzs4oisKuXbvo1KlTiX02b95M3759sbKyIjc3t3zV1zC1ccbCuiIqKgp/f382btxI3759K+y4vXr1ol27dnzxxRd3fIwbjVl9LfkZq51U1RSgs9PyycnMvzKSSD7ZGabHuRn55GQWkJNZQG5mPrmZBVTIIEoKaBTl6h/dor+PGtMfWkUpdq8pulcoVFXiMnIxAgEe9ljpNSgaUyDXaBXz9hqNcmU55vVF4xkrxc6ZnJvEgfgDqKgEewfjZe9l3qaoNvPf+2KPS4SCGywvESqKnhTfr2hdiR1vHkSKB6aSQcS8180DRlENN9jGfIRbhpGS5726j+levRIkUYuFW6NKYYERQ9Gt0HRfWGjEWKianl+5GQ2mMFtYUEhCQhKoCk6OTmgUDQZDsaBsVDFeuYBRBvISd6L3mOa07HbrrsMVpUpmLGzWrBm7du3i/Pnz5hDt6OhIQEAAkZGRrF+//roQvXHjRuDqRV5CVEebNm0iMzOTNm3aEBMTw7///W8CAwMrZYKgr776ivnz57Nr164yfw167733sm3btgqvSdQMiqKYW5Hh9i00qtEUunOzCky3zIISj/OyC8nNLiAvq4DcLNN2BXkGU6DKN1wNP6qp9c/8pAxcMH0Lk3GTUU3KKgjTN1JpSSpplLIpXlQKHaZvorNTbzxleWlotKYPTEUfpDQa09jVGgXTfbEPVTf+4HXN86IPaRpKrC+xrXKDD23FHnPlsUaD+cOXolFKfhjjmhZaSn5YuPrrcuNWa3N7Zsm7a7a72UXvN3kzix/rykYljmtef+VDlHl5sW3V4vtcU3vR8+LbFXsd174GtVhB19V8o/rMi01PHN2rXwNQuUJ0ly5d2LVrF7t372b06NHm5ffffz//+9//+OSTT+jatSt9+vQB4JdffuGLL75AURS6detWvsqFqEQFBQW89tprnD9/HkdHR7p27crSpUvR6yt2auilS5eSk2MKE0UjlZTF/Pnzy7W/qFsUjWLuI11WRV+fFxYYKcw3oBqhKCioqlrsD2Oxr8WLfxVuBKNBZXtYAp9vCMPVRs+sUe3QKkqxr+mLfRV/7dfrxqtBQ73yh15VocBQwMLjC0nKSaapS1OGNh56Zf3VcFBU/7X7wpWv7E1lX92ueKCg+H43+Pq+6DxQcr9bBIzrAtKNQkvxOszLyxBCSrymaxdcvSv5bQFXAqeCVq9Bq9eg05nutcXvdQoabcnHGq1CbFwMf63/C71ex+NjHsPaxhrNleBbPBybH2uvCcu1ZDQaUXeUqztHUdcMPz8/Ll68aL5QKjIykpYtW5r/uLu5uZGXl0dWVhaqqqLVatm+fbu59bqukO4cwlLkZ0xUFwUGI/d8vIm49Dy+eKQdQ9vXK/cxTyWdYvSfoyk0FvJu13cZ1mRYBVQqykpVVWbPnk1SUhKDBw+mY8eOli5JiDtS2u4c5bpEu1evXkyfPp3x48dz+fJl8/IGDRqwfPlynJ2dUVWVpKQkMjMzUVUVa2tr5s2bV+cCtBBCCNBrNTx2dwAAC/+5UCEz3bZwb8GUdlMA+GjvR1zKuFTuY4qyUxTFHJz37dsnsxiLWq9c3TkURWH69Ok3XHfvvfdy7tw5li9fzokTJygsLKRJkyaMHDmSevXK3/JQG8l/OKKyyM+WqE5G392A2ZvPcSQqjX0RKXRqWP5JFEJbhbItahsH4w/y+o7XWThwIVqNzIxb1dq2bcvGjRuJj48nMjKSgIAAS5ckRKWp1EFn3dzcmDRpUmWeolYo6mebnZ2Nra2MdSoqXnZ2NkCF9+kW4k54OFjzUIf6/Lg3krnbwiskRGs1Wj7s/iEPrXmIQ/GHmHdsHk+3fboCqhVlYWtry1133cXBgwfZvXu3hGhRq8nMDdWAVqvFxcWF+Ph4wDTW9p3O5iVEcaqqkp2dTXx8PC4uLmWa4EWIyvRk94b8tC+SjafiORefSWMvh3Ifs55DPV6/+3Ve2/Eac47MIdg7mI4+0i+3qnXu3JmDBw9y+vRpUlJScK0ls9MJcS0J0dWEj48PgDlIC1GRXFxczD9jQlQHQZ4O9GvhzYaTcczffp6PHrqrQo47JGgIe2P3surcKv697d8sH7IcD1uPCjm2KB0vLy+CgoIIDw9nz549DBo0yNIlCVEpSjU6R2WNQ1sZY+5WZ6W52tNgMFBQcOdjbApxLb1eLy3QolraH5HMw1/vwkqrYcd/euPlWDEjx+QU5jD6j9GcSz1HZ9/OfN3va+kfXcXOnj3L0qVLsbKyYtq0aTIqkKhRKnSylV69elV49wJFUSgsLKzQY9YGWq1WAo8Qok4ICXSjQwMXDkam8t3Oi7w0sFmFHNdWZ8vMnjN59I9H2R2zm/nH5jOprVyfU5UaN26Mh4cHiYmJHDp0iC5duli6JCEqXKmHuDMPfl+BNyGEEHXbUz0aAfD97otk51dcw0qQSxBvdH4DgK+OfMW+2H0Vdmxxe4qimIey3bNnD0aj0cIVCVHxStUSvXnz5puuy8/P54033mDfvn14enoycuRIOnXqhLe3N6qqEh8fz759+1i2bBnx8fF06tSJ999/X0YJEEIIQf+WPgS62xGRlM2yfZcI7dawwo79QNAD7IvdJ/2jLaRt27b8/fffpKamcvr0aVq2bGnpkoSoUOWasVBVVQYPHsxff/3FE088wRdffIG9vf0Nt83Ozmbq1KnMnz+fQYMG8eeff95x0TVVafvYCCFEXfL97ou8ueo4/m62bH6xFzptueYBK0H6R1vW33//zfbt2/H392fChAmWLkeIUqmSGQsXLFjAunXr6NevH/PmzbtpgAbTsG1z586lf//+/PXXX8ydO7c8pxZCCFFLPNyhPm72VlxKzmHdidgKPXZR/2hbnS27Y3bzv8P/q9Dji1vr1KkTGo2GS5culZjZWIjaoFwhetGiRSiKwrPPPlvqfSZPnoyqqixevLg8pxZCCFFL2FppGdPZNCnH3G3nK/yamSCXIKZ3Mc2uO+/YPNZHrK/Q44ubc3R0pE2bNgDs2rXLwtUIUbHKFaJPnz4NQIMGDUq9j7+/f4l9hRBCiLFdArDWaTgalcbu88kVfvzBjQYzruU4AN745w3CUsIq/BzixoouMDxx4gRpaWkWrkaIilOuEJ2bmwvApUuXSr1P0bZ5eXnlObUQQohaxN3BmhEh9QH4emt4pZxjavBUOvt2Jqcwh+c3PU9angS6quDr60tgYCCqqrJ3715LlyNEhSlXiG7cuDEAX3/9dan3Kdo2KCioPKcWQghRyzzVPQitRmFrWALHoio+4Oo0Oj7p8Qn1HOoRlRnFy1tfptAo8xVUhaLW6AMHDkgjmqg1yhWiR4wYgaqq/PXXXzz77LPmlukbycvLY8qUKaxbtw5FURg1alR5Ti2EEKKWaeBuxwNt/QD4asu5SjmHi40L/+39X2x1tuyK2cWXB7+slPOIkpo2bYq7uzu5ubkcOHDA0uUIUSHKNcRdbm4u7du358yZMyiKgre3NyNHjqRjx454eXmhKApxcXHs27eP5cuXExsbi6qqNG/enEOHDmFtbV2Rr6XakyHuhBDi1sLiMhjw+TYUBTa80IPGXo6Vcp6/Iv7ipa0vAfBx94+5r9F9lXIecdXBgwdZs2YNDg4OTJ06FZ2uVFNVCFHlSpvXyhWiAWJiYhg8eDCHDx82HfAm04MXnaZ9+/b8/vvv+Pr6lue0NZKEaCGEuL2nvtvP+pNxPNShPp+ObFtp5/nvwf8y/9h8rLXWLBi4gLaelXcuAYWFhXz55Zekp6dz//33ExISYumShLihKhknGkwXDOzbt4///ve/tGjR4qZTfLdo0YIvv/ySvXv31skALYQQonQm9zZdb7Pq8GUuJWdX2nmmtJtCz/o9yTPk8dym57iUUfqL5EXZ6XQ6unTpAsA///yDwWCwcEVClE+5W6KvFRMTw7Fjx0hJSUFVVdzc3GjTpo0EZ6QlWgghSmvMgj1sP5vImM4BvDe0daWdJ7sgm9B1oZxKPkVD54Z8f+/3OFs7V9r56rr8/Hw+//xzcnJyeOihh8xjSAtRnVRZdw5RehKihRCidHaFJ/HovN1Y6TTseKU3Xo42lXau+Ox4HvvzMWKzYuno05Fv+n2DXquvtPPVdVu3bmXz5s14e3vz9NNP37QbqBCWUmXdOYQQQoiK1rmRGx0auJBfaGTBjguVei4vOy9m95mNvd6efbH7mL5zeoXPmiiu6tSpE1ZWVsTFxXH27FlLlyPEHZMQLYQQotpRFIUpfUx9o5fsukhqdn6lnq+ZWzM+7fkpWkXLb+d/4+ujpZ//QJSNra2t+aLC7du3W7gaIe5chYTowsJCVq9ezUsvvcTw4cPp378/ffr0ueWtb9++FXHq2/rggw/o2rUrdnZ2uLi43HCbyMhIhgwZgr29PR4eHjz33HPk55f8D/vYsWP07NkTW1tb6tWrx7vvvistFUIIUYl6N/OiuY8jWfkGFu+8WOnn61avG693fh2Arw5/xZrwNZV+zrqqS5cuaLVaLl26xMWLlf9vK0RlKPcgjTt27GDMmDFERkaal90qXCqKgqqqVdYHKj8/nxEjRtClSxcWLFhw3XqDwcDgwYPx9PRkx44dJCUlMW7cOFRVZdasWYCpb0z//v3p3bs3+/btIywsjNDQUOzt7XnxxRer5HUIIURdoygKk3s35l8/HmLhzgs82b0h9taVO7bwiKYjuJRxiYXHF/LWP2/hZOVEL/9elXrOusjR0ZF27dpx4MABtm/fTkBAgKVLEqLMyvW/0enTpxk0aBA5OTmoqoqVlRVNmjTBzc0NjaZ69BR55513AFi0aNEN169fv56TJ09y6dIl/PxMM2V9+umnhIaG8sEHH+Dk5MTSpUvJzc1l0aJFWFtb07p1a8LCwvjss8+YNm2aXBQhhBCV5L42vny2IYwLiVn8sCeSiT0aVfo5p3aYSmJ2Ir+d/42Xtr7E1/2+JsRHxjSuaN26dePgwYOcO3eOmJgYGcVL1DjlCtEffvgh2dnZaLVa3nnnHZ577jkcHBwqqrYqsWvXLlq3bm0O0AADBw4kLy+PAwcO0Lt3b3bt2kXPnj1LzLA4cOBAXn31VSIiImjYsOENj52Xl0deXp75eXp6euW9ECGEqIW0GoVnegbx7xVHmbf9PGO6BGCj11bqOTWKhne6vUNGfgZborbwr03/4tuB39LCvUWlnreucXNzo3Xr1hw7dozt27czcuRIS5ckRJmUq7l406ZNKIrC888/z2uvvVbjAjRAbGws3t7eJZa5urpiZWVFbGzsTbcpel60zY3MmDEDZ2dn883f37+CqxdCiNpvaPt6+DnbEJ+Rxy8HoqrknHqNnk96fkKwdzCZBZk8vfFpItIiquTcdck999wDwMmTJ4mLi7NwNUKUTblCdGJiIgDDhg2rkGJK6+2330ZRlFve9u/fX+rj3ag7xrX9tq/dpqjf9626crz66qukpaWZb5cuyWxYQghRVlY6DU9d6cbx9dZwCgzGKjmvjc6GWX1m0cKtBcm5yTy14Slis27ecCLKztvbm1atWgGwZcsWyxYjRBmVK0R7enoCpuFqqtKUKVM4derULW+tW5duhisfH5/rWpNTUlIoKCgwtzbfaJv4+HiA61qoi7O2tsbJyanETQghRNk90rEB7vZWRKXk8NuR6Co7r6OVI3P6zSHQKZCYrBgmbZhEcm5ylZ2/LujZsycAp06dIiYmxsLVCFF65QrRRV/DHD9+vEKKKS0PDw+aN29+y5uNTelmt+rSpQvHjx8v8Yu7fv16rK2tCQ4ONm+zbdu2EsPerV+/Hj8/PwIDAyv0tQkhhLierZWWCd1N1598tSUco7Hqhhh1t3Xnm/7f4G3nzfm080xcP5GU3JQqO39t5+XlZZ7+W1qjRU1SrhA9bdo0tFot//3vfyksLKyomipUZGQkhw8fJjIyEoPBwOHDhzl8+DCZmZkADBgwgJYtWzJmzBgOHTrE33//zUsvvcTEiRPNLcejR4/G2tqa0NBQjh8/zsqVK/nwww9lZA4hhKhCYzoH4Gij41x8Jn+dqNpuFX4OfswbMA8PWw/CUsKYuH4iqbmpVVpDbdazZ08UReHMmTNcvnzZ0uUIUSrlCtEdO3bks88+4/DhwwwfPtzcR7o6eeutt2jfvj3Tp08nMzOT9u3b0759e3Ofaa1Wyx9//IGNjQ3dunVj5MiRDB06lJkzZ5qP4ezszIYNG4iKiiIkJIRnn32WadOmMW3aNEu9LCGEqHMcbfSEdg0E4H9bzlX5hFcNnRuyYOAC3G3cOZNyhokbJpKWl1alNdRWHh4e3HXXXYC0RouaQ1HL8b/Qu+++C8C6devYvXs3tra29O/fn+bNm2NnZ3fb/d966607PXWNlJ6ejrOzM2lpadI/Wggh7kByVj7dPtpEToGBReM70quZV5XXcD71POP/Gk9ybjIt3Fowb8A8nK2dq7yO2iYpKYnZs2ejqioTJkyQEa2ExZQ2r5UrRGs0mhLdGco6E6HBYLjTU9dIEqKFEKL83v/9JPN3XKBjoCvLn+5qkRrOpZxjwvoJJOcm09K9JXP7z5UgXQFWr17NoUOHCAoKYsyYMZYuR9RRpc1r5Z5WUFVV8+3a57e7CSGEEGU1sUcjrLQa9kWksPeCZUbKaOzamPkD5uNq7crJpJM8teEp6SNdAXr06IFGoyE8PJyLFy9auhwhbqlcIdpoNJbrJoQQQpSVt5MND4fUB2DWprMWq6OJaxPmD7wapEPXhRKfHW+xemoDV1dX2rdvD8DmzZstXI0Qt1bulmghhBCiqj3dIwitRmH72UT2R1hu3Oamrk1ZOGghXrZehKeFM3btWC5lyMRa5dG9e3c0Gg0RERFcuHDB0uUIcVMSooUQQtQ4DdztGHmlNfrT9WEWrSXIJYjF9y6mvkN9LmdeJnRtKOGp4RatqSZzcXExz9OwceNG6f4pqi0J0UIIIWqkKX2aYKXVsOt8EjvPWXaI1fqO9fnu3u9o7NKY+Jx4QteFciLxhEVrqsl69uyJXq/n8uXLnDx50tLlCHFDEqKFEELUSPVcbHm0k2kYtE83hFm8xdLTzpOFAxfSxqMNqXmpTFg/gX2x+yxaU03l4OBAt27dAFNrdHWd0E3UbRUSovPz81m4cCEPPvgggYGBODg4oNVqb3nT6XQVcWohhBB12OTejbHWaThwMYWtYQmWLgcXGxfmDZhHJ59OZBVkMWnDJP48/6ely6qRunTpgr29PSkpKRw4cMDS5QhxnXKH6LCwMNq1a8eTTz7Jb7/9RmRkJNnZ2TLEnRBCiErn5WTD2C4BgKlvdHX422Kvt+erfl/RP6A/BcYCXtn+CguOLagWtdUk1tbW9OrVC4CtW7eSm5tr2YKEuEa5QnRWVhb33nsvp0+fRlEUhg4dysSJEwFQFIU333yTKVOm0LlzZ/Oyrl27Mn369Do3W6EQQojK8XTPIOystBy7nMb6k3GWLgcAa601n/T4hDEtTROGfHHwC97f/T6FRumWUBYdOnTA3d2d7Oxsdu7caelyhCihXCH666+/5sKFC2i1WtavX8+vv/7Kc889Z17/zjvv8OWXX7Jz504OHjxIixYt2L17N+7u7kyfPr3cxQshhBDuDtaM7xYIwOcbwjAaq0eLr1aj5d8d/81/Ov0HBYVlYct4fvPzZBdkW7q0GkOr1dKvXz8Adu3aRXp6uoUrEuKqcoXo3377DUVRGDlyJH369Lnltu3atWPz5s14eXkxbdo06d8khBCiwkzs3ghHax2nYzP441iMpcsp4bEWj/F5r8+x1lqzLWqbTMpSRs2bN8ff35+CggK2bNli6XKEMCtXiC4admbYsGE3XH9t/y9PT0+mTZtGYWEhs2fPLs+phRBCCDMXOyue7N4IgM83hlFoqF6z4vYN6MuCgQtwtXblVPIpHvn9EQ7GHbR0WTWCoij0798fgEOHDpGQYPkLSIWAcobo1NRUAAICAszLrK2tzY8zMzOv26doyJqtW7eW59RCCCFECU/cE4iLnZ7zCVmsOhxt6XKu09azLUvvW0oT1yYk5iQy4a8J/HDqB7ngsBQaNGhA8+bNUVWVjRs3WrocIYByhmg7OzvA9CmxiIuLi/lxZGTkdfsUbRsbG1ueUwshhBAlONromdQjCDD1jc4tMFi4ouv5O/mz5N4lDAocRKFayIy9M3h9x+vkFsrIE7fTt29fFEXhzJkzMh24qBbKFaIbNmwIQHT01U/8Hh4euLm5AfDPP/9ct09RX2grK6vynFoIIYS4zvhugfg623A5NYdFOyMsXc4N2ent+L8e/8dLIS+hVbT8dv43xq4dy+XMy5YurVrz9PQkJCQEgLVr12IwVL8PSaJuKVeILvph3r9/f4nlffv2RVVVPvnkE5KSkszLIyIi+Pjjj1EUhXbt2pXn1EIIIcR1bPRaXhzQDID/bT5HSla+hSu6MUVRGNdqHHP7zy3RT3pntAzjdiu9e/fG1taW+Ph4GaBAWFy5QnT//v1RVZU1a9aUWF40zN358+dp2rQpI0aMYPDgwbRt25aoqCgAnnrqqfKcWgghhLihYe3r0cLXiYzcQr7cdNbS5dxSJ99O/Hz/z7Ryb0VaXhrPbHxGJma5BTs7O/NoYJs2bSI7W4YLFJZTrhB9//3306NHDxwdHQkPDzcv79atG2+99RaqqpKSksKvv/7KunXryMjIAGD8+PGMHj26fJULIYQQN6DVKLx2X3MAvt91kYjELAtXdGu+Dr4svncxQxsPxaga+eLgF7y49UWyCqp33ZYSHByMt7c3ubm5bNq0ydLliDpMUSvx4+7ff//N/PnzOXHiBIWFhTRp0oSxY8fy0EMPVdYpq7X09HScnZ1JS0vDycnJ0uUIIUStNvbbvWwLS+C+Nj589Viwpcu5LVVVWR62nBl7Z1BoLCTIOYgven9BoHOgpUurdiIiIli0aBGKovDUU0/h6+tr6ZJELVLavFapIVqUJCFaCCGqzunYdO7773aMKqx4pivBAa6WLqlUDscf5sUtLxKfE4+D3oH3ur1Hv4B+li6r2lm+fDknTpygQYMGjB8/vsRIYUKUR2nzWrm6cwghhBDVVXMfJx4Org/Ah3+eqjH9jNt5tePnIT/TwasDmQWZvLDlBV7b/hppeWmWLq1a6d+/PzqdjsjISE6cOGHpckQdVO4h7oKCgjh37lyp94mMjKRRo0YEBQWV59RCCCHEbU3r3wwbvYYDF1P460TNmZ/Aw9aD+QPn80TrJ9AoGn47/xvDVw9ne9R2S5dWbbi4uHDPPfcAsH79evLzq+dILKL2KleIvnjxIhEREWX6wS0oKCAiIoKIiIjynFoIIYS4LR9nGyZemQ7843VnKKhm04Hfil6j54XgF/ju3u8IdAokPieeZ/9+lrd3vk1m/vUzAtdF3bp1w9nZmfT0dHbs2GHpckQdI905hBBC1GqTegbh4WDFhcQsFlfTCVhupa1nW5YNWcbjLR5HQWHF2RUMXzOc3TG7LV2axen1egYOHAiYJnhLTEy0cEWiLqnyEJ2WZurTVTRluBBCCFGZHKx1vHRlApb/bjxLQkaehSsqO1udLa90eoVvB35LPYd6xGTFMHH9RN7b9V6dHwqvRYsWNG7cGIPBwO+//15j+r6Lmq/KQ/SSJUsACAgIqOpTCyGEqKNGhvhzV31nMvIK+XjdaUuXc8dCfEL49YFfeaTZIwAsC1vG8NXD2ROzx8KVWY6iKAwePBidTkdERASHDx+2dEmijijTEHdFswQV2bJlC4qiEBISgr29/S33zcvL4/z588THxwPw/PPP89lnn91ByTWXDHEnhBCWcygyhWFfmabV/vXZrnRoUDOGvLuZPTF7mL5zOpczLwMwsulIpoVMw15/67/HtdWOHTvYuHEjtra2TJky5ba5RIibqZRxojUaDYqilPurkkaNGrFr1y48PT3LdZyaRkK0EEJY1kvLj/DLgSja1HNm1eRuaDU1e2zh7IJsPjvwGT+f+RkAP3s/Xu/8Oj3q97BwZVXPYDAwd+5c4uLiaNu2LcOGDbN0SaKGqpQQ3atXrxKDmW/duhVFUQgODr7lJz5FUbCxscHX15euXbsyatSoOvkJUUK0EEJYVkJGHn1mbiEjr5AZw9vwaKcGli6pQuyJ2cNb/7xFdFY0AP0D+vNKx1fwtve2cGVV69KlSyxYsACAcePG0bBhQwtXJGqiKpmxsKhl+tixY7Rs2fJOD1NnSIgWQgjLW7DjAu/9fhI3eys2v9gLZzu9pUuqENkF2cw5MofvT36PQTVgr7fnX+3/xahmo9BqtJYur8r88ccf7Nu3Dzc3N5555hn0+trx7yuqTpXMWDh27FjGjh2Lq2vN7lcmhBCi7hjbJYAmXg4kZ+Xz2YYzli6nwtjp7Xgx5EV+vv9n7vK4i6yCLD7a+xGj/xzNicS6M6Nf3759cXBwIDk5WcaOFpWqXC3RomykJVoIIaqHnecSGT1/DxoF/niuOy18a9f/yUbVyC9hv/DFgS/IKMhAQWFo46E81+E5PGw9LF1epTtx4gTLly9Ho9HwzDPP1LlrsET5VElLdGkkJSWRkpJS2acRQgghSq1rYw/ua+ODUYXpq0/UurGFNYqGkc1GsmbYGu5vdD8qKivPreT+lfez6PgiCgwFli6xUrVs2ZImTZpgNBpZvXo1RmPNmalS1ByVEqLj4uJ46qmn8PDwwMvLCw8PD1xdXQkNDSUyMrIyTimEEEKUyeuDW2Kr17I3Ipnl+6MsXU6l8LD1YEb3GXx/7/e0cm9FVkEWnx74lGFrhrH10tZa9+GhiKIo3H///VhbWxMVFcWuXbssXZKohUodomNjY/Hz88PPz485c+bcdLvz588THBzMggULSE5ORlVVVFUlLS2N77//nvbt28tA6EIIISyunost0/o3BeCDP0/VyJkMS6udVzt+GPwD73V7D3cbdy6mX2TKpilMXD+R44nHLV1epXB2djZPCb5p0yYSEhIsXJGobUodordu3UpsbCzJycmMHDnyptuNGjWK6Oho86dbf39/7r77bhwdHVFVlZSUFB599FEKCwvLX70QQghRDuO7BdLKz4m0nALe/f2kpcupVBpFw9DGQ/l92O+Mbz0evUbPntg9PPrHo0zbMo2ItAhLl1jh2rdvb54SfNWqVRgMBkuXJGqRUofoLVu2ANC7d2/c3d1vuM3vv//O/v37URQFNzc31q1bx8WLF9m1axexsbGMHz8egLCwMFasWFH+6oUQQohy0Gk1fDT8LjQK/HYkms2n4y1dUqVzsHJgWvA0fhv2Gw8EPYCCwoaLGxi6eijv7HqH+Oza8x4oisIDDzyAtbU1ly9fZufOnZYuSdQipQ7RR44cQVEU+vfvf9Ntli5dan786aefMmDAAPNzW1tb5s+fT5s2bQBYvXr1ndQrhBBCVKg29Z2ZcI9pUo43Vh0nK69ufFNaz6EeH9zzAb888As96/fEoBr4JewX7vv1Pt7e+TbhqeGWLrFCODk5ce+99wKmBsG4uDgLVyRqi1KH6KIfurZt2950m6LWamdnZ0aPHn3dekVReOKJJ1BVlSNHjpSxVCGEEKJyvNC/KfVcbLmcmsPnG8IsXU6VauralNl9Z7N40GLae7Unz5DHirMrGLp6KE9vfJqd0Ttr/AWIbdu2pWnTptKtQ1SoUofo+HjT1zseHjceX/L8+fPExcWhKArdu3e/6QxB7du3ByA6OrqstQohhBCVws5Kx/vDWgPw7T8XOBqVatmCLKCDdwcWD1rM4kGL6dugLwoK/1z+h0kbJjF8zXBWhK0gtzDX0mXekaLROmxsbIiJiZFJWESFKHWILroQMD8//4br9+zZY34cHBx80+O4uLgAkJWVVdpTCyGEEJWudzMvHmjrh1GF/6w4RqGh7o0trCgKHbw78EXvL/hj2B881uIxbHW2nEs9x9u73qbfL/344sAXxGbFWrrUMnNycuK+++4DTIMlSGOeKK9Sh+iiFuiwsBt/zVV8DMaQkJCbHicjIwMAGxub0p5aCCGEqBJv3t8SZ1s9J2PSmb/jgqXLsSh/J3/+0+k/bByxkReDX8TP3o+0vDQWHF/AoBWDmLZlGgfjDtaorh5t2rShefPmGI1GVqxYcdOGQSFKo9Qhuqgv9I1G1VBVld9++810QI2Gbt263fQ4Fy9eBMDb27tMhQohhBCVzdPRmtcHtwDgsw1hnI3LsHBFludk5URo61D+HP4nX/T+gk4+nTCoBjZc3MC4deN45PdH+C38txoxC2LRaB2Ojo4kJSWxbt06S5ckarBSh+gHH3wQVVVZvXo13333XYl1n3zyCRcvXkRRFPr27Yuzs/NNj1PUYt2sWbM7LFkIIYSoPCOC69OrmSf5hUZeXH6EgjrYreNGtBotfRv0ZcHABax4YAUPNXkIa601p5JP8dqO1xi4YiBzj84lJTfF0qXekp2dHcOHDwfg4MGDnDhxwsIViZpKUUv5PUx2djatWrUyT9sdEhJC48aNOXXqFEeOHEFVVRRFYe3atSWGtitOVVUaNGhAdHQ077zzDm+88UbFvZIaID09HWdnZ9LS0nBycrJ0OUIIIW4iLj2XAZ9vIy2ngGn9m/Jc3yaWLqlaSslNYXnYcn46/RMJOaYZAa211gwJGsKoZqNo5lZ9G8w2btzIjh07sLGx4emnnzZfsyVEafNaqUM0wN69exkwYADp6ekoimJeXnSICRMmMG/evJvu/8cffzBkyBAUReGff/6hc+fOpT11rSAhWgghao7Vhy/z/E+H0WkUVk3uRut6N/+Wta4rMBSwLmId35/8nlPJp8zL23u1Z2SzkQwIGICV1sqCFV7PYDCwYMECoqOjadCgAaGhoWg0pf6CXtRilRKiAcLDw3nttdf4448/yM7OBiAgIIB//etfvPDCCyXC9bU6d+7M3r178fX15fLly2U5ba0gIVoIIWoOVVV5dulB1h6PpZm3I2v+1Q1rndbSZVVrqqqyP24/P57+kc2RmylUTSN7uVq7MqzJMB5u+jD+jv4WrvKqpKQkvvnmG/Lz8+nduzc9e/a0dEmiGqi0EF3EaDSSkJCAlZUVrq6updqnaFg7nU6HtbX1nZy2RpMQLYQQNUtSZh4DPt9GUlY+z/QK4pVBzS1dUo0Rnx3PirMr+CXslxJTid/tczdDmwylX4N+2OgsP1LX4cOHWbVqlXlCOH//6hPyhWVUeogWZSchWgghap6/TsQy6fsDaBRY/nRXggNK13AkTAqNhWyN2sqyM8vYFb0LFVPscNQ7cm/DexnWZBit3Fvd8pvsyqSqKr/++ivHjh3D2dmZSZMmYWdnZ5FaRPUgIboakhAthBA107SfD/Procs09LDnz+e6Y2sl3TruRHRmNKvDV7P63GouZ17t1tnIuRH3N7qf+xrdRz2HelVeV25uLt988w0pKSk0adKERx99VPpH12ESoqshCdFCCFEzpWUXMPCLbcSm5zL67gZ8OKyNpUuq0YyqkX2x+1h5biUbL24kz5BnXtfBqwODGw1mYOBAnK2r7mLOmJgYFixYQGFhofSPruMkRFdDEqKFEKLm+udcIo8v2IOqwpzHOnBvG19Ll1QrZORnsPHiRv44/wd7Y/eau3voNDq6+HZhQOAAevv3rpJAffDgQdasWQPAmDFjCAoKqvRziupHQnQ1JCFaCCFqto/XnWbOlnCcbHT8+Xx36rtK39mKFJcVx9oLa/n9/O+cSTljXq7T6Ojs25kBAQPo06BPpQbq1atXc+jQIezs7Jg0adItJ5ATtZOE6GpIQrQQQtRsBQYjI77exeFLqYQEuPLTU53RaaXvbGU4n3qevy7+xfqI9ZxLPWderlN0BPsE08e/D30a9MHH3qdCz1tQUMCCBQuIjY2lfv36hIaGotPpKvQconqTEF0NSYgWQoia71JyNvf9dzsZeYU816cx0wZU31n5aovzaedZH7GevyL+KhGoAVq4taBPgz708u9FM9dmFTLKR3JyMnPnziU3N5e7776be++9t9zHFDWHhOhqSEK0EELUDmuORPPcj4dQFPjhyc50CXK3dEl1RmR6JJsvbWZT5CYOxR8y96EG8LL1onv97nSv153Ofp2x19vf8XnOnDnDjz/+CMBDDz1EmzZyMWldISG6GpIQLYQQtce/fznCsv1R+DjZsPb57rjaV69preuCpJwktkVtY1PkJvbE7iGnMMe8TqfREewVTBe/LnT160ozt2ZolLJ1vdm4cSM7duxAp9Mxfvx46tWr+uH3RNWTEF0NSYgWQojaIzu/kPtn7eB8Qhb9Wngxb2yIxSYMEZBnyONA7AG2X97OtqhtRGZElljvZuPG3T5308WvC138upSqL7XRaOTHH3/k7NmzODo6MnHiRPn7XQdIiK6GJEQLIUTtciI6jWH/20m+wch/7m3O0z1lSLTq4mL6RXZc3sGu6F3si91HdmF2ifX+jv509Olounl3xNve+4bHyc3NZcGCBSQkJODn58f48ePR6/VV8RKEhUiIroYkRAshRO2zdM9FXl95HI0CSybcTdfGHpYuSVyjwFDA0cSj7Irexa7oXRxPOo5RNZbYJsApgBDvENp7taeDVwfqO9Y3f7OQnJzMvHnzyMnJoU2bNgwfPly+dajFJERXQxKihRCi9lFVlZd/OcovB6Jwt7fit3/dg5+LraXLEreQmZ/JwfiD7Ivdx77YfZxKPnVdqPaw9TAH6raebbFOt+anpT9hNBrp27cv3bt3t1D1orJJiAYiIiJ477332LRpE7Gxsfj5+fH444/z+uuvY2V19QKQyMhIJk+ezKZNm7C1tWX06NHMnDmzxDbHjh1jypQp7N27Fzc3NyZNmsSbb75Zpk+iEqKFEKJ2yi0wMPyrnZyMSaedvws/T+qMtU5r6bJEKaXnp3Mo7hAH4w9yMO4gx5OOU2gsLLGNlcaKBtYNUGIV3HLdCB0YSre7ukmLdC1U2rxWq0cPP336NEajkW+++YbGjRtz/PhxJk6cSFZWFjNnzgTAYDAwePBgPD092bFjB0lJSYwbNw5VVZk1axZgejP79+9P79692bdvH2FhYYSGhmJvb8+LL75oyZcohBCiGrDRa/n68WCGzN7B4UupvPf7Sd4fKkOi1RROVk709O9JT/+eAOQW5nIi6QSH4g9xMO4gxxKPkZqXyrmcc+AMOMOew3twO+lGW++23OV5F2082tDKvRUOVg6WfTGiytTqlugb+eSTT5gzZw7nz58HYO3atdx///1cunQJPz8/AH766SdCQ0OJj4/HycmJOXPm8OqrrxIXF4e1tTUAH330EbNmzSIqKqrUn0KlJVoIIWq3zWfieWLRPlQVZo5oy8PB9S1dkqgAqqoSmRHJ0YSjHI4/zJawLSSoCahKyQiloNDIuRGtPVrTxqMNrT1a09S1KXqtXIhYk0hL9E2kpaXh5uZmfr5r1y5at25tDtAAAwcOJC8vjwMHDtC7d2927dpFz549zQG6aJtXX32ViIgIGjZseMNz5eXlkZeXZ36enp5eCa9ICCFEddG7mRfP923CFxvP8vrKY7TwdaSVn7OlyxLlpCgKAU4BBDgFMCRoCC+1e4k58+ZwPus8Rm8jNg1tOJ50nJisGMLTwglPC2d1+GoA9Bo9Ldxa0MK9BS3dW9LcrTmNXRpjpZVxxWu6OhWiw8PDmTVrFp9++ql5WWxsLN7eJYe1cXV1xcrKitjYWPM2gYGBJbYp2ic2NvamIXrGjBm88847FfgKhBBCVHfP9WnCkUupbD6TwFPfHWDV5G54OlrffkdRY9ja2jJ29Fjmz59PbmQubV3b8ulDn5KUm8TxxOMcSzzGicQTHEs8Rnp+OkcTj3I08ah5f51GRxOXJrRwb0ELtxa0cm9FU7emWGvl56QmqZEh+u23375tON23bx8hISHm59HR0QwaNIgRI0bw5JNPltj2Rt0xVFUtsfzabYp6wdyqK8err77KtGnTzM/T09Px9/e/Zd1CCCFqNo1G4YtH2jP0q3+4kJjFpO/388PEztjo5ULD2sTDw4MRI0awZMkSjhw5gpeXF926daOXfy96+fcCTFnhUsYljice51TyKU4lneJU8inS89NNz5NPmY+nU3QEuQTR0r2l+dbUtSk2OhsLvUJxOzUyRE+ZMoVRo0bdcpviLcfR0dH07t2bLl26MHfu3BLb+fj4sGfPnhLLUlJSKCgoMLc2+/j4mFuli8THxwNc14pdnLW1dYkuIEIIIeoGZzs988eFMOx//3AwMpVXfz3GZyPbykgOtUxQUBCDBg1i7dq1bNiwAQ8PD5o1a2ZerygKDZwa0MCpAfc1ug8wBevorGhOJZ3iZNJJ8y0lL4UzKWc4k3KGledWAqBVtDRyaURLt5bmVuumrk3l4sVqotZfWHj58mV69+5NcHAwS5YsQast2RJQdGFhVFQUvr6+APz888+MGzeuxIWFr732GnFxceZh7z7++GO+/PJLubBQCCHETe04m8i4hXsxGFVeHtiMyb0bW7okUcFUVeWPP/5g//79WFlZMWHChFs2sN3sGLFZsZxMOsmJpBOcSjYF7OTc5BtuX9+hPs3dmtPUrSnNXJvRxLUJ9RzqoVE0FfGS6jwZJxpTC3TPnj1p0KAB3333XYkA7ePjA5iGuGvXrh3e3t588sknJCcnExoaytChQ81D3KWlpdGsWTP69OnDa6+9xtmzZwkNDeWtt94q0xB3EqKFEKLuWbL7Im+sOg7AnMc6cG8bXwtXJCqawWBgyZIlXLhwAWdnZyZOnIiDQ/lai1VVJS47ztRinWxqrT6TfIa47Lgbbm+rs6WxS2PzLdA5EG87b7zsvHCxdpFvQcpAQjSwaNEixo8ff8N1xV92ZGQkzz777HWTrRTvinHs2DEmT57M3r17cXV15emnn+att96SyVaEEELc1ttrTrBoZwQ2eg2/PN2V1vVkxI7aJjs7m/nz55OcnIy/vz/jxo1Dp6v4XrOpuamcSTnD6eTThKWEcSb5DOfTzlNgLLjpPnqNHi87L7zsvLDT22GlscJKa2W+12v06DQ6833RTatorz5XrizTaEs+v7KNVqNFp5juzcsUbYnlGkVz3WON5sq9ojHva+kWdQnR1ZCEaCGEqJsKDUaeWLyfbWEJeDtZs3ryPfg4ywVjtU1CQgLz588nLy+Ptm3bMnTo0CppAS40FhKZEcnZlLOcSz3H2ZSzRGVEEZ8dT0peSqWfvzJoFa05hGsUDa92epUHGz9YJeeWEF0NSYgWQoi6Kz23gOFf7eRcfCbNvB1ZNqkLznYyCUdtEx4ezpIlS1BVlX79+nHPPfdYtJ58Qz4JOQkkZCcQnx1PdmE2+YZ8CowFJe4LjYWmm1poflxgLMCgGszPDUYDBWoBBqNpmUE1mB5f2ceoGm+6vOh58W3K4t2u7zKsybBKepdKkhBdDUmIFkKIuu1ScjbD5+wkISOPkABXvp9wN7ZWMvRdbbN3717+/PNPAEaNGkXz5s0tXFH1VBSuDarBHNaNqhGDasCoGs2B26gacbVxxdHKsUrqKm1ek8s4hRBCiCri72bHd090wtFGx/6LKUz54SCFBqOlyxIVrFOnTnTs2BGAFStWXDdMrjDRKBr0Wj02Ohvs9fY4WzvjauOKh60HXnZe+Nj7UN+xPg2cGlRZgC4LCdFCCCFEFWrh68SCcR2x1mn4+3Q8r/56DPlSuPYZNGgQjRo1oqCggB9++IGMjAxLlyQqmIRoIYQQoop1aujG7NEd0GoUlh+I4uN1ZyxdkqhgWq2WESNG4O7uTnp6Oj/++CN5eXmWLktUIAnRQgghhAX0b+nNjGFtAPh6azjzt5+3cEWiohUNm2tra0t0dDTLli3DYCjbBXWi+pIQLYQQQljIyI7+/HuQaZro9/84xbJ9lyxckaho7u7uPPbYY+j1esLDw1m9erV036klJEQLIYQQFvRMzyAmdm8IwH9+PcrvR6MtXJGoaPXr12fEiBEoisLRo0fZuHGjpUsSFUBCtBBCCGFBiqLw2n0teLSTP0YVpv50mL9P3XhqZ1FzNW3alAceeACAf/75h127dlm4IlFeEqKFEEIIC1MUhfeHtuHBdn4UGlWeWXqQneGJli5LVLD27dvTt29fAP766y+OHTtm4YpEeUiIFkIIIaoBrUZh5oi29G/pTX6hkScX7+dgZM2cslnc3D333EOnTp0AWLlyJbt27cJolLHCayIJ0UIIIUQ1oddqmPVoe+5p7EF2voHQb/dyIjrN0mWJCqQoCoMGDaJ169YYjUb++usv5s+fT0xMjKVLE2UkIVoIIYSoRmz0WuaODSY4wJX03EIem7+Ho1Gpli5LVCCNRsPw4cMZMmQI1tbWREdHM3fuXDZs2EB+fr6lyxOlpKgyzkqVKe1c7EIIIURaTgFjv93LkUupOFjrWDAuhLsbuVu6LFHBMjIyWLduHSdOnADAxcWF+++/n8aNG1u4srqrtHlNQnQVkhAthBCiLDLzCnly8T52n0/GRq/h68eD6dXMy9JliUpw5swZ/vjjD9LT0wFo27YtAwcOxM7OzsKV1T0SoqshCdFCCCHKKrfAwLNLD7LpdDx6rcKXo9pzbxtfS5clKkFeXh6bNm1iz549ANjZ2TFo0CDatGmDoigWrq7ukBBdDUmIFkIIcSfyC428sOwwfxyNQaPA/z3cloeD61u6LFFJoqKiWLNmDfHx8QA0adKEwYMH4+LiYtnC6ggJ0dWQhGghhBB3ymBUefXXoyzbHwXAW/e35Il7Glq4KlFZCgsL+eeff9i2bRsGgwG9Xk+fPn3o1KkTWq3W0uXVahKiqyEJ0UIIIcrDaFR574+TLPwnAoBnegXx74HN5Kv+WiwhIYHffvuNyMhIALy8vBg8eDABAQEWrqz2khBdDUmIFkIIUV6qqvLVlnA++esMACOC6zNjeBt0Whm1trYyGo0cOnSIjRs3kpOTA5guPOzfvz8ODg4Wrq72kRBdDUmIFkIIUVF+3hfJq78ew6hC3+ZezB7dAVsr+Zq/NsvKyuLvv//m4MGDAFhbW9OnTx9CQkKki0cFkhBdDUmIFkIIUZE2nIxjyg8HySs00qGBC9+GdsTFzsrSZYlKFhUVxR9//GGe5dDT05OBAwfK2NIVREJ0NSQhWgghREXbH5HME4v2kZ5bSGMvBxaGdsTfTcYWru2MRiMHDhxg06ZN5i4ejRs3ZsCAAXh5yVji5SEhuhqSEC2EEKIyhMVlMHbBXmLTc/FwsGbBuBDa+rtYuixRBXJycti2bRt79uzBaDSiKArBwcH06tVL+kvfIQnR1ZCEaCGEEJUlJi2HJxbt51RMOjZ6Df8d1Z6BrXwsXZaoIsnJyWzYsIFTp04BYGNjw6hRowgMDLRsYTWQhOhqSEK0EEKIypSZV8iUHw6y5UwCigKv39eCCfc0lCHw6pCLFy+ydu1aYmNj0Wg0DB06lLvuusvSZdUopc1rMh6OEEIIUUs4WOuYPzaExzs3QFXh/T9OMX3NCQoNRkuXJqpIQEAAEyZMoGXLlhiNRn799Ve2bduGtJlWPAnRQgghRC2i02p478HWvDG4BYoC3+26yJPf7Sc9t8DSpYkqotfrefjhh+natSsAmzZt4rfffsNgMFi4stpFQrQQQghRyyiKwpPdGzHnsQ7Y6DVsOZPAsP/9w4XELEuXJqqIRqNhwIAB3HfffSiKwsGDB/nhhx/Iy8uzdGm1hoRoIYQQopYa1NqX5ZO64uNkQ3hCFg/O3sH2swmWLktUoU6dOjFq1Cj0ej3h4eF8//33FBTItxIVQUK0EEIIUYu1qe/Mmn91o30DF9JzCxn37V6+3XFB+sjWIc2aNSM0NBQbGxvzRC3y719+EqKFEEKIWs7L0YafnurMw8H1Marw7u8n+fcvR8krlD6ydUW9evUYMWIEiqJw+PBh9u7da+mSajwJ0UIIIUQdYK3T8snDd/HG4BZoFFh+IIoHZ//Dieg0S5cmqkhQUBD9+/cHYN26dVy4cMHCFdVsEqKFEEKIOqLogsOF4zvhZm/F6dgMHpz9D//deJYCGQavTujSpQt33XUXqqqybNkyUlJSLF1SjSUhWgghhKhjejb1ZP0LPRjUyodCo8rnG8MY/tVOwuIyLF2aqGSKojBkyBB8fX3Jycnhp59+Ij8/39Jl1UgSooUQQog6yMPBmjmPd+C/o9rhbKvn2OU07v9yB//bfI7s/EJLlycqkV6vZ9SoUdjb2xMXF8fq1avlQsM7ICFaCCGEqKMUReHBdvVY/0IP+jT3It9g5JO/ztD5w7/58M9TXErOtnSJopI4OzszcuRINBoNJ06cYPv27ZYuqcZRVPnoUWVKOxe7EEIIUdVUVeXXg5eZteksEUmm8KxRoH9Lb8Z3a8jdDd1QFMXCVYqKtn//fn7//XcARo4cScuWLS1ckeWVNq9JiK5CEqKFEEJUd0ajypaweBb+E8H2s4nm5c28HRkRUp9h7evh7mBtwQpFRVu7di179uxBp9Mxfvx46tWrZ+mSLEpCdDUkIVoIIURNcjYug4U7I/j1YBS5BabRO/Rahb7NvRnZsT49mnii00rP0JrOYDDw448/cu7cORwdHZk4cWKdzikSoqshCdFCCCFqorScAtYciWb5/kscjbo6rrSXozWD7/JlUCsfQgLd0Gqku0dNlZuby4IFC0hISMDHx4cnnngCKysrS5dlERKiqyEJ0UIIIWq607HpLN8fxcpDl0nOujo0mru9Ff1bejOwtQ9dg9yx1mktWKW4EykpKcybN4/s7GyaN29uvvCwrpEQXQ1JiBZCCFFb5Bca2RqWwLrjsWw8FUdaToF5nYO1jh5NPejT3JtezTzxkD7UNUZkZCSLFy/GYDDQrVs38wyHdYmE6GpIQrQQQojaqMBgZO+FZNYdj2X9yVji0vPM6xQF2vm70Le5F72aedHS1wmNdPuo1o4ePcqvv/4KwODBg+nYsaOFK6paEqKrIQnRQgghajujUeXY5TT+Ph3PptNxHL+cXmK9h4MV3Zt40qOpB/c09sTTUVqpq6PNmzezdetWFEVh5MiRtGjRwtIlVRkJ0dWQhGghhBB1TWxaLpvPxPP3qTh2hieRnW8osb6lrxPdm3jQJcidjoFu2FvrLFSpKE5VVX777TcOHjyIVqtlzJgxBAYGWrqsKiEhuhqSEC2EEKIuyys0cPBiKtvOJrAtLIET0SVbqXUahXb+LnQNcqdLkAftG7hgo5cLFC3FYDCwbNkyzpw5g7W1NU888QTe3t6WLqvSSYiuhiRECyGEEFclZOTxz7lEdoYn8s+5JC6n5pRYb6XVcFd9Zzo2dKNTQzeCA1xxstFbqNq6qaCggO+++45Lly7h6OjIhAkTcHFxsXRZlUpCdDUkIVoIIYS4uUvJ2ewMT2RneBK7wpOIz8grsV6jQHMfJ4IDXOkQ4EJwAzf83WxlOvJKlp2dzcKFC0lISMDd3Z0JEyZgZ2dn6bIqjYToakhCtBBCCFE6qqoSmZzNngvJ7LuQzN6IZC4mZV+3nYeDNR0auNCugQvt6rvQur6ztFZXgrS0NBYsWEB6ejr16tVj7NixWFvXzotCJURXQxKihRBCiDsXm5bLgYspHIxM4cDFFE5Ep1FguD7GBHna07a+C3fVd6ZNfWda+DphZyUXLJZXfHw83377Lbm5uTRo0IDHH3+8Vs5qKCG6GpIQLYQQQlSc3AIDxy+ncTAyhSOX0jgSlUpUSs5122kUaOTpQGs/J1rXc6alnxMtfZ1wsat9AbCyXb58me+++468vDwaNmzI6NGj0etrV8u/hOhqSEK0EEIIUbmSMvM4GmUK1EcupXIiOv26vtVFfJ1taO7jSAtfJ1r4OtHcx5FAD3v02ro31XVZXLp0ie+++46CggKaNGnCI488gk5Xe1r6JURXQxKihRBCiKoXn57Lieh0jl9O43h0Gidj0rmUfH2LNYBeq9DQw56m3o5Xbg409nIkwN1OwnUxERERLFmyhMLCQpo3b86IESPQamvHcIQSoqshCdFCCCFE9ZCRW8CZ2AxOxaRz6sp9WGwGWddMBlNEp1EIcLcjyNOBxl4ONPJ0oJ6LLfVdbfF2ssFKV/cCdnh4OD/88AMGg4FWrVoxfPjwWhGkJURXQxKihRBCiOpLVVWi03IJi80gLC6DsLhMzsZnEB6fedNwDaAo4O1og5+LDT7ONrjZW+Fmb42Hg9WVx1a421vjaq/H1c6qVrVoh4WF8dNPP2E0GmndujXDhg2r8UFaQnQ1JCFaCCGEqHlUVSU2PZdz8Zmci88kPCGTiMRsLqfmcDk1h/xCY5mO52ijuxKsrQhwtyfQ3Z6GnvY0dLcn0MMOxxo2RN+pU6dYvnw5RqOR5s2b8/DDD9foPtISoqshCdFCCCFE7aKqKomZ+aZAnZJDQkYuyVn5JGXlm+4z80nKyiM1u4CU7HyMpUhdHg5WNHCzI8DdngB3OwLc7WjgZk8DNzs8HKyq5eQyZ86cYdmyZRgMBpo0acLIkSNr7KgdEqKrIQnRQgghRN1lNKqk5xaQnJVPSnY+cel5XEjMIiIxi4ikLC4kZpGYmX/LY9jqtdR3tcXfzY4GbnbUdzX1y/ZzsaWeiy1u9pYL2eHh4fz4448UFhbSsGFDHn300TseR1pVVYwqGIwqRlVFp1HQVVE3GAnR1ZCEaCGEEELcSnpuAZFJ2VxMyiYiKcv0ODmLi0nZxKbncrvUZqvX4udig7eTDY42Ohxt9DjZ6K881qHVKOZgajBy5V6l0KhiMBopNKoUGoqWGU33huLbXF1efFnRzTo3iUbph9GqBtK1zpywu4sCVYvhynmMV/YpOq+pFlNYNqgqqnp1WXH/9/BdjAzxr7w3vpjS5rWa22FFCCGEEKKWcbLR07qeM63rOV+3Lq/QQHRqLpeSs7mUks2l5BwupWQTfaUrSXxGHjkFBsITsghPyLJA9QAawpSm9LcKw8mQRuO0g2zMb0peOSOnsTT9YKpYrQ/RDzzwAIcPHyY+Ph5XV1f69evHxx9/jJ+fn3mbyMhIJk+ezKZNm7C1tWX06NHMnDmzxFcQx44dY8qUKezduxc3NzcmTZrEm2++WS37JQkhhBCi9rHWaWnoYU9DD/sbrs8rNBCblmvqm52ZR3puIRm5BaTnXLnPLcSoqmgVBa1GQaMoaDWg1SjoNJor96ZuEzqNYn6u1V6512jQKqDTmrY1r79yrKLHWo1Cdmprjm75Dc+8LJ70jqDzgKE4ODpd3VaroFUUNBrFXI+imGopvlxz5XjW1XAIwVofonv37s1rr72Gr68vly9f5qWXXuLhhx9m586dABgMBgYPHoynpyc7duwgKSmJcePGoaoqs2bNAkzN+v3796d3797s27ePsLAwQkNDsbe358UXX7TkyxNCCCGEAEwh23Qx4o1DdtXy5u4gT5YsWUJ6Wgp71/3C448/jre3t6ULqzB1rk/0mjVrGDp0KHl5eej1etauXcv999/PpUuXzK3TP/30E6GhocTHx+Pk5MScOXN49dVXiYuLw9raGoCPPvqIWbNmERUVVerWaOkTLYQQQoi6JC0tjSVLlpCQkIC1tTWPPvoogYGBli7rlkqb16pf23glSk5OZunSpXTt2tU87MquXbto3bp1ie4dAwcOJC8vjwMHDpi36dmzpzlAF20THR1NRERElb4GIYQQQoiawtnZmSeeeIIGDRqQl5fH999/z8mTJy1dVoWoEyH6lVdewd7eHnd3dyIjI1m9erV5XWxs7HVfLbi6umJlZUVsbOxNtyl6XrTNjeTl5ZGenl7iJoQQQghRl9ja2jJmzBiaN2+OwWBg2bJl7Nmzx9JllVuNDNFvv/02iqLc8rZ//37z9i+//DKHDh1i/fr1aLVaxo4dS/FeLDfqjqGqaonl125TtP+tunLMmDEDZ2dn883fv2qGZhFCCCGEqE70ej0jR44kJCQEgLVr1/Lnn39iMNx8OvXqrkZeWDhlyhRGjRp1y22K97fx8PDAw8ODpk2b0qJFC/z9/dm9ezddunTBx8fnuk9DKSkpFBQUmFubfXx8rmtxjo+PB7hlB/lXX32VadOmmZ+np6dLkBZCCCFEnaTRaBg8eDDOzs78/fff7N27l6SkJEaMGIGNjY2lyyuzGhmii0LxnShqQc7LywOgS5cufPDBB8TExODr6wvA+vXrsba2Jjg42LzNa6+9Rn5+vnnYu/Xr1+Pn53fLzvHW1tYl+lELIYQQQtRliqLQvXt33N3dWblyJeHh4cyfP5/Ro0fj5uZm6fLKpEZ25yitvXv3Mnv2bA4fPszFixfZvHkzo0ePJigoiC5dugAwYMAAWrZsyZgxYzh06BB///03L730EhMnTjRfkTl69Gisra0JDQ3l+PHjrFy5kg8//JBp06bJONFCCCGEEGXUsmVLxo8fj6OjI4mJicybN6/GDdZQq0O0ra0tv/76K3379qVZs2Y88cQTtG7dmq1bt5pbiLVaLX/88Qc2NjZ069aNkSNHMnToUGbOnGk+jrOzMxs2bCAqKoqQkBCeffZZpk2bVqKrhhBCCCGEKD0/Pz8mTpyIn58fOTk5fPfdd+aR0WqCOjdOtCXJONFCCCGEECXl5+ezevVqTpw4AUD79u257777zMMRVzUZJ1oIIYQQQlR7VlZWPPTQQ/Tt2xdFUTh06BDffvstqampli7tliRECyGEEEIIi9JoNHTv3p3HH38cW1tbYmJi+Oabbzh37pylS7spCdFCCCGEEKJaCAoKYtKkSeZ+0kuWLGHbtm0YjUZLl3YdCdFCCCGEEKLacHFxYfz48XTo0AGATZs2sXHjRgtXdT0J0UIIIYQQolrR6/U88MADPPDAAzg4ONCxY0dLl3SdGjnZihBCCCGEqP06dOhAmzZtLDZSx61IS7QQQgghhKi2qmOABgnRQgghhBBClJmEaCGEEEIIIcpIQrQQQgghhBBlJCFaCCGEEEKIMpIQLYQQQgghRBlJiBZCCCGEEKKMJEQLIYQQQghRRhKihRBCCCGEKCMJ0UIIIYQQQpSRhGghhBBCCCHKSEK0EEIIIYQQZSQhWgghhBBCiDKSEC2EEEIIIUQZSYgWQgghhBCijCRECyGEEEIIUUYSooUQQgghhCgjCdFCCCGEEEKUkYRoIYQQQgghykhCtBBCCCGEEGUkIVoIIYQQQogykhAthBBCCCFEGUmIFkIIIYQQoowkRAshhBBCCFFGEqKFEEIIIYQoI52lC6hLVFUFID093cKVCCGEEEKIGynKaUW57WYkRFehjIwMAPz9/S1ciRBCCCGEuJWMjAycnZ1vul5RbxezRYUxGo1ER0fj6OiIoiiWLqfaSU9Px9/fn0uXLuHk5GTpcmoseR/LT97DiiHvY/nJe1gx5H2sGHXlfVRVlYyMDPz8/NBobt7zWVqiq5BGo6F+/fqWLqPac3JyqtW/nFVF3sfyk/ewYsj7WH7yHlYMeR8rRl14H2/VAl1ELiwUQgghhBCijCRECyGEEEIIUUYSokW1YW1tzfTp07G2trZ0KTWavI/lJ+9hxZD3sfzkPawY8j5WDHkfS5ILC4UQQgghhCgjaYkWQgghhBCijCRECyGEEEIIUUYSooUQQgghhCgjCdFCCCGEEEKUkYRoUS0FBgaiKEqJ23/+8x9Ll1Vj5eXl0a5dOxRF4fDhw5Yup0Z54IEHaNCgATY2Nvj6+jJmzBiio6MtXVaNEhERwYQJE2jYsCG2trYEBQUxffp08vPzLV1ajfPBBx/QtWtX7OzscHFxsXQ5NcJXX31Fw4YNsbGxITg4mO3bt1u6pBpn27ZtDBkyBD8/PxRFYdWqVZYuqVqQEC2qrXfffZeYmBjz7Y033rB0STXWv//9b/z8/CxdRo3Uu3dvli1bxpkzZ1ixYgXh4eE8/PDDli6rRjl9+jRGo5FvvvmGEydO8Pnnn/P111/z2muvWbq0Gic/P58RI0bwzDPPWLqUGuHnn39m6tSpvP766xw6dIju3btz7733EhkZaenSapSsrCzatm3L7NmzLV1KtSJD3IlqKTAwkKlTpzJ16lRLl1LjrV27lmnTprFixQpatWrFoUOHaNeunaXLqrHWrFnD0KFDycvLQ6/XW7qcGuuTTz5hzpw5nD9/3tKl1EiLFi1i6tSppKamWrqUau3uu++mQ4cOzJkzx7ysRYsWDB06lBkzZliwsppLURRWrlzJ0KFDLV2KxUlLtKi2Pv74Y9zd3WnXrh0ffPCBfPV7B+Li4pg4cSLff/89dnZ2li6nxktOTmbp0qV07dpVAnQ5paWl4ebmZukyRC2Wn5/PgQMHGDBgQInlAwYMYOfOnRaqStQmEqJFtfT888/z008/sXnzZqZMmcIXX3zBs88+a+myahRVVQkNDeXpp58mJCTE0uXUaK+88gr29va4u7sTGRnJ6tWrLV1SjRYeHs6sWbN4+umnLV2KqMUSExMxGAx4e3uXWO7t7U1sbKyFqhK1iYRoUWXefvvt6y4WvPa2f/9+AF544QV69uzJXXfdxZNPPsnXX3/NggULSEpKsvCrsLzSvo+zZs0iPT2dV1991dIlVztl+VkEePnllzl06BDr169Hq9UyduxYpCdc2d9HgOjoaAYNGsSIESN48sknLVR59XIn76MoPUVRSjxXVfW6ZULcCekTLapMYmIiiYmJt9wmMDAQGxub65ZfvnyZ+vXrs3v3bu6+++7KKrFGKO37OGrUKH777bcSfywMBgNarZbHHnuMxYsXV3ap1VZ5fhajoqLw9/dn586ddOnSpbJKrBHK+j5GR0fTu3dv7r77bhYtWoRGI+04cGc/j9In+vby8/Oxs7Nj+fLlDBs2zLz8+eef5/Dhw2zdutWC1dVc0if6Kp2lCxB1h4eHBx4eHne076FDhwDw9fWtyJJqpNK+j19++SXvv/+++Xl0dDQDBw7k559/rvMfRMrzs1jU7pCXl1eRJdVIZXkfL1++TO/evQkODmbhwoUSoIspz8+juDkrKyuCg4PZsGFDiRC9YcMGHnzwQQtWJmoLCdGi2tm1axe7d++md+/eODs7s2/fPl544QXzeL2idK59rxwcHAAICgqifv36liipxtm7dy979+7lnnvuwdXVlfPnz/PWW28RFBRU51uhyyI6OppevXrRoEEDZs6cSUJCgnmdj4+PBSureSIjI0lOTiYyMhKDwWAe971x48bm33Fx1bRp0xgzZgwhISF06dKFuXPnEhkZKf3xyygzM5Nz586Zn1+4cIHDhw/j5uZWt/8uq0JUMwcOHFDvvvtu1dnZWbWxsVGbNWumTp8+Xc3KyrJ0aTXahQsXVEA9dOiQpUupMY4ePar27t1bdXNzU62trdXAwED16aefVqOioixdWo2ycOFCFbjhTZTNuHHjbvg+bt682dKlVVv/+9//1ICAANXKykrt0KGDunXrVkuXVONs3rz5hj9348aNs3RpFiV9ooUQQgghhCgj6ZQmhBBCCCFEGUmIFkIIIYQQoowkRAshhBBCCFFGEqKFEEIIIYQoIwnRQgghhBBClJGEaCGEEEIIIcpIQrQQQgghhBBlJCFaCCGEEEKIMpIQLYQQQgghRBlJiBZCiFpq0aJFKIqCoihERERYupxSKSgooFmzZiiKws8//3zT7VRVxcnJCY1Gg7e3NyNHjuTixYu3Pf6zzz6LoiiMGzeuIssWQtRBEqKFEEJUG7NmzSIsLIwWLVowYsSIm24XHh5ORkYGqqoSHx/P8uXLue+++257/FdffRUrKyu+//579u3bV5GlCyHqGAnRQgghqoXMzExmzJgBwFtvvYVGc/M/Ub6+vhw7dox169bRsGFDAE6ePMmBAwdueQ5/f3/GjRuHqqq88cYbFVe8EKLOkRAthBCiWpgzZw6JiYn4+/szcuTIW25rb29P69atGThwIO+99555+eHDh297nhdffBGA9evXS2u0EOKOSYgWQghhcQaDgdmzZwPw6KOP3rIV+lpdu3Y1Pz5+/Phtt2/WrBkdOnQA4L///W8ZKxVCCBMJ0UIIISxuw4YNREZGAvD444+Xad/AwEAcHR2B0oVogMceewyAFStWkJaWVqbzCSEESIgWQog6LT8/n6+++orevXvj6emJlZUVPj4+3HfffSxZsgSj0XjbYyQmJvLyyy/TtGlTbG1t8fb2pn///qxcuRIo3Sghy5YtA6BJkya0adOmTK9BURSaNGkClD5EP/TQQwDk5uayevXqMp1PCCFAQrQQQtRZFy9epF27dkyePJktW7aQmJhIQUEBcXFxrF27ljFjxtCzZ0+Sk5NveowjR47QsmVLZs6cydmzZ8nNzSU+Pp6NGzcyfPhwJk2aVKpaNm/eDEDnzp3L/DoOHDhg7gsdGxtLUlLSbfcJCAjA19cXgC1btpT5nEIIISFaCCHqoMzMTPr06cOpU6cAGDp0KGvWrGH//v0sX76cnj17ArBjxw7uv/9+DAbDdcdISUlh0KBBJCQkAKYuEmvXrmX//v389NNPdOnShblz5/L111/fspaoqChzC3XHjh3L9DoMBgNPPfVUiRbzEydOlGrfonNt3769TOcUQgiQEC2EEHXSO++8w/nz5wF44403WLlyJUOGDCE4OJiHH36YzZs3m/sN79q1i7lz5153jLfffpvY2FgAZs6cyZIlSxg0aBDBwcE88sgjbN++nQcffJA9e/bcspadO3eaH7dv375Mr2PWrFkcPHiwxLLSdukIDg4G4Ny5c8THx5fpvEIIISFaCCHqmLy8PObPnw9Ay5Ytefvtt6/bRlEUvvrqK9zd3QHMI2cUyc3NZfHixQB06NCBadOmXXcMrVbLN998g42NzS3riYqKMj/28vIq9euIiorizTffBMo+Qse157p8+XKpzyuEECAhWggh6pwDBw6QmpoKQGhoKFqt9obbOTk5mcdrPnnyJDExMSWOUTSqxdixY1EU5YbH8Pb2ZuDAgbesp6g7CICrq2upX8e//vUvMjMzcXR05Oeff8bFxQUofYh2c3O7YQ1CCFEaEqKFEMKCCgsLzSNXlOe2aNGiUp+zeMi8++67b7lt8fXF9yv+uKhbxM2EhITccn3xCxdLG6LXrFnDqlWrAPjwww+pX7++eVSP0obo4ucqzcWIQghRnIRoIYSoY4qHVm9v71tu6+Pjc8P9UlJSzI9v1wXD09PzluuLd/fIycm55bYAWVlZ/Otf/wJMIf/ZZ58FMIfolJQUoqOjb3uc4ueytbW97fZCCFGcztIFCCFEXabT6cwjZJRH0XBtZXWzbhhFVFW9o+OWRfGQnZycbJ445WbeeustIiMj0ev1zJs3zzy7YfHxpY8fP46fn98tj1P8Q8Htgr4QQlxLQrQQQlhY8+bNq/R8xfsCx8bG0rRp05tuGxcXd8P9ineFiI+Pv+UxbtffuHiATUlJISAg4KbbHjlyxDxV90svvVQiON91113mx8ePH2fAgAG3PG/x1nQJ0UKIspLuHEIIUce0bt3a/Ph2w8/t3bv3hvu1atXK/Hj//v23PMbt1hcPwmFhYTfdzmg08tRTT2EwGAgKCjKPzHGj+krTL7roXPb29jRq1Oi22wshRHESooUQoo4JDg42j2SxePHiG06kApCRkWGejrtly5YluoyEhITg7OwMwPfff3/Tbh9xcXH89ddft6wnJCTE3Cd53759N91uzpw55lD/9ddfX9eP2cnJydyKXZoQXXSuzp07o9PJF7NCiLKREC2EEHWMtbU1Tz75JGCa3e+dd965bhtVVZkyZQqJiYkATJkypcR6Gxsbxo4dC8DBgwf57LPPrjuG0Whk0qRJ5Obm3rIeKysrOnXqBJRs+S4uJiaG119/HTANqdevX78bblfUqn3y5Mlb9ufOy8vj6NGjAHTv3v2W9QkhxI1IiBZCiDrorbfeMndheO+99xg+fDi///47Bw8eZMWKFfTp04fvvvsOgC5duvDUU09dd4y3337bPHrHSy+9xOOPP85ff/3FwYMHWbZsGd27d2f16tXmgAw3v5Bx8ODBgClEZ2RkXLf++eefJy0tDQ8PDz799NObvq6iftFZWVlcuHDhpttt27aNgoKCEucWQoiykBAthBB1kKOjI3///bf5osZrp/3esmULAN26deP333+/4YQsbm5urFu3znxR3tKlS0tM+71z505CQ0OZNGmSeZ+bzV44evRotFotubm5rFy5ssS6tWvXsnz5cgA+/fRTPDw8bvq6rh2h42Z++OEHAJo1a3bbcayFEOJGJEQLIUQdFRgYyJEjR5g9ezY9e/bE3d0dvV6Pt7c3gwYN4vvvv2fbtm0lRuW4Vtu2bTl58iQvvvgiTZo0wdraGg8PD3r37s0PP/zAwoULSU9PN29f1I/6WvXq1ePBBx8ETGG8SE5ODpMnTwagb9++5i4kN1OaEF08qBeNMS2EEGWlqFUxCKgQQog668knn2TBggXUr1+fS5cu3XS73bt306VLF7RaLefOnSMwMLBS6lmyZAljxozBzc2NiIiI245LLYQQNyIt0UIIISpNTk4Oq1evBkyjYNxK586duffeezEYDMyYMaNS6jEajXz44YeAqR+3BGghxJ2SEC2EEOKOhYeH33QUDIPBwDPPPGMe4WPcuHG3Pd7HH3+MVqtl4cKFREZGVmitAMuXL+fUqVP4+/szderUCj++EKLukIExhRBC3LH33nuPvXv3MmrUKO6++268vLzIycnh6NGjzJs3j4MHDwKm/sylGQWjTZs2LFq0iHPnzhEZGUmDBg0qtF6DwcD06dPp06fPdeNMCyFEWUifaCGEEHcsNDSUxYsX33Kbbt26sXr1atzd3auoKiGEqHwSooUQQtyxM2fOsGLFCjZs2MDFixdJSEigoKAAd3d3QkJCeOSRRxg1ahQajfQeFELULhKihRBCCCGEKCNpGhBCCCGEEKKMJEQLIYQQQghRRhKihRBCCCGEKCMJ0UIIIYQQQpSRhGghhBBCCCHKSEK0EEIIIYQQZSQhWgghhBBCiDKSEC2EEEIIIUQZSYgWQgghhBCijCRECyGEEEIIUUYSooUQQgghhCij/wfSfQ7HaDOlngAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_fig, ax = subplots(figsize=(8,8))\n",
    "soln_path.plot(ax=ax, legend=False)\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Standardized coefficiients', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a6fe960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114690.73118253506"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(tuned_lasso.mse_path_.mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7fcfa72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lassoCV_fig, ax = subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(tuned_lasso.alphas_),\n",
    "            tuned_lasso.mse_path_.mean(1),\n",
    "            yerr=tuned_lasso.mse_path_.std(1) / np.sqrt(K))\n",
    "ax.axvline(-np.log(tuned_lasso.alpha_), c='k', ls='--')\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "547516f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-210.01008773,  243.4550306 ,    0.        ,    0.        ,\n",
       "          0.        ,   97.69397357,  -41.52283116,   -0.        ,\n",
       "          0.        ,   39.62298193,  205.75273856,  124.55456561,\n",
       "       -126.29986768,   15.70262427,  -59.50157967,   75.24590036,\n",
       "         21.62698014,  -12.04423675,   -0.        ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c3a9a3",
   "metadata": {},
   "source": [
    "##### PCR and PLS Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f7437f",
   "metadata": {},
   "source": [
    "Principal Components Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f63ae11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09846131, 0.4758765 ])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "linreg = skl.LinearRegression()\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('linreg', linreg)])\n",
    "pipe.fit(X, Y)\n",
    "pipe.named_steps['linreg'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec8ffd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([106.36859204,  21.60350456])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('scaler', scaler),\n",
    "                 ('pca', pca),\n",
    "                 ('linreg', linreg)])\n",
    "pipe.fit(X, Y)\n",
    "pipe.named_steps['linreg'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87aec2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-6.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-6.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;pca&#x27;, PCA(n_components=2)),\n",
       "                                       (&#x27;linreg&#x27;, LinearRegression())]),\n",
       "             param_grid={&#x27;pca__n_components&#x27;: range(1, 20)},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">Pipeline(step...egression())])</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;pca__n_components&#x27;: range(1, 20)}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;neg_mean_squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">KFold(n_split... shuffle=True)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___scaler__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>If False, try to avoid a copy and do inplace scaling instead.<br>This is not guaranteed to always work inplace; e.g. if the data is<br>not a NumPy array or scipy.sparse CSR matrix, a copy may still be<br>returned.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_mean',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_mean,-bool%2C%20default%3DTrue\">\n",
       "            with_mean\n",
       "            <span class=\"param-doc-description\">with_mean: bool, default=True<br><br>If True, center the data before scaling.<br>This does not work (and will raise an exception) when attempted on<br>sparse matrices, because centering them entails building a dense<br>matrix which in common use cases is likely to be too large to fit in<br>memory.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_std',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_std,-bool%2C%20default%3DTrue\">\n",
       "            with_std\n",
       "            <span class=\"param-doc-description\">with_std: bool, default=True<br><br>If True, scale the data to unit variance (or equivalently,<br>unit standard deviation).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>PCA</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___pca__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_components',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=n_components,-int%2C%20float%20or%20%27mle%27%2C%20default%3DNone\">\n",
       "            n_components\n",
       "            <span class=\"param-doc-description\">n_components: int, float or 'mle', default=None<br><br>Number of components to keep.<br>if n_components is not set all components are kept::<br><br>    n_components == min(n_samples, n_features)<br><br>If ``n_components == 'mle'`` and ``svd_solver == 'full'``, Minka's<br>MLE is used to guess the dimension. Use of ``n_components == 'mle'``<br>will interpret ``svd_solver == 'auto'`` as ``svd_solver == 'full'``.<br><br>If ``0 < n_components < 1`` and ``svd_solver == 'full'``, select the<br>number of components such that the amount of variance that needs to be<br>explained is greater than the percentage specified by n_components.<br><br>If ``svd_solver == 'arpack'``, the number of components must be<br>strictly less than the minimum of n_features and n_samples.<br><br>Hence, the None case results in::<br><br>    n_components == min(n_samples, n_features) - 1</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">17</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>If False, data passed to fit are overwritten and running<br>fit(X).transform(X) will not yield the expected results,<br>use fit_transform(X) instead.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('whiten',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=whiten,-bool%2C%20default%3DFalse\">\n",
       "            whiten\n",
       "            <span class=\"param-doc-description\">whiten: bool, default=False<br><br>When True (False by default) the `components_` vectors are multiplied<br>by the square root of n_samples and then divided by the singular values<br>to ensure uncorrelated outputs with unit component-wise variances.<br><br>Whitening will remove some information from the transformed signal<br>(the relative variance scales of the components) but can sometime<br>improve the predictive accuracy of the downstream estimators by<br>making their data respect some hard-wired assumptions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('svd_solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=svd_solver,-%7B%27auto%27%2C%20%27full%27%2C%20%27covariance_eigh%27%2C%20%27arpack%27%2C%20%27randomized%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27auto%27\">\n",
       "            svd_solver\n",
       "            <span class=\"param-doc-description\">svd_solver: {'auto', 'full', 'covariance_eigh', 'arpack', 'randomized'},            default='auto'<br><br>\"auto\" :<br>    The solver is selected by a default 'auto' policy is based on `X.shape` and<br>    `n_components`: if the input data has fewer than 1000 features and<br>    more than 10 times as many samples, then the \"covariance_eigh\"<br>    solver is used. Otherwise, if the input data is larger than 500x500<br>    and the number of components to extract is lower than 80% of the<br>    smallest dimension of the data, then the more efficient<br>    \"randomized\" method is selected. Otherwise the exact \"full\" SVD is<br>    computed and optionally truncated afterwards.<br>\"full\" :<br>    Run exact full SVD calling the standard LAPACK solver via<br>    `scipy.linalg.svd` and select the components by postprocessing<br>\"covariance_eigh\" :<br>    Precompute the covariance matrix (on centered data), run a<br>    classical eigenvalue decomposition on the covariance matrix<br>    typically using LAPACK and select the components by postprocessing.<br>    This solver is very efficient for n_samples >> n_features and small<br>    n_features. It is, however, not tractable otherwise for large<br>    n_features (large memory footprint required to materialize the<br>    covariance matrix). Also note that compared to the \"full\" solver,<br>    this solver effectively doubles the condition number and is<br>    therefore less numerical stable (e.g. on input data with a large<br>    range of singular values).<br>\"arpack\" :<br>    Run SVD truncated to `n_components` calling ARPACK solver via<br>    `scipy.sparse.linalg.svds`. It requires strictly<br>    `0 < n_components < min(X.shape)`<br>\"randomized\" :<br>    Run randomized SVD by the method of Halko et al.<br><br>.. versionadded:: 0.18.0<br><br>.. versionchanged:: 1.5<br>    Added the 'covariance_eigh' solver.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=tol,-float%2C%20default%3D0.0\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=0.0<br><br>Tolerance for singular values computed by svd_solver == 'arpack'.<br>Must be of range [0.0, infinity).<br><br>.. versionadded:: 0.18.0</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('iterated_power',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=iterated_power,-int%20or%20%27auto%27%2C%20default%3D%27auto%27\">\n",
       "            iterated_power\n",
       "            <span class=\"param-doc-description\">iterated_power: int or 'auto', default='auto'<br><br>Number of iterations for the power method computed by<br>svd_solver == 'randomized'.<br>Must be of range [0, infinity).<br><br>.. versionadded:: 0.18.0</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_oversamples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=n_oversamples,-int%2C%20default%3D10\">\n",
       "            n_oversamples\n",
       "            <span class=\"param-doc-description\">n_oversamples: int, default=10<br><br>This parameter is only relevant when `svd_solver=\"randomized\"`.<br>It corresponds to the additional number of random vectors to sample the<br>range of `X` so as to ensure proper conditioning. See<br>:func:`~sklearn.utils.extmath.randomized_svd` for more details.<br><br>.. versionadded:: 1.1</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('power_iteration_normalizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=power_iteration_normalizer,-%7B%27auto%27%2C%20%27QR%27%2C%20%27LU%27%2C%20%27none%27%7D%2C%20default%3D%27auto%27\">\n",
       "            power_iteration_normalizer\n",
       "            <span class=\"param-doc-description\">power_iteration_normalizer: {'auto', 'QR', 'LU', 'none'}, default='auto'<br><br>Power iteration normalizer for randomized SVD solver.<br>Not used by ARPACK. See :func:`~sklearn.utils.extmath.randomized_svd`<br>for more details.<br><br>.. versionadded:: 1.1</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.PCA.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Used when the 'arpack' or 'randomized' solvers are used. Pass an int<br>for reproducible results across multiple function calls.<br>See :term:`Glossary <random_state>`.<br><br>.. versionadded:: 0.18.0</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___linreg__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Whether to calculate the intercept for this model. If set<br>to False, no intercept will be used in calculations<br>(i.e. data is expected to be centered).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=copy_X,-bool%2C%20default%3DTrue\">\n",
       "            copy_X\n",
       "            <span class=\"param-doc-description\">copy_X: bool, default=True<br><br>If True, X will be copied; else, it may be overwritten.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=tol,-float%2C%20default%3D1e-6\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-6<br><br>The precision of the solution (`coef_`) is determined by `tol` which<br>specifies a different convergence criterion for the `lsqr` solver.<br>`tol` is set as `atol` and `btol` of :func:`scipy.sparse.linalg.lsqr` when<br>fitting on sparse training data. This parameter has no effect when fitting<br>on dense data.<br><br>.. versionadded:: 1.7</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to use for the computation. This will only provide<br>speedup in case of sufficiently large problems, that is if firstly<br>`n_targets > 1` and secondly `X` is sparse or if `positive` is set<br>to `True`. ``None`` means 1 unless in a<br>:obj:`joblib.parallel_backend` context. ``-1`` means using all<br>processors. See :term:`Glossary <n_jobs>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=positive,-bool%2C%20default%3DFalse\">\n",
       "            positive\n",
       "            <span class=\"param-doc-description\">positive: bool, default=False<br><br>When set to ``True``, forces the coefficients to be positive. This<br>option is only supported for dense arrays.<br><br>For a comparison between a linear regression model with positive constraints<br>on the regression coefficients and a linear regression without such constraints,<br>see :ref:`sphx_glr_auto_examples_linear_model_plot_nnls.py`.<br><br>.. versionadded:: 0.24</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-6');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('pca', PCA(n_components=2)),\n",
       "                                       ('linreg', LinearRegression())]),\n",
       "             param_grid={'pca__n_components': range(1, 20)},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'pca__n_components': range(1, 20)}\n",
    "grid = skm.GridSearchCV(pipe,\n",
    "                        param_grid,\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "175e707a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pcr_fig, ax = subplots(figsize=(8,8))\n",
    "n_comp = param_grid['pca__n_components']\n",
    "ax.errorbar(n_comp,\n",
    "            -grid.cv_results_['mean_test_score'],\n",
    "            grid.cv_results_['std_test_score'] / np.sqrt(K))\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20)\n",
    "ax.set_xlabel('# principal components', fontsize=20)\n",
    "ax.set_xticks(n_comp[::2])\n",
    "ax.set_ylim([50000,250000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f71399c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204139.30692994667"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xn = np.zeros((X.shape[0], 1))\n",
    "cv_null = skm.cross_validate(linreg,\n",
    "                             Xn,\n",
    "                             Y,\n",
    "                             cv=kfold,\n",
    "                             scoring='neg_mean_squared_error')\n",
    "-cv_null['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1dd3c5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3831424 , 0.21841076])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps['pca'].explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a12e3d",
   "metadata": {},
   "source": [
    "Partial Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "386cb0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-7.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-7.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PLSRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>PLSRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html\">?<span>Documentation for PLSRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_components',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=n_components,-int%2C%20default%3D2\">\n",
       "            n_components\n",
       "            <span class=\"param-doc-description\">n_components: int, default=2<br><br>Number of components to keep. Should be in `[1, n_features]`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=scale,-bool%2C%20default%3DTrue\">\n",
       "            scale\n",
       "            <span class=\"param-doc-description\">scale: bool, default=True<br><br>Whether to scale `X` and `y`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=max_iter,-int%2C%20default%3D500\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=500<br><br>The maximum number of iterations of the power method when<br>`algorithm='nipals'`. Ignored otherwise.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">500</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=tol,-float%2C%20default%3D1e-06\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-06<br><br>The tolerance used as convergence criteria in the power method: the<br>algorithm stops whenever the squared norm of `u_i - u_{i-1}` is less<br>than `tol`, where `u` corresponds to the left singular vector.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>Whether to copy `X` and `y` in :term:`fit` before applying centering,<br>and potentially scaling. If `False`, these operations will be done<br>inplace, modifying both arrays.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-7');</script></body>"
      ],
      "text/plain": [
       "PLSRegression()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pls = PLSRegression(n_components=2,\n",
    "                    scale=True)\n",
    "pls.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a6da065e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-8.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-8.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=PLSRegression(),\n",
       "             param_grid={&#x27;n_components&#x27;: range(1, 20)},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">PLSRegression()</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;n_components&#x27;: range(1, 20)}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;neg_mean_squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">KFold(n_split... shuffle=True)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: PLSRegression</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>PLSRegression(n_components=12)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>PLSRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html\">?<span>Documentation for PLSRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_components',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=n_components,-int%2C%20default%3D2\">\n",
       "            n_components\n",
       "            <span class=\"param-doc-description\">n_components: int, default=2<br><br>Number of components to keep. Should be in `[1, n_features]`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">12</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=scale,-bool%2C%20default%3DTrue\">\n",
       "            scale\n",
       "            <span class=\"param-doc-description\">scale: bool, default=True<br><br>Whether to scale `X` and `y`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=max_iter,-int%2C%20default%3D500\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=500<br><br>The maximum number of iterations of the power method when<br>`algorithm='nipals'`. Ignored otherwise.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">500</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=tol,-float%2C%20default%3D1e-06\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-06<br><br>The tolerance used as convergence criteria in the power method: the<br>algorithm stops whenever the squared norm of `u_i - u_{i-1}` is less<br>than `tol`, where `u` corresponds to the left singular vector.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.cross_decomposition.PLSRegression.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>Whether to copy `X` and `y` in :term:`fit` before applying centering,<br>and potentially scaling. If `False`, these operations will be done<br>inplace, modifying both arrays.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-8');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=PLSRegression(),\n",
       "             param_grid={'n_components': range(1, 20)},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_components':range(1, 20)}\n",
    "grid = skm.GridSearchCV(pls,\n",
    "                        param_grid,\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "324a2b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuAAAAK6CAYAAAB4y+mYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAigpJREFUeJzs3XlcVmX+//H3YbsFhFsQATFFK6MMM7VyqzRLzXHJNms0kqnsO5X5bdT5zthMZc2UzbRM87Npambas2was0XN1HLJUVwj96VccAFxgRsB2a/fH8jRW0DRGw8gr+fjcT+Ecz7nXNe5RXxzcZ3rWMYYIwAAAACO8KvrDgAAAACNCQEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwUIMM4JMnT9bVV1+tsLAwRUdHa9iwYdqyZYtXTXJysizL8np1797dq6awsFCPPvqooqKiFBoaqqFDh2rPnj1eNVlZWUpKSpLb7Zbb7VZSUpKys7O9atLS0jRkyBCFhoYqKipKY8eOVVFRkVfNunXr1Lt3bwUHB6tVq1Z65plnZIypvTcFAAAADUKDDOCLFi3SI488opSUFM2bN08lJSXq37+/8vLyvOpuvvlmpaen26/Zs2d77X/sscc0Y8YMTZs2TUuWLFFubq4GDx6s0tJSu2bEiBFKTU3VnDlzNGfOHKWmpiopKcneX1paqkGDBikvL09LlizRtGnTNH36dI0fP96uycnJUb9+/RQXF6eVK1dqypQpevHFF/Xyyy+fo3cIAAAA9ZVlzoNh2AMHDig6OlqLFi3S9ddfL6l8BDw7O1ufffZZlcd4PB61aNFC77//vu666y5J0r59+9S6dWvNnj1bAwYM0KZNm9ShQwelpKSoW7dukqSUlBT16NFDmzdvVkJCgr766isNHjxYu3fvVlxcnCRp2rRpSk5OVmZmpsLDw/X3v/9dEydO1P79++VyuSRJzz//vKZMmaI9e/bIsqxz/A4BAACgvgio6w7UBo/HI0mKjIz02r5w4UJFR0erWbNm6t27t5599llFR0dLklavXq3i4mL179/fro+Li1NiYqKWLl2qAQMGaNmyZXK73Xb4lqTu3bvL7XZr6dKlSkhI0LJly5SYmGiHb0kaMGCACgsLtXr1at1www1atmyZevfubYfvipqJEydq586dateuXaVrKiwsVGFhof15WVmZDh8+rObNmxPYAQAA6iFjjI4cOaK4uDj5+VU/0aTBB3BjjMaNG6drr71WiYmJ9vaBAwfqzjvvVHx8vHbs2KEnnnhCffv21erVq+VyuZSRkaGgoCBFRER4nS8mJkYZGRmSpIyMDDuwnyg6OtqrJiYmxmt/RESEgoKCvGratm1bqZ2KfVUF8MmTJ+vpp58+w3cDAAAAdW337t264IILqt3f4AP4mDFjtHbtWi1ZssRre8W0EklKTEzUVVddpfj4eM2aNUu33XZbteczxniNMFc12lwbNRUzf6obzZ44caLGjRtnf+7xeNSmTRvt3r1b4eHh1fYfAAAAdSMnJ0etW7dWWFjYKesadAB/9NFH9cUXX2jx4sWn/ClDklq2bKn4+Hht27ZNkhQbG6uioiJlZWV5jYJnZmaqZ8+eds3+/fsrnevAgQP2CHZsbKyWL1/utT8rK0vFxcVeNRWj4Se2I6nS6HkFl8vlNWWlQnh4OAEcAACgHjvddOEGuQqKMUZjxozRp59+qm+//bbKKRwnO3TokHbv3q2WLVtKkrp27arAwEDNmzfPrklPT9f69evtAN6jRw95PB6tWLHCrlm+fLk8Ho9Xzfr165Wenm7XzJ07Vy6XS127drVrFi9e7LU04dy5cxUXF1dpagoAAADObw1yFZSHH35YH374oT7//HMlJCTY291ut4KDg5Wbm6tJkybp9ttvV8uWLbVz5049/vjjSktL06ZNm+xfCzz00EOaOXOm3nnnHUVGRmrChAk6dOiQVq9eLX9/f0nlc8n37dunN954Q5L04IMPKj4+Xl9++aWk8mUIr7zySsXExOiFF17Q4cOHlZycrGHDhmnKlCmSyqePJCQkqG/fvnr88ce1bds2JScn68knn/RarvBUcnJy5Ha75fF4GAEHAACoh2qc10wDJKnK19tvv22MMSY/P9/079/ftGjRwgQGBpo2bdqYUaNGmbS0NK/zHD161IwZM8ZERkaa4OBgM3jw4Eo1hw4dMiNHjjRhYWEmLCzMjBw50mRlZXnV7Nq1ywwaNMgEBwebyMhIM2bMGFNQUOBVs3btWnPdddcZl8tlYmNjzaRJk0xZWVmNr9nj8RhJxuPx1PyNAgAAgGNqmtca5Ah4Y8QIOAAAQP1W07zWIOeAAwAAAA0VARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcBABHAAAAHAQARwAAABwEAEcAAAAcFCDDOCTJ0/W1VdfrbCwMEVHR2vYsGHasmWLvb+4uFi/+c1v1LFjR4WGhiouLk733nuv9u3b53WePn36yLIsr9fdd9/tVZOVlaWkpCS53W653W4lJSUpOzvbqyYtLU1DhgxRaGiooqKiNHbsWBUVFXnVrFu3Tr1791ZwcLBatWqlZ555RsaY2n1jAAAAUO81yAC+aNEiPfLII0pJSdG8efNUUlKi/v37Ky8vT5KUn5+vNWvW6IknntCaNWv06aefauvWrRo6dGilc40ePVrp6en264033vDaP2LECKWmpmrOnDmaM2eOUlNTlZSUZO8vLS3VoEGDlJeXpyVLlmjatGmaPn26xo8fb9fk5OSoX79+iouL08qVKzVlyhS9+OKLevnll8/ROwQAAID6yjLnwTDsgQMHFB0drUWLFun666+vsmblypW65pprtGvXLrVp00ZS+Qj4lVdeqVdeeaXKYzZt2qQOHTooJSVF3bp1kySlpKSoR48e2rx5sxISEvTVV19p8ODB2r17t+Li4iRJ06ZNU3JysjIzMxUeHq6///3vmjhxovbv3y+XyyVJev755zVlyhTt2bNHlmWd9hpzcnLkdrvl8XgUHh5+pm8RAAAAzrGa5rUGOQJ+Mo/HI0mKjIw8ZY1lWWrWrJnX9qlTpyoqKkqXX365JkyYoCNHjtj7li1bJrfbbYdvSerevbvcbreWLl1q1yQmJtrhW5IGDBigwsJCrV692q7p3bu3Hb4ravbt26edO3dW2d/CwkLl5OR4vQAAANDwBdR1B3xljNG4ceN07bXXKjExscqagoIC/fa3v9WIESO8fhoZOXKk2rVrp9jYWK1fv14TJ07UDz/8oHnz5kmSMjIyFB0dXel80dHRysjIsGtiYmK89kdERCgoKMirpm3btl41FcdkZGSoXbt2ldqYPHmynn766Rq+CwAAAGgoGnwAHzNmjNauXaslS5ZUub+4uFh33323ysrK9Nprr3ntGz16tP1xYmKi2rdvr6uuukpr1qxRly5dJKnK6SHGGK/tZ1NTMfOnuuknEydO1Lhx4+zPc3Jy1Lp16yprAQAA0HA06Ckojz76qL744gstWLBAF1xwQaX9xcXFGj58uHbs2KF58+addu50ly5dFBgYqG3btkmSYmNjtX///kp1Bw4csEewY2Nj7ZHuCllZWSouLj5lTWZmpiRVGj2v4HK5FB4e7vUCAABAw9cgA7gxRmPGjNGnn36qb7/9tsopHBXhe9u2bZo/f76aN29+2vNu2LBBxcXFatmypSSpR48e8ng8WrFihV2zfPlyeTwe9ezZ065Zv3690tPT7Zq5c+fK5XKpa9euds3ixYu9liacO3eu4uLiKk1NAQAAwPmtQa6C8vDDD+vDDz/U559/roSEBHu72+1WcHCwSkpKdPvtt2vNmjWaOXOm1yhzZGSkgoKC9NNPP2nq1Kn62c9+pqioKG3cuFHjx49XcHCwVq5cKX9/f0nSwIEDtW/fPnt5wgcffFDx8fH68ssvJZUvQ3jllVcqJiZGL7zwgg4fPqzk5GQNGzZMU6ZMkVR+A2hCQoL69u2rxx9/XNu2bVNycrKefPJJr+UKT4VVUAAAAOq3mua1BhnAq5s3/fbbbys5OVk7d+6sclRckhYsWKA+ffpo9+7duueee7R+/Xrl5uaqdevWGjRokJ566imv1VQOHz6ssWPH6osvvpAkDR06VK+++qrXaippaWl6+OGH9e233yo4OFgjRozQiy++6LXqybp16/TII49oxYoVioiI0C9/+Us9+eSTNVqCUCKAAwAA1HfndQBvjAjgAAAA9VujWgccAAAAaCgI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgwjgAAAAgIMI4AAAAICDCOAAAACAgxpkAJ88ebKuvvpqhYWFKTo6WsOGDdOWLVu8aowxmjRpkuLi4hQcHKw+ffpow4YNXjWFhYV69NFHFRUVpdDQUA0dOlR79uzxqsnKylJSUpLcbrfcbreSkpKUnZ3tVZOWlqYhQ4YoNDRUUVFRGjt2rIqKirxq1q1bp969eys4OFitWrXSM888I2NM7b0pAAAAaBAaZABftGiRHnnkEaWkpGjevHkqKSlR//79lZeXZ9f8+c9/1ssvv6xXX31VK1euVGxsrPr166cjR47YNY899phmzJihadOmacmSJcrNzdXgwYNVWlpq14wYMUKpqamaM2eO5syZo9TUVCUlJdn7S0tLNWjQIOXl5WnJkiWaNm2apk+frvHjx9s1OTk56tevn+Li4rRy5UpNmTJFL774ol5++eVz/E4BAACg3jHngczMTCPJLFq0yBhjTFlZmYmNjTXPP/+8XVNQUGDcbrd5/fXXjTHGZGdnm8DAQDNt2jS7Zu/evcbPz8/MmTPHGGPMxo0bjSSTkpJi1yxbtsxIMps3bzbGGDN79mzj5+dn9u7da9d89NFHxuVyGY/HY4wx5rXXXjNut9sUFBTYNZMnTzZxcXGmrKysRtfo8XiMJPucAAAAqF9qmtca5Aj4yTwejyQpMjJSkrRjxw5lZGSof//+do3L5VLv3r21dOlSSdLq1atVXFzsVRMXF6fExES7ZtmyZXK73erWrZtd0717d7ndbq+axMRExcXF2TUDBgxQYWGhVq9ebdf07t1bLpfLq2bfvn3auXNnlddUWFionJwcrxcAAAAavgYfwI0xGjdunK699lolJiZKkjIyMiRJMTExXrUxMTH2voyMDAUFBSkiIuKUNdHR0ZXajI6O9qo5uZ2IiAgFBQWdsqbi84qak02ePNmed+52u9W6devTvBMAAABoCBp8AB8zZozWrl2rjz76qNI+y7K8PjfGVNp2spNrqqqvjRpz7AbM6vozceJEeTwe+7V79+5T9hsAAAANQ4MO4I8++qi++OILLViwQBdccIG9PTY2VlLl0eXMzEx75Dk2NlZFRUXKyso6Zc3+/fsrtXvgwAGvmpPbycrKUnFx8SlrMjMzJVUepa/gcrkUHh7u9QIAAEDD1yADuDFGY8aM0aeffqpvv/1W7dq189rfrl07xcbGat68efa2oqIiLVq0SD179pQkde3aVYGBgV416enpWr9+vV3To0cPeTwerVixwq5Zvny5PB6PV8369euVnp5u18ydO1cul0tdu3a1axYvXuy1NOHcuXMVFxentm3b1tK7AgAAgIbAMqbhLUb98MMP68MPP9Tnn3+uhIQEe7vb7VZwcLAk6U9/+pMmT56st99+W+3bt9dzzz2nhQsXasuWLQoLC5MkPfTQQ5o5c6beeecdRUZGasKECTp06JBWr14tf39/SdLAgQO1b98+vfHGG5KkBx98UPHx8fryyy8llS9DeOWVVyomJkYvvPCCDh8+rOTkZA0bNkxTpkyRVH6TaEJCgvr27avHH39c27ZtU3Jysp588kmv5QpPJScnR263Wx6Ph9FwAACAeqjGee3cLsZybkiq8vX222/bNWVlZeapp54ysbGxxuVymeuvv96sW7fO6zxHjx41Y8aMMZGRkSY4ONgMHjzYpKWledUcOnTIjBw50oSFhZmwsDAzcuRIk5WV5VWza9cuM2jQIBMcHGwiIyPNmDFjvJYcNMaYtWvXmuuuu864XC4TGxtrJk2aVOMlCI1hGUIAAID6rqZ5rUGOgDdGjIADAADUbzXNaw1yDjgAAADQUBHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAH1TiA33bbbbr99tu1Z8+eKvfn5+dr8eLFWrx48SnPs3nzZkVGRqp58+Zn1lMAAADgPBBQ08LPPvtMlmXpD3/4Q5X7d+zYoT59+sjPz08lJSXVnqe0tFTZ2dmyLOvMewsAAAA0cLU+BcUYU9unBAAAAM4bzAEHAAAAHEQABwAAABxEAAcAAAAcRAAHAAAAHEQABwAAABxEAAcAAAAcRAAHAAAAHFTjB/FU+P3vf69mzZpV2p6dnW1/fN9991V7/Il1AAAAQGNjmRo+OcfPz6/Wnl5pjJFlWSotLa2V8zUGOTk5crvd8ng8Cg8Pr+vuAAAA4CQ1zWtnNALOUy4BAAAA39Q4gO/YseNc9gMAAABoFGocwOPj489lPwAAAIBGgVVQAAAAAAcRwAEAAAAHnfEyhDWVlpamGTNm6Mcff5Sfn5/atWunIUOG6KKLLjpXTQIAAAD1Xo0DeElJid566y1JUseOHdWjR49qa5955hk9++yzKikp8dr+61//WmPHjtVLL710lt0FAAAAGrYaB/BVq1bpl7/8pSzL0ty5c6ute+GFFzRp0qQq95WWluqVV16Rn5+fXnjhhTPuLAAAANDQ1XgO+KJFiyRJbdq00Y033lhlzb59+/TUU0/Zn/fq1UtvvvmmvvrqKz3zzDNyu90yxuiVV17Rtm3bfOw6AAAA0PDUeAT8u+++k2VZuuWWW6qteeutt1RQUGDXTZ8+3X565oABAzRkyBB1795dRUVFeu+99/SHP/zB9ysAAAAAGpAaj4CnpaVJ0innfn/55Zf2x3/+858rPbq+U6dOuvfee2WM0ZIlS860rwAAAECDV+MAnpmZKUlq27Ztlfvz8/P1/fffy7IsdezYURdffHGVdTfffLMkacuWLWfYVQAAAKDhq3EAz8rKkiQFBwdXuX/VqlX2qie9evWq9jwVT9TMzs6uadMAAADAeaPGATwkJESSdODAgSr3L1++3P74yiuvrPY8FdNSSktLa9o0AAAAcN6ocQCvmHqybNmyKvcvXLjQ/vhU88QrArzb7a5p0wAAAMB5o8YB/Nprr5UxRq+//rqOHDnitW/Xrl2aN2+eLMtSXFycEhMTqz1PamqqJKldu3Zn12MAAACgAatxAL///vtlWZbS09PVp08fzZkzR9u2bdMXX3yhm2++2Z7/PWrUqFOe55tvvpFlWerUqZNvPQcAAAAaIMsYY2paPGbMGL322muVlheUJGOMYmJitHHjRkVERFR5fHp6utq0aaOysjK9++67uueee86+541MTk6O3G63PB6PwsPD67o7AAAAOElN81qNH8QjSf/v//0/exrKybk9NjZWn3/+ebXhW5JeeeUVlZaWKiAgQAMHDjyTpgEAAIDzwhkFcD8/P/3tb3/TI488oi+++EK7du1SUFCQOnfurDvvvFOhoaGnPD4kJETjx49Xy5Yt1bx5c586DgAAADREZzQFBXWHKSgAAAD1W03zWo1vwgQAAADgOwI4AAAA4CACOAAAAOCgGt+E2bdv31pt2LIsffPNN7V6TgAAAKC+q3EAX7hwob3+tzGmyrXAa8rX4wEAAICG6oyWIZSkJk2aKDo6+lz0BQAAADjvnXEALygoUMuWLZWUlKS77rpLkZGR56JfAAAAwHmpxjdh/uEPf1BCQoKMMUpJSdGYMWMUFxen2267TTNmzFBxcfG57CcAAABwXjjjB/GsWrVK7733nj7++GMdOHCg/CSWpWbNmmn48OG655571KtXr3PS2caMB/EAAADUbzXNa2f9JMzS0lJ99dVXeu+99zRz5kwVFBTYN1a2bdtWSUlJGjlypNq3b392VwAvBHAAAID67ZwH8JMb++STT/T+++/ru+++81rl5JprrtG9997LfHEfEcABAADqN0cD+InS0tL03nvv6YMPPtDWrVvtIB4WFqbs7OzabKpRIYADAADUbzXNa7X+JMw2bdro97//vTZv3qwpU6bI5XLJGKOioqLabgoAAABocM54GcLTSUtL09SpU/X+++9ry5Yt9vagoKDabgoAAABocGolgFfMAf/ggw/sOeAVM1t69OhhrxkOAAAANHZnHcArVkF5//339eWXX6qwsNAO3RdeeKHuueceJSUl6aKLLqq1zgIAAAAN3RkH8JUrV+r999/XtGnTdOjQIUmSMcZeBzwpKYl1wAEAAIBq1DiAP/vss3r//fe1bds2SeWhOzAwUAMHDlRSUpKGDBnCPG8AAADgNGq8DKGfn58sy5IxRt26ddO9996ru+++WxEREee6jxDLEAIAANR3tb4OeEUAb9KkiWJiYnzuoGVZ+umnn3w+T2NBAAcAAKjfaprXzngO+NGjR7Vz505f+iZJ9gN6AAAAgMakxgH8+uuvJzQDAAAAPqpxAF+4cOE57AYAAADQONT6o+gBAAAAVK9BBvDFixdryJAhiouLk2VZ+uyzz7z2W5ZV5euFF16wa/r06VNp/9133+11nqysLCUlJcntdsvtdispKUnZ2dleNWlpaRoyZIhCQ0MVFRWlsWPHqqioyKtm3bp16t27t4KDg9WqVSs988wzquG9rwAAADjP1Mqj6J2Wl5enTp066Re/+IVuv/32SvvT09O9Pv/qq690//33V6odPXq0nnnmGfvz4OBgr/0jRozQnj17NGfOHEnSgw8+qKSkJH355ZeSyp8GOmjQILVo0UJLlizRoUOHNGrUKBljNGXKFEnld8P269dPN9xwg1auXKmtW7cqOTlZoaGhGj9+vO9vBgAAABqUBhnABw4cqIEDB1a7PzY21uvzzz//XDfccIMuvPBCr+0hISGVaits2rRJc+bMUUpKirp16yZJ+uc//6kePXpoy5YtSkhI0Ny5c7Vx40bt3r1bcXFxkqSXXnpJycnJevbZZxUeHq6pU6eqoKBA77zzjlwulxITE7V161a9/PLLGjduHDe2AgAANDINcgrKmdi/f79mzZql+++/v9K+qVOnKioqSpdffrkmTJigI0eO2PuWLVsmt9tth29J6t69u9xut5YuXWrXJCYm2uFbkgYMGKDCwkKtXr3arundu7dcLpdXzb59+065nGNhYaFycnK8XgAAAGj4GuQI+Jl49913FRYWpttuu81r+8iRI9WuXTvFxsZq/fr1mjhxon744QfNmzdPkpSRkaHo6OhK54uOjlZGRoZdc/JDiSIiIhQUFORV07ZtW6+aimMyMjLUrl27Kvs9efJkPf3002d+wQAAAKjXzvsA/tZbb2nkyJFq0qSJ1/bRo0fbHycmJqp9+/a66qqrtGbNGnXp0kVS1Q8LMsZ4bT+bmoobME81/WTixIkaN26c/XlOTo5at25dbT0AAAAahvN6Csp3332nLVu26IEHHjhtbZcuXRQYGKht27ZJKp9Hvn///kp1Bw4csEewY2Nj7ZHuCllZWSouLj5lTWZmpiRVGj0/kcvlUnh4uNcLAAAADd95HcDffPNNde3aVZ06dTpt7YYNG1RcXKyWLVtKknr06CGPx6MVK1bYNcuXL5fH41HPnj3tmvXr13utujJ37ly5XC517drVrlm8eLHX0oRz585VXFxcpakpAAAAOP81yACem5ur1NRUpaamSpJ27Nih1NRUpaWl2TU5OTn65JNPqhz9/umnn/TMM89o1apV2rlzp2bPnq0777xTnTt3Vq9evSRJl112mW6++WaNHj1aKSkpSklJ0ejRozV48GAlJCRIkvr3768OHTooKSlJ33//vb755htNmDBBo0ePtkesR4wYIZfLpeTkZK1fv14zZszQc889xwooAAAAjZVpgBYsWGAkVXqNGjXKrnnjjTdMcHCwyc7OrnR8Wlqauf76601kZKQJCgoyF110kRk7dqw5dOiQV92hQ4fMyJEjTVhYmAkLCzMjR440WVlZXjW7du0ygwYNMsHBwSYyMtKMGTPGFBQUeNWsXbvWXHfddcblcpnY2FgzadIkU1ZWdkbX7PF4jCTj8XjO6DgAAAA4o6Z5zTKGRzI2BDk5OXK73fJ4PMwHBwAAqIdqmtdqtArKiVM7alObNm3OyXkBAACA+qpGAby6tap9YVmWSkpKav28AAAAQH1WowDOLBUAAACgdtQogL/99tun3P/aa69p5cqVCgwMVP/+/XXNNdcoJiZGxhhlZmZq5cqVmjt3roqLi3X11VfroYceqpXOAwAAAA1NjQL4qFGjqt33wAMPaNWqVerfv7/efPNNtWrVqsq6vXv3avTo0fr666/VsWNH/fOf/zy7HgMAAAANmE/rgP/nP//RW2+9pauuukqzZs2qNnxLUqtWrfTll1+qa9eueuutt/Tvf//bl6YBAACABsmnAP7GG2/IsiyNGzdO/v7+p6339/fX+PHjZYzRP/7xD1+aBgAAABoknwL42rVrJUmXXHJJjY+pqF23bp0vTQMAAAANkk8B/MiRI5KkzMzMGh9TUVtxLAAAANCY+BTA4+PjJUnvvfdejY+pqOUhPAAAAGiMfArgt9xyi4wxmjZtmv785z+ftv7FF1/URx99JMuydOutt/rSNAAAANAgWcaHp+xkZ2erQ4cO2r9/vyTpiiuu0KhRo3T11VcrOjpalmVp//79Wrlypd5//32lpqbKGKOWLVtqw4YNatasWW1dx3kvJydHbrdbHo9H4eHhdd0dAAAAnKSmec2nAC5JGzdu1IABA7R3715ZlnXKWmOMLrjgAs2ZM0cdOnTwpdlGhwAOAABQv9U0r/k0BUWSOnTooA0bNuhXv/qVmjVrJmNMla9mzZpp3LhxWr9+PeEbAAAAjZbPI+AnKioq0urVq7Vu3TplZWXJGKPIyEh17NhRXbt2VVBQUG011egwAg4AAFC/OTYFBc4ggAMAANRvjk1BAQAAAFBzAbV5su3bt2vZsmXKyMhQfn6+HnroIUVFRdVmEwAAAECDVisB/Pvvv9djjz2mJUuWeG2//fbbvQL43/72Nz399NNyu93auHGjAgMDa6N5AAAAoMHweQrKrFmz1LNnTy1ZssRr1ZOqjBo1SkePHtX27ds1c+ZMX5sGAAAAGhyfAnhGRoZ+/vOfq7CwUB06dNBXX32lI0eOVFvftGlTDRs2TJL01Vdf+dI0AAAA0CD5FMD/8pe/KDc3V/Hx8fruu+80YMAAhYaGnvKYPn36yBij1atX+9I0AAAA0CD5FMC//vprWZal8ePH1/ix8gkJCZKknTt3+tI0AAAA0CD5FMB37NghSbrmmmtqfExYWJgkKTc315emAQAAgAbJpwBeXFwsSWe0mkl2drYknXaqCgAAAHA+8imAx8bGSjo+El4Ty5YtkyRdcMEFvjQNAAAANEg+BfBevXpJkmbMmFGj+vz8fL3++uuyLEvXX3+9L00DAAAADZJPAXzUqFEyxuijjz7S3LlzT1mbm5ur4cOHKy0tTZJ0//33+9I0AAAA0CD5FMBvuukmDRs2TGVlZRo6dKh+/etfa8WKFfb+w4cPa/ny5frDH/6ghIQEffXVV7IsS/fee686d+7sc+cBAACAhsYy1T22soby8/M1ePBgLVy4UJZlVVtX0cyNN96omTNnyuVy+dJso5OTkyO32y2Px6Pw8PC67g4AAABOUtO85vOj6ENCQjR//ny98MILio2N9Xoc/YmvyMhIPffcc/r6668J3wAAAGi0fB4BP1FJSYlWrFihVatWKTMzU6WlpWrevLk6d+6sa6+9luDtA0bAAQAA6rea5rVaDeA4dwjgAAAA9VtN81qAL40sXrxYknT11VcrODi4RscUFBTYN2qyFCEAAAAaG58CeJ8+feTn56e1a9eqQ4cONTpm79699nElJSW+NA8AAAA0OD7fhHm2M1iY+QIAAIDGyOcAfqbKysokSf7+/k43DQAAANQ5xwP4zp07JUlut9vppgEAAIA6d0ZzwCseI3+y9PR0NW3a9JTHFhYW6qefftITTzwhy7J0+eWXn0nTAAAAwHnhjAJ4u3btKm0zxqh///5n3PC99957xscAAAAADd0ZBfDqbpw8kxsqmzRporFjx+q+++47k6YBAACA88IZBfC3337b6/Nf/OIXsixLf/jDH9SqVatqj7MsS02aNFHLli3VuXPn005XAQAAAM5XPj0J08/PT5Zlad26dTVeBxxnhydhAgAA1G+OPAlzwYIFkqqeGw4AAACgMp8CeO/evWurHwAAAECj4Pg64AAAAEBj5tMI+ImMMUpNTdUPP/yggwcP6ujRo6ddHeXJJ5+sreYBAACABsGnmzArvPvuu3r66ae1a9euMzqutLTU16YbDW7CBAAAqN8cuQlTkn73u9/p+eefr9Fa4JZlndGa4QAAAMD5xqc54MuXL9fkyZMlSf369VNqaqrWrFkjqTxsl5aW6uDBg5ozZ45uueUWGWN07bXXKj09XWVlZb73HgAAAGhgfArgf//73yVJ8fHxmjVrlq644goFBgba+y3LUmRkpPr3768ZM2bob3/7m5YsWaKbb75ZRUVFvvUcAAAAaIB8CuBLly6VZVkaO3asAgJOP5vloYce0u233661a9fqtdde86VpAAAAoEHyKYCnp6dLki6//PLjJ/Q7fsri4uJKxyQlJckYo48//tiXpgEAAIAGyacAXhGwo6Oj7W1Nmza1Pz5w4EClY1q3bi1J+vHHH31pGgAAAGiQfArgLVq0kFS+5EqFmJgY+fv7S5I2bdpU6ZiKUfMjR4740jQAAADQIPkUwCumnmzevNneFhQUZG+vaprJ1KlTJUlxcXG+NA0AAAA0SD4F8Ouuu07GGC1YsMBr+1133SVjjN566y09+eST2rBhg1auXKkxY8boo48+kmVZGjhwoE8dBwAAABoin56EuWHDBnXs2FFNmzbVnj177Cf+5OfnKzExUTt37pRlWV7HGGMUGRmp1NRUXXDBBb71vhHhSZgAAAD1W03zms9TUBYsWKAZM2aopKTE3h4SEqIFCxaoV69eMsZ4vRITE/XNN98QvgEAANAo+TQCXhNbtmzRhg0bVFJSovbt26tz587nsrnzFiPgAAAA9VtN89rpn57jo4SEBCUkJJzrZgAAAIAGwacpKAAAAADODAEcAAAAcFCNpqA888wz56TxJ5988pycFwAAAKivanQTpp+fX6XlBGtDaWlprZ/zfMVNmAAAAPVbrd+EebqcbllWrdQAAAAA57MazQEvKyur9rV9+3ZdffXVMsZo4MCB+uSTT7Rr1y4VFBSooKBAu3bt0n/+8x8NHDhQxhhdffXV2rFjh8rKys6604sXL9aQIUMUFxcny7L02Wefee1PTk6WZVler+7du3vVFBYW6tFHH1VUVJRCQ0M1dOhQ7dmzx6smKytLSUlJcrvdcrvdSkpKUnZ2tldNWlqahgwZotDQUEVFRWns2LEqKiryqlm3bp169+6t4OBgtWrVSs888ww/iAAAADRSPt2E6fF41L9/f61Zs0bvvfeeZs2apdtvv12tW7dWUFCQgoKC1Lp1a912222aNWuW3n//fa1evVo33XSTPB7PWbebl5enTp066dVXX6225uabb1Z6err9mj17ttf+xx57TDNmzNC0adO0ZMkS5ebmavDgwV7TYkaMGKHU1FTNmTNHc+bMUWpqqpKSkuz9paWlGjRokPLy8rRkyRJNmzZN06dP1/jx4+2anJwc9evXT3FxcVq5cqWmTJmiF198US+//PJZXz8AAAAaMOODp556yliWZR566KEaH/PLX/7SWJZlnnjiCV+atkkyM2bM8No2atQoc8stt1R7THZ2tgkMDDTTpk2zt+3du9f4+fmZOXPmGGOM2bhxo5FkUlJS7Jply5YZSWbz5s3GGGNmz55t/Pz8zN69e+2ajz76yLhcLuPxeIwxxrz22mvG7XabgoICu2by5MkmLi7OlJWV1fg6PR6PkWSfFwAAAPVLTfOaTyPg06dPl2VZuvPOO2t8zPDhwyVJn376qS9Nn9bChQsVHR2tSy65RKNHj1ZmZqa9b/Xq1SouLlb//v3tbXFxcUpMTNTSpUslScuWLZPb7Va3bt3smu7du8vtdnvVJCYmKi4uzq4ZMGCACgsLtXr1arumd+/ecrlcXjX79u3Tzp07q+1/YWGhcnJyvF4AAABo+HwK4BUB0u121/iYitpdu3b50vQpDRw4UFOnTtW3336rl156SStXrlTfvn1VWFgoScrIyFBQUJAiIiK8jouJiVFGRoZdEx0dXenc0dHRXjUxMTFe+yMiIhQUFHTKmorPK2qqMnnyZHvuudvtVuvWrc/kLQAAAEA95VMADwwMlFR+k2FNVdRWHHsu3HXXXRo0aJASExM1ZMgQffXVV9q6datmzZp1yuOMMV7LLVa19GJt1JhjN2CeamnHiRMnyuPx2K/du3efsu8AAABoGHwK4J06dZIxRn/605+Un59/2vr8/Hz96U9/kmVZuuKKK3xp+oy0bNlS8fHx2rZtmyQpNjZWRUVFysrK8qrLzMy0R6djY2O1f//+Suc6cOCAV83Jo9hZWVkqLi4+ZU3FdJiTR8ZP5HK5FB4e7vUCAABAw+dTAH/ggQckSVu2bFGfPn2Umppabe0PP/ygG264QZs3b5YkPfjgg740fUYOHTqk3bt3q2XLlpKkrl27KjAwUPPmzbNr0tPTtX79evXs2VOS1KNHD3k8Hq1YscKuWb58uTwej1fN+vXrlZ6ebtfMnTtXLpdLXbt2tWsWL17stTTh3LlzFRcXp7Zt256zawYAAED9VKMnYZ7KHXfcoU8//dSeTtGxY0ddffXVio6OlmVZ2r9/v1auXGlPPTHG6Pbbb9cnn3xy1m3m5ubqxx9/lCR17txZL7/8sm644QZFRkYqMjJSkyZN0u23366WLVtq586devzxx5WWlqZNmzYpLCxMkvTQQw9p5syZeueddxQZGakJEybo0KFDWr16tfz9/SWVzyXft2+f3njjDUnlPzTEx8fryy+/lFS+DOGVV16pmJgYvfDCCzp8+LCSk5M1bNgwTZkyRVL5Uo0JCQnq27evHn/8cW3btk3Jycl68sknvZYrPB2ehAkAAFC/1Tiv+brcSklJiRkzZozx9/c3lmUZy7KMn59fpVfF9kcffdQUFxf71OaCBQuMpEqvUaNGmfz8fNO/f3/TokULExgYaNq0aWNGjRpl0tLSvM5x9OhRM2bMGBMZGWmCg4PN4MGDK9UcOnTIjBw50oSFhZmwsDAzcuRIk5WV5VWza9cuM2jQIBMcHGwiIyPNmDFjvJYcNMaYtWvXmuuuu864XC4TGxtrJk2adEZLEBrDMoQAAAD1XU3zms8j4BXWrVun119/XfPnz9ePP/7o9aTH9u3b66abbtL//M//ODr3+3zCCDgAAED9VtO8VmsB/ESFhYXKzs6WMUYRERFea2Dj7BDAAQAA6rea5rWAc9G4y+U65QofAAAAQGPl0yooAAAAAM4MARwAAABwUI2moPTt21dS+ZMbv/nmm0rbz8bJ5wIAAAAagxrdhOnnVz5QblmWSktLvbZblqUzuY+zov7kc+HUuAkTAACgfqvVmzCvv/56+0E7NdkOAAAAoGrnZBlC1D5GwAEAAOq3muY1bsIEAAAAHEQABwAAABxEAAcAAAAcRAAHAAAAHFSjVVD8/f1rvWHLslRSUlLr5wUAAADqsxoFcBZKAQAAAGpHjQL4U089da77AQAAADQKrAPeQLAOOAAAQP3GOuAAAABAPUQABwAAABxEAAcAAAAcVKObMGsqKytLP/zwgw4ePKijR4+edvWUe++9tzabBwAAAOq9WgngCxcu1FNPPaUlS5bU+BjLsgjgAAAAaHR8DuB///vf9eijj8oYw3rhAAAAwGn4NAd806ZNGjt2rIwx6tixoz777DPNmjVLUvkI908//aRVq1bp9ddfV5cuXSRJ1157rTZs2KDt27f73nsAAACggfEpgE+ZMkWlpaWKiorSd999p6FDh6pNmzb2/nbt2qlLly568MEHtXLlSv3617/WkiVL9Oijjyo+Pt7nzgMAAAANjU8BfNGiRbIsS2PHjlVYWNgpay3L0p/+9Cf17dtXCxYs0FtvveVL0wAAAECD5FMA37NnjyTZ00uk8qBdobi4uNIxDz74oIwx+uCDD3xpGgAAAGiQfArgBQUFkqS4uDh7W2hoqP1xVlZWpWMuvvhiSdLGjRt9aRoAAABokHwK4JGRkZKkvLw8e1uLFi3sUfCtW7dWOubgwYOSpOzsbF+aBgAAABoknwL4pZdeKknatm2bvS0kJETt27eXJH3xxReVjqnY1qJFC1+aBgAAABoknwL4tddeK2OMFi9e7LX9tttukzFG/+///T+99dZbysvL04EDB/Tiiy/qH//4hyzLUt++fX3qOAAAANAQWcaHp+csX75cPXr0UGRkpPbs2aMmTZpIkg4dOqSEhIQq54AbYxQcHKxVq1bpsssuO/ueNzI5OTlyu93yeDwKDw+v6+4AAADgJDXNaz6NgHfr1k1vv/22/vSnP3mF7ebNm+vrr79W27Zt7SdkVryio6M1Y8YMwjcAAAAaJZ9GwE+nuLhY3377rTZs2KCSkhK1b99eAwYMUEhIyLlq8rzFCDgAAED9VtO8dk4DOGoPARwAAKB+c2QKCgAAAIAz41MAv/rqq/XXv/5VGRkZtdUfAAAA4LzmUwBfvXq1xo0bp9atW6t///569913deTIkdrqGwAAAHDe8SmAX3bZZTLGqLS0VN98843uu+8+xcbG6q677tIXX3yhkpKS2uonAAAAcF7wKYBv2LBB33//vSZMmKBWrVrJGKOjR4/qP//5j2699VbFxMTooYce0nfffVdb/QUAAAAatFpdBWXRokX68MMP9Z///MdeF9yyLEnSBRdcoJEjR2rEiBFKTEysrSYbDVZBAQAAqN/qdBnC4uJizZ49Wx9++KG+/PJLFRQUlDd2LIxffvnluueee/R///d/td30eYsADgAAUL/Vm3XAc3NzNX36dE2dOlULFixQaWlpecOWZX+M0yOAAwAA1G/1Zh3wpk2batSoUfr666/17rvvqlmzZue6SQAAAKDeCjjXDaxZs0Yffvihpk2bpvT09HPdHBq4/KISdXjya0nSxmcGKCTonH+JAgAAOOqcpJuffvpJH374oT788ENt3bpVklQx0yUsLEy33nqrRo4ceS6aBgAAAOq1WgvgmZmZ+vjjj/Xhhx9qxYoVko6H7sDAQA0YMEAjR47ULbfcoiZNmtRWswAAAECD4lMAz8vL06effqqpU6fq22+/tW+qrAjePXv21D333KPhw4crMjLS994CAAAADZxPATwmJkZHjx6VdDx0X3bZZfZ6323btvW5g0BjUZfz35l7DwCAc3z6XzY/P1+SFBcXp7vvvlsjR45U586da6VjAAAAwPnIpwCenJyse+65RzfccIP9kB2goWIUGAAAOMGnhPHWW2/VVj8AAACARuGcPIhn586d6tu3r2688cZzcXoAAACgwTonv2PPy8vTwoULmZYCAAAAx9X3aaXn/FH0AHAq+UUlavvbWWr721nKLyqp6+4AAGoJ39+rRwAHAAAAHEQARyX8xAoAAHDuEMABAAAABxHAAQAAAAedk1tCo6Oj9dRTT52LUwMAAAAN2jkJ4C1atCCAAwAAAFVgCgoAAADgoHO+KvmXX36pf//73zp48KDatWun0aNHq3Pnzue6WQAAAKBe8mkEfMGCBYqOjlabNm2UnZ1daf8TTzyhYcOG6cMPP9TcuXP1xhtvqFu3bpo6daovzQIAAAANlk8BfPbs2Tp48KC6d++uZs2aee1bu3atnnvuORljZIxRs2bNZIxRSUmJHnzwQe3atcuXpgGgVrDuPQDAaT4F8CVLlsiyLPXr16/Svr///e8yxigiIkKrV6/WoUOHtGLFCkVGRqqgoECvv/66L00DAAAADZJPATwjI0OSdOmll1baN3PmTFmWpUceecSe833VVVdpzJgxMsZo/vz5vjQNAAAANEg+BfDMzExJktvt9tr+008/ae/evZKk2267zWvfddddJ0n68ccfz7rdxYsXa8iQIYqLi5NlWfrss8/sfcXFxfrNb36jjh07KjQ0VHFxcbr33nu1b98+r3P06dNHlmV5ve6++26vmqysLCUlJcntdsvtdispKanSXPe0tDQNGTJEoaGhioqK0tixY1VUVORVs27dOvXu3VvBwcFq1aqVnnnmGRljzvr6AQAA0HD5FMArQqTH4/Ha/t1330kqD+ZXXnml177mzZtLkvLz88+63by8PHXq1EmvvvpqpX35+flas2aNnnjiCa1Zs0affvqptm7dqqFDh1aqHT16tNLT0+3XG2+84bV/xIgRSk1N1Zw5czRnzhylpqYqKSnJ3l9aWqpBgwYpLy9PS5Ys0bRp0zR9+nSNHz/ersnJyVG/fv0UFxenlStXasqUKXrxxRf18ssvn/X1AwAA1AT3udRPPi1DGBsbq127dmnTpk32yLYkff3115KkXr16VTomLy9PkhQREXHW7Q4cOFADBw6scp/b7da8efO8tk2ZMkXXXHON0tLS1KZNG3t7SEiIYmNjqzzPpk2bNGfOHKWkpKhbt26SpH/+85/q0aOHtmzZooSEBM2dO1cbN27U7t27FRcXJ0l66aWXlJycrGeffVbh4eGaOnWqCgoK9M4778jlcikxMVFbt27Vyy+/rHHjxsmyrLN+HwAAANDw+DQC3r17dxlj9Pe//90e0d6+fbs+//zzam/O3Lp1qyRVG3zPBY/HI8uyKq3UMnXqVEVFRenyyy/XhAkTdOTIEXvfsmXL5Ha77fAtlV+v2+3W0qVL7ZrExEQ7fEvSgAEDVFhYqNWrV9s1vXv3lsvl8qrZt2+fdu7cWW2fCwsLlZOT4/UCAOBs1fVIaF23D9QnPgXwBx54QFL5koOJiYm644471L17dxUUFCg4OFgjRoyodMzixYslSR06dPCl6RorKCjQb3/7W40YMULh4eH29pEjR+qjjz7SwoUL9cQTT2j69Ole89UzMjIUHR1d6XzR0dH2zacZGRmKiYnx2h8REaGgoKBT1lR8XlFTlcmTJ9tzz91ut1q3bn2GVw4A1SMMAc7g3xqq4tMUlL59++qxxx7TK6+8op07d2rXrl32vPAXXnhBUVFRXvUFBQWnHB2vbcXFxbr77rtVVlam1157zWvf6NGj7Y8TExPVvn17XXXVVVqzZo26dOkiSVVODzHGeG0/m5qK9+hU008mTpyocePG2Z/n5OQQwnHOFJeW2R//sDtbzZu6FOoKUNOgAIW6/BXg79PP6qhGflGJOjxZPmVv4zMDFBJ0zh9ODACoB3z+bv/yyy+rb9+++uSTT5SRkaGWLVvq3nvvVd++fSvVfvHFFwoPD5fb7T7nAby4uFjDhw/Xjh079O2333qNflelS5cuCgwM1LZt29SlSxfFxsZq//79leoOHDhgj2DHxsZq+fLlXvuzsrJUXFzsVXPySHfF6jEnj4yfyOVyeU1bAWpTQXGpftidrRU7Dmv5jsNavSvL3vfzfy6vVO8K8FNTV0B5KD/2CnX525+H2vv81dQVqFCXv1d96LH6pq4ABQf6c+8DAEfxwy7qm1r5Chw8eLAGDx582rrhw4dr+PDhtdHkKVWE723btmnBggX2yiunsmHDBhUXF6tly5aSpB49esjj8WjFihW65pprJEnLly+Xx+NRz5497Zpnn31W6enp9nFz586Vy+VS165d7ZrHH39cRUVFCgoKsmvi4uLUtm3b2r50oEr5RSVavSvLDtypu7NVVFJWZW2rZsHKLypRXmGpio6NjBeWlKmwpEiH8oqqPOZM+FnyCubBgf72vveW7lSPi6LUIS5cgYy6AwDOUw3yR8Dc3FyvdcR37Nih1NRURUZGKi4uTnfccYfWrFmjmTNnqrS01B6BjoyMVFBQkH766SdNnTpVP/vZzxQVFaWNGzdq/Pjx6ty5s71yy2WXXaabb75Zo0ePtpcnfPDBBzV48GAlJCRIkvr3768OHTooKSlJL7zwgg4fPqwJEyZo9OjR9oj7iBEj9PTTTys5OVmPP/64tm3bpueee05PPvkko4A4ZzxHi7V612Et314euNfv9aikzHvt+aimLnVrF6luF0bqigvcGva38puL54273h4dKiopU15hiXKPvfLsP0tP+Pjk/eX78opO2FZQoryiUklSmZGOFJToSEHluZDPz9kiaYuCA/3VqbVbXeMjdFV8pLq0iZA7JPDcvmkAADjEkQD+008/6eDBg2rbtu0pp13U1KpVq3TDDTfYn1fMlR41apQmTZqkL774QpIqrUG+YMEC9enTR0FBQfrmm2/017/+Vbm5uWrdurUGDRqkp556Sv7+x0fjpk6dqrFjx6p///6SpKFDh3qtPe7v769Zs2bp4YcfVq9evewbT1988UW7pmJZxEceeURXXXWVIiIiNG7cOK/53YCvDuUWauXO8rC9fPthbcrI0cnPeopzN1G3C5urW7tIXdMuUu2iQu0fAqu7MSgowE9BAUGKCA3yuY9lZUb5xZWD+6HcIj360feSpN6XtFDq7mx5jhYrZfthpWw/LOknSdIlMU3VNT5CXeMjdVV8hOKbh/BDLADAZoxRflGp8opKdDC30N5+4Eih4pvXrzFnn3pz4MABffLJJ5LKVxU5+YmYP/74o+666y6lpqZKKr/pcNiwYfrXv/5VaUnAM9GnT59TPknydE+ZbN26tRYtWnTadiIjI/XBBx+csqZNmzaaOXPmKWs6duxor/4C1IYMT4GW7zhkTyn5MTO3Uk27qFBd07Y8bHe7MFIXRITUQU+P8/Oz7PnjJ/4YfmL4//s9XdQkwF8/HcjVql1ZWn3steNgnrbuz9XW/bn6aMVuSVJU0yB1aROhq9qWh/LEVuFyBfgLDQNzcgGUlhnlFZUPyOSd8NtT74/Lf7Oab/9mtfzj3GOf5xeWKrewxA7eVUXAJT8eVHzzUOcv8BR8+o43ffp0jRkzRgkJCXr44Ye99hUWFmrgwIHavn27HYiNMZoxY4YOHjyohQsX+tI00GgYY7Qn66hStpcH7hU7D2vXocpPkr0kpqm6tWuua46NcMeEN6mD3vrOz89S+5gwtY8J08+vKX9w1sHcQq05FsZX7crSuj0eHcwt0tyN+zV3Y/nN0kEBfrqilVtd21ZMW2mm5k25kRmVEf6Bc6+guFSLtx6wP7/nX8t1tLjs2D1G5QG6oLjqe5F8ZVlSSJC/8grLpz42Cah/9xT59F1n7ty5sixLt99+e6V977zzjn766SdZlqWhQ4fqxhtv1Pz58/Xll1/qu+++07///W9HbsgEGqLtB3K1dk+OPcqd7inw2u9nSR3iwu3AfXXbSEXWwjSR+iqqqUv9L49V/8vLH+BVUFyqDfs8WrWzPJCv2ZWlQ3lFWnUsoL+h7ZKkC6NCy+eRt41Q1/gIXdSiKdNWAOAc2X04Xwu2ZGrB5kwt/emQCk+42X9NWna1xwX4WeWrZQWVr64VcmxVrdCg46tole8P8Kpr6gpQyIkfn7Da1tHiUvsH7YEdW57rSz9jPgXwLVu2SJK9SsiJPvroI0nla4V/9tlnkqRHH31U/fv31/z58/XRRx8RwNFglZUZFZWWqbC4TIUlpcdWCTn+cVHF58Unfe61v1SFxWX2efJOmIoxeMp/vdoL8LN0xQVuXdOuubpdGKmu8REKb9J4b0psEuivrvGR6hofqf9R+W8Jdh7K16qdh+1pK9syc7X9YJ62H8zTJ6v3SJKahQSqa5sIdYmP0FXxEerUulmdXgcANGRFJWVatfNweejecqDSdMjY8CbKyCkfQHrlrk6KCHWpqctfIUHHV8IKCfKXK8Cv0Q2O+DwHXJLXo9gl6ejRo1q2bJksy9KDDz7ote++++7T/PnztWbNGl+aBiopKzM6Wlxa/io6/md+UakKisv/LN9WcuzPMuUXl6jgWE1u4fEAfM+/lqu41BwPyscCdMXnxaWnvs/AV64AP3Vu06w8cLeLVOc2zfg1+SlYlqV2UaFqFxWqO68qf2BVdn6R1qRladXO8kD+w55sZecX65vNmfpmc/la/IH+li5refwZAZk5BWob1bROrgEAGoL9OQVauCVTCzYf0JIfD3r93+nvZ6lrfIRuSIjWDZe2UOuIYF3+1FxJUv/LY/l/7AQ+vRPZ2dmSJD8/77k1KSkpKi4ulp+fn2666Savfe3atZN0/GE0QIXs/CKt3+uxP39l/jaVlBqv0FwRpu2Pi0qVfyxoF1azrvXZONWvyk7mZ0muAH+5Av0U5O8nV6Bf+ecBfgoK8JMroPzzEz+uqtaS9Oevy3+rtPzxG9Us5PydUuKEZiFB6ntpjPpeWn7LZ1FJmTam5xwbIT+sVTuzlHmkUGv3HP+a6/PiIrVqFqzObZqpa3yEurSJYE1yAI1aaZlR6u4sLdh8QAu2ZGrDvhyv/VFNg9T7kvLAfV37FnIHH//tbHUrbMHHAN60aVN5PJ5KT3qsuMGyQ4cOioiI8NoXGFj+FxMQwE9BjVFZmVF6ToF+zMzVj5m5+ulA+Z/bD+TqYK73Q17+sXj7WbcTHOiv4CD/qv8M9FdIkL+aBPkr5Nj2JoH+CvC3NHn2ZknSX+++UuFNAk8I0dUH7AA/q1Z+dZZfVGIH8KB6eMNIQxcU4KcrWzfTla2b6f5r29k3ty796aB+M32dpPIfpvZmH9Xe7KOauTZdktQk0E9XtGqmzvHN7OkrUdzcCeA8djivSIu3lgfuRVsPKDu/2N5nWdIVFzTTDQkt1PfSaCXGueXn17imj9QGn1LwpZdequXLl2vOnDn62c9+Zm+fPn26LMtS7969Kx1TEdZrYz1w1F9FJWXaeShPP50YtA/k6qfMPB0tLq32uFh3E2Ucu+Hwnu5tFNYk8HhgPvZncKB3eK7YV14XIFeA31l9M8gvKrEDeL8OMfyq7DxnWZZaR4ZoSNM4O4Avf/xGbdufq9W7srQmLUtr0srXJF+xs3z1mQrxzUPUpU2EurRppi7xEUqICVMAo+SoAVZgQX1UVma0MT1HCzZn6tstmUrdne21nF94kwBdf0kL3ZAQrd4JLRiEqAU+/csfNGiQUlJS9I9//EOXXXaZrrvuOr3zzjvauHGjLMvSbbfdVumYirnfF1xwgS9No57IKSjWT5m5+ulAnj2qvf1ArnYdzldpWdXzpAP8LLWNCtXFLZrq4uimuig6VBe3CNOFLUJlWbL/c3r8Z5fxnxMcFeoKUM+Lo9Tz4ihJ5f8pbT+YpzVpWfo+7fjNnbsO5WvXoXzN+H6vpPLlrq5s3aw8lMc3U+fWEbXy8CIAOFdyCor1320H7RsoDxwp9Np/aWyYbrg0Wn0vjVbn1s0YZKhlPqWbMWPG6LXXXlN6errGjBnjta9Hjx5eT6us8OWXX8qyLF133XW+NA0HGWOUeaSw0rSRHzNzlXnSP9gTNXUF6KIWoboo+ljQPha420SGVDunlvliqE/8/CxdfOzrd/ixmzs9R4uVujtba46NkqemZetIYYmW/nRIS386ZB97YYtQe8pKlzYRah/dlF/TAqhTP2bmKmX7IX27OVOrdmap5ISBspAgf/W6OMq+gbKlO7gOe3r+8ymAu91uzZ8/X0lJSV6rmlx33XX2MoQn+uGHH7Ry5UpZlqV+/fr50jTOoROXEbrrjRTtPJinI4XVB+PoMJdXwK74OCbc1eiWFcL5zx0cqN6XtFDvS1pIKr9B6cfME6etZGn7gTz7VbEEYliTAF3Z+vjNnVe2aaaAswjkRSXlD7LILyo99kCLUvtpcHlFJTpaVKq8ooqnxh2vOfmYE1cueGTqGl3ZOkIdLwhXx1bN1CKMXy+fj8pOCFuTvtig8CaB5dP6gsqXgit/BRzb5m9vCw4KUEigv0Jc/gryb3zLxdUVY4yKS433UrfFpSo4efnb4lIVnLDsbcWStxV1eSf8Wx/6qvcStxdGhapPQvko99XtIniasIN8/v3+ZZddplWrVmnHjh3KyMhQy5Yt1bZt22rr3377bUlSz549fW0a58jG9ON3OK87tiqJnyXFNw/VRS0qpoyUB+0LWzT1uuMZaGz8/SwlxIYpITZMI7qVP7kzK69I3+8un7KyZle2ftiTrSMFJfpu20F9t+2gpPIbmS5ucXzJw+e/2qyikrITwnNFYPYO0+diCcwFWw5owZbjT6xr6W6ixFZuXdHKrY4XuNWxlZunijZgBcWlmr5mj/55wo3t/16156zO5e9ned1/c2J4r7hfJ8R1LLCfsD84yF/+J/zAuS0zVzFhTeQODlSTwPMj1BeXlik7v1jZ+UXKyi9WVn6RsvOLtD/n+IPUfjN9rUrLjAqLy1Rw7FkQJz4joqAiRB8Lz9XM5DxrQQF+6n5hc/VNaKE+CdFqG1W/Hs/emNTaBNt27drZSwxWp1OnTurUqVNtNYlzpMMJ6yL/5a5OujzOrfjmIfxkDNRQRKj3EoglpWXanHFE3x+7sXP1riylHc7XthN+2/Tesl1n1EZQgJ9CTxixDDn2dLiQoPKnxlWMZoaetK+i1t+S7nlzhSRp4s8u1Zb0I1q716OfDuQq3VOgdE+B5m3cb7fXqlmwEluF64oLmqljq/JQzjz3+u1gbqHeW7ZLH6Ts0uE871WmxtxwkYrLTPlvTApLdbT4+A98R4/9sFfx25SjRaUqKi1f5rW0zOhIYckpfytaE7ecMBIb6G/JHRyo8CaBCg8uf5V/HnDCx8f+DA7w+jysSUCtz002pnz526z8YmXlFSk7v1iHj4XprLzjwTrrWNg+nF+k7LziGr0nX/6Qftb9clUsZRvob3/cxP7Y/9gKXeUfNzlhtS4/P8teVWzpb29QVNMmZ90H1B7ucEMlF0cfH5UbwML5gM8C/P2U2MqtxFZuJfUo33bgSKGWbT+osR+lSpJGX9dOzUKCFBzofyxABxz/MyhAwUHHt4cE+fu8NvmJ91skdY+3/53nFpZo474crd2TrfV7PVq716PtB/Ls5Rm/3nA8lF8QEVwexi9w64pW5cHcHcJvxOraj5lH9K/vdujT7/eq6NjzES6ICFZS93hN/qp8paeHb7j4jL63l5SW2c9cqJjKdDywnxzeT9p/LNznFpRo1a4sSeVPpT1SUKLSsvJpFgdziyotRVtTTV0BdlivLrA3CTz+7+Wz7/cqv6hUWSeG6GNBu2Jb0Vk+V8KyyqepRYQEqVlI+Z/hTQL0Weo+SdL/DUhQWJOAEwKzd3D2CtUnhGhfnhSZX1RiB3D+P68/avVvYv/+/Vq4cKHWr1+vw4fLl+yKjIxUYmKi+vTpw9KDAHBMizCXbrrs+PfEX/W7pF7859jUFaBr2kXqmnaR9rYjBcXasC9H6/aUB/L1ez3acTBPe7KOak/WUX21/vizINpEhtjTVq5o5dblrdxMU3OAMUbLth/Sv77boW83H3/Q3ZWtm2n0dRdqwOUxKiotswP4mQrw91O4v5/Cm5z93+WJSzAu/W1fBQf6K6+oVDlHi+U5Wnz8z4IS+/Ocgop9JSd9Xqy8ovIlbXMLS5RbWKJ9noJTNW97fMb6GtUF+fvZIbpZSKAiQ4PULCRIESHeATsi9NifIUEKDw70mmpTcd0VATy5V9t68e8cda9WvgrS09M1btw4ffrppyopqfpXMP7+/rrjjjv00ksvqWXLlrXRLADAAWFNAtX9wubqfmFze5vnaLE27PVo3bFR8nV7PEo7nG+/Zq09/qv2ts1D1PGCZurYqvwmz8RW4ZVCCs5OcWmZZq1N1z+/224/odCypP4dYjT6ugvVNT7CHjmtmEZSX1iWpaauADV1BSiu2ZmvuFFcWqYj1YR1z0lhPSuvSP89tkpRr4uaKyrM5RWiK/4sD9nlH4cE+Z8Xc9NRP/kcwH/44QfddNNNOnz4sIyp/m6BkpISffzxx5o/f76++eYbdezY0demAQB1xB0c6LVmuiRl5xdp/d4crd17bPrKHo/2ZB3VzkP52nkoX1/+sM+ubds8xP74/ZRdah0Rougwl6LDmig63KUmgdxzcio5BcX6aHma3lm6U+nHRn6bBPrpzq6tdd+17dSuEdxcF+jvp8jQ8tB8OieOvv9z1FWMQqPO+fQVmJeXp0GDBunQofKfKm+66SaNHj1a3bp1U2xsrKTyJ1+uWLFC//rXvzR37lwdPHhQgwYN0ubNmxUSEnKq0wMAGpBmIUG6tn2Urm1/PJRn5RVp3bGR8nV7yv/cm10eyitUPIH2ROFNAhQTXh7GK0J5dFgTRYe5yreHuRQd7mp0QWpPVr7e/u9Ofbxyt72UZFRTl5J7xmtkt3hujAUaCJ++c7366qvat2+f/Pz89MYbb+j++++vVNOmTRu1adNGd9xxh9566y2NHj1ae/fu1d/+9jf9+te/9qV5AEA9FxEapOsvaaHrj62bLkmHcgu1atdh/c/75c+P6H95jA7lFinzSIH25xSqqKRMOQUlyinI9VoppiphrgC1CHcpxg7p5QG9hVdQb6KmroYd1H/Yna1/frddX63PsJ8yfElMUz1w7YW6pXMcq1QBDYxP35E+//xzWZal5OTkKsP3ye677z4tXbpUb731lmbMmEEAB6CQoADtfH5QXXcDDmre1KXr2h8P5K/cdaU9km2MUc7REjuMn/hn5pFCZeaU/7k/p0AFxWXlS+IdKNH2A3mnbDM0yF/Rx4J5VNPjo8RLfzqkxDh3vXxwWFmZ0TebM/XP77ZrxY7D9vZrL47SA9e1U+9LWtS7PgOoGZ8C+NatWyVJd999d42P+fnPf6633nrLPhYAgAqWZckdEih3SKDax4RVW2dM+XrUmTnHQ/nxsF4e0A8c+zP/2HrWOw7macdB76D+wLurJJWv/nJRi1BddMJTfS9q0VTxzUN8XvLxTB0tKn9wzltLdmj7sf4G+FkaemWcHrj2QnWICz/NGQDUdz4F8Nzc8l8NRkZGnqbyuIiICEnl88cBADgblmWVP7ilSaDXswuqkltY4jVyvjfrqP789RZJUnzzEO0+nK/cwhL9sMejH/Z4vI4N9LeOPQU41A7lFX+G1vK0lgNHCvX+sp16P2WXsvKLJZXPhR/RLV7JPdsq1s0DVIDzhU/fPVq0aKF9+/Zp06ZN6tKlS42O2bRpkyQpKirqNJUAAPiuqStATVs01YUtyoN6flGJHcC/+t/r5O9nadehfP2UmasfM3P104Fc/XggVz9l5ulocal+PLb9xIcQSVJLdxM7jF8U3VQXt2iqi6JD1aLpmU1nqe7BOfdf207Dr2pd60EfQN3z6V919+7dNX36dL388su66667FBBw6tMVFxfrpZdekmVZ6t69uy9NA6hFzMNGY+YK8NclMWG65KQpL2VlRuk5BeWhPLMilJcH9IO5RUr3FCjdU6Dvth30Oi68SYAdyE8cNW8d6b3yV8r2Q3p/2S4t2HLA3nbig3Nq+xHrAOoPnwL4vffeq+nTpys1NVWDBg3S22+/rbi4uCpr9+7dq/vuu0+pqan2jZsAUNf44QPV8fOz1KpZsFo1C1bvE1ZxkcrXPP/pQMWIeZ49cr77cL5yCkr0fVq2vk/L9jomyN9P8Sesf37fO+Xzz6t7cA6A85dPAXzIkCEaNmyYPvvsM82fP18XXnih+vXrp27duikmJkaWZSkjI0PLly/XvHnzVFxcPqft1ltv1aBB/IcHAGiYmoUEqWt8pLrGe98DVVBcqp2H8uxpKxXhfPuBXBWWlHktq9jYHpwD4DifJ5Z99NFHuvfee/XJJ5+oqKhIs2fP1uzZsyvVVTwl884779R7773na7MAANQ7TQL9dWlsuC6N9V6ppKzMaG/2UW3Y59EvPyhf//zb8b0V14wH0gHnQn3/7abPE8xcLpc+/vhjffnllxo4cKCCg4NljPF6BQcHa+DAgZo5c6Y+/vhjuVyu2ug7AAANgp+fpdaRIV4PJGoWwlMrgcaq1m6tHjRokAYNGqTS0lJt375dhw+XPzQgMjJSF154ofz9eUoXANQX9X10CEDDx/eZ6vkUwPv27StJSkpK0i9+8QtJkr+/v9q3b+97zwAAQK0hDAH1h08B/LvvvlNZWZmeeOKJ2uoPADQaBCIAaJx8CuDR0dHKyMhQs2bNaqk7AAAA5w9+0EZVfArgnTp1UkZGhrZu3arOnTvXVp8AAABQC/gBoH7yaRWUBx54QMYYvf7667XVHwAAcB6qCII7nx+kkKBaWwMCaJB8+hdw22236Z577tEHH3yg++67T1OmTFFoKA8TAACcGqNycBJfb6hvfArg7733nm688UatXbtW7777rj7//HMNGTJEV1xxhSIiIk679OC9997rS/MAAABAg+NTAE9OTpZlWfbnWVlZev/992t0rGVZBHAAAAA0Oj5Pwqp4xHx1nwOoGX5FCgBA4+BTAN+xY0dt9QOocwRgAADgBJ8CeHx8fG31AwAAAGgUWAcIANCo8NsuAHXNp3XAAQAAAJyZMwrgX331lbp06aIuXbroww8/PKOGpk6dah87f/78MzoWAAAAOF/UOIAbY/SrX/1KP/zwg5o3b64RI0acUUMjRoxQ8+bNlZqaqvHjx59xRwEAAIDzQY3ngH/77bfaunWr/P399corr5xxQ5Zl6a9//as6deqk9evXa+HCherTp88ZnwfnHvMjAeDc4PsrAOkMRsCnT58uSerXr58uv/zys2qsQ4cOGjBggNf5AAAAgMakxgF8xYoVsixLQ4YM8anBwYMHyxijlJQUn84DAAAANEQ1noKya9cuSVJCQoJPDV5yySWSpJ07d/p0Hpyf+PUsAAA439V4BNzj8UiSIiMjfWqw4vicnByfzgMAAAA0RDUO4OHh4ZKk7OxsnxqsOD4sLMyn8wAAAAANUY0DeHR0tCRp48aNPjW4adMmr/MBAAAAjUmNA/g111wjY4y++OILnxr8/PPPZVmWrr76ap/OAwAAADRENQ7gAwcOlCTNmzdPixcvPqvGFi9erLlz53qdDwAAAGhMahzAb7/9dl144YUyxmj48OHasmXLGTW0detWDR8+XJZlqW3btrrjjjvOuLMAAABAQ1fjAB4QEKCXXnpJlmXpwIEDuuqqq/SXv/xFubm5pzwuNzdXr7zyiq666iplZmZKkl566SUFBNR4BUQAAADgvGEZY8yZHDB58mT97ne/k2VZkqTQ0FBdd9116tKli2JiYhQaGqq8vDzt379fa9as0Xfffae8vDxVNPPMM8/o97//fe1fyXkuJydHbrdbHo/HXpEGAAAA9UdN89oZB3BJev/99/Xwww8rLy+v/CTHwnhVKk4fEhKiV199VcnJyWfaHEQABwAAqO9qmtdqPAXlRElJSdq6davGjx+vFi1ayBhT7SsqKkoTJkzQ1q1bCd8AAABo9M5qBPxkGzdu1A8//KCDBw/qyJEjCgsLU1RUlDp16qQOHTrURj8bPUbAAQAA6rea5rVauROyQ4cOBG0AAACgBs5qCgoAAACAs0MABwAAABxEAAcAAAAcRAAHAAAAHEQABwAAABxEAAcAAAAcRAAHAAAAHNQgA/jixYs1ZMgQxcXFybIsffbZZ177jTGaNGmS4uLiFBwcrD59+mjDhg1eNYWFhXr00UcVFRWl0NBQDR06VHv27PGqycrKUlJSktxut9xut5KSkpSdne1Vk5aWpiFDhig0NFRRUVEaO3asioqKvGrWrVun3r17Kzg4WK1atdIzzzyjWnj+EQAAABqgBhnA8/Ly1KlTJ7366qtV7v/zn/+sl19+Wa+++qpWrlyp2NhY9evXT0eOHLFrHnvsMc2YMUPTpk3TkiVLlJubq8GDB6u0tNSuGTFihFJTUzVnzhzNmTNHqampSkpKsveXlpZq0KBBysvL05IlSzRt2jRNnz5d48ePt2tycnLUr18/xcXFaeXKlZoyZYpefPFFvfzyy+fgnQEAAEC9Zxo4SWbGjBn252VlZSY2NtY8//zz9raCggLjdrvN66+/bowxJjs72wQGBppp06bZNXv37jV+fn5mzpw5xhhjNm7caCSZlJQUu2bZsmVGktm8ebMxxpjZs2cbPz8/s3fvXrvmo48+Mi6Xy3g8HmOMMa+99ppxu92moKDArpk8ebKJi4szZWVlNb5Oj8djJNnnBQAAQP1S07zWIEfAT2XHjh3KyMhQ//797W0ul0u9e/fW0qVLJUmrV69WcXGxV01cXJwSExPtmmXLlsntdqtbt252Tffu3eV2u71qEhMTFRcXZ9cMGDBAhYWFWr16tV3Tu3dvuVwur5p9+/Zp586d1V5HYWGhcnJyvF4AAABo+M67AJ6RkSFJiomJ8doeExNj78vIyFBQUJAiIiJOWRMdHV3p/NHR0V41J7cTERGhoKCgU9ZUfF5RU5XJkyfbc8/dbrdat2596gsHAABAg3DeBfAKlmV5fW6MqbTtZCfXVFVfGzXm2A2Yp+rPxIkT5fF47Nfu3btP2XcAAAA0DOddAI+NjZVUeXQ5MzPTHnmOjY1VUVGRsrKyTlmzf//+Suc/cOCAV83J7WRlZam4uPiUNZmZmZIqj9KfyOVyKTw83OsFAACAhu+8C+Dt2rVTbGys5s2bZ28rKirSokWL1LNnT0lS165dFRgY6FWTnp6u9evX2zU9evSQx+PRihUr7Jrly5fL4/F41axfv17p6el2zdy5c+VyudS1a1e7ZvHixV5LE86dO1dxcXFq27Zt7b8BAAAAqNcaZADPzc1VamqqUlNTJZXfeJmamqq0tDRZlqXHHntMzz33nGbMmKH169crOTlZISEhGjFihCTJ7Xbr/vvv1/jx4/XNN9/o+++/1z333KOOHTvqpptukiRddtlluvnmmzV69GilpKQoJSVFo0eP1uDBg5WQkCBJ6t+/vzp06KCkpCR9//33+uabbzRhwgSNHj3aHrEeMWKEXC6XkpOTtX79es2YMUPPPfecxo0bd9opMQAAADgPnfsFWWrfggULjKRKr1GjRhljypcifOqpp0xsbKxxuVzm+uuvN+vWrfM6x9GjR82YMWNMZGSkCQ4ONoMHDzZpaWleNYcOHTIjR440YWFhJiwszIwcOdJkZWV51ezatcsMGjTIBAcHm8jISDNmzBivJQeNMWbt2rXmuuuuMy6Xy8TGxppJkyad0RKExrAMIQAAQH1X07xmGcMjGRuCnJwcud1ueTwe5oMDAADUQzXNaw1yCgoAAADQUBHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHEcABAAAABxHAAQAAAAcRwAEAAAAHnbcBvG3btrIsq9LrkUcekSQlJydX2te9e3evcxQWFurRRx9VVFSUQkNDNXToUO3Zs8erJisrS0lJSXK73XK73UpKSlJ2drZXTVpamoYMGaLQ0FBFRUVp7NixKioqOqfXDwAAgPrpvA3gK1euVHp6uv2aN2+eJOnOO++0a26++WavmtmzZ3ud47HHHtOMGTM0bdo0LVmyRLm5uRo8eLBKS0vtmhEjRig1NVVz5szRnDlzlJqaqqSkJHt/aWmpBg0apLy8PC1ZskTTpk3T9OnTNX78+HP8DgAAAKA+sowxpq474YTHHntMM2fO1LZt22RZlpKTk5Wdna3PPvusynqPx6MWLVro/fff11133SVJ2rdvn1q3bq3Zs2drwIAB2rRpkzp06KCUlBR169ZNkpSSkqIePXpo8+bNSkhI0FdffaXBgwdr9+7diouLkyRNmzZNycnJyszMVHh4eI36n5OTI7fbLY/HU+NjAAAA4Jya5rXzdgT8REVFRfrggw903333ybIse/vChQsVHR2tSy65RKNHj1ZmZqa9b/Xq1SouLlb//v3tbXFxcUpMTNTSpUslScuWLZPb7bbDtyR1795dbrfbqyYxMdEO35I0YMAAFRYWavXq1dX2ubCwUDk5OV4vAAAANHyNIoB/9tlnys7OVnJysr1t4MCBmjp1qr799lu99NJLWrlypfr27avCwkJJUkZGhoKCghQREeF1rpiYGGVkZNg10dHRldqLjo72qomJifHaHxERoaCgILumKpMnT7bnlbvdbrVu3fqsrh0AAAD1S0Bdd8AJb775pgYOHOg1Cl0xrUSSEhMTddVVVyk+Pl6zZs3SbbfdVu25jDFeo+gnfuxLzckmTpyocePG2Z/n5OQQwgEAAM4D5/0I+K5duzR//nw98MADp6xr2bKl4uPjtW3bNklSbGysioqKlJWV5VWXmZlpj2jHxsZq//79lc514MABr5qTR7qzsrJUXFxcaWT8RC6XS+Hh4V4vAAAANHznfQB/++23FR0drUGDBp2y7tChQ9q9e7datmwpSeratasCAwPt1VMkKT09XevXr1fPnj0lST169JDH49GKFSvsmuXLl8vj8XjVrF+/Xunp6XbN3Llz5XK51LVr11q7TgAAADQM5/UqKGVlZWrXrp1+/vOf6/nnn7e35+bmatKkSbr99tvVsmVL7dy5U48//rjS0tK0adMmhYWFSZIeeughzZw5U++8844iIyM1YcIEHTp0SKtXr5a/v7+k8rnk+/bt0xtvvCFJevDBBxUfH68vv/xSUvkyhFdeeaViYmL0wgsv6PDhw0pOTtawYcM0ZcqUGl8Lq6AAAADUb6yCImn+/PlKS0vTfffd57Xd399f69at0y233KJLLrlEo0aN0iWXXKJly5bZ4VuS/vKXv2jYsGEaPny4evXqpZCQEH355Zd2+JakqVOnqmPHjurfv7/69++vK664Qu+//75XW7NmzVKTJk3Uq1cvDR8+XMOGDdOLL7547t8AAAAA1Dvn9Qj4+YQRcAAAgPqNEXAAAACgHiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOIoADAAAADiKAAwAAAA4igAMAAAAOOi8D+KRJk2RZltcrNjbW3m+M0aRJkxQXF6fg4GD16dNHGzZs8DpHYWGhHn30UUVFRSk0NFRDhw7Vnj17vGqysrKUlJQkt9stt9utpKQkZWdne9WkpaVpyJAhCg0NVVRUlMaOHauioqJzdu0AAACo387LAC5Jl19+udLT0+3XunXr7H1//vOf9fLLL+vVV1/VypUrFRsbq379+unIkSN2zWOPPaYZM2Zo2rRpWrJkiXJzczV48GCVlpbaNSNGjFBqaqrmzJmjOXPmKDU1VUlJSfb+0tJSDRo0SHl5eVqyZImmTZum6dOna/z48c68CQAAAKh/zHnoqaeeMp06dapyX1lZmYmNjTXPP/+8va2goMC43W7z+uuvG2OMyc7ONoGBgWbatGl2zd69e42fn5+ZM2eOMcaYjRs3GkkmJSXFrlm2bJmRZDZv3myMMWb27NnGz8/P7N2716756KOPjMvlMh6P54yuyePxGElnfBwAAACcUdO8FlC38f/c2bZtm+Li4uRyudStWzc999xzuvDCC7Vjxw5lZGSof//+dq3L5VLv3r21dOlS/c///I9Wr16t4uJir5q4uDglJiZq6dKlGjBggJYtWya3261u3brZNd27d5fb7dbSpUuVkJCgZcuWKTExUXFxcXbNgAEDVFhYqNWrV+uGG26otv+FhYUqLCy0P/d4PJKknJycWnl/AAAAULsqcpox5pR152UA79atm9577z1dcskl2r9/v/74xz+qZ8+e2rBhgzIyMiRJMTExXsfExMRo165dkqSMjAwFBQUpIiKiUk3F8RkZGYqOjq7UdnR0tFfNye1EREQoKCjIrqnO5MmT9fTTT1fa3rp161MeBwAAgLp15MgRud3uaveflwF84MCB9scdO3ZUjx49dNFFF+ndd99V9+7dJUmWZXkdY4yptO1kJ9dUVX82NVWZOHGixo0bZ39eVlamw4cPq3nz5qc9tjbk5OSodevW2r17t8LDw895e/VFY71uiWtvjNfeWK9barzX3livW+LaG+O118V1G2N05MgRr9kPVTkvA/jJQkND1bFjR23btk3Dhg2TVD463bJlS7smMzPTHq2OjY1VUVGRsrKyvEbBMzMz1bNnT7tm//79ldo6cOCA13mWL1/utT8rK0vFxcWVRsZP5nK55HK5vLY1a9asZhdci8LDwxvVP9YKjfW6Ja69MV57Y71uqfFee2O9bolrb4zX7vR1n2rku8J5uwrKiQoLC7Vp0ya1bNlS7dq1U2xsrObNm2fvLyoq0qJFi+xw3bVrVwUGBnrVpKena/369XZNjx495PF4tGLFCrtm+fLl8ng8XjXr169Xenq6XTN37ly5XC517dr1nF4zAAAA6qfzcgR8woQJGjJkiNq0aaPMzEz98Y9/VE5OjkaNGiXLsvTYY4/pueeeU/v27dW+fXs999xzCgkJ0YgRIySV/+Ry//33a/z48WrevLkiIyM1YcIEdezYUTfddJMk6bLLLtPNN9+s0aNH64033pAkPfjggxo8eLASEhIkSf3791eHDh2UlJSkF154QYcPH9aECRM0evToRvkTKAAAAM7TAL5nzx79/Oc/18GDB9WiRQt1795dKSkpio+PlyT93//9n44ePaqHH35YWVlZ6tatm+bOnauwsDD7HH/5y18UEBCg4cOH6+jRo7rxxhv1zjvvyN/f366ZOnWqxo4da6+WMnToUL366qv2fn9/f82aNUsPP/ywevXqpeDgYI0YMUIvvviiQ+/E2XO5XHrqqacqTYM53zXW65a49sZ47Y31uqXGe+2N9bolrr0xXnt9vm7LnG6dFAAAAAC1plHMAQcAAADqCwI4AAAA4CACOAAAAOAgAjgAAADgIAI4vCxevFhDhgxRXFycLMvSZ599VtddcsTf//53XXHFFfZi/T169NBXX31V191yxKRJk2RZltcrNja2rrt1zrVt27bSdVuWpUceeaSuu+aII0eO6LHHHlN8fLyCg4PVs2dPrVy5sq67VetO9z3t008/1YABAxQVFSXLspSamlon/axtp7vuSZMm6dJLL1VoaKgiIiJ00003VXpwXEN1umtPTk6u9O++4inZDdnprruq73eWZemFF16omw7XotNd+/79+5WcnKy4uDiFhITo5ptv1rZt2+qms8cQwOElLy9PnTp18lpOsTG44IIL9Pzzz2vVqlVatWqV+vbtq1tuuUUbNmyo66454vLLL1d6err9WrduXV136ZxbuXKl1zVXPHjrzjvvrOOeOeOBBx7QvHnz9P7772vdunXq37+/brrpJu3du7euu1arTvc9LS8vT7169dLzzz/vcM/OrdNd9yWXXKJXX31V69at05IlS9S2bVv1799fBw4ccLinta8m/4/dfPPNXv/+Z8+e7WAPz43TXfeJ15uenq633npLlmXp9ttvd7inte9U126M0bBhw7R9+3Z9/vnn+v777xUfH6+bbrpJeXl5ddDb4x0DqiTJzJgxo667UWciIiLMv/71r7ruxjn31FNPmU6dOtV1N+rc//7v/5qLLrrIlJWV1XVXzrn8/Hzj7+9vZs6c6bW9U6dO5ne/+10d9ercO9X3tB07dhhJ5vvvv3e0T06oyfdyj8djJJn58+c70ymHVHXto0aNMrfcckud9McpNfk7v+WWW0zfvn2d6ZCDTr72LVu2GElm/fr19raSkhITGRlp/vnPf9ZBD8sxAg6cpLS0VNOmTVNeXp569OhR191xxLZt2xQXF6d27drp7rvv1vbt2+u6S44qKirSBx98oPvuu0+WZdV1d865kpISlZaWqkmTJl7bg4ODtWTJkjrqFepKUVGR/vGPf8jtdqtTp0513R1HLFy4UNHR0brkkks0evRoZWZm1nWXHLV//37NmjVL999/f1135ZwrLCyUJK/vd/7+/goKCqrT73cEcOCYdevWqWnTpnK5XPrlL3+pGTNmqEOHDnXdrXOuW7dueu+99/T111/rn//8pzIyMtSzZ08dOnSorrvmmM8++0zZ2dlKTk6u6644IiwsTD169NAf/vAH7du3T6Wlpfrggw+0fPlypaen13X34JCZM2eqadOmatKkif7yl79o3rx5ioqKqutunXMDBw7U1KlT9e233+qll17SypUr1bdvXzuoNQbvvvuuwsLCdNttt9V1V865Sy+9VPHx8Zo4caKysrJUVFSk559/XhkZGXX6/Y4ADhyTkJCg1NRUpaSk6KGHHtKoUaO0cePGuu7WOTdw4EDdfvvt6tixo2666SbNmjVLUvk36MbizTff1MCBAxUXF1fXXXHM+++/L2OMWrVqJZfLpf/3//6fRowYIX9//7ruGhxyww03KDU1VUuXLtXNN9+s4cOHN4qR4LvuukuDBg1SYmKihgwZoq+++kpbt261v/c1Bm+99ZZGjhxZ6bdg56PAwEBNnz5dW7duVWRkpEJCQrRw4UINHDiwTr/fEcCBY4KCgnTxxRfrqquu0uTJk9WpUyf99a9/retuOS40NFQdO3as8zvEnbJr1y7Nnz9fDzzwQF13xVEXXXSRFi1apNzcXO3evVsrVqxQcXGx2rVrV9ddg0NCQ0N18cUXq3v37nrzzTcVEBCgN998s6675biWLVsqPj6+0XzP++6777Rly5ZG9T2va9euSk1NVXZ2ttLT0zVnzhwdOnSoTr/fEcCBahhjGtWvJCsUFhZq06ZNatmyZV13xRFvv/22oqOjNWjQoLruSp0IDQ1Vy5YtlZWVpa+//lq33HJLXXcJdaSxfs87dOiQdu/e3Wi+57355pvq2rVro5nvfyK3260WLVpo27ZtWrVqVZ1+vwuos5ZRL+Xm5urHH3+0P9+xY4dSU1MVGRmpNm3a1GHPzq3HH39cAwcOVOvWrXXkyBFNmzZNCxcu1Jw5c+q6a+fchAkTNGTIELVp00aZmZn64x//qJycHI0aNaquu3bOlZWV6e2339aoUaMUENC4vh1+/fXXMsYoISFBP/74o379618rISFBv/jFL+q6a7XqdN/TDh8+rLS0NO3bt0+StGXLFklSbGxsg14P/1TX3bx5cz377LMaOnSoWrZsqUOHDum1117Tnj17zotlOE917ZGRkZo0aZJuv/12tWzZUjt37tTjjz+uqKgo3XrrrXXYa9/V5P/vnJwcffLJJ3rppZfqqpvnxOmu/ZNPPlGLFi3Upk0brVu3Tv/7v/+rYcOGqX///nXX6TpbfwX10oIFC4ykSq9Ro0bVddfOqfvuu8/Ex8eboKAg06JFC3PjjTeauXPn1nW3HHHXXXeZli1bmsDAQBMXF2duu+02s2HDhrruliO+/vprI8ls2bKlrrviuI8//thceOGFJigoyMTGxppHHnnEZGdn13W3at3pvqe9/fbbVe5/6qmn6rTfvjrVdR89etTceuutJi4uzgQFBZmWLVuaoUOHmhUrVtR1t2vFqa49Pz/f9O/f37Ro0cIEBgaaNm3amFGjRpm0tLS67rbPavL/9xtvvGGCg4PPu3/rp7v2v/71r+aCCy6w/85///vfm8LCwjrts2WMMec24gMAAACowBxwAAAAwEEEcAAAAMBBBHAAAADAQQRwAAAAwEEEcAAAAMBBBHAAAADAQQRwAAAAwEEEcAAAAMBBBHAA57WdO3fKsixZlqV33nmnrrtTpUmTJtl9rM8awnsJAA0BARyAJGnDhg2yLEsBAQHKzc21t5eWliosLEyWZWnZsmV12EMAAM4PBHAAkqQlS5ZIkq688ko1bdrU3v79998rNzdXTZo0UdeuXeuqewBge+edd+zfxuzcubOuuwOcMQI4AEnHA/h1113ntX3x4sWSpGuuuUZBQUGO98tXbdu2lTFGxhglJyfXdXeqNGnSJLuPAIDzHwEcgKTjAfzaa6/12v7dd99VuR0AAJwdAjgA7du3z/417slBu7pgDgAAzg4BHIAdstu3b6+YmBh7+6ZNm3Tw4EH5+fmpZ8+ePrdz8rzNwsJCvfjii+rSpYvcbrfCw8PVrVs3/e1vf1NpaWm15+nTp48sy1KfPn0kSdu2bdOYMWPUvn17hYSEeM0LPd3KHSevQFJQUKAXXnhBXbp0UVhYmMLCwnTNNdfo1VdfVUlJyWmvsaioSP/4xz80aNAgtWrVSi6XS9HR0eratavGjBmj7777rtJUk9OtgtK2bVtZlmVPoVm5cqV+/vOfq3Xr1mrSpIlat26t5ORkbdq06ZR9S09P12uvvaY77rhD7du3V2hoqFwul1q1aqVbbrlFH3/8scrKyk57jbVl9uzZuueee3ThhRcqNDRUbrdbl19+ue6++25Nnz5dR48erfK4srIyffDBB/rZz36m2NhYBQUFqUWLFrrhhhv02muvqaioqNo2T36vc3JyNGnSJHXs2FFNmzZVTEyMfvazn2np0qVex2VmZur3v/+9Lr/8coWGhqp58+a65ZZb9P3331fbVm19vVc4cOCAfv/736tz585q1qyZmjRporZt2yopKcn+N1ydk7+GNm/erNGjR6tt27ZyuVyKiYnRrbfeqpSUlNP2Q5L27NmjiRMnqkuXLoqIiFCTJk3Upk0b3XXXXVqwYEG1x1X173HevHkaMmSIYmNj5XK51K5dOz300EPas2dPpeMXLlwoy7L0i1/8wt7Wrl07+5wVr4ULF3odt3XrVj366KNKTExU06ZNFRQUpLi4OF155ZW677779PHHH6uwsLBG1w7UCgOgUXn77beNJJ9fO3bs8KntNWvWmK5du1Z7/muvvdbk5ORUeZ7evXsbSaZ3797ms88+M6GhodX2b8eOHfa2t99+u9K5nnrqKXt/RkaG6dSpU7V9GjJkiCktLa32+r7//nvTrl27M37vTuxDVeLj440kM2rUKPPmm2+agICAKs/rcrnMtGnTqjxHSUmJ8fPzO23f+vXrZ44cOVLlOU73XtbUwYMHzY033njavlTVxqFDh0yvXr1Oedxll11mdu7cWWXbJ77XaWlp5pJLLqnyHP7+/ubf//63McaYH374wbRq1ara9/ybb76psq3a+no3xpivv/7ahIeHn/K6H3nkkWq/Pk/8Gpo+fboJCQmp9rqr+xqq8K9//csEBwefsi/333+/KS4urnTsyV9Dv/nNb6o9R4sWLczGjRu9jl+wYEGNvj8tWLDAPubf//63CQoKOu0x69atO+V1A7WJAA40MvUlgF999dVGkrnrrrvM7NmzzapVq8yHH35ob68IvFWpCODt2rUzTZs2NS1atDDPP/+8+e9//2tSUlLMlClTzIEDB4wxZxbAe/bsaYKCgszYsWPNvHnzzOrVq82HH35oLrvsMrvm9ddfr7JPGzZsME2bNrXrbr31VvPxxx+blStXmpSUFPPuu++ae+65x4SGhp51AO/UqZMJDAw0cXFxZsqUKWb58uVm0aJF5je/+Y1xuVxGkgkICDDLly+vdI7i4mLj5+dn+vbta1544QUzZ84cs3r1arNw4ULz1ltvmR49eth9uPfee6vsR20E8Ly8PNOxY0f7PF27djVvvPGG+e9//2tWrVplZsyYYX71q1+ZuLi4Sm2UlJR49bN3797mk08+MatWrTJffPGFGTZsmL3voosuqvIHiRPf627dupmQkBAzceJEs2jRIrNy5Urzl7/8xQ66YWFhZvv27aZ169YmMjLSPPvss2bJkiVm+fLl5umnn7ZDXZs2bUxhYWGltmrr6/3777+32woMDDSPPfaYWbBggVmxYoV54403vH7o+7//+78qz1HxNdS5c2fTpEkT065dO/Pqq6+alJQUs2zZMjNp0iTTpEkTI8mEh4ebzMzMKs/z5ptv2m0lJiaaKVOmmCVLlpg1a9aY6dOnm5/97Gf2/nHjxlU6/sSvoZ49e9p/jx9++KFZtWqVmT9/vrn33nvtmu7du3sdn5uba9atW2f++Mc/2jVff/21WbdundcrNzfXGGNMRkaG/QN6dHS0eeaZZ8zcuXPNmjVrzNKlS80HH3xgHnzwQRMVFUUAh6MI4EAjk52dbTZt2mS//vvf/9r/kc2dO9drX3R0tJFk/va3v3lt37RpkykqKjrjtk8O/88991ylmuLiYjNgwAC7ZubMmZVqKgK4JBMXF2d27dpVbZtnEsADAwO9Rs4qHDp0yMTExBhJ5oorrqiync6dOxtJxs/Pz3z00UfV9ufgwYMmPz+/2j5UpSI8STLx8fEmPT29Us23335rj4xfddVVlfaXlZWZbdu2VdsvY4x58sknjSRjWZbZunVrpf21EcAfe+wx+xyPPPKIKSsrq7KusLDQZGRkeG179dVXvX5IqOrYxx9//JRh9MT32uVymZSUlEo1s2bN8hqFjYqKMj/++GOlur/97W923aefflppf219vVeEdH9/f/P1119X2n/48GHToUMH++tv/fr1lWpO/Brq2rWryc7OrlTzwQcf2DUvv/xypf1paWn2yPmoUaOqHOE25vjfgZ+fn9myZYvXvhO/hiSZ0aNHV/n3+MADD9g1a9asqbT/xPf2VIMBJ/7AcKqAffTo0Ur/LoFziQAONHJffPGFPTp0oj179tj/cVUV+M7Gif9pXnHFFdX+unz37t0mMDDQSDI/+9nPKu0/MYC/9957p2zzTAJ4VSN2FX7729/adSeHlzlz5tj7/vd///eU/anKmQTw//znP9We56GHHrLrVqxYccb9KCkpMVFRUUaSefHFFyvt9zWAHz582A5wXbp0MSUlJWd0fMVvIqKioqqdrlFSUmIuvfRSI8lERESYgoICr/0nvte/+c1vqm3rxPe8ut965Ofn26PGv/rVryrtr42v9+XLl9vn+J//+Z9q+7tkyRK77uGHHz7l9fzwww9VnqOsrMzExcUZqfw3OCcbP368/UPv0aNHq+1LcXGxPWXnd7/7nde+E7+GWrZsWenvp8LmzZvtur/+9a+V9tc0gD/77LP21wJQn3ATJtDIVSwz2KtXL6/t//3vfyVJF110kWJjY2u93VGjRsnPr+pvQRdccIH69+8vqfymq+puUAsKCtKdd95Za30aOXJktftOfAjRjh07vPbNmjXL/vhXv/pVrfXnZBEREbrllluq3X/ffffZH8+fP/+U5yorK9O+ffu0ZcsWrV+/XuvXr9emTZt0wQUXSJJ++OGH2un0CRYsWKD8/HxJ0tixY+Xv71/jY/ft22ffZDp8+HCFhYVVWefv72/foJeVlaU1a9ZUe86777672n1XXHGFJMmyLA0fPrzKmuDgYLVv316StH379lP2/2y/3k/8e7z//vurPX+vXr102WWXVTrmZB07drSv7WSWZalz586Sqr6ezz//XJI0ZMgQNWnSpNo2AgIC1KNHD0k65dNz77jjDrlcrir3JSQk2A8EO917eyotW7aUVP61UNF/oD4ggAONXHXLDFasAnGulh+8+uqrT7n/mmuukSTl5+dX+x9w+/btTxkEztSll15a7b7IyEj74yNHjnjtq1gJo02bNoqPj6+1/pys8/9v7+5jmrr6OIB/NVDBVSYF0dBNkUyiS8mqIJgQUIxzm1riskXdiOASFUxDhkZdpjPLomYkS8SMusw34oKbZGITp2NBEhV0ayYyqzUmQp24YJhz1nWSDXnJff4g9+4Cvbf0FR75fpKb1PvSe87pqf1x7nmZOxcRERGKx41Go7RY0s2bN4ccFwQBx48fR25uLrRaLfR6PWbPno3U1FRps9vtAIA///wz6OmXzxiSk5Pj07Xy/GRmZqqeKz/uqRxEKSkpiscmT54MAIiPj0dsbKzX8wbXicH8re9i+jUajRQcKxHz3draqjgTjFodB/6r54Pz43a74XQ6AQAHDx4cMuvI4K2mpgYA8Pvvvyvey1taxHL3VrZq8vLypM/ozTffxOLFi1FeXo7m5uZhzTxDFCoMwInGsK6uLjQ3NwMYGmiLLeCDW8aDJSEhQfW4fDpEl8vl8Ry1wMgfEydOVDwmb70c/MMtBqtia1uoeCuziIgIKYAaXGZdXV1Yvnw51q5di4sXLypO8Sfydtwf8qDe17KS50deNzyRP7FRqjvA8D5vtXPk53kL5vyt7+JrnU6n+scX8F++BUHA48ePPZ7jb37++OMP1euUiE88gpkWX8TFxeG7776DXq+HIAi4cOECtmzZgvT0dOh0Orz11ls4e/as3+9P5C/1bzMRPVOSkpJw7949j8eUWhU3btyIjRs3Sv8uLCz0OJ+2r5TmvBYJw1iW3ZcuDOHgLU/heH+lctu7dy9++OEHAMDChQthNpsxb948TJs2DdHR0VKwk5OT43Gu8tEkGHUn3AJNcyCffTDIg+DS0lLV7jBy4hOZkZSdnQ2n04lTp06htrYWjY2NaG9vx99//w2r1Qqr1YrXXnsNVqvV6x8FRMHCAJyIRsSDBw9UuwDIW9zk3T9Go/j4eAD9/ZRD6cGDB6rHe3t7pZZPeZkJgoAjR44A6H/Scf78ecX+yEotp8EglhPQvyjQzJkzh32tPD9q3RqAgeU0WuqOv/VdfP3o0SP09vaqtoKL+R43blzQnw7FxcVJr//55x8YDIagvn+oRUVFIT8/Xxrn8euvv+L777+HxWJBS0sL6urqsHPnTpSXl49wSmmsYBcUojHk3LlzcDgc0iYOlNq2bduA/QUFBQCAZcuWDdjvcDiwd+/eoKSlqalpWMcnTpyI5OTkoNwzVObNmwcA+O233xSfMASD3W5XXY3z+vXrUt9feYDkcrmkoHXVqlWKwXdnZydu374dxBQPJJYTADQ2Nvp0rTw/P//8s+q5V65c8XjdSPK3vovp7+7uVl11E/gv37NmzQp6y/OUKVOg1+sB9A/yHOmnDIE+bUpOTkZJSQmampqkgcfffvttMJJGNCwMwInGkJSUFBgMBhgMBrz88su4desWgP7BSeJ+g8GA1tZWAMAbb7wxYL/BYJB+hANVVVWl+CN+//59nDt3DkD/svOjravJYCaTSXodyhY0l8uFM2fOKB6vrKyUXi9ZskR6LQ/a1frkHj16FD09PQGmUllubi6ee+45AEBFRYVPfXsTExOlWT5OnjypODCvr69P6iIVGxs7IOgfSf7Wd/nnePToUcX3t9ls0vdZfk0w5eXlAehvPRYHWY4U+eDrQJaQj4mJkQbIhmLgMZESBuBEY5Tdbofb7UZ0dDTS09Ol/f/++y+uXr0KwPeZKny9/2effTZkf29vLzZs2CC15G7atClkaQiWJUuWSNMUVlRUoLq6WvFcl8sV0ADHLVu2eOyK0tDQgEOHDgHonzJRPuvGlClTpJkgqqurPc6Q0dTUhI8++sjvdA3H5MmTUVRUBABobm5GaWmpYlDa09MzZOCf2WwGADx8+BAlJSUer/3kk0+kQHTDhg2K09yFm7/1PSMjQ/osjxw5gvr6+iHv4Xa7pXIdP358yL4z27Ztk8qzuLhY+n9CSW1tLW7cuBGStMgH8d65c0fxvLq6OnR0dCged7vd0pMDX7pEEQWKfcCJxiixC8CCBQsQGRkp7bfZbOjp6YFOp0NqamrI7p+eno4PPvgAdrsdBQUFSEhIQGtrK/bt2yf9IJpMJqxYsSJkaQimqqoqZGRkoLOzE++88w5OnjyJNWvWIDk5GX19fXA6naivr0dNTQ0cDgeSkpJ8vscrr7yCW7duIS0tDR9++CEyMjLw9OlT1NbWory8XOojfODAgQHXjR8/Hvn5+Thw4ADsdjuys7OxefNmvPTSS3C73aitrcUXX3wBrVaLxMREtLS0BKlUhtq9ezfq6+vhcDhgsVhgs9lQVFSE1NRUaDQatLe34/Lly/jmm2+wZ88erFu3Trq2uLgYX3/9NWw2G7766ivcu3cPZrMZycnJ6OjoQGVlJaxWK4D++et37doVsnz4KpD6fujQIWRmZqK7uxvLly9HSUkJTCYTtFotrl27hrKyMmnqwq1bt4as283MmTPx5Zdf4r333oPL5UJWVhbWrl2LFStWYPr06ejt7UV7ezuuXLmCmpoa3LlzB2fOnFGcdzwQc+fORVRUFLq6urBr1y5EREQgKSlJ6l6l1+sRHR2NEydOwGQy4dVXX8XSpUthMBig0+nw5MkT3Lx5ExaLBffv3wfw//HHPj1DRmDxHyIaBVauXCkAED7++OMB+8WVAvPy8oJ+T/nqdb/88ou0fLunLSsrS3G1Q3ElzIULF3q9py8rYaq5cOGCdJ6n5eoFQRCuXr0qvPjii4p5ErfBK/cNdyXMwsJC4fDhw9KS84M3jUYjnDhxwuN7/PXXX4LRaFRMk06nExoaGlTLNhhL0QuCIDx8+FDIycnxWk6e7vHo0SMhKytL9bo5c+YIbW1tHu893M+7sLBQACDMmDFD9Ty18gpWfRcEQairqxNiYmJU8202mxVX25TXoUDzXV1d7TUtQP9S9OfPnx9wrS91yFuat2/frnhv8Tsq5sfbplZ2RKHALihEY5AgCNICPIO7mYgrY4ay+wnQ3z/3p59+wqeffgqj0YhJkyZBq9Vi/vz5qKioQENDg+Jqh6NVWloabt++jc8//xyLFy9GQkICIiMjMW3aNKSlpeH999+HzWbzq/VbtH79ely6dAmrVq1CYmIiNBoN9Ho9CgoKcO3aNcXVHZ9//nn8+OOP2L17N1JTUxEVFQWtVos5c+Zg69atuH79esg/c1F8fDwaGhpgtVrx9ttv44UXXsCECRMQGxsLg8GA/Px8nD59Gu++++6Qa3U6HRobG1FVVYXXX38dU6dORWRkJOLi4rBo0SJYLBbY7faQLojkj0Dr+9KlS+F0OrFjxw4YjUbExMRgwoQJmD59OvLz83Hp0iVYLBbFAbbBtHr1arS1taGsrAyLFi2S6rk4gNRkMmHfvn1oa2tDbm5uyNJRVlaGw4cPIzs7GzqdzuNYkf379+PUqVMoLi5Geno69Ho9NBoNoqOjkZKSgnXr1uHy5cthKzsi0ThBGIUTphLRM+nYsWPSMuF3794NKBAdS8T524M1BzuFB+s7ESnhn3tERERERGHEAJyIiIiIKIwYgBMRERERhREDcCIiIiKiMGIATkREREQURpwFhYiIiIgojNgCTkREREQURgzAiYiIiIjCiAE4EREREVEYMQAnIiIiIgojBuBERERERGHEAJyIiIiIKIwYgBMRERERhREDcCIiIiKiMPofg7EMl46M5AsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pls_fig, ax = subplots(figsize=(8,8))\n",
    "n_comp = param_grid['n_components']\n",
    "ax.errorbar(n_comp,\n",
    "            -grid.cv_results_['mean_test_score'],\n",
    "            grid.cv_results_['std_test_score'] / np.sqrt(K))\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20)\n",
    "ax.set_xlabel('# principal components', fontsize=20)\n",
    "ax.set_xticks(n_comp[::2])\n",
    "ax.set_ylim([50000,250000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ec4278",
   "metadata": {},
   "source": [
    "#### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f309d2d6",
   "metadata": {},
   "source": [
    "$Conceptual$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d10c828",
   "metadata": {},
   "source": [
    "1. We perform best subset, forward stepwise, and backward stepwise selection on a single data set. For each approach, we obtain $p + 1$ models, containing $0, 1, 2, \\ldots, p$ predictors. Explain your answers:\n",
    "\n",
    "   (a) Which of the three models with $k$ predictors has the smallest training RSS?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fe514d",
   "metadata": {},
   "source": [
    "**Answer: Best Subset Selection**\n",
    "\n",
    "Explanation:\n",
    "Best subset selection examines all $\\binom{p}{k}$ possible models with exactly $k$ predictors and selects the one with the lowest training RSS. Forward and backward stepwise selection use greedy algorithms that don't consider all possible combinations, so they may miss the optimal k-variable model. Therefore, best subset selection is guaranteed to find the model with the smallest training RSS among all possible k-variable models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d774aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RSS Comparison for k-variable models:\n",
      "==================================================\n",
      "Best Subset:     SMALLEST (examines all combinations)\n",
      "Forward Stepwise: ≥ Best Subset (greedy, may be suboptimal)\n",
      "Backward Stepwise: ≥ Best Subset (greedy, may be suboptimal)\n"
     ]
    }
   ],
   "source": [
    "# Conceptual illustration\n",
    "print(\"Training RSS Comparison for k-variable models:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Best Subset:     SMALLEST (examines all combinations)\")\n",
    "print(\"Forward Stepwise: ≥ Best Subset (greedy, may be suboptimal)\")\n",
    "print(\"Backward Stepwise: ≥ Best Subset (greedy, may be suboptimal)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b13305",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "069c7440",
   "metadata": {},
   "source": [
    "(b) Which of the three models with $k$ predictors has the smallest test RSS?  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b731c932",
   "metadata": {},
   "source": [
    "**Answer: Cannot be determined with certainty**\n",
    "\n",
    "Explanation:\n",
    "While best subset has the smallest *training* RSS, this doesn't guarantee the smallest *test* RSS. The model with the smallest training RSS may overfit the training data. Forward or backward stepwise selection might produce models that generalize better to test data due to their more constrained search process, which can act as implicit regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1dfdfa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RSS Comparison for k-variable models:\n",
      "==================================================\n",
      "Cannot determine which will be smallest:\n",
      "  - Best subset: smallest training RSS, but may overfit\n",
      "  - Forward/Backward: may generalize better despite higher training RSS\n",
      "  - Test performance depends on the specific dataset\n"
     ]
    }
   ],
   "source": [
    "# Conceptual illustration\n",
    "print(\"Test RSS Comparison for k-variable models:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Cannot determine which will be smallest:\")\n",
    "print(\"  - Best subset: smallest training RSS, but may overfit\")\n",
    "print(\"  - Forward/Backward: may generalize better despite higher training RSS\")\n",
    "print(\"  - Test performance depends on the specific dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c339d8b4",
   "metadata": {},
   "source": [
    "(c) True or False:  \n",
    "   i. The predictors in the $k$-variable model identified by forward stepwise are a subset of the predictors in the $(k + 1)$-variable model identified by forward stepwise selection.  \n",
    "   ii. The predictors in the $k$-variable model identified by backward stepwise are a subset of the predictors in the $(k + 1)$-variable model identified by backward stepwise selection.  \n",
    "   iii. The predictors in the $k$-variable model identified by backward stepwise are a subset of the predictors in the $(k + 1)$-variable model identified by forward stepwise selection.  \n",
    "   iv. The predictors in the $k$-variable model identified by forward stepwise are a subset of the predictors in the $(k + 1)$-variable model identified by backward stepwise selection.  \n",
    "   v. The predictors in the $k$-variable model identified by best subset are a subset of the predictors in the $(k + 1)$-variable model identified by best subset selection.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5537815",
   "metadata": {},
   "source": [
    "i. Forward Stepwise: k-variable ⊆ (k+1)-variable\n",
    "\n",
    "**TRUE**\n",
    "\n",
    "Forward stepwise starts with no predictors and *adds* one predictor at a time. The (k+1)-variable model is constructed by adding one predictor to the k-variable model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "29b421ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Stepwise Selection:\n",
      "Step 0: {} (no predictors)\n",
      "Step 1: {X₃} (add best single predictor)\n",
      "Step 2: {X₃, X₅} (add best to existing)\n",
      "Step 3: {X₃, X₅, X₁} (add best to existing)\n",
      "\n",
      "Clearly: k-variable ⊆ (k+1)-variable ✓\n"
     ]
    }
   ],
   "source": [
    "# Forward stepwise illustration\n",
    "print(\"Forward Stepwise Selection:\")\n",
    "print(\"Step 0: {} (no predictors)\")\n",
    "print(\"Step 1: {X₃} (add best single predictor)\")\n",
    "print(\"Step 2: {X₃, X₅} (add best to existing)\")\n",
    "print(\"Step 3: {X₃, X₅, X₁} (add best to existing)\")\n",
    "print(\"\\nClearly: k-variable ⊆ (k+1)-variable ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebe2a41",
   "metadata": {},
   "source": [
    "ii. Backward Stepwise: k-variable ⊆ (k+1)-variable\n",
    "\n",
    "**TRUE**\n",
    "\n",
    "Backward stepwise starts with all p predictors and *removes* one predictor at a time. The k-variable model is constructed by removing one predictor from the (k+1)-variable model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8d8800a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward Stepwise Selection:\n",
      "Step 0: {X₁, X₂, X₃, X₄, X₅} (all predictors)\n",
      "Step 1: {X₁, X₂, X₃, X₄} (remove worst)\n",
      "Step 2: {X₁, X₂, X₄} (remove worst from remaining)\n",
      "Step 3: {X₁, X₄} (remove worst from remaining)\n",
      "\n",
      "Clearly: k-variable ⊆ (k+1)-variable ✓\n"
     ]
    }
   ],
   "source": [
    "# Backward stepwise illustration\n",
    "print(\"Backward Stepwise Selection:\")\n",
    "print(\"Step 0: {X₁, X₂, X₃, X₄, X₅} (all predictors)\")\n",
    "print(\"Step 1: {X₁, X₂, X₃, X₄} (remove worst)\")\n",
    "print(\"Step 2: {X₁, X₂, X₄} (remove worst from remaining)\")\n",
    "print(\"Step 3: {X₁, X₄} (remove worst from remaining)\")\n",
    "print(\"\\nClearly: k-variable ⊆ (k+1)-variable ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37fc85b",
   "metadata": {},
   "source": [
    "iii. Backward k-variable ⊆ Forward (k+1)-variable\n",
    "\n",
    "**FALSE**\n",
    "\n",
    "These are independent algorithms with no inherent subset relationship. Backward stepwise removes predictors from the full model, while forward stepwise adds predictors from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c7ef1567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:\n",
      "Backward k-variable: {X₁, X₃, X₅}\n",
      "Forward (k+1)-variable: {X₂, X₄, X₆, X₇}\n",
      "\n",
      "No subset relationship guaranteed ✗\n"
     ]
    }
   ],
   "source": [
    "# Example showing they're independent\n",
    "print(\"Example:\")\n",
    "print(\"Backward k-variable: {X₁, X₃, X₅}\")\n",
    "print(\"Forward (k+1)-variable: {X₂, X₄, X₆, X₇}\")\n",
    "print(\"\\nNo subset relationship guaranteed ✗\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82abde69",
   "metadata": {},
   "source": [
    "iv. Forward k-variable ⊆ Backward (k+1)-variable\n",
    "\n",
    "**FALSE**\n",
    "\n",
    "Same reasoning as (iii): these are independent algorithms with no inherent subset relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "876cf725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:\n",
      "Forward k-variable: {X₂, X₄}\n",
      "Backward (k+1)-variable: {X₁, X₃, X₅}\n",
      "\n",
      "No subset relationship guaranteed ✗\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example showing they're independent\n",
    "print(\"Example:\")\n",
    "print(\"Forward k-variable: {X₂, X₄}\")\n",
    "print(\"Backward (k+1)-variable: {X₁, X₃, X₅}\")\n",
    "print(\"\\nNo subset relationship guaranteed ✗\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f4ce3e",
   "metadata": {},
   "source": [
    "v. Best Subset k-variable ⊆ Best Subset (k+1)-variable\n",
    "\n",
    "**FALSE**\n",
    "\n",
    "Best subset selection independently chooses the optimal set of predictors for each model size. There's no guarantee that the optimal k-variable model is contained in the optimal (k+1)-variable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c921643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Subset Selection Example:\n",
      "==================================================\n",
      "Suppose for some dataset:\n",
      "  Best k=2 model: {X₁, X₃} (lowest RSS among all 2-variable models)\n",
      "  Best k=3 model: {X₂, X₄, X₅} (lowest RSS among all 3-variable models)\n",
      "\n",
      "{X₁, X₃} ⊄ {X₂, X₄, X₅}\n",
      "\n",
      "Best subset independently optimizes for each k ✗\n"
     ]
    }
   ],
   "source": [
    "# Example demonstration\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "# Simulated example\n",
    "print(\"Best Subset Selection Example:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Suppose for some dataset:\")\n",
    "print(\"  Best k=2 model: {X₁, X₃} (lowest RSS among all 2-variable models)\")\n",
    "print(\"  Best k=3 model: {X₂, X₄, X₅} (lowest RSS among all 3-variable models)\")\n",
    "print(\"\\n{X₁, X₃} ⊄ {X₂, X₄, X₅}\")\n",
    "print(\"\\nBest subset independently optimizes for each k ✗\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d98f85",
   "metadata": {},
   "source": [
    "##### Summary Table\n",
    "\n",
    "| Statement | Answer | Reason |\n",
    "|-----------|--------|--------|\n",
    "| (c)(i) Forward k ⊆ Forward (k+1) | **TRUE** | Forward adds predictors sequentially |\n",
    "| (c)(ii) Backward k ⊆ Backward (k+1) | **TRUE** | Backward removes predictors sequentially |\n",
    "| (c)(iii) Backward k ⊆ Forward (k+1) | **FALSE** | Independent algorithms |\n",
    "| (c)(iv) Forward k ⊆ Backward (k+1) | **FALSE** | Independent algorithms |\n",
    "| (c)(v) Best k ⊆ Best (k+1) | **FALSE** | Independent optimization for each k |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4f1358",
   "metadata": {},
   "source": [
    "2. For parts (a) through (c), indicate which of i. through iv. is correct. Justify your answer.  \n",
    "   (a) The lasso, relative to least squares, is:  \n",
    "   i. More flexible and hence will give improved prediction accuracy when its increase in bias is less than its decrease in variance.  \n",
    "   ii. More flexible and hence will give improved prediction accuracy when its increase in variance is less than its decrease in bias.  \n",
    "   iii. Less flexible and hence will give improved prediction accuracy when its increase in bias is less than its decrease in variance.  \n",
    "   iv. Less flexible and hence will give improved prediction accuracy when its increase in variance is less than its decrease in bias.  \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d384c180",
   "metadata": {},
   "source": [
    "(a) The Lasso relative to Least Squares is\n",
    "\n",
    "**Answer: iii. Less flexible and hence will give improved prediction accuracy when its increase in bias is less than its decrease in variance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2e1d74df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO vs Least Squares\n",
      "============================================================\n",
      "\n",
      "Least Squares minimizes: RSS = Σ(yᵢ - ŷᵢ)²\n",
      "LASSO minimizes: RSS + λΣ|βⱼ|\n",
      "\n",
      "Key differences:\n",
      "  - LASSO adds L1 penalty constraint\n",
      "  - Constraint reduces the space of possible coefficient values\n",
      "  - Some coefficients shrink to exactly zero\n",
      "  - Results in LESS FLEXIBLE model\n",
      "\n",
      "Bias-Variance Tradeoff:\n",
      "  - Flexibility ↓  →  Bias ↑ (more restricted coefficient space)\n",
      "  - Flexibility ↓  →  Variance ↓ (less sensitive to training data)\n",
      "\n",
      "Improved prediction when: Decrease in Variance > Increase in Bias\n",
      "Equivalently: Increase in Bias < Decrease in Variance ✓\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"LASSO vs Least Squares\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nLeast Squares minimizes: RSS = Σ(yᵢ - ŷᵢ)²\")\n",
    "print(\"LASSO minimizes: RSS + λΣ|βⱼ|\")\n",
    "print(\"\\nKey differences:\")\n",
    "print(\"  - LASSO adds L1 penalty constraint\")\n",
    "print(\"  - Constraint reduces the space of possible coefficient values\")\n",
    "print(\"  - Some coefficients shrink to exactly zero\")\n",
    "print(\"  - Results in LESS FLEXIBLE model\")\n",
    "print(\"\\nBias-Variance Tradeoff:\")\n",
    "print(\"  - Flexibility ↓  →  Bias ↑ (more restricted coefficient space)\")\n",
    "print(\"  - Flexibility ↓  →  Variance ↓ (less sensitive to training data)\")\n",
    "print(\"\\nImproved prediction when: Decrease in Variance > Increase in Bias\")\n",
    "print(\"Equivalently: Increase in Bias < Decrease in Variance ✓\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d2c850dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Plot saved as 'lasso_flexibility.png']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Conceptual illustration of flexibility\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Coefficient space visualization\n",
    "ax = axes[0]\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "\n",
    "# Least squares (unconstrained)\n",
    "circle_r = 2\n",
    "x_circle = circle_r * np.cos(theta)\n",
    "y_circle = circle_r * np.sin(theta)\n",
    "ax.fill(x_circle, y_circle, alpha=0.3, color='blue', label='Least Squares (unconstrained)')\n",
    "\n",
    "# LASSO (L1 constraint creates diamond)\n",
    "lasso_constraint = 1\n",
    "diamond_x = np.array([lasso_constraint, 0, -lasso_constraint, 0, lasso_constraint])\n",
    "diamond_y = np.array([0, lasso_constraint, 0, -lasso_constraint, 0])\n",
    "ax.fill(diamond_x, diamond_y, alpha=0.3, color='red', label='LASSO (L1 constrained)')\n",
    "\n",
    "ax.set_xlabel('β₁')\n",
    "ax.set_ylabel('β₂')\n",
    "ax.set_title('Coefficient Space: LASSO is LESS Flexible')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axis('equal')\n",
    "\n",
    "# Bias-Variance tradeoff\n",
    "ax = axes[1]\n",
    "flexibility = np.linspace(0, 10, 100)\n",
    "bias_squared = 5 / (flexibility + 1)  # Decreases with flexibility\n",
    "variance = 0.3 * flexibility  # Increases with flexibility\n",
    "test_error = bias_squared + variance\n",
    "\n",
    "ls_flex = 8  # Least squares is more flexible\n",
    "lasso_flex = 4  # LASSO is less flexible\n",
    "\n",
    "ax.plot(flexibility, bias_squared, 'b-', label='Bias²', linewidth=2)\n",
    "ax.plot(flexibility, variance, 'r-', label='Variance', linewidth=2)\n",
    "ax.plot(flexibility, test_error, 'k-', label='Test Error', linewidth=2)\n",
    "\n",
    "ax.axvline(lasso_flex, color='red', linestyle='--', alpha=0.5, label='LASSO')\n",
    "ax.axvline(ls_flex, color='blue', linestyle='--', alpha=0.5, label='Least Squares')\n",
    "\n",
    "ax.set_xlabel('Model Flexibility')\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_title('Bias-Variance Tradeoff')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('lasso_flexibility.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n[Plot saved as 'lasso_flexibility.png']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c24e35",
   "metadata": {},
   "source": [
    "(b) Ridge Regression relative to Least Squares is\n",
    "\n",
    "**Answer: iii. Less flexible and hence will give improved prediction accuracy when its increase in bias is less than its decrease in variance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "db6ebdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RIDGE REGRESSION vs Least Squares\n",
      "============================================================\n",
      "\n",
      "Least Squares minimizes: RSS = Σ(yᵢ - ŷᵢ)²\n",
      "Ridge minimizes: RSS + λΣβⱼ²\n",
      "\n",
      "Key differences:\n",
      "  - Ridge adds L2 penalty constraint\n",
      "  - Constraint reduces the space of possible coefficient values\n",
      "  - Coefficients shrink toward zero (but not exactly to zero)\n",
      "  - Results in LESS FLEXIBLE model\n",
      "\n",
      "Bias-Variance Tradeoff:\n",
      "  - Flexibility ↓  →  Bias ↑ (coefficients shrunk)\n",
      "  - Flexibility ↓  →  Variance ↓ (less sensitive to training data)\n",
      "\n",
      "Improved prediction when: Decrease in Variance > Increase in Bias\n",
      "Equivalently: Increase in Bias < Decrease in Variance ✓\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RIDGE REGRESSION vs Least Squares\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nLeast Squares minimizes: RSS = Σ(yᵢ - ŷᵢ)²\")\n",
    "print(\"Ridge minimizes: RSS + λΣβⱼ²\")\n",
    "print(\"\\nKey differences:\")\n",
    "print(\"  - Ridge adds L2 penalty constraint\")\n",
    "print(\"  - Constraint reduces the space of possible coefficient values\")\n",
    "print(\"  - Coefficients shrink toward zero (but not exactly to zero)\")\n",
    "print(\"  - Results in LESS FLEXIBLE model\")\n",
    "print(\"\\nBias-Variance Tradeoff:\")\n",
    "print(\"  - Flexibility ↓  →  Bias ↑ (coefficients shrunk)\")\n",
    "print(\"  - Flexibility ↓  →  Variance ↓ (less sensitive to training data)\")\n",
    "print(\"\\nImproved prediction when: Decrease in Variance > Increase in Bias\")\n",
    "print(\"Equivalently: Increase in Bias < Decrease in Variance ✓\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89df722c",
   "metadata": {},
   "source": [
    "##### Comparison of LASSO and Ridge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ad0dc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numerical Example:\n",
      "------------------------------------------------------------\n",
      "\n",
      "Least Squares:\n",
      "  Flexibility: 10\n",
      "  Bias²:       0.5\n",
      "  Variance:    8.0\n",
      "  Test Error:  8.5\n",
      "\n",
      "Ridge (λ=1):\n",
      "  Flexibility: 6\n",
      "  Bias²:       1.2\n",
      "  Variance:    4.0\n",
      "  Test Error:  5.2\n",
      "\n",
      "LASSO (λ=1):\n",
      "  Flexibility: 5\n",
      "  Bias²:       1.5\n",
      "  Variance:    3.5\n",
      "  Test Error:  5.0\n",
      "\n",
      "Both Ridge and LASSO trade increased bias for decreased variance\n",
      "Both are LESS flexible than least squares\n"
     ]
    }
   ],
   "source": [
    "# Numerical example\n",
    "print(\"\\nNumerical Example:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Simulated scenario\n",
    "scenarios = {\n",
    "    'Least Squares': {'flexibility': 10, 'bias²': 0.5, 'variance': 8.0},\n",
    "    'Ridge (λ=1)': {'flexibility': 6, 'bias²': 1.2, 'variance': 4.0},\n",
    "    'LASSO (λ=1)': {'flexibility': 5, 'bias²': 1.5, 'variance': 3.5}\n",
    "}\n",
    "\n",
    "for method, values in scenarios.items():\n",
    "    test_error = values['bias²'] + values['variance']\n",
    "    print(f\"\\n{method}:\")\n",
    "    print(f\"  Flexibility: {values['flexibility']}\")\n",
    "    print(f\"  Bias²:       {values['bias²']:.1f}\")\n",
    "    print(f\"  Variance:    {values['variance']:.1f}\")\n",
    "    print(f\"  Test Error:  {test_error:.1f}\")\n",
    "\n",
    "print(\"\\nBoth Ridge and LASSO trade increased bias for decreased variance\")\n",
    "print(\"Both are LESS flexible than least squares\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92879c3c",
   "metadata": {},
   "source": [
    "(c) Non-linear Methods relative to Least Squares is\n",
    "\n",
    "**Answer: ii. More flexible and hence will give improved prediction accuracy when its increase in variance is less than its decrease in bias.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e201db0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "NON-LINEAR METHODS vs Least Squares\n",
      "============================================================\n",
      "\n",
      "Least Squares assumes: f(X) = β₀ + β₁X₁ + ... + βₚXₚ (linear)\n",
      "Non-linear methods allow: f(X) = arbitrary non-linear function\n",
      "\n",
      "Examples of non-linear methods:\n",
      "  - Polynomial regression: β₀ + β₁X + β₂X² + β₃X³ + ...\n",
      "  - Splines: piecewise polynomials\n",
      "  - GAMs: Σ fⱼ(Xⱼ) where fⱼ are smooth non-linear functions\n",
      "  - Decision trees, random forests, neural networks\n",
      "\n",
      "Key differences:\n",
      "  - Can capture non-linear relationships\n",
      "  - Can fit more complex patterns\n",
      "  - Results in MORE FLEXIBLE model\n",
      "\n",
      "Bias-Variance Tradeoff:\n",
      "  - Flexibility ↑  →  Bias ↓ (can fit complex true functions)\n",
      "  - Flexibility ↑  →  Variance ↑ (more sensitive to training data)\n",
      "\n",
      "Improved prediction when: Decrease in Bias > Increase in Variance\n",
      "Equivalently: Increase in Variance < Decrease in Bias ✓\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"NON-LINEAR METHODS vs Least Squares\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nLeast Squares assumes: f(X) = β₀ + β₁X₁ + ... + βₚXₚ (linear)\")\n",
    "print(\"Non-linear methods allow: f(X) = arbitrary non-linear function\")\n",
    "print(\"\\nExamples of non-linear methods:\")\n",
    "print(\"  - Polynomial regression: β₀ + β₁X + β₂X² + β₃X³ + ...\")\n",
    "print(\"  - Splines: piecewise polynomials\")\n",
    "print(\"  - GAMs: Σ fⱼ(Xⱼ) where fⱼ are smooth non-linear functions\")\n",
    "print(\"  - Decision trees, random forests, neural networks\")\n",
    "print(\"\\nKey differences:\")\n",
    "print(\"  - Can capture non-linear relationships\")\n",
    "print(\"  - Can fit more complex patterns\")\n",
    "print(\"  - Results in MORE FLEXIBLE model\")\n",
    "print(\"\\nBias-Variance Tradeoff:\")\n",
    "print(\"  - Flexibility ↑  →  Bias ↓ (can fit complex true functions)\")\n",
    "print(\"  - Flexibility ↑  →  Variance ↑ (more sensitive to training data)\")\n",
    "print(\"\\nImproved prediction when: Decrease in Bias > Increase in Variance\")\n",
    "print(\"Equivalently: Increase in Variance < Decrease in Bias ✓\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f44229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Plot saved as 'nonlinear_flexibility.png']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate example data with non-linear relationship\n",
    "np.random.seed(42)\n",
    "X = np.linspace(0, 10, 100)\n",
    "true_function = lambda x: 2 * np.sin(x) + 0.5 * x\n",
    "y_true = true_function(X)\n",
    "y_observed = y_true + np.random.normal(0, 0.5, len(X))\n",
    "\n",
    "# Fit different models\n",
    "from numpy.polynomial import Polynomial\n",
    "\n",
    "# Linear (least squares)\n",
    "linear_coef = np.polyfit(X, y_observed, 1)\n",
    "y_linear = np.polyval(linear_coef, X)\n",
    "\n",
    "# Polynomial degree 5 (non-linear)\n",
    "poly_coef = np.polyfit(X, y_observed, 5)\n",
    "y_poly = np.polyval(poly_coef, X)\n",
    "\n",
    "# Polynomial degree 15 (overly flexible)\n",
    "poly15_coef = np.polyfit(X, y_observed, 15)\n",
    "y_poly15 = np.polyval(poly15_coef, X)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.scatter(X, y_observed, alpha=0.5, s=20, label='Observed data')\n",
    "ax.plot(X, y_true, 'g-', linewidth=2, label='True function')\n",
    "ax.plot(X, y_linear, 'b--', linewidth=2, label='Linear (Least Squares)')\n",
    "ax.plot(X, y_poly, 'r-', linewidth=2, label='Non-linear (degree 5)')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_title('Non-linear Methods are MORE Flexible')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Bias-variance illustration\n",
    "ax = axes[1]\n",
    "flexibility = np.linspace(0, 10, 100)\n",
    "# For non-linear vs linear comparison\n",
    "bias_squared = 3 / (flexibility + 0.5)  # Decreases with flexibility\n",
    "variance = 0.2 * flexibility**1.3  # Increases with flexibility\n",
    "test_error = bias_squared + variance\n",
    "\n",
    "linear_flex = 2  # Linear is less flexible\n",
    "nonlinear_flex = 5.5  # Non-linear is more flexible\n",
    "\n",
    "ax.plot(flexibility, bias_squared, 'b-', label='Bias²', linewidth=2)\n",
    "ax.plot(flexibility, variance, 'r-', label='Variance', linewidth=2)\n",
    "ax.plot(flexibility, test_error, 'k-', label='Test Error', linewidth=2)\n",
    "\n",
    "ax.axvline(linear_flex, color='blue', linestyle='--', alpha=0.5, label='Linear (LS)')\n",
    "ax.axvline(nonlinear_flex, color='red', linestyle='--', alpha=0.5, label='Non-linear')\n",
    "\n",
    "ax.set_xlabel('Model Flexibility')\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_title('Non-linear: Higher Flexibility, Lower Bias, Higher Variance')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('nonlinear_flexibility.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n[Plot saved as 'nonlinear_flexibility.png']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0cef66",
   "metadata": {},
   "source": [
    "Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "114f9f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Method               Flexibility vs LS Bias Change  Variance Change  Answer\n",
      "-------------------- ----------------- ------------ ---------------- ------\n",
      "LASSO                LESS ↓            ↑            ↓                iii   \n",
      "Ridge                LESS ↓            ↑            ↓                iii   \n",
      "Non-linear           MORE ↑            ↓            ↑                ii    \n",
      "\n",
      "============================================================\n",
      "KEY INSIGHT:\n",
      "============================================================\n",
      "Regularization (LASSO, Ridge): Less flexible\n",
      "  → Improves when: Increase in Bias < Decrease in Variance\n",
      "\n",
      "Non-linear methods: More flexible\n",
      "  → Improves when: Increase in Variance < Decrease in Bias\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "summary = [\n",
    "    [\"Method\", \"Flexibility vs LS\", \"Bias Change\", \"Variance Change\", \"Answer\"],\n",
    "    [\"-\" * 20, \"-\" * 17, \"-\" * 12, \"-\" * 16, \"-\" * 6],\n",
    "    [\"LASSO\", \"LESS ↓\", \"↑\", \"↓\", \"iii\"],\n",
    "    [\"Ridge\", \"LESS ↓\", \"↑\", \"↓\", \"iii\"],\n",
    "    [\"Non-linear\", \"MORE ↑\", \"↓\", \"↑\", \"ii\"]\n",
    "]\n",
    "\n",
    "for row in summary:\n",
    "    print(f\"{row[0]:<20} {row[1]:<17} {row[2]:<12} {row[3]:<16} {row[4]:<6}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY INSIGHT:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Regularization (LASSO, Ridge): Less flexible\")\n",
    "print(\"  → Improves when: Increase in Bias < Decrease in Variance\")\n",
    "print(\"\\nNon-linear methods: More flexible\")\n",
    "print(\"  → Improves when: Increase in Variance < Decrease in Bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c676c0",
   "metadata": {},
   "source": [
    "3. Suppose we estimate the regression coefficients in a linear regression model by minimizing\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} \\left( y_i - (\\beta_0 + \\sum_{j=1}^{p} \\beta_j x_{ij}) \\right)^2\n",
    "$$\n",
    "\n",
    "subject to\n",
    "\n",
    "$$\n",
    "\\sum_{j=1}^{p} |\\beta_j| \\leq s\n",
    "$$\n",
    "\n",
    "for a particular value of $s$. For parts (a) through (e), indicate which of i. through v. is correct. Justify your answer.\n",
    "\n",
    "(a) As we increase $s$ from 0, the training RSS will:\n",
    "   i. Increase initially, and then eventually start decreasing in an inverted U shape.  \n",
    "   \n",
    "\n",
    "   ii. Decrease initially, and then eventually start increasing in a U shape.  \n",
    "   \n",
    "   iii. Steadily increase.\n",
    "   \n",
    "   iv. Steadily decrease.  \n",
    "   \n",
    "   v. Remain constant.  \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2dd42d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO: Effect of Constraint Parameter s\n",
      "======================================================================\n",
      "\n",
      "Key relationships:\n",
      "  s = 0     → All βⱼ = 0 (null model, maximum constraint)\n",
      "  s small   → Highly constrained (high bias, low variance)\n",
      "  s → ∞     → Unconstrained (least squares, low bias, high variance)\n",
      "\n",
      "As s increases: constraint relaxes, model becomes MORE FLEXIBLE\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"LASSO: Effect of Constraint Parameter s\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nKey relationships:\")\n",
    "print(\"  s = 0     → All βⱼ = 0 (null model, maximum constraint)\")\n",
    "print(\"  s small   → Highly constrained (high bias, low variance)\")\n",
    "print(\"  s → ∞     → Unconstrained (least squares, low bias, high variance)\")\n",
    "print(\"\\nAs s increases: constraint relaxes, model becomes MORE FLEXIBLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbee34b",
   "metadata": {},
   "source": [
    "(a) Training RSS as s increases\n",
    "\n",
    "**Answer: iv. Steadily decrease**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a3b3f1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "(a) TRAINING RSS\n",
      "======================================================================\n",
      "\n",
      "Logical reasoning:\n",
      "  1. At s = 0: All βⱼ = 0 → Training RSS is maximized\n",
      "     (predicting ȳ for all observations)\n",
      "\n",
      "  2. As s increases: Constraint relaxes\n",
      "     - Optimizer can use larger |βⱼ| values\n",
      "     - Can fit training data better\n",
      "     - Training RSS decreases\n",
      "\n",
      "  3. As s → ∞: Approaches least squares solution\n",
      "     - Least squares minimizes training RSS\n",
      "     - Training RSS reaches minimum\n",
      "\n",
      "Conclusion: Training RSS STEADILY DECREASES ✓\n",
      "\n",
      "Why not U-shaped?\n",
      "  - More flexibility ALWAYS allows better training fit\n",
      "  - Optimizer never forced to fit worse as s increases\n",
      "  - Training RSS is monotonically non-increasing in s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(a) TRAINING RSS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nLogical reasoning:\")\n",
    "print(\"  1. At s = 0: All βⱼ = 0 → Training RSS is maximized\")\n",
    "print(\"     (predicting ȳ for all observations)\")\n",
    "print(\"\\n  2. As s increases: Constraint relaxes\")\n",
    "print(\"     - Optimizer can use larger |βⱼ| values\")\n",
    "print(\"     - Can fit training data better\")\n",
    "print(\"     - Training RSS decreases\")\n",
    "print(\"\\n  3. As s → ∞: Approaches least squares solution\")\n",
    "print(\"     - Least squares minimizes training RSS\")\n",
    "print(\"     - Training RSS reaches minimum\")\n",
    "print(\"\\nConclusion: Training RSS STEADILY DECREASES ✓\")\n",
    "print(\"\\nWhy not U-shaped?\")\n",
    "print(\"  - More flexibility ALWAYS allows better training fit\")\n",
    "print(\"  - Optimizer never forced to fit worse as s increases\")\n",
    "print(\"  - Training RSS is monotonically non-increasing in s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c73055",
   "metadata": {},
   "source": [
    "\n",
    "Simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bcb66f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Creating visualization...]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ0AAAHWCAYAAADdF/hPAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAvGdJREFUeJzs3Xd0FFUbx/HvpBMgoaVCKEoR6YLSVFAgASkCKijSiyCvIkVFRJCiIBZAQRDpIkVFQFFEQKlSRaKiIBaKlBBESGgpZPf9Y8ySJR022U3y+5yzx5k7d+48c7Mxuw/33jGsVqsVERERERERERERB3JzdgAiIiIiIiIiIpL/KOkkIiIiIiIiIiIOp6STiIiIiIiIiIg4nJJOIiIiIiIiIiLicEo6iYiIiIiIiIiIwynpJCIiIiIiIiIiDqekk4iIiIiIiIiIOJySTiIiIiIiIiIi4nBKOomIiIiIiIiIiMMp6VQAjB07FsMwCAoK4vLlyzfURuvWrTEMg2bNmmWpfvny5TEMI0uvBQsW3FBMaRkzZsxNt3vkyBFbG02bNnVYbDcqrT7z9fWlWrVqvPDCC8TExKQ65+LFi4wePZpq1apRqFAhChUqRGhoKHfddRd9+vThwIEDdvVXrFhBs2bNKFGiBJ6enpQsWZLbbruNjh07snDhwty6VadLTEzkrbfe4o477qBIkSJ4e3sTHBxMnTp16N69O9u3bwdgwYIFWX5/ly9fHrB/b6b1KlasWJoxbd261a7eLbfcgtVqTVVv06ZNdvXc3d3x9fWlTJkyNGnShFdeeYWoqKhU56W8l5Tv95TtJd9Dsueee8527Pbbbyc+Pj5VLG5ubhiGgZeXFz/++GO6fX59X3p4eFCkSBHKlStHixYtmDp1KufPn0913o30p9VqZcWKFXTo0IEyZcrg7e1NyZIlqVWrFsOGDePXX3+11U3r/2E+Pj5UrFiRgQMHcvLkSbu2U/5/I73XqlWr0uyDSpUq2dXbvHlzuv2Vnd/Vpk2bZhhP+/bt7epHR0fzzDPPUKlSJXx8fChcuDBlypShcePGPPnkk5w6dSrduERERERE0mSVfO3YsWPWQoUKWQHrm2++ecPt7N692wpYAevy5cszrV+uXDlb/cxe8+fPv+G4rvfyyy/fdLuHDx+2tdGkSROHxXajMuu/+vXrW5OSkmz1ExMTrXfeeWeG53zyySe2+lOnTs2wbuvWrZ1x207Rvn37DPvijTfesFqtVuv8+fOz/P4uV66c1Wq1f2+m9fL3908zpt69e6equ2nTplT1Nm7cmGks/v7+1lWrVtmdl/JeUr7fU7aXfA/Jrly5Yq1SpYrt+EsvvWQ7dvnyZWvFihVtx8aMGZNhn2elL0NDQ63fffed3XnZ7c/z589bmzVrluE5zzzzjK1+Zv8PK1++vPXixYu2+in/v5Hea+XKlanuf8uWLanq9ezZM82+yu7vapMmTTKs/+CDD9rqnjt3zlq+fPkM6+/ZsyfDn6WIiIiIyPU00imfmzx5MleuXMHb25vevXvfcDt33nkndevWBeDVV1/NtP6RI0ewWq22V7ly5WzHNm7caHesZ8+eabZxI6OyxowZk2m7mSlfvrytjU2bNt1QGznl8OHDJCQksHr1atzczF/fXbt2sXPnTludzz77jD179gDQsmVLDh8+THx8PEeOHOHLL7+kd+/e+Pn5AZCUlMSYMWMA8PPzY+PGjVy+fJmzZ8+ye/duxo0bR9WqVXP3Jp1k7969tpEoderU4eDBg8THx3P8+HE2bNjAU089RWBgIAA9e/a0ew/Pnz/f1k6TJk3sjh05ciTVtXr06GFXx2q1pjma5/Lly3zyySeAOeItWWaj+MqVK4fVauXy5cvs3r2bRx55BICYmBgeeeQR24itG+Xj48OCBQts78FJkybx008/AfDyyy/zxx9/AFC7dm1efPHFLLeb3HcXLlxg06ZN3H///QCcPHmSBx54wNbu9bLSn506deKbb74BIDg4mGXLlnH+/HmuXLnC3r17GTp0KIUKFUqz/Y0bN3L16lW2b99O0aJFAfP/cZ999lm693J9PFarNdXIIrD/WSb/jJcvX86lS5fs6t3s7+r8+fNTxZNy5NXcuXNt79WePXty8uRJ4uLi+OOPP1i+fDmdO3fGx8cn3fZFRERERNKipFM+FhcXZ/sy3Lp1a4oXL253fPDgwdx1110EBQXh7e2Nr68vVapUYfDgwfzzzz+p2nv88ccB2Ldvn12S42alnMKzY8cOmjRpQuHChXnggQcAWLlyJa1ataJcuXIULVoUT09PgoODadeuHVu2bLFrK73pdSmnyhw6dIgOHTrg7+9PQEAAnTt3Jjo62lY3vel1Kdt+//33GT16NOXKlcPX15e6deuyfv36VPc2d+5cbrvtNry9valatSpz5sy56SmAnp6etGnThlq1atnKjh49ats+dOiQbfvuu++mfPnyeHl5Ua5cOR544AHmzp1LeHg4YE6nSf5yHhISwr333kuhQoUoUaIEd955J6NGjeKNN97IMJ5//vkHb29vDMOgSpUqdseuXLmCv78/hmEQEhLC1atXAXjjjTeoVasWhQsXxsvLi+DgYO6++25Gjx6d6f2fOHGCHj16EBYWhpeXF0WKFOGWW26hffv2rFu3zlYv5fSwrEyTTNlvdevWpUqVKnh5eVG6dGmaNWvGtGnT6N69e6btONKnn37KhQsXAHjsscfw9/cH0k5KpKVQoULceeedfPzxx7bEU2JiIsOHD7/p2Bo0aMDQoUNtbfbp04fdu3czefJkwHyfLliwAE9Pz2y3XaRIEZo0acK6deto2LAhYCbMxo4de0Oxrl+/3vbeMAyDlStX0rlzZ/z9/fHx8eGOO+7grbfeYvz48em24e7uTsOGDWnevLmtLOXv3Y1ImVQsXLgwXbt2BczpscuXL7er64jf1YykfP83b96ckJAQvL29ufXWW3nooYdYtmwZ1atXv+H2RURERKRgUtIpH9u2bZttvZ+0vnQvWLCAPXv2EB0dTUJCAleuXOHQoUO8/fbbNG3alMTERLv6Kdv48ssvHR7vmTNnaNasGVu2bLEb5bR582bWrl3LsWPHuHjxIlevXuX06dOsXr2a+++/n61bt2brOg0aNGDVqlXExsbyzz//8PHHH9OtW7dstfHCCy8wfvx4jh07xpUrV/jhhx9o06aN3aiWt99+m759+/Lbb7+RkJDAwYMH6devH/PmzcvWtdJjTbGuT/IIHICyZcvatkePHk3z5s0ZO3Ysa9eutSUwUp6XPHrht99+o0qVKjz11FMsWrSIv/76K0txlCpVig4dOgDmF9ddu3bZjn322WfExsYC0KtXLzw8PHj77bd5/vnn+emnn7h8+TKJiYmcPn2a7777Lkt906ZNGz744AOOHz9OYmIily5d4vDhw3z22WepkpDZkbLf5syZQ6NGjXjxxRf57LPPOHv27A23ezNSJiW7d+9Ou3btgLSTEpl57rnnbNvfffcdZ86cuen4xo8fb0s0fv/99zRv3pykpCQARo4caZcYvRHu7u4MGTLEtv/5559jsViy3U7KEUn33XcfDRo0SLOeh4dHpm2l93t3I1ImFdu2bWs3OvP6hLQjflczkvL937t3b9q2bctrr73Gxo0buXLlyk23LyIiIiIFk5JO+VjK0UhpffmbOXMmBw8e5Pz58yQmJnL8+HFatmwJwC+//MLatWvt6tesWRN3d/dUbTvK5cuXadCgAYcOHeLSpUvMmDEDgIcffpjvvvuO06dPk5CQQExMDDNnzgTMKSdTp07N1nVq1arF33//zcGDB21fGtetW5fmIsvpuXr1KuvWreP8+fN06dIFgISEBJYtWwbAhQsXeOmll2z1Z8yYQWxsLJ999hmnT5/OVrzXS0xM5IsvvrBNZypbtiz33nuv7XiHDh2oVKkSABaLhW+++YYxY8bQqlUrAgIC6NWrl23EhLu7u220CsAff/zBu+++S/fu3bn11lupV68e27ZtyzSmJ554wra9aNGiVNuGYdC3b18A2xSnIkWKcOjQIRISEvj7779Zs2YN/fr1y/A6//77L5GRkQA89NBDxMTEcPHiRQ4ePMj7779PvXr1Mo01PQ0bNuTuu++27e/YsYOJEyfSvn17goKCaN++PcePH7/h9lNauHBhqkWdr58OeuzYMdv0zpIlS9KsWTM6depkO57dUXIpR6mkN+0vu66fZpecQMnutLqMpIw7NjY2zQRgZv15+PBh23a1atVuKI6kpCR27tzJhg0bAChatCgPPvhguvXTWrj7eil/hp07d6ZJkyYEBQUBZrI95c/oZn9Xe/XqleFDHPr06UPJkiUB8/9lX3zxBSNGjOD+++8nMDCQYcOGpVowXkREREQkM0o65WMpnzQUEBCQ6nihQoV46qmnqFixIj4+PpQpU8Yu0ZTySU5gfukpUaJEqrYdaeHChVSqVAlfX19uv/12AMqUKcO8efNo2LAhRYsWxd/fnyeffDLdODPz9ttvU6ZMGapUqcI999xjK8/Ol/C+ffvSokUL/P39eeyxx1K1sX37di5evAiY6wM9+eSTFC1alHbt2tlGBd2IChUq4OXlRdu2bbFYLDRs2JB169bZTWHy9fVl165dDBo0iJCQELvz4+PjWbBggS0BBOYaXQsWLKBevXqpvhjv3buX1q1bc+LEiQzjuu+++2yJrmXLlpGYmEh0dLRtSlPz5s255ZZbALj11lsBuHTpEmPGjGHatGn8+OOP1K1bl5dffjnD6xQrVsz2Hvzuu+8YN24cy5Yt4+zZs3Tv3t1uzZymTZtma20uNzc31q1bx6hRo2yxJktKSuKzzz6jY8eONzTS5kYsXLjQdq2HHnoIDw8PwsPDbU9luz4pkV1pJUFuRMppdmCOFrrRaXVZcSNxpxyddCPn33fffXh4eNCwYUMuXrxItWrV+PrrrylVqlS220qWMqno5+dHy5YtcXd356GHHrLFfP3T6Bzxu5qe4OBgIiMj6dmzp+13LNnFixeZPHkyI0eOvKG2RURERKTgUtKpgFq+fDkdOnRgw4YN/PPPP7YpMSnl9pSKgIAAwsLC7MouXLhAo0aNmDt3Ln/99Vea/9Ke3ThTLrZbuHBh23ZcXJzD2ki5JlbKRdSBVI+fvxnJ0w2vV7x4cd5++21OnDjB/v37ee+992xr4wCsWrXKri979OjBnj17iIqKYtWqVfTt29eWNIiNjeWrr77KMI6UI5nOnj3LmjVrWLJkiS22/v372+q+/PLLtG7dGsMwWLJkCcOGDaNNmzaEhITQpUuXNN+Lydzc3Fi2bBm33HILUVFRvPXWW/Tt25fGjRvbFoe+GYUKFWLcuHH8+eef/PHHHyxYsMA2+g9gz549DpnKlNbC19ePXPrggw9s2zVq1CAyMpJff/3VNjUsraRERpJHxgG2NdQcpXXr1rbt0qVL3/S0upRSxu3v758qIQKZ92dyohPMUZw369KlS6mmH18vrYXEU0qZVKxfvz4HDx4kMjLSbmTXwoULU513o7+raS0kfv3oujJlyjB//nyio6PZu3cvU6ZMsRsZdrO/XyIiIiJS8CjplI+lHOVy/fotixcvtm0/99xzxMbGYrVa7UYsXC8pKYl///0XMP9V3NF8fX1TlX377be2UVXVqlXjr7/+wmKx2H0Rza6UIzBudLRHZm2kHFn2999/2x1LOdUnuw4fPsy///7LwIEDAfj5559p3bq1bVQVYFtDKTm2atWq0b9/fzZv3mx7OldSUpJtil3K+oGBgTz44IPMnj2bHj162MqzsqZRz549bf2yaNEi29S6oKAg21pEYI5W+uKLLzh79ixbtmxh4cKFREREYLFYWLp0qW1h5fS0aNHClhT68ssvmTx5MsHBwZw/f56+fftmmLTKyKVLl+zOvfXWW+nRowdfffUVFStWtJXnxvpOW7dutXtS29NPP02dOnWoU6eO3WjEtJIS6Xn99ddt23ffffdNjdLJLVevXrUtTA7Qrl0721S+7Eg5De7bb79l9+7d6V4vLRs3buTChQu88sorgDmisV27djc8qgjsk4rr16+3/XyTf7fB/H1PuU6Zo35X05K8/h+Yo1rvuOMOBg8ezNdff33TbYuIiIhIwaWkUz5Wv35923byOjjJUi6Y6+vri6enJ1u3bs1w5MRPP/1k+1Ke3kK8jpYyTg8PDwoXLkxUVJTD1ovJKQ0bNqRIkSKAOe1l/vz5XLx4kc8//5yVK1feVNvFixfnnXfe4Y477gDMJ2hNnDjRdvzjjz+mVq1aTJ06lf379xMXF8fFixdZvHixbVRYQEAAgYGBXL16lbJlyzJo0CC+/fZbzp07R2JiIj/99JPdl92srIOT/CUYzIWbf/jhB8BcSyZlkm727NnMnj2bqKgoateuzcMPP0yjRo1sx48dO5bhdf73v/+xdu1avLy8aN68OZ07dyY0NBQwE0fJX4yz+/S6HTt2ULlyZV599VX27t3LpUuXuHLlCl988YVtLScPD49UT+jLCVldr+n6pMT14uLi2LNnDw8//DArVqwAzITppEmTshXPlStXWLt2barXzSRdMnLp0iU2b95MeHi4LUHk7++f6fTL9DRv3pyIiAjAHIHUoUMHPvnkE2JjY4mLi2Pfvn0MHTrUbh226xUpUoSRI0fa3uMxMTE8//zzNxTP9UnFjCS/Fxz5u5qWN998k7vvvpvZs2fz+++/k5CQwLlz5+zeizfatoiIiIgUYFbJty5fvmz18/OzAtaOHTvaHVu2bJkVSPWqXLmybfvll1+2O2fy5Mm2Y9u3b89WLOXKlbOdu3HjRrtjyeXlypVLdd65c+eswcHBGcaZ8ryXX37ZVj5//vw0r59Sjx49UsV1+PBhW1mTJk0ybXvjxo228h49etjKp06dmmYfly5d2ra9YMGCTPsu5bmHDx+2lW/atMlW7uPjYz127JjVarVaZ8+eneZ1U75mzJhhtVqt1sTExEzrNmzY0Hr16tVM47RardZ169bZnWsYhvXPP/+0q9OnT590r+Xh4WHdt29fhtdwd3dP9/y6deva6qX8uaT8OaZn/fr1mfbF888/n+a58+fPz/RaKd8/6b0OHz5svXTpkrVo0aK2sh9//DFVW8OHD7cd79mzZ6r7Te/l7+9vXbVqVZZiz0p7yb8HKeum9XuckZTXT+9VunRp63fffXdD/Zns/Pnz1mbNmmVY/5lnnrHVT+//WYcOHbJ6enra3t+7du2yWq32/99I75X8/9TevXvbyoYMGZKqTw4ePGg7XqRIEevFixdv6He1SZMmGdZP+bMaOXJkhnXd3Nysq1evztbPVkREREREI53ysUKFCtGrVy8A1qxZY5tOBeaTkt577z0qV66Mt7c3VapUYfbs2XaLYl8veUpe7dq17dYHyknFihXj66+/plmzZhQtWpSSJUvSp08fPvroo1y5/s145plnmD17NpUrV8bLy4vKlSszc+ZMu6k+NzPFqUmTJra24uLiGDFiBAAtW7bk9ddfp3Xr1tx66634+/vj7u5OQEAAERERrFq1yrYQu4eHBx988AG9e/emRo0aBAYG2kaU1apVizFjxrBu3TrbUwszk3LBcIBmzZqlWpS7Y8eOdOrUiVtvvZWiRYvi7u5OqVKlaNWqFRs2bKB27doZXmPEiBE0bdqUkJAQvLy88PLy4tZbb7WNgLpRd9xxB++88w4dO3akcuXKFC9eHHd3d4oXL869997L/Pnzee211264/axasWKF7SlwdevWpWbNmqnq9O7d27a9fPlyLl26lKqOYRj4+PgQGhrKPffcwyuvvMJvv/2W4RPXXIFhGPj6+lK2bFmaN2/O1KlT+eWXX+xGw90If39/1q1bxyeffMKDDz5IaGgoXl5eFC9enJo1azJkyBC7pzCmp1KlSrYpcFarlWHDhmUrjsuXL9tNIU35s0xWpUoV2/1evHiR5cuXO/x39XrdunVj3LhxNG/enAoVKlCkSBE8PDwICQmhffv2bNy4kTZt2txQ2yIiIiJScBlWaxYXBJE86dixY9x2221cuXKFyZMnM2TIkBtqZ8+ePdx1112A+SU3+QlLkr6TJ09y9OhR6tevb1uHZvv27bRu3Zrz589TuHBhjh8/bnsamYiIiIiIiEh+opFO+VzZsmUZPnw4AJMmTeLy5cs31M7YsWMB89HhSjhlzaFDh2jUqBG+vr6EhYVRvHhxGjduzPnz53Fzc2PatGlKOImIiIiIiEi+pZFOIjnk8OHDPP/88+zZs4fo6GiSkpIICQmhcePGPPPMM7aRYyIiIiIiIiL5kZJOIiIiIiIiIiLicJpeJyIiIlIAbNmyhbZt2xIaGophGKxatSrTczZv3kzdunXx8fHhlltu4b333sv5QEVERCTfUNJJREREpAC4dOkStWrVYvr06Vmqf/jwYR544AHuuece9u3bx4svvsigQYP49NNPczhSERERyS80vU5ERESkgDEMg5UrV9K+fft06wwfPpzPP/+cAwcO2MoGDBjAjz/+yI4dO3IhShEREcnrPJwdQF5isVg4efIkRYsWxTAMZ4cjIiIi6bBarVy4cIHQ0FDc3DSw+0bs2LGD8PBwu7KIiAjmzp1LYmIinp6eaZ4XHx9PfHy8bd9isfDvv/9SsmRJfX4SERFxYTnx+UlJp2w4efIkYWFhzg5DREREsujvv/+mTJkyzg4jT4qKiiIoKMiuLCgoiKtXr/LPP/8QEhKS5nkTJ05k7NixuRGiiIiI5ABHfn5S0ikbihYtCpg/AD8/P4e1a7FYOHPmDAEBAfrX2DSofzKm/smY+idj6p+MqX8y56p9FBsbS1hYmO1vt9yY60cmJa/KkNGIpREjRjB06FDbfkxMDGXLlnX45ycRERFxrJz4/KSkUzYkf8Dy8/NzeNIpLi4OPz8/l/rA7irUPxlT/2RM/ZMx9U/G1D+Zc/U+0nSuGxccHExUVJRdWXR0NB4eHpQsWTLd87y9vfH29k5V7ujPTyIiIpIzHPn5yfU+HYqIiIiI0zVs2JD169fbla1bt4569eqlu56TiIiISEpKOomIiIgUABcvXiQyMpLIyEgADh8+TGRkJMeOHQPMaXHdu3e31R8wYABHjx5l6NChHDhwgHnz5jF37lyeffZZZ4QvIiIieZCm14mIiIgUAN9//z333XefbT953aUePXqwYMECTp06ZUtAAVSoUIE1a9YwZMgQ3n33XUJDQ3nnnXd46KGHcj12ERERyZuUdBIRkZtmtVq5evUqSUlJzg7FoSwWC4mJicTFxbnkekWuwFl95O7ujoeHh9ZsyoamTZvaFgJPy4IFC1KVNWnShB9++CEHoxIREZH8TEknERG5KQkJCZw6dYrLly87OxSHs1qtWCwWLly4oORGOpzZR76+voSEhODl5ZWr1xURERGRrFHSSUREbpjFYuHw4cO4u7sTGhqKl5dXvkrOJI/g0oia9Dmjj6xWKwkJCZw5c4bDhw9TqVIljUQTERERcUFKOomIyA1LSEjAYrEQFhaGr6+vs8NxOCWdMuesPipUqBCenp4cPXqUhIQEfHx8cu3aIiIiIpI1+mdBERG5aRplIs6g952IiIiIa9OnNRERERERERERcTglnURERERERERExOGUdBIREcmCpk2bMnjw4CzXP3LkCIZhEBkZmWMx5YS5c+cSHh7u7DD4+eefKVOmDJcuXXJ2KCIiIiJyg5R0EhGRAqlnz54YhsGAAQNSHRs4cCCGYdCrVy9b2YoVKxg/fnyW2w8LC+PUqVNUr17dIfHmhvj4eEaPHs2oUaOcHQo1atTgrrvuYsqUKc4ORURERERukJJOLiAmBmbN8iUx0dmRiIgULGFhYSxbtowrV67YyuLi4li6dClly5a1q1uiRAmKFi2a5bbd3d0JDg7GwyPvPCj2008/pUiRItxzzz3ODgWAXr16MXPmTJKSkpwdioiIiIjcACWdnGzZMrjlFoMxY/xYtMjZ0YiIOFBCQvqvq1ezXvf6jHxadW7QHXfcQdmyZVmxYoWtbMWKFYSFhVGnTh27utdPrytfvjwTJkygd+/eFC1alLJly/L+++/bjl8/vW7Tpk0YhsHXX39NnTp1KFSoEPfffz/R0dF89dVXVK1aFT8/Px577DEuX75sd52pU6faxVK7dm3GjBlj2zcMg1mzZtGmTRt8fX2pWrUqO3bs4I8//qBp06YULlyYhg0b8ueff2bYH8uWLaNdu3Z2ZZs2beKuu+6icOHCFCtWjMaNG3P06NEM2wH47bffMq2TmYiICM6ePcvmzZtvui0RERERyX15559f86ny5eH8eQOAiRMNevaEPPSP4iIi6ZswIf1jlSrB449f23/jjdTJpWTly0PPntf2p06FFEkZAFIkYLKrV69ezJ8/n8f/i2fevHn07t2bTZs2ZXruW2+9xfjx43nxxRdZvnw5Tz75JPfeey+33XZbuueMGTOG6dOn4+vrS6dOnejUqRPe3t4sWbKEixcv0qFDB6ZNm8bw4cOzdR/jx49n8uTJTJ48meHDh9OlSxduueUWRowYQdmyZenduzdPPfUUX331VbptbN261dYPAFevXqV9+/b069ePpUuXkpCQwO7duzEMI8NYLly4QOPGjRk2bBgjRoywa2/QoEFs2LCBli1b8uabb7Jw4ULeeecdypcvz7vvvms3wszLy4tatWqxdetW7r///mz1h4iIiIg4n0Y6OVmDBtC8uRWAv/4yWLLEyQGJiBQw3bp1Y9u2bRw5coSjR4/y3Xff0bVr1yyd+8ADDzBw4EAqVqzI8OHDKVWqVKbJqldeeYXGjRtTp04d+vTpw+bNm5k5cyZ16tThnnvu4eGHH2bjxo3Zvo9evXrRqVMnKleuzPDhwzly5AiPP/44ERERVK1alWeeeSbD2M6fP8/58+cJDQ21lcXGxhITE0ObNm249dZbqVq1Kj169Eg19fB6RYsW5auvvuL1119nQork44IFCyhXrhx79+4lMTGRjh078uGHH7Ju3TpGjhzJs88+m6qt0qVLc+TIkWz3h4iIiIg4n8bUuICXXrKyYYP5r8avvgqP1/gJ95BACA52cmQiIjfhxRfTP+Z23b95PPdc+nWvH1WTjSfIZUWpUqVo3bo1CxcuxGq10rp1a0qVKpWlc2vWrGnbNgyD4OBgoqOjs3xOUFAQvr6+3HLLLXZlu3fvzuZdpG4XzMW4U5bFxcURGxuLn59fqvOT17Xy8fGxlZUoUYKePXsSERFBixYtaN68OZ06dSIkJAQw++7s2bMZxjVy5EhatGjBnXfeyQ8//MDYsWMpWrQo06ZNo0yZMqxYsYKQkBBCQkJITGO0W6FCheymG4qIiIhI3qGRTi7gnnugUaN4AAod2ofbHbUgJASaNoW5cyGTD/QiIi7Jyyv91/XziDOq6+mZed2b1Lt3bxYsWMDChQvp3bt3ls/zvC42wzCwWCxZPscwjEzbcHNzw2q12tVJKzlzfbvplaUXX8mSJTEMg3PnztmVz58/nx07dtCoUSM++ugjKleuzM6dOwHYuXMnv/76Kz/99BO//vorBw4csL2+/vprihUrRo8ePahbty4AVapUYc2aNQAsXryYkJAQRo0axaVLl/j777/TjO3ff/8lICAgzZhFRERExLUp6eQihg69BEA0gdcKN2+Gvn0hKAjCw+H991OvYyIiIjetZcuWJCQkkJCQQEREhLPDsRMQEMCpU6ds+7GxsRw+fNjh1/Hy8uL222/n119/TXWsTp06jBgxgu3bt1O9enWW/DcXvGLFitx2222pXqGhofTv35/27dszb9483P4b2fbEE0+wevVqypQpw4cffsimTZto2rQplSpVolWrVowbNy7Vtffv359qUXcRERERyRuUdHIRjRol0LixlVOUZgv3Xjvg5QVJSbB+PfTvD4MGOS9IEZF8yt3d3TZCx93d3dnh2Ln//vtZtGgRW7duZf/+/fTo0SPHYoyIiGDbtm22/cOHDzNixAh27NjB0aNHWbduHYcOHaJq1aoZtuPn58f06dOZO3euLeEE5lS55cuXc/z4cdavX4+/vz+jRo3ixIkT7N+/n1q1atm1c+TIEU6cOEHz5s0de6MiIiIikiu0ppOLMAxzbadWrQw+oDtN2ILVywsjIQHKlIEuXSAyElq0cHaoIiL5UlrrHLmCESNG8Ndff9GmTRv8/f0ZP358jox0AujXrx933HEHMTEx+Pv74+vry8GDB1m4cCFnz54lJCSEp556iv79+2faVuvWrbN83fSehrd06VLCw8MpV65cltsSEREREddhWK9fKELSFRsbi7+/PzExMQ79cmKxWIiOjiYgIJDGjd04tOtfThOEJ1chLAz+/tt8ZPimTVAAP3gn909gYKDdv5iLSf2TMfVPxm62f+Li4jh8+DAVKlSwW4A6v7BarVy9ehUPD490EyP5TadOnWzT6bIip/ooPj6eSpUqsXTpUho3bpxmnYzefzn1N1uyTz8LERGRvCEn/mbrG5gLMQwYNQrOUYL1mCOarJ06QcWKcOSIubC4HhstIiI56I033qBIkSLODoOjR48ycuTIdBNOIiIiIuL6lHRyMQ88AHfcAR/TCYB/v/7eHOFUqZISTyIikuPKlSvH008/7ewwqFy5cpam8YmIiIiI61LSycUYBoweDct4lFk8wduX+2ENLQ0bN5qJp6NHoUkTyKH1PEREREREREREHEFJJxfUrh1UqenDAGYx/q/HWb8eKF3aHPFUuTIcO2aOePrrLydHKiIiIiIiIiKSNiWdXFDy2k7Jxo0DqxUIDTVHPFWposSTiLgUPZNCnEHvOxERERHXpqSTi+rYEW6/3dz+7jtzkBNwLfF0223mU+2aNIE//3RWmCJSwHl6egJw+fJlJ0ciBVHy+y75fSgiIiIirsXD2QFI2tzc4KWXoEsXc3/cOLjvvv8OhoSYiaf77oODB80RTxs3mk+5ExHJRe7u7hQrVozo6GgAfH19MQzDyVE5jtVq5erVq3h4eOSr+3IkZ/SR1Wrl8uXLREdHU6xYMdzd3XPluiIiIiKSPUo6ubBOnWDMGDh0yBzptHUr3HPPfweDg81E0/33w4EDZuJp0yYlnkQk1wUHBwPYEk/5idVqxWKx4ObmpqRTOpzZR8WKFbO9/0RERETE9Sjp5MLc3WHkSOjRw9wfPx7WrUtRIWXi6ddfzal2mzaZT7kTEcklhmEQEhJCYGAgiYmJzg7HoSwWC2fPnqVkyZK4uWlGelqc1Ueenp4a4SQiIiLi4pR0cnFdusDYseZ64evXw44d0LBhigpBQfDtt9cST8lT7SpXdlbIIlJAubu757skgMViwdPTEx8fHyWd0qE+EhEREZH06NOhi/PwMEc7JRs/Po1KQUFmoqlaNTh50kw8/fZbboUoIiIiIiIiIpKKkk55QLduUK6cuf3VV/D992lUCgw0RzxVrw6nTpmLjCvxJCIiIiIiIiJOoqRTHuDpCSNGXNtPc7QTXEs81ahhJp6aNjWfbiciIiIiIiIiksuUdMojevaEMmXM7c8/h8jIdCoGBMA335iJp6goc8TTgQO5FKWIiIiIiIiIiElJpzzC2xuGD7+2/8orGVQOCDBHPNWseS3x9OuvOR6jiIiIiIiIiEgypyedtmzZQtu2bQkNDcUwDFatWpWqzoEDB2jXrh3+/v4ULVqUBg0acOzYMdvx+Ph4nn76aUqVKkXhwoVp164dx48ft2vj3LlzdOvWDX9/f/z9/enWrRvnz5/P4btzrL59ISTE3P70U9i/P4PKpUqZiadateD0aSWeRERERERERCRXOT3pdOnSJWrVqsX06dPTPP7nn39y9913c9ttt7Fp0yZ+/PFHRo0ahY+Pj63O4MGDWblyJcuWLWPbtm1cvHiRNm3akJSUZKvTpUsXIiMjWbt2LWvXriUyMpJu3brl+P05ko8PPP/8tf0MRzsBlCxpTrWrXRuio83E0y+/5GSIIiIiIiIiIiIAGFar1ersIJIZhsHKlStp3769rezRRx/F09OTRYsWpXlOTEwMAQEBLFq0iM6dOwNw8uRJwsLCWLNmDRERERw4cIDbb7+dnTt3Ur9+fQB27txJw4YNOXjwIFWqVMlSfLGxsfj7+xMTE4Ofn9/N3WwKFouF6OhoAgMDcXPLOA94+TJUqGDmkAzDHLx0222ZXODsWWjRAvbtuzb1rnp1h8Wf07LTPwWR+idj6p+MqX8ypv7JnKv2UU79zZbs089CREQkb8iJv9keDmklh1gsFr788kuef/55IiIi2LdvHxUqVGDEiBG2xNTevXtJTEwkPDzcdl5oaCjVq1dn+/btREREsGPHDvz9/W0JJ4AGDRrg7+/P9u3b0006xcfHEx8fb9uPjY21xWWxWBx6n1arNUtt+vjAsGEwfLgbViu88oqVDz7IJG9YvDisW4cREYHxww9Y778f64YNeSbxlJ3+KYjUPxlT/2RM/ZMx9U/mXLWPXC0eERERkYLIpZNO0dHRXLx4kddee41XXnmFSZMmsXbtWjp27MjGjRtp0qQJUVFReHl5Ubx4cbtzg4KCiIqKAiAqKorAwMBU7QcGBtrqpGXixImMHTs2VfmZM2eIi4u7ybu7xmKxEBMTg9VqzdK/Ej/0kMFrrwVw7pwbS5fC//53lgoVkjI9z/jwQ0p07oznzz9jve8+/l2+nKtVqzriFnJUdvunoFH/ZEz9kzH1T8bUP5lz1T66cOGCs0MQERERKfBcOumU/K+UDz74IEOGDAGgdu3abN++nffee48mTZqke67VasUwDNt+yu306lxvxIgRDB061LYfGxtLWFgYAQEBDp9eZxgGAQEBWf7APmwYvPQSWCwG779firlzszBLMjAQNm7EGhGB2969lHzkEXPEU82aN3kHOetG+qcgUf9kTP2TMfVPxtQ/mXPVPkq59qOIiIiIOIdLJ51KlSqFh4cHt99+u1151apV2bZtGwDBwcEkJCRw7tw5u9FO0dHRNGrUyFbn9OnTqdo/c+YMQUFB6V7f29sbb2/vVOVubm4O/2BtGEa22n36aXjzTTh/HhYtMhg92qBChSycWLIkbNgALVpgfP89RvPm5mLjtWrdVPw5Lbv9U9CofzKm/smY+idj6p/MuWIfuVIsIiIiIgWVS38i8/Ly4s477+S3336zKz906BDlypUDoG7dunh6erJ+/Xrb8VOnTrF//35b0qlhw4bExMSwe/duW51du3YRExNjq5PX+PnBf4O/SEqC117LxsnFisH69XDnneYi482aQWRkDkQpIiIiIiIiIgWV05NOFy9eJDIyksj/kh6HDx8mMjKSY8eOAfDcc8/x0UcfMXv2bP744w+mT5/O6tWrGThwIAD+/v706dOHYcOG8c0337Bv3z66du1KjRo1aN68OWCOjGrZsiX9+vVj586d7Ny5k379+tGmTZssP7nOFQ0aZCafAObPh/+6LGuKFYN16+Cuu64lnvbty4kwRURERERERKQAcnrS6fvvv6dOnTrUqVMHgKFDh1KnTh1Gjx4NQIcOHXjvvfd4/fXXqVGjBnPmzOHTTz/l7rvvtrUxZcoU2rdvT6dOnWjcuDG+vr6sXr0ad3d3W53FixdTo0YNwsPDCQ8Pp2bNmixatCh3b9bBihUzE08AiYkwadINNLBuHdSvD//+q8STiIiIiIiIiDiMYbVas7ACtYC5kLi/vz8xMTEOX0g8OjqawMDAbK9BcfYslC8PFy+Clxf89ReULp3NAGJioGVL2LkTihc313y6445sNpJzbqZ/CgL1T8bUPxlT/2RM/ZM5V+2jnPqbLdmnn4WIiEjekBN/s13n06HckJIl4X//M7cTEuCNN26gEX9/+PpraNAAzp0zRzzt3evQOEVERERERESkYFHSKR8YOhR8fc3tWbMgKuoGGvHzMxNPDRuaj8Rr3hy+/96RYYqIiIiIiIhIAaKkUz4QGAgDBpjbcXHw1ls32FBy4qlRIzPx1KIF7NnjqDBFREREREREpABR0imfePZZ8PExt2fMgDNnbrChokVh7Vpo3Pha4mn3bkeFKSIiIiIiIiIFhJJO+URICDzxhLl9+TJMnnwTjRUtCl99BXffbS4yrsSTiIiIiIiIiGSTkk75yPPPm0+wA5g+Hf799yYaS0483XMPxMaaiadduxwSp4iIiIiIiIjkf0o65SOlS0OfPub2xYswdepNNlikCKxZA/feey3xtHPnzYYpIiIiIiIiIgWAkk75zAsvgKenuf3OO+ayTDelSBH48kto0gQuXIDwcNix42bDFBEREREREZF8TkmnfKZsWejRw9yOiYFp0xzQaHLiqWlTM/EUEQHbtzugYRERERERERHJr5R0yodGjAB3d3N7yhRzZtxNK1wYvvgC7rvvWuLpu+8c0LCIiIiIiIiI5EdKOuVDt9wC3bqZ2+fOwYwZDmo4OfF0//3molEtW8K2bQ5qXERERERERETyEyWd8qkXXwS3/366b71l5ogcwtcXVq+GZs2uJZ62bnVQ4yIiIiIiIiKSXyjplE9VqgSPPWZu//MPvPeeAxv39YXPP4fmzeHSJWjVCrZsceAFRERERERERCSvU9IpHxs5EgzD3H7zTbh82YGNJyeeWrQwE08PPKDEk4iIiIiIiIjYKOmUj1WtCo88Ym6fPg2zZzv4AoUKwWefQXj4tRFPmzY5+CIiIiIiIiIikhcp6ZTPvfTSte1JkyAuzsEXKFQIVq0yn2Z3+TK0bq3Ek4iIiIiIiIgo6ZTf1agBHTqY26dOwbx5OXCR6xNPDzwAGzfmwIVEREREREREJK9Q0qkAGDXq2vbEiRAfnwMX8fExE08tW8KVK+aIp2+/zYELiYiIiIiIiEheoKRTAVCnDrRta24fPw4LF+bQhXx8YOVKc6RTcuLpm29y6GIiIiIiIiIi4sqUdCogrh/tlJiYQxfy8YEVK8zEU1wctGkDGzbk0MVERERERERExFUp6VRA3HmnOfMN4MgR+PDDHLyYt7eZeGrd2kw8tW0L69fn4AVFRERERERExNUo6VSAjB59bXvs2Bx4kl1K3t7w6admwik58bRuXQ5eUERERERERERciZJOBUjDhuYD5gCOHoVp03L4gt7e8MknZsIpPh7atYOvv87hi4qIiEhGZsyYQYUKFfDx8aFu3bps3bo1w/qLFy+mVq1a+Pr6EhISQq9evTh79mwuRSsiIiJ5mZJOBcwbb4Dbfz/1V1+Ff/7J4Qt6e8Py5fDgg2bi6cEHYe3aHL6oiIiIpOWjjz5i8ODBjBw5kn379nHPPffQqlUrjh07lmb9bdu20b17d/r06cMvv/zCJ598wp49e+jbt28uRy4iIiJ5kZJOBUyNGtCrl7kdEwPjx+fCRb284OOPoX37a4mnr77KhQuLiIhISpMnT6ZPnz707duXqlWrMnXqVMLCwpg5c2aa9Xfu3En58uUZNGgQFSpU4O6776Z///58//33uRy5iIiI5EVKOhVA48aBr6+5PWMG/P57LlzUyws++gg6dICEBDMBtWZNLlxYREREABISEti7dy/h4eF25eHh4Wzfvj3Ncxo1asTx48dZs2YNVquV06dPs3z5clq3bp3udeLj44mNjbV7iYiISMGkpFMBFBoKzz9vbl+9Ci+8kEsXTk48dexoJp46dIAvv8yli4uIiBRs//zzD0lJSQQFBdmVBwUFERUVleY5jRo1YvHixXTu3BkvLy+Cg4MpVqwY0zJYGHLixIn4+/vbXmFhYQ69DxEREck7lHQqoJ59FkJCzO0VKyCTNUQdx9MTli2Dhx4yE08dO8IXX+TSxUVERMQwDLt9q9WaqizZr7/+yqBBgxg9ejR79+5l7dq1HD58mAEDBqTb/ogRI4iJibG9/v77b4fGLyIiInmHkk4FVOHC9us5DRsGFksuXdzTE5YuhYcfvpZ4Wr06ly4uIiJSMJUqVQp3d/dUo5qio6NTjX5KNnHiRBo3bsxzzz1HzZo1iYiIYMaMGcybN49Tp06leY63tzd+fn52LxERESmYlHQqwHr2hOrVze09e8y1vnONpycsWQKPPAKJiebIp88/z8UAREREChYvLy/q1q3L+vXr7crXr19Po0aN0jzn8uXLuLnZf1x0d3cHzBFSIiIiIhlR0qkAc3eHN9+8tv/CCxAXl4sBJCeeOnUyE08PPwyffZaLAYiIiBQsQ4cOZc6cOcybN48DBw4wZMgQjh07ZpsuN2LECLp3726r37ZtW1asWMHMmTP566+/+O677xg0aBB33XUXoaGhzroNERERySOUdCrgIiIg+SE2R4/C9Om5HICHByxeDJ07X0s8rVqVy0GIiIgUDJ07d2bq1KmMGzeO2rVrs2XLFtasWUO5cuUAOHXqFMeOHbPV79mzJ5MnT2b69OlUr16dRx55hCpVqrBixQpn3YKIiIjkIYZVY6OzLDY2Fn9/f2JiYhy6PoHFYiE6OprAwMBUQ9hzw08/Qe3aYLWCvz/8+SeULJnLQVy9Ct26mYuMe3iYc/06dACc3z+uTv2TMfVPxtQ/GVP/ZM5V+yin/mZL9ulnISIikjfkxN9s1/l0KE5Tsyb06mVux8TAuHFOCMLDAxYtgi5dzARUp07mY/VEREREREREJE9S0kkA80l2vr7m9owZ8PvvTgjCwwMWLrRPPH36qRMCEREREREREZGbpaSTABAaCs89Z25fvWouKu4UHh7wwQfQtSskJZlrPS1f7qRgRERERERERORGKekkNs8+C8HB5vaKFbBtm5MCcXeHBQvMNZ6SkjC6dMF79WonBSMiIiIiIiIiN0JJJ7EpUsScZpds2DBzcXGncHeH+fOhe3eMpCSKPfkkfPSRk4IRERERERERkexS0kns9OoF1aub27t3mw+Rcxp3d5g3D+t/iSejWzclnkRERERERETyCCWdxI67O7zxxrX9F16AuDjnxYO7O9Y5c7j86KMYSUnmIuNLlzoxIBERERERERHJCqcnnbZs2ULbtm0JDQ3FMAxWrVqVbt3+/ftjGAZTp061K4+Pj+fpp5+mVKlSFC5cmHbt2nH8+HG7OufOnaNbt274+/vj7+9Pt27dOH/+vONvKB+IiIAWLcztI0dg+nSnhgPu7sS+9RbWnj3BYjEXGV+yxMlBiYiIiIiIiEhGnJ50unTpErVq1WJ6JpmNVatWsWvXLkJDQ1MdGzx4MCtXrmTZsmVs27aNixcv0qZNG5KSkmx1unTpQmRkJGvXrmXt2rVERkbSrVs3h99PfmAY8Oab5n8BXnkFzp51bky4uWGdPRv69DETT926weLFTg5KRERERERERNLj4ewAWrVqRatWrTKsc+LECZ566im+/vprWrdubXcsJiaGuXPnsmjRIpo3bw7Ahx9+SFhYGBs2bCAiIoIDBw6wdu1adu7cSf369QGYPXs2DRs25LfffqNKlSo5c3N5WM2a5vpO8+ZBTIy5wPh1A8xyn5sbvP++mQ2bMwe6dzdXOu/a1cmBiYiIiIiIiMj1nJ50yozFYqFbt24899xzVKtWLdXxvXv3kpiYSHh4uK0sNDSU6tWrs337diIiItixYwf+/v62hBNAgwYN8Pf3Z/v27ekmneLj44mPj7ftx8bG2mKyWCyOukUsFgtWq9WhbTrCmDGwbJnB5csG775r5cknrVSqlPtx2PWPmxvMnIkBGHPmYO3RA2tSkjnyqYBy1fePq1D/ZEz9kzH1T+ZctY9cLR4RERGRgsjlk06TJk3Cw8ODQYMGpXk8KioKLy8vihcvblceFBREVFSUrU5gYGCqcwMDA2110jJx4kTGjh2bqvzMmTPEOXB1bYvFQkxMDFarFTc3p894tPH0hAEDijB5chGuXjUYNiyeOXPO53ocafbP2LH4xcXh++GH0KsXMTExxHXqlOuxuQJXff+4CvVPxtQ/GVP/ZM5V++jChQvODkFERESkwHPppNPevXt5++23+eGHHzCSFxjKIqvVandOWudfX+d6I0aMYOjQobb92NhYwsLCCAgIwM/PL1vxZMRisWAYBgEBAS71gR3g5Zdh8WIrp08bfPmlD7//HkjjxrkbQ7r9M38+1sKFMWbNwn/wYPyKFoUePXI3OBfgyu8fV6D+yZj6J2Pqn8y5ah/5+Pg4OwQRERGRAs+lk05bt24lOjqasmXL2sqSkpIYNmwYU6dO5ciRIwQHB5OQkMC5c+fsRjtFR0fTqFEjAIKDgzl9+nSq9s+cOUNQUFC61/f29sbb2ztVuZubm8M/WBuGkSPt3iw/P3M9pyeeMPefe86NHTuuLTKeW9LsHzc3mDED3NwwZs7E6NPHDKxnz9wNzgW46vvHVah/Mqb+yZj6J3Ou2EeuFIuIiIhIQeXSn8i6devGTz/9RGRkpO0VGhrKc889x9dffw1A3bp18fT0ZP369bbzTp06xf79+21Jp4YNGxITE8Pu3bttdXbt2kVMTIytjqSvVy9IXk5r1y74+GPnxmPHzQ3efRcGDjQXFe/d21z9XEREREREREScyukjnS5evMgff/xh2z98+DCRkZGUKFGCsmXLUrJkSbv6np6eBAcH2xb/9vf3p0+fPgwbNoySJUtSokQJnn32WWrUqGF7ml3VqlVp2bIl/fr1Y9asWQA88cQTtGnTRk+uywIPD3jzTUh+yOALL0D79pDGIDDnMAyYPt3877vvQt++Znnv3s6NS0RERERERKQAc/pIp++//546depQp04dAIYOHUqdOnUYPXp0ltuYMmUK7du3p1OnTjRu3BhfX19Wr16Nu7u7rc7ixYupUaMG4eHhhIeHU7NmTRYtWuTw+8mvIiKgRQtz+8gRM8fjUgwDpk2Dp54yRzz16QNz5jg7KhEREREREZECy7BarVZnB5FXxMbG4u/vT0xMjMMXEo+OjiYwMNCl16D48UeoU8fM6RQrBn/8AdcNRMsR2eofqxUGD4Z33jH3338f+vXL8RidKa+8f5xF/ZMx9U/G1D+Zc9U+yqm/2ZJ9+lmIiIjkDTnxN9t1Ph2Ky6tV69oa3efPwyuvODOadBgGTJ0Kzzxj7j/xhJl4EhEREREREZFcpaSTZMv48VCokLn97rvmaCeXYxgwZYo54gmgf3/4by0vEREREREREckdSjpJtpQuDc8+a24nJpqLirskw4DJk2HIEHN/wACYOdO5MYmIiIiIiIgUIEo6SbY99xwEBZnbn34K333n3HjSZRjw1lswbJi5P3AgzJjh3JhERERERERECgglnSTbihY1p9klGzbMXL/bJRkGvPHGteFZ//ufOS9QRERERERERHKUkk5yQ3r1gmrVzO1du+CTT5wbT4YMA15/3RyiBfDUUzB9unNjEhEREREREcnnlHSSG+LhYQ4gSvbCCxAf77x4MmUYMGkSDB9u7j/9NEyb5tyYRERERERERPIxJZ3khrVsCc2bm9uHD+eBwUOGARMnXlv9fNAgeOcd58YkIiIiIiIikk8p6SQ3LHm5JMMw9195Bf75x7kxZcowYMIEGDHC3H/mGY14EhEREREREckBSjrJTaldG3r0MLfPn4fnn3dmNFlkGPDqqzBypLk/ahRYLM6NSURERERERCSfUdJJbtqECeDnZ27Pnw+bNzs3niwxDPMRfB9+CLNmgZt+FUREREREREQcSd+05aaFhJhLJSUbMMDFFxVPZhjw+OPQubOzIxERERERERHJd5R0Eofo3x/q1ze3Dx6E1193bjwiIiIiIiIi4lxKOolDuLubs9Tc3c39V1+F3393bkwiIiIiIiIi4jxKOonD1KoFQ4ea2/Hx8OSTYLU6NyYRERERERERcQ4lncShXn4ZypUzt7/5BhYvdm48IiIiIiIiIuIcSjqJQxUuDNOnX9sfOhT+/dd58dyUc+egWzfw9zdf3brB+fPOjkpEREREREQkT1DSSRyuTRt4+GFz+8wZGD7cufHcsC5dIDIS1q41X5GRZuJJRERERERERDKlpJPkiLffhqJFze05c2DrVgc0unw51KgBhQpByZLQvDlcuuSAhtNw4ICZaJozBxo2NF+zZ8MXX8Bvv+XMNUVERERERETyESWdJEeEhsKECdf2+/eHhIQbb8/t9GmMxx+H3r3NhNCmTdCxY8YrlRcpkvGrVav0z92xw5xSV7/+tbIGDcyy7dtv/EZERERERERECggPZwcg+deTT8IHH8CePWae6M034cUXb6wtt9OnMa5eNRNNySuV16iR8UmRkRkfL1Qo/WNRURAYmLo8MNA8JiIiIiIiIiIZUtJJcoy7O7z/PtSrB0lJMH48dOoEFStmv62r1aphbdYMo0YNiIiA8HBz4ajixdM/6UYulJJhpC6zWtMuFxERERERERE7ml4nOap2bXjmGXM7Lg4GDsx4Rly63N2xfv01fPUV3H47TJsGVarA4cPpn3Mz0+uCg+H06dTlZ85AUNAN3ICIiIiIiIhIwaKRTpLjxo6FTz6Bv/+G9eth6VLzwXDZZhjQuLH5Gj3anGa3ciUMHZp2/ZuZXtewIcTEwO7dcNddZtmuXWZZo0Y3ELyIiIiIiIhIwaKkk+S4IkXg3XehXTtzf8gQc5BRRjPjruf5ww+wb585tS4w0EwAnTkDVaumf9LNTK+rWhVatoR+/WDWLLPsiSegTRtzhJWIiIiIiIiIZEjT6yRXtG0LHTqY29HR8MIL2TvfUqQIxpYt8MADULkyvPQSvPVWxlPkbtbixeZi5eHh5qtmTVi0KOeuJyIiIiIiIpKPaKST5Jp33jGn1128aC4w3r27OVMuK5IqV8b61VcYbrmYJy1RAj78MPeuJyIiIiIiIpKPaKST5JoyZeDVV6/tDxgAiYnOi0dEREREREREco6STpKr/vc/qFvX3N6/35whJyIiIiIiIiL5j5JOkqvc3c11uZNnyY0dC3/95dyYRERERERERMTxlHSSXFe3LgwaZG7HxcHAgWC1OjcmEREREREREXEsJZ3EKcaNM9d4Avj6a/j4Y+fGIyIiIiIiIiKOpaSTOEXRojBt2rX9Z56B8+ezcOLZsxAYCEeOOD6oI0fAMCAy0tzftMncz1JgucAwYNWqrNfv2RPat7+2//DDMHmyg4MSERERERERSZuSTuI07dvDgw+a26dPw4gRWThp4kRo2xbKlzf3kxNFgYFw4YJ93dq1YcwYR4Wb940ebT4+MDbW2ZGIiIiIiIhIAaCkkzjVtGlQuLC5PWsW7NiRQeUrV2DuXOjbN/WxCxfgzTdzJMZ8o2ZNM1m3eLGzIxEREREREZECQEkncaqwMBg/3ty2WqF/f0hMTKfyV1+Bhwc0bJj62NNPm1PHoqPTv1ha09OKFYMFC7IfeMo2Z82CNm3A1xeqVjUzZ3/8AU2bmhm1hg3hzz/tz5s5E269Fby8oEoVWLTI/vjvv8O994KPD9x+O6xfn/raJ05A584YJUsSePvtGO3bZz7tsF07WLr0xu9XREREREREJIuUdBKne/ppqFPH3P75Z5gyJe16xtatUK9e2gcfewwqVjRXKM9t48dD9+7mWlC33QZdupjZsxEj4PvvzTpPPXWt/sqV5iJWw4bB/v1m3V69YONG87jFAh07grs77NwJ770Hw4fbX/PyZbjvPihSBOumTZxdtQqKFIGWLSEhIf1Y77oLdu+G+HhH9oCIiIiIiIhIKko6idN5eMD774Pbf+/GMWPg8OE0Kh45AqGhaTdiGPDaa2ZD148qymm9ekGnTlC5spkcOnIEHn8cIiLMkU/PPGMuSp7szTfNRb4HDjTPGTrUTDIlTw/csAEOHDBHP9WubY54mjDB/prLlpkdNmcO1KhBUuXKWOfNg2PH7K91vdKlzYRTVJRDu0BERERERETkeko6iUuoV+/aYKArV8xtq/W6SleumNPN0hMRAXffDaNG5VicaapZ89p2UJD53xo17Mvi4q4t4H3gADRubN9G48ZmefLxsmWhTJlrx6+fUrh3rzmFr2hRDD8/Am+9FaNUKfM6GSXdChUy/3v5ctbvT0REREREROQGOD3ptGXLFtq2bUtoaCiGYbAqxZo7iYmJDB8+nBo1alC4cGFCQ0Pp3r07J0+etGsjPj6ep59+mlKlSlG4cGHatWvH8ePH7eqcO3eObt264e/vj7+/P926deP8+fO5cIeSVePHXxvItGYNLFlyXYVSpeDcuYwbee01+Ogj2Lcv9THDSJ3JSncBqWzw9LS/RnplFkvqsmRW67WyVNm2NOpbLFC3LkRGYv3hB85u2ID1hx/g0CFzel96/v3X/G9AQPp1RERERERERBzA6UmnS5cuUatWLaZPn57q2OXLl/nhhx8YNWoUP/zwAytWrODQoUO0a9fOrt7gwYNZuXIly5YtY9u2bVy8eJE2bdqQlJRkq9OlSxciIyNZu3Yta9euJTIykm7duuX4/UnW+fmZT7NL9r//mbPFklnr1IFff824kbvuMqeqvfBC6mMBAXDq1LX93393zoifqlVh2zb7su3bzXIwFw4/dgxSJlevf6zfHXeY8QcGQsWKJFWoYK5pVbEi+Punf+39+80RVKVKOeZeRERERERERNLh4ewAWrVqRatWrdI85u/vz/rrnto1bdo07rrrLo4dO0bZsmWJiYlh7ty5LFq0iObNmwPw4YcfEhYWxoYNG4iIiODAgQOsXbuWnTt3Ur9+fQBmz55Nw4YN+e2336hSpUrO3qRkWceO5kCdJUsgJsZc+mjduv8OhofDiy+ao52KF0+/kVdfhWrVzMWiUrr/fpg+HRo0MEcKDR9uPyIptzz3nLkG1B13QLNmsHo1rFhhruUE0Ly5+US77t3hrbfMaXkjR9q38fjj8MYb8OCDMGYM7oUKmdPyVq0y2085NS+lrVvNfhQRERERERHJYU5POmVXTEwMhmFQrFgxAPbu3UtiYiLhKb5Ih4aGUr16dbZv305ERAQ7duzA39/flnACaNCgAf7+/mzfvj3dpFN8fDzxKZ7yFfvfmjwWiwVLyqlSN8lisWC1Wh3aZl42bRps3Wrw998GGzfClClWuna1YqlWDaNePazLlplPfAOwWHDD7EPb9LWKFTF69cKYPRur1Yo1ufyNNzB69zYX5g4NxTplCsbevebx/152baXV9nVSHU/rnOvL2rWDKVMw3ngDBg2CChWwzp1rxpV8zqefYvTrZ47cKl8e69SpuD3wwLU2fHxg0yaMF17AePhhSl24AKVLY73/fqxFioDFgmG1Qsr7j4vDWLkS61dfpXs/+ZF+vzKm/smY+idzrtpHrhaPiIiISEGUp5JOcXFxvPDCC3Tp0gU/Pz8AoqKi8PLyovh1I1+CgoKI+u8JXVFRUQQGBqZqLzAw0FYnLRMnTmTs2LGpys+cOUNcXNzN3Iodi8VCTEwMVqsVNzenz3h0CVOmePHII8WxWg1eesmNSpWucNdd0fg89RR+Y8fyz4MPmk9v8/W9NmUuOvpaA+PGma+U5R4e8MEH9hc6ePBanevbuv12cz8hwb7tlK6/dlrxpNXOQw+Zr5RSXqNYMfjkk4yv5eYGr7+O5bXXiImJwd/f33z/xMWZr0mT7Or7zp+Pd+3anLvllvTvJx/S71fG1D8ZU/9kzlX76MKFC84OQURERKTAyzNJp8TERB599FEsFgszZszItL7VasVIsfiycf1CzGnUud6IESMYOnSobT82NpawsDACAgJsSS9HsFgsGIZBQECAS31gd6YOHWDoUHN2WUKCwYgRYezZY+D72GNw5gyBiYkQFubsMF1Clt8/xYvDe++lmYDNz/T7lTH1T8bUP5lz1T7yyehppyIiIiKSK7KUdEpMTOTKlSupEi1RUVG8+eabHDhwgJCQEAYMGEC9evUcHmRiYiKdOnXi8OHDfPvtt3ZxBAcHk5CQwLlz5+xGO0VHR9OoUSNbndOnT6dq98yZMwQlP+I+Dd7e3nh7e6cqd3Nzc/gHa8MwcqTdvOzVV2H9evjpJzh40JNRo6xMmWLA4MHODs3lZOn9M2BA7gXkYvT7lTH1T8bUP5lzxT5ypVhERERECqosfSIbOnQod955p13Z2bNnueOOO5g8eTK7du1i4cKF3HPPPURGRjo0wOSE0++//86GDRsoWbKk3fG6devi6elpt+D4qVOn2L9/vy3p1LBhQ2JiYti9e7etzq5du4iJibHVEdfj7Q0ffgje3lYApk41+OYbJwclIiIiIiIiIlmSpaTT1q1b6datm13ZW2+9RVRUFLNnz+aff/7hxIkTVKpUiYkTJ2YrgIsXLxIZGWlLVh0+fJjIyEiOHTvG1atXefjhh/n+++9ZvHgxSUlJREVFERUVRUJCAmA+4a5Pnz4MGzaMb775hn379tG1a1dq1Khhe5pd1apVadmyJf369WPnzp3s3LmTfv360aZNGz25zsXVqAETJlht+z16mA+vExERERERERHXlqWk07Fjx6hdu7Zd2WeffUaVKlXo06cPYC7KPWzYMLvRRFnx/fffU6dOHerUqQOYo6rq1KnD6NGjOX78OJ9//jnHjx+ndu3ahISE2F7bt2+3tTFlyhTat29Pp06daNy4Mb6+vqxevRp3d3dbncWLF1OjRg3Cw8MJDw+nZs2aLFq0KFuxinMMGgT33GM+RfDECXjySbBaMzlJRERE0jRjxgwqVKiAj48PdevWZevWrRnWj4+PZ+TIkZQrVw5vb29uvfVW5s2bl0vRioiISF6W5TWdfH19bfvnz5/n4MGDDLhujZhbbrklzbWTMtK0aVOsGWQQMjqWzMfHh2nTpjFt2rR065QoUYIPP/wwW7GJa3Bzg6lTY2jWLIDz5w0++gjatoXHH3d2ZCIiInnLRx99xODBg5kxYwaNGzdm1qxZtGrVil9//ZWyZcumeU6nTp04ffo0c+fOpWLFikRHR3P16tVcjlxERETyoiyNdLr11lvZsWOHbf/rr78GoFmzZnb1/v33X7vFvEUcJTTUwowZ1xKQAwfC0aNODEhERCQPmjx5Mn369KFv375UrVqVqVOnEhYWxsyZM9Osv3btWjZv3syaNWto3rw55cuX56677tKamCIiIpIlWUo69enThwkTJvDqq68yd+5chg8fTlBQEK1atbKrt3HjRm677bYcCVSkc2fo2tXcjo0113dKSnJuTCIiInlFQkICe/fuJTw83K48PDzcbtmClD7//HPq1avH66+/TunSpalcuTLPPvssV65cSfc68fHxxMbG2r1ERESkYMpS0mngwIF069aNcePG0a9fPwCWLl1KoUKFbHXOnz/PBx98QMuWLXMmUhFg+nRIHv2/eTO89ZZz4xEREckr/vnnH5KSkggKCrIrDwoKIioqKs1z/vrrL7Zt28b+/ftZuXIlU6dOZfny5fzvf/9L9zoTJ07E39/f9goLC3PofYiIiEjekaWkk7u7O++99x7nz58nOjqaI0eO0KRJE7s6RYoU4ffff2fw4ME5EacIAP7+8MEHYBjm/ksvwX8PPhQREZEsMJL/iP7HarWmKktmsVgwDIPFixdz11138cADDzB58mQWLFiQ7minESNGEBMTY3v9/fffDr8HERERyRuylHRKVqhQIUqVKpXmMQ8PD0qWLImnp6dDAhNJT5Mm8Nxz5nZiojnlLoNR/iIiIgKUKlUKd3f3VKOaoqOjU41+ShYSEkLp0qXx9/e3lVWtWhWr1crx48fTPMfb2xs/Pz+7l4iIiBRMWUo6/fHHH6xevTpV+ddff029evUoXLgwt956K9OnT3d4gCJpGTcOatUyt3/5BUaMcG48IiIirs7Ly4u6deuyfv16u/L169enuzB448aNOXnyJBcvXrSVHTp0CDc3N8qUKZOj8YqIiEjel6Wk09ixY3njjTfsyn7++WcefPBBfv/9d1q1akWRIkV45pln+Oyzz3IkUJGUvL1h8WLzvwBvvw3XfYYWERGR6wwdOpQ5c+Ywb948Dhw4wJAhQzh27BgDBgwAzKlx3bt3t9Xv0qULJUuWpFevXvz6669s2bKF5557jt69e9ut7SkiIiKSliwlnXbu3EmnTp3syqZNm0ZSUhJbtmxh+fLlREZG0rp1a6ZOnZoTcYqkUq0aTJp0bb9nT/j3X6eFIyIi4vI6d+7M1KlTGTduHLVr12bLli2sWbOGcuXKAXDq1CmOHTtmq1+kSBHWr1/P+fPnqVevHo8//jht27blnXfecdYtiIiISB7ikZVKp06domrVqnZlX375JfXr16fWf3OcDMOgd+/ePPnkk46PUiQdTz8NX35pjnI6eRIGDICPPrq20LiIiIjYGzhwIAMHDkzz2IIFC1KV3Xbbbamm5ImIiIhkRZZGOhUqVIiEhATb/tGjRzl16hT33nuvXb1SpUoRExPj2AhFMuDmBvPnQ/Hi5v4nn8CHHzo3JhERERERERHJYtKpWrVqLF++3La/YsUKDMOgZcuWdvWOHj1KcHCwYyMUyUTp0jBr1rX9//0PjhxxWjgiIiIiIiIiQhan1w0fPpzWrVtz9OhRQkJCWL58OXXr1k010mn16tXccccdORKoSEYeeQS6d4cPPoALF8ztjRvB3d3ZkYmIiIiIiIgUTFka6dSqVSuWLFlCXFwc+/bto1OnTqxatcquTnR0NIcOHUq14LhIbnnnHfhvHVS2boXrHrgoIiIiIiIiIrkoSyOdAB599FEeffTRdI8HBgbyww8/OCQokRvh7w+LFkGTJmC1wujR0Lw51Kvn7MhERERERERECp4sjXTKqnPnzjFu3DhHNimSLffcA8OHm9uJifDQQ/DPP86NSURERERERKQgylbS6fTp0+zZs4czZ87YlZ84cYIhQ4ZQtmxZXnnlFYcGKJJdY8dCgwbm9rFj8OijcPWqc2MSERERERERKWiylHQ6d+4crVu3JjQ0lAYNGhAaGsqQIUOwWCyMHDmSihUrMm3aNB588EH279+f0zGLZMjLC5Yvh6Agc/+bb2DkSOfGJCIiIiIiIlLQZGlNp7Fjx7JhwwaeeOIJatWqxdGjR5k1axY//PADW7du5cEHH2TSpElUrlw5p+MVyZLSpeGTT+D++81RTq+/bq7t9Mgjzo5MREREREREpGDIUtLpyy+/ZNSoUbz00ku2snvuuYc2bdrQr18/Zs2alWMBityoe+6ByZNh0CBzv1cvuP12qFbNuXGJiIiIiIiIFARZml537NgxmjRpYlfWtGlTALp27erwoEQc5amnIPkteukSdOgAMTHOjUlERERERESkIMhS0ikxMRFvb2+7suT9woULOz4qEQcxDJg1C2rXNvd//x26dQOLxalhiYiIiIiIiOR7WZpeB7B06VK2bdtm27dYLBiGweLFi9m0aZOt3DAMhgwZ4tAgRW6Gry+sWGGu6fTvv7B6Nbz6Kowa5ezIRERERERERPKvLCed3n777TTLp0yZYrevpJO4ogoVYOlSaNkSrFZ4+WWoWxceeMDZkYmIiIiIiIjkT1maXmexWLL8SkpKyumYRW5IeLg5wgnMxNPjj8Mffzg3JhEREREREZH8KktJJ5H84oUXzMXEAc6fh44dzQXGRURERERERMSxlHSSAsUwYMECuO02c//nn6FvX3Pkk4iIiIiIiIg4jpJOUuD4+cHKlVC0qLm/bBlctzSZiIiIiIiIiNwkJZ2kQLrtNvjgg2v7zz8PGzc6Lx4RERERERGR/EZJJymw2reHkSPN7aQk6NwZ/v7bqSGJiIiIiIiI5BtKOkmBNnYsRESY22fOwEMPQVycc2MSERERERERyQ88snvCli1b0j3m5uaGv78/lStXxtvb+6YCE8kN7u6wZAnUqweHD8OePfD00zB7trMjExEREREREcnbsp10atq0KYZh2PatVqvdPkChQoXo378/b7zxBm5uGkwlrq1ECXNh8YYN4coVmDMH7rwTnnjC2ZGJiIiIiIiI5F3Zzgh9+eWXlClThu7du/Ppp5+ybds2Pv30U7p27UqZMmVYvHgxgwcP5t1332Xs2LE5EbOIw9WqZSabkj31FOzc6bx4RERERERERPK6bI90mjt3Ll26dGHixIl25e3bt2fEiBF8/PHHrFixAqvVyqJFi5R4kjyjSxdzet3UqZCYCA8/DHv3QlCQsyMTERERERERyXuyPdLp66+/plmzZmkeu//++1m/fj0A9913HydOnLi56ERy2euvQ5Mm5vaJE/DII2YCSkRERERERESyJ9tJpyJFirBx48Y0j23cuJEiRYoAkJCQgJ+f381FJ5LLPD3ho4+gdGlzf+tWc20nq9W5cYmIiIiIiIjkNdmeXvfkk08yduxYzpw5Q9u2bQkICODMmTN89tlnzJ8/nzFjxgCwfft2atWq5eh4RXJcUBB8+qk54ik+HhYsgLAwGDfO2ZGJiIiIiIiI5B3ZTjqNHj2aYsWKMWnSJObMmYNhGFitVoKDg5k6dSpPP/00AF27duUJPf5L8qj69WHxYnN6ndUK48ebiad+/ZwdmYiIiIiIiEjekO2kE8CgQYN46qmnOH78OKdOnSIkJIQyZcrg5nZttt5tt93msCBFnOGhh8xFxZ95xtx/8kkIDYXWrZ0aloiIiIiIiEiekO01nWwnurlRtmxZ6tevT9myZe0STiL5xaBBMGyYuZ2UBJ06mU+4ExEREREREZGM3VCm6ODBg0yYMIGBAwfSu3dvu1efPn2y1daWLVto27YtoaGhGIbBqlWr7I5brVbGjBlDaGgohQoVomnTpvzyyy92deLj43n66acpVaoUhQsXpl27dhw/ftyuzrlz5+jWrRv+/v74+/vTrVs3zp8/fyO3LwXM669D587m9uXL5kinP/90bkwiIiIiIiIiri7bSadFixZRvXp1XnnlFb755hv27NmT6pUdly5dolatWkyfPj3N46+//jqTJ09m+vTp7Nmzh+DgYFq0aMGFCxdsdQYPHszKlStZtmwZ27Zt4+LFi7Rp04akpCRbnS5duhAZGcnatWtZu3YtkZGRdOvWLbu3LwWQmxssXGguLA5w5gy0amX+V0RERERERETSlu01ncaPH0+HDh2YP38+RYoUuekAWrVqRatWrdI8ZrVamTp1KiNHjqRjx44ALFy4kKCgIJYsWUL//v2JiYlh7ty5LFq0iObNmwPw4YcfEhYWxoYNG4iIiODAgQOsXbuWnTt3Ur9+fQBmz55Nw4YN+e2336hSpcpN34fkb97esHIl3H03/Por/P47tGsH33wDvr7Ojk5ERERERETE9WQ76XTy5ElmzpzpkIRTZg4fPkxUVBTh4eG2Mm9vb5o0acL27dvp378/e/fuJTEx0a5OaGgo1atXZ/v27URERLBjxw78/f1tCSeABg0a4O/vz/bt29NNOsXHxxMfH2/bj42NBcBisWCxWBx2nxaLBavV6tA28xNX6R9/f/jyS2jc2ODkSYOdO+Gxx6wsX27F3d15cblK/7gq9U/G1D8ZU/9kzlX7yNXiERERESmIsp10uvfee9m/fz/NmjXLiXjsREVFARAUFGRXHhQUxNGjR211vLy8KF68eKo6yedHRUURGBiYqv3AwEBbnbRMnDiRsWPHpio/c+YMcXFx2buZDFgsFmJiYrBarVqQPQ2u1D8+PvDBBx60b1+Cixfd+PxzgyeeuMyECRcwDOfE5Er944rUPxlT/2RM/ZM5V+2jlNPwRURERMQ5sp10evXVV+nWrRs+Pj60aNGCYsWKpapTokQJR8RmY1z3bd5qtaYqu971ddKqn1k7I0aMYOjQobb92NhYwsLCCAgIwM/PL6vhZ8pisWAYBgEBAS71gd1VuFr/BAbCp59C69ZWrl41WLCgMFWqFOL5550Tj6v1j6tR/2RM/ZMx9U/mXLWPfHx8nB2CiIiISIGX7aRT3bp1AXjyySfTTdikXMD7ZgQHBwPmSKWQkBBbeXR0tG30U3BwMAkJCZw7d85utFN0dDSNGjWy1Tl9+nSq9s+cOZNqFFVK3t7eeHt7pyp3c3Nz+AdrwzBypN38wtX6Jzwc5s2D7t3N/REj3AgLg8cfd048rtY/rkb9kzH1T8bUP5lzxT5ypVhERERECqpsJ53mzZuX6SgjR6lQoQLBwcGsX7+eOnXqAJCQkMDmzZuZNGkSYCbBPD09Wb9+PZ06dQLg1KlT7N+/n9dffx2Ahg0bEhMTw+7du7nrrrsA2LVrFzExMbbElEh2desGx4/Diy+a+716QXAw5MLMUxERERERERGXl+2kU8+ePR0awMWLF/njjz9s+4cPHyYyMpISJUpQtmxZBg8ezIQJE6hUqRKVKlViwoQJ+Pr60qVLFwD8/f3p06cPw4YNo2TJkpQoUYJnn32WGjVq2J5mV7VqVVq2bEm/fv2YNWsWAE888QRt2rTRk+vkprzwAhw7Bu+9B4mJ0LEjbN0KNWs6OzIRERERERER58p20snRvv/+e+677z7bfvIaSj169GDBggU8//zzXLlyhYEDB3Lu3Dnq16/PunXrKFq0qO2cKVOm4OHhQadOnbhy5QrNmjVjwYIFuKd4pNjixYsZNGiQ7Sl37dq1Y/r06bl0l5JfGQZMmwYnTsDq1RAbCw88ADt2QFiYs6MTERERERERcR7DarVaM6tUs2ZNlixZQvXq1alRo0aG0+sMw+DHH390aJCuIjY2Fn9/f2JiYhy+kHh0dDSBgYFagyINeaF/Ll+G+++HXbvM/WrVYNs2SGOdfYfLC/3jTOqfjKl/Mqb+yZyr9lFO/c2W7NPPQkREJG/Iib/ZWRrpVLduXQoXLmzbzq01nUTyCl9fc6RTo0bwxx/wyy/QoQOsXQtprEUvIiIiIiIiku9lKek0f/582/aCBQtyKhaRPC0gAL76ykw8nTkDmzZBz56weDG40D/+i4iIiIiIiOQKfRUWcaCKFeGLL6BQIXN/2TJzsXERERERERGRguaGFhI/ePAgK1as4Pjx48TFxdkdMwyDuXPnOiQ4kbzorrvgo4+gfXuwWOCNN8xFxZ9+2tmRiYiIiIiIiOSebCedFi1aRK9evfDy8iIsLAwvLy+741rvSQTatoUZM2DAAHP/mWegdGno2NG5cYmIiIiIiIjklmwnncaPH0+HDh2YP38+RYoUyYmYRPKF/v3h77/h1VfBaoXHH4cNG6BxY2dHJiIiIiIiIpLzsr2m08mTJxkwYIASTiJZMH48dO9ubsfFQbt28Ntvzo1JREREREREJDdkO+l07733sn///pyIRSTfMQyYPRuaNzf3//0XWraEqCjnxiUiIiIiIiKS07I9ve7VV1+lW7du+Pj40KJFC4oVK5aqTokSJRwRm0i+4OUFn34K994LP/4IR45A69awaRMULers6ERERERERERyRraTTnXr1gXgySefTHfR8KSkpJuLSiSf8fODNWugQQNznacffoBOneDzz8HT09nRiYiIiIiIiDhetpNO8+bN0xPqRG5AaCisXWsuJH7+vLndrRt8+CF4ZPs3UURERERERMS1Zfurbs+ePXMgDJGC4fbb4bPPoEULSEiAjz4CNzf44AMlnkRERERERCR/yfZC4iJyc+6911zjKXla3dKl0KMHaFaqiIiIiIiI5CdZGltRs2ZNlixZQvXq1alRo0aG0+sMw+DHH390WIAi+VGbNmbi6aGHIDERliwxRzwtWADu7s6OTkREREREROTmZSnpVLduXQoXLmzb1ppOIjevbVtYvhwefthMPH34IRgGzJ+vxJPkQcuXw9ix8Mcf4OsLdeqYc0n/+9uRZYcPQ+nS5mMfRUREREQkT8tS0mn+/Pm27QULFuRULCIFTrt28MknZuLp6lVYtMgc8TR3rhJPkoecOgWPPQavvw4dOsCFC7B1K1it2W+rf3/w8TGTWBklng4cgAEDzFX5x441F0p74gn48Udo3x5eeeVG70ZERERERBxEazqJONmDD8LHH19bSHzhQujXDywW58YlkmWnTplZ044doXx5qFEDBg6EIkWy39aSJXD0qDn3NCEh/XrPPQfvvmsmp0aONOvXqgU7d5pDBz/99IZvR0REREREHOOGnpdlsVj49ttvOXToEHFxcamODx069KYDEylIOnQwn2TXqZO5oPj8+eZUu9mzzZFPIi6tVi1o1sxMNkVEQHi4OXyvePG06z/8cOZJoZ9+grffNpNLafHxgerVze1Jk2DoUFi71tzv0QMWLzYTUSIiIiIi4jTZTjpFRUXRtGlTDh06hGEYWP+bPpFynSclnUSyr2NHM/HUubOZeJo3z0w4zZqlxJO4OHd3WL8etm+Hdetg2jRz9NGuXVChQur677yT/vS3+HgzaWQY0Lt3+te8dAlOnwY/P/OXxNcX3nvPnHL39ddQpYpj7k1ERERERG5Ytr/KDh06lJIlS/L3339jtVrZtWsXR44cYfz48VSqVIlDhw7lRJwiBcJDD8HSpdfWc5ozx/wOral24vIMAxo3NtdX2rfPXI9p5cq064aGwm23pf0aN87Msn7zDZQsmf71xoyB5s3h1luhSRMz6fXJJ2bbO3ZAly45cpsiIiIiIpJ12R7ptGXLFt555x1CQkIAsFqtlC1blhdffBGr1cpTTz3FV1995fBARQqKRx4x11/u0sUc8TR7tvl9fuZMjXgSF7Vrl5kkCg+HwEBz/8wZqFo1+20NG2Ymn0qUyLhe/frw88/2Zd98Y/7y6AmrIiIiIiIuIdtJp5iYGAICAnBzc8PPz4/o6GjbsYYNG/Laa685NECRgqhTp2uJJ4sF3n/fTDjNmKHv0+KC/PxgyxaYOhViY6FcOXjrLWjVKvttNWp0c7HoF0RERERExGVkO+lUoUIFTp06BUC1atVYtGgRbdq0AWDlypWUyOxfp0UkSzp3NhNOXbua/33vPfP79Lvv6nu1uJiqVa8t4i0iIiIiIvKfbCedHnjgAdatW0enTp146aWXePDBBwkMDMTT05OoqCgmTZqUE3GKFEiPPWaOeOrWzUw8JU+xmzZNiScRERERERFxbdleIea1115jzpw5ALRq1Yrt27fTr18/OnfuzBdffMGzzz7r8CBFCrIuXWDhwmvrOb37LjzzjJmMEhERya4ZM2ZQoUIFfHx8qFu3Llu3bs3Sed999x0eHh7Url07ZwMUERGRfCNbI53i4+OZPn064eHh1KhRA4B69epRr169HAlORExdu5pJph49zP8mj3SaOtXZkYmISF7y0UcfMXjwYGbMmEHjxo2ZNWsWrVq14tdff6Vs2bLpnhcTE0P37t1p1qwZp0+fzsWIRUREJC/L1kgnb29vRo0axblz53IqHhFJR7duMH/+tWl177wDQ4ZoxJOIiGTd5MmT6dOnD3379qVq1apMnTqVsLAwZs6cmeF5/fv3p0uXLjRs2DCXIhUREZH8INvT62rXrs2vv/6aE7GISCZ69IB5864lnt5+G5591lDiSUREMpWQkMDevXsJDw+3Kw8PD2f79u3pnjd//nz+/PNPXn755SxdJz4+ntjYWLuXiIiIFEzZTjq9/fbbTJkyhRUrVnDlypWciElEMtCzJ8ydey3xNHWqwbhxRZV4Euc7exYCA+HIEWdHIilNnw7t2jk7CnEB//zzD0lJSQQFBdmVBwUFERUVleY5v//+Oy+88AKLFy/GwyNrqzJMnDgRf39/2yssLOymYxcREZG8KUtJpw8++ICzZ88CcP/993PkyBEeeeQRihQpQtGiRfHz87O9/P39czRgEYFevWD27Gv7771XmOHDNeJJnGziRGjbFsqXN/ePHDGzo5GRzolnzBjIyoLHly7B8OFwyy3g4wMBAdC0KXzxRQ4HmEv69YM9e2DbNmdHIi7CuO7xp1arNVUZQFJSEl26dGHs2LFUrlw5y+2PGDGCmJgY2+vvv/++6ZhFREQkb8rSP1n16tWLHTt2ULJkSYYNG5bmBxMRyV19+pjrOfXrZ+6/9ZaBuzu89tq1UVAiuebKFXMI3po1zo4k+wYMgN27zRFBt99ujtjavt38r7MlJICX18214e1tPgZz2jS4+27HxCV5UqlSpXB3d081qik6OjrV6CeACxcu8P3337Nv3z6eeuopACwWC1arFQ8PD9atW8f999+f6jxvb2+8vb1z5iZEREQkT8lS0smaYvjEmDFjcioWEcmmvn3h6lULTz5pDlp8/XX491+YOROyOAtCxDG++sp802VnkWGrFd54A957D06dgsqVYdQoePhh83hSEjzxBHz7LURFQdmyMHAgPPPMtTY2bYLnn4dffgFPT6hWDZYsgY0bYexYs05yFnb+fHN+6vVWrzYXSHvgAXO/fHmoW9fctljM/0ZHmxneDRsgOBheeQVGjoTBg83XkSNQoQLs23dtdNX581C8uBlL06ZZu5+ePc3z6tc3k0ReXmbbJ07A0KGwbh24uZnJo7ffvjaqLL1+KFfOPN6uHYSHm8nBQoWy/jOSfMXLy4u6deuyfv16OnToYCtfv349Dz74YKr6fn5+/Pzzz3ZlM2bM4Ntvv2X58uVUqFAhx2MWERGRvE1fS0XyuCeegNjYGIYPN6e2zpljfp9dtgwKF3ZycFJwbNkC9epl75yXXoIVK8wsaaVKZhtdu5rT25o0MRM+ZcrAxx9DqVLm6KMnnoCQEOjUCa5ehfbtzWTQ0qXmqKDdu80kU+fOsH8/rF1rJooA0pv+HRxsjtDq2BGKFk2zitGrFxw/biaMvLxg0CAzEZUdmd1Psm++AT8/WL/eTMxdvgz33Qf33GP2kYeHmfRq2RJ++slMQqXXD8nq1YPERLO8SZPsxS35ytChQ+nWrRv16tWjYcOGvP/++xw7dowBAwYA5tS4EydO8MEHH+Dm5kb16tXtzg8MDMTHxydVuYiIiEhaspx0Wrp0KduysB6EYRgMGTLkpoISkezp3v0KZcoUpWdPNxITzaVomjUzB3AEBDg7OikQjhyB0NCs1790CSZPNpM4yaOjbrnFXHdo1iwzMeLpeW20EpgjibZvN5M2nTpBbCzExECbNnDrrWadqlWv1S9SxEzQBAdnHMv778Pjj0PJklCrljmK6OGHoXFjANz//BNj7VrYudMcgQTmVMKU18qKzO4nWeHCZvY4eVrdvHlmYmnOHPtRW8WKmSOc6tXLuB+S2yxWzPw5KelUoHXu3JmzZ88ybtw4Tp06RfXq1VmzZg3l/hsVd+rUKY4dO+bkKEVERCS/yHLS6e23385SPSWdRJzj0UfN79YdOpjfxXftMr8zr11rfpcXyVFXrpiLcGfVr79CXBy0aGFfnpAAdepc23/vPTPZcvSoeY2EhGvT10qUMKejRUSY7TRvbiZvQkKyF/u998Jff5lJpe++MxNhb79tJohGjsTj99+xenhgpBzJddttZhInuzK6n2Q1ativ47R3L/zxR+pRWHFx8Oef5rS5rPRDoULmqCkp8AYOHMjAgQPTPLZgwYIMzx0zZoyWWhAREZEsy9LT6wB27tyJxWLJ9JWUlJST8YpIBu6/35x9k/xd8/ffoVEj+OEH58YlBUCpUnDuXNbrJ6+V9OWX5tPtkl+//grLl5vHPv4YhgyB3r3NtYwiI81HNyYkXGtn/nzYscN8o3/0kbku1M6d2Y/f09OcvvbCC+a1xo2D8ePNayWva5jRCv1u//05TfkIycRE+zpZuR9IPS/WYjHXmErZT5GRcOiQuUA4ZK0f/v1XQx9FREREJFdlOekkInlDrVrmd8/k2TWnT5uzadatc25cks/VqWMmjLLq9tvNp6odOwYVK9q/wsLMOlu3mkmUgQPN9itWNEf2pHXtESPMqWrVq5sLaIM5WuhG/yHk9tvNNaPi4rhaqRLG1avw/ffXjv/2m7ngd7LkZM6pU9fKIiPt28zq/VzvjjvMDHJgYOq+SrlOVXr9AOZ14uLsR5GJiIiIiOQwJZ1E8qFy5cylcf5bkoaLF6F1a/jgA+fGJflYRIT55LS0Rjv99lvqUTre3vDss+bIn4ULzaTIvn3w7rvmPphJle+/h6+/Nkf1jBoFe/Zca/fwYTPJsmOHOV1t3TqzXnLGtXx5s05kJPzzD8THpx1706bmOlJ795prHq1ZAy++aC7e7edHUsWKWCMizIW6d+0y6/Xta/8UuEKFoEEDeO01M/m2ZYu5UHpKmd1Peh5/3BxJ9uCDZuLq8GHYvNl86t3x45n3A5jn3XLLtTWfRERERERygZJOIvlUiRLmw686djT3r16FHj1g4kT7GUAiDlGjhrmg9ccfpz726KPmCJuUr5Mnzelro0ebb8qqVc3E1erV5gLbAAMGmG/gzp3NBbzPnjVHCSXz9YWDB+Ghh8zpZE88AU89Bf37m8cfesh8wtt995kjkZYuTTv2iAgz0RUebsbx9NNmWYp7sc6bZ47AatLEjOmJJ8yRRynNm2dOqatXz0wIvfKK/fHM7ic9vr5mEqtsWfP8qlXNKXpXrphPucusH8C89379Mr+WiIiIiIgDGVara3/9vHr1KmPGjGHx4sVERUUREhJCz549eemll3D7bw0Nq9XK2LFjef/99zl37hz169fn3XffpVq1arZ24uPjefbZZ1m6dClXrlyhWbNmzJgxgzJlymQ5ltjYWPz9/YmJicHPz89h92ixWIiOjiYwMNB2T3KN+idjmfVPUpL5/ffdd6+VDRwI77wD7u65GKiT6P2TMYf2z5o15uil/fuvrXGUx2XYP+XLw+DB5suV7d9vPs7y0CH76XgO4qq/Yzn1N1uyTz8LERGRvCEn/ma7zqfDdEyaNIn33nuP6dOnc+DAAV5//XXeeOMNpk2bZqvz+uuvM3nyZKZPn86ePXsIDg6mRYsWXLhwwVZn8ODBrFy5kmXLlrFt2zYuXrxImzZttPC55Hvu7jBtmjmYJNmMGfDII+ZACRGHeeABc3TNiRPOjkRSOnnSnFubAwknEREREZGMeDg7gMzs2LGDBx98kNatWwNQvnx5li5dyvf/LehqtVqZOnUqI0eOpON/84gWLlxIUFAQS5YsoX///sTExDB37lwWLVpE8+bNAfjwww8JCwtjw4YNREREOOfmRHKJYZgP5QoNhT59zKl2K1eaT1f//HNzKp6IQzzzjLMjkOuFhzs7AhEREREpoFw+6XT33Xfz3nvvcejQISpXrsyPP/7Itm3bmDp1KgCHDx8mKiqK8BQfqr29vWnSpAnbt2+nf//+7N27l8TERLs6oaGhVK9ene3bt6ebdIqPjyc+xcKzsbGxgDmVwJL8uG8HsFgsWK1Wh7aZn6h/Mpad/una1Vza5pFHDC5dMvjuO7j7bitr1lgpWzYXgnUCvX8ypv7JWIb989dfyZVyNygX46rvIVeLR0RERKQgcvmk0/Dhw4mJieG2227D3d2dpKQkXn31VR577DEAoqKiAAgKCrI7LygoiKNHj9rqeHl5Ubx48VR1ks9Py8SJExk7dmyq8jNnzhAXF3dT95WSxWIhJiYGq9XqUuthuAr1T8ay2z916sCnn3rQtWtx/vnHnQMHDBo2tLB48Tluv/1qLkScu/T+yZj6J2Pqn8y5ah+lnGIvIiIiIs7h8kmnjz76iA8//JAlS5ZQrVo1IiMjGTx4MKGhofTo0cNWzzAMu/OsVmuqsutlVmfEiBEMHTrUth8bG0tYWBgBAQEOX0jcMAwCAgJc6gO7q1D/ZOxG+qdFC/Pp6g88YOX33w2iotzp0KEkn35q5f77czjgXKb3T8bUPxlT/2TOVfvIx8fH2SGIiIiIFHgun3R67rnneOGFF3j00UcBqFGjBkePHmXixIn06NGD4OBgANuT7ZJFR0fbRj8FBweTkJDAuXPn7EY7RUdH06hRo3Sv7e3tjbe3d6pyNzc3h3+wNgwjR9rNL9Q/GbuR/qlYEb77Dtq0gd27ITbW4IEHDD74wHzCfX6i90/G1D8Zy3L/XLwI990H1avDvHnmYmoFhCu+h1wpFhEREZGCyuU/kV2+fDnVB0d3d3fbWg0VKlQgODiY9evX244nJCSwefNmW0Kpbt26eHp62tU5deoU+/fvzzDpJJLfBQTAt9+aiSeAxER47DGYPNm5cYnkSRYL/PwzLFhgPi1ORERERKSAc/mkU9u2bXn11Vf58ssvOXLkCCtXrmTy5Ml06NABMP91dfDgwUyYMIGVK1eyf/9+evbsia+vL126dAHA39+fPn36MGzYML755hv27dtH165dqVGjhu1pdiIFVeHC5pPs+vW7VjZsGAwdWuDXRxbJHj8/SF4HcMgQyGDNQBERERGRgsDlp9dNmzaNUaNGMXDgQKKjowkNDaV///6MHj3aVuf555/nypUrDBw4kHPnzlG/fn3WrVtH0aJFbXWmTJmCh4cHnTp14sqVKzRr1owFCxbg7u7ujNsScSkeHjBrFpQpAy+/bJZNmQInTpgDNtKYZSoiaRk2DD7+GH74AZ5+Gj75xNkRiYiIiIg4jWG1Wq3ODiKviI2Nxd/fn5iYGIcvJB4dHU1gYKDWoEiD+idjju6fOXNgwABISjL3mzY1R0IVK3bTTTuF3j8ZU/9k7Ib6JzIS6tUzf4k+/RQ6dszRGJ3NVd9DOfU3W7JPPwsREZG8ISf+ZrvOp0MRcQl9+8KqVVCokLm/aRPce6856klEsqB2bRg+3NweOBDOnXNqOCIiIiIizqKkk4ik0qYNbNwIpUqZ+z//DA0bwi+/ODcukTxj1Ci47TY4fdqcciciIiIiUgAp6SQiaapfH777DipUMPf//hvuvhu2bnVuXCJ5go+POVfVMGD+fEjx9FQRERERkYJCSScRSVflyrBjB9xxh7l//jy0aGEuUyMimWjcGJ56ytx+4gm4eNG58YiIiIiI5DIlnUQkQ0FB5rpOERHmfnw8PPIITJ/u1LBE8oYJE6BsWThyBF56ydnRiIiIiIjkKiWdRCRTRYvC6tXQvbu5b7WaT4MfOhSuXnVubCIurUgReP99c/udd8yhgyIiIiIiBYSSTiKSJZ6esGABvPjitbIpU8wRUP/847SwRFxfRAT06GFma/v0MYcLioiIiIgUAEo6iUiWGQa8+iq89x54eJhl334L9erBDz84NzYRlzZ5sjlX9cABeOUVZ0cjIiIiIpIrlHQSkWzr3x82bjS/QwMcPWqumfzhh86NS8RllSgB775rbr/2Gvz4o3PjERERERHJBUo6icgNuftu2LsX6tc39+PioFs3GDIEEhOdG5uIS3roIejY0VwIrU8fLYgmIiIiIvmekk4icsNKl4bNm6Fv32tlU6dCeDhERzstLBHXNX06FCtmZmynTHF2NCIiIiIiOUpJJxG5Kd7eMHs2zJplLjYOsGmTuc7T9987NTQR1xMSYq7vBDB6NPz+u3PjERERERHJQUo6iYhDPPGEmWwKDjb3//7bnIL3wQdODUvE9fTsCS1amHNS+/YFi8XZEYmIiIiI5AglnUTEYRo1MmcNNWxo7sfHm0+KHzRI6zyJ2BgGvP8+FC4MW7aY2yIiIiIi+ZCSTiLiUKGh5oinAQOulU2bBs2bw+nTTgtLxLWULw8TJpjbzz9vDg0UEREREclnlHQSEYfz8oKZM821nry8zLItW8x1nvbscW5sIi7jf/8zhwVeuABPPglWq7MjEhERERFxKCWdRCTH9O1rPt0uNNTcP34c7rkH5s93blwiLsHdHebMMTOzX34JS5c6OyIREREREYdS0klEclSDBuY6T40bm/vx8dC7tznIIyHBubGJON3tt8OoUeb2oEFw5oxz4xERERERcSAlnUQkxwUHw7ffwsCB18pmzID774eoKOfFJeIShg+HmjXh7Fkz8SQiIiIikk8o6SQiucLLC959F+bOvbbO03ffQd26sGuXc2MTcSpPT5g3D9zcYNky+PxzZ0ckIiIiIuIQSjqJSK7q3Ru2boXSpc39kyfh3nvNZJRIgVW3Ljz7rLn95JMQE+PceEREREREHEBJJxHJdXfdZa7zdO+95n5Cgrno+JNPap0nKcDGjIGKFc1M7PPPOzsaEREREZGbpqSTiDhFUBBs2ABPP32t7L334L774NQp58Ul4jSFCplPswN4/33YuNG58YiIiIiI3CQlnUTEaTw94Z13YMEC8PY2y7ZvN2cabd/u1NBEnKNJExgwwNzu1w8uX3ZuPCIiIiIiN0FJJxFxuh49zEXFw8LM/VOnoGlTmDXLqWGJOMekSVCmDPz5J7z8srOjERERERG5YUo6iYhLqFvXXOepaVNzPzHRHPDxxBMQH+/U0ERyl5+fOdcUYPJk2LPHufGIiIiIiNwgJZ1ExGUEBMC6dTB48LWy2bPNGUcnTjgtLJHc17o1PP44WCzmIx+1wr6IiIiI5EFKOomIS/H0hClTYNEi8PExy3btgjvugK++cm5sIrlq6lQoVQr274fXXnN2NCIiIiIi2aakk4i4pK5dzXWeypUz96Oj4YEHYNAguHLFubGJ5IpSpWDaNHP7lVfgl1+cG4+IiIiISDYp6SQiLuuOO+D7781kU7Jp0+DOO+Gnn5wXl0iu6dwZ2rY1Fznr0weSkpwdkYiIiIhIlinpJCIurVQp+OILmD792nS7X34xE09Tp5pL3ojkW4YBM2eai4vv2nVt5JOIiIiISB6gpJOIuDzDgP/9z3y6Xa1aZllCAgwZAi1bwsmTzo1PJEeVLg1vvmlujxwJf/3l3HhERERERLJISScRyTNuv90c7DFs2LWy9euhZk1YtcppYYnkvL594b774PJl6NcPrFZnRyQiIiIikiklnUQkT/H2Ngd9rF8PISFm2dmz0KED9O8Ply45Nz6RHGEY8P77UKgQfPstzJvn7IhERERERDKlpJOI5EnNm8PPP5vJpmTvv28uPr53r/PiEskxFSvC+PHm9rBhmlcqIiIiIi5PSScRybNKloRPP4U5c8DX1yw7dAgaNIBJk/SgL8mHnnnGXEU/JgYGDtQ0OxERERFxaUo6iUieZhjmk+T37YN69cyyq1fhhRegWTP4+2/nxifiUB4e5tQ6T0/47DNYvtzZEYmIiIiIpEtJJxHJFypXhu3b4cUXzUQUwObNULu2weef+zg3OBFHql7dfKMDPPWUuaiZiIiIiIgLUtJJRPINT0949VXYtAnKljXLzp836N+/GL16GcTGOjU8EccZMQKqVYPoaBgyxNnRiIiIiIikSUknEcl37r0XfvwRHn30WtkHHxjUqQM7djgvLhGH8faGuXPNYX2LFsFXXzk7IhERERGRVPJE0unEiRN07dqVkiVL4uvrS+3atdmb4vFUVquVMWPGEBoaSqFChWjatCm//PKLXRvx8fE8/fTTlCpVisKFC9OuXTuOHz+e27ciIrmkWDFYsgQWLrRQpIgFgL/+gnvugXHjzHWfRPK0+vVh8GBzu39/uHDBqeGIiIiIiFzP5ZNO586do3Hjxnh6evLVV1/x66+/8tZbb1GsWDFbnddff53Jkyczffp09uzZQ3BwMC1atOBCig/ggwcPZuXKlSxbtoxt27Zx8eJF2rRpQ5IebyWSbxkGdO0K33xzlkaNzKd8JSXByy9DkyZmEkokTxs/Hm65xVwxf8QIZ0cjIiIiImLH5ZNOkyZNIiwsjPnz53PXXXdRvnx5mjVrxq233gqYo5ymTp3KyJEj6dixI9WrV2fhwoVcvnyZJUuWABATE8PcuXN56623aN68OXXq1OHDDz/k559/ZsOGDc68PRHJBWXLJrFxo5Vx48Dd3Szbvh1q1zZnJump85JnFS4Ms2eb2+++C1u3OjceEREREZEUPJwdQGY+//xzIiIieOSRR9i8eTOlS5dm4MCB9OvXD4DDhw8TFRVFeHi47Rxvb2+aNGnC9u3b6d+/P3v37iUxMdGuTmhoKNWrV2f79u1ERESkee34+Hji4+Nt+7H/rUJssViwWCwOu0eLxYLVanVom/mJ+idj6p+MJfePm5uFkSOhWTPo1s3gr78MLlyA7t3hyy+tzJhhJcUAygJD75+M5Yn+adoUo08fjLlzsfbti3XfPvDJvSc2umofuVo8IiIiIgWRyyed/vrrL2bOnMnQoUN58cUX2b17N4MGDcLb25vu3bsTFRUFQFBQkN15QUFBHD16FICoqCi8vLwoXrx4qjrJ56dl4sSJjB07NlX5mTNniIuLu9lbs7FYLMTExPz3xdjlB5/lOvVPxtQ/Gbu+f265Bb7+2uCll4ry0Ue+AHz0kcHWrRYmT46hSZMEJ0ecu/T+yVhe6R/jueco9cUXuB86xKXhw7k4cmSuXdtV++iC1rgSERERcTqXTzpZLBbq1avHhAkTAKhTpw6//PILM2fOpHv37rZ6hmHYnWe1WlOVXS+zOiNGjGDo0KG2/djYWMLCwggICMDPz+9GbidNFosFwzAICAhwqQ/srkL9kzH1T8bS6p/AQHOR8Q4dLAwYYHD+vMHJk+48+mgJHn/cyltvWQkIcHLguUTvn4zlmf4JDISZM6FjRwrPnIlvjx5wxx25cmlX7SOfXBztJSIiIiJpc/mkU0hICLfffrtdWdWqVfn0008BCA4OBszRTCEhIbY60dHRttFPwcHBJCQkcO7cObvRTtHR0TRq1Cjda3t7e+Pt7Z2q3M3NzeEfrA3DyJF28wv1T8bUPxlLr386d4ZGjaBnT/j2W7Ns8WKDtWsN3nrLnHqXSe46X9D7J2N5pn86dIBOnTA+/hijXz/YvRs8PXPl0q7YR64Ui4iIiEhB5fKfyBo3bsxvv/1mV3bo0CHKlSsHQIUKFQgODmb9+vW24wkJCWzevNmWUKpbty6enp52dU6dOsX+/fszTDqJSP4XFgYbNsDcuZCckz571kxENW8Of/zh1PBEsmfaNChRAiIj4c03nR2NiIiIiBRwLp90GjJkCDt37mTChAn88ccfLFmyhPfff5///e9/gPmvq4MHD2bChAmsXLmS/fv307NnT3x9fenSpQsA/v7+9OnTh2HDhvHNN9+wb98+unbtSo0aNWjevLkzb09EXIBhQO/ecOAAPPbYtfJvv4UaNWDiREhMdF58IlkWGAhvv21ujx0LBw86Nx4RERERKdBcPul05513snLlSpYuXUr16tUZP348U6dO5fHHH7fVef755xk8eDADBw6kXr16nDhxgnXr1lG0aFFbnSlTptC+fXs6depE48aN8fX1ZfXq1bgnPz9dRAq8oCBzrac1a+C/wZTExcGLL5rL4+zc6dz4RLLk8cehVSuIj4e+fUFPcRMRERERJzGsVqvV2UHkFbGxsfj7+xMTE+PwhcSjo6MJDAzUGhRpUP9kTP2TsRvtn0uX4OWXYcqUa9/ZDQMGDoQJE8CB/wtwKr1/MpZn++fYMahWDS5eNKfcPfVUjl3KVfsop/5mS/bpZyEiIpI35MTfbNf5dCgi4kIKFzaXxNmz59pDwKxWePdduP12WLXKqeGJZKxsWZj0//buPK6K6v/j+OuyCIiKKYIQhkuuqWmapmZSLi1+LbPU0lJTK3MLt8qlNCvtm2XW1yUzLctcUrPsp6W2uKWWEpYhrS5oQS4pICYId35/TFy8sgh4YS7wfj4e8+DeM2fmfu6ZmXvnfjhz5r/m46eegsOHrY1H3MrcuXOpVasWvr6+tGjRgm3btuVa98MPP6Rz586OO/e2adOGDRs2FGO0IiIiUpIp6SQikofrroNvvoGZM6F8ebPsjz/MG4X16GE+FnFLQ4ZA+/Zmt71HHzWzplLmrVixgsjISCZOnEh0dDTt27fn9ttvJy4uLsf6W7dupXPnzqxfv56oqChuvvlmunXrRnR0dDFHLiIiIiWRkk4iIpfg5QWjRkFMjDlUTqY1a6BhQ7P3U0aGdfGJ5MjDA956C3x8YMMGeO89qyMSNzBz5kwGDRrE4MGDadiwIbNmzaJGjRrMmzcvx/qzZs3iiSee4Prrr6du3bpMmzaNunXr8sknnxRz5CIiIlISKekkIpJPNWvCunWwfLl5kzCA5GRzuJwbb4R9+ywNTyS7evXMu9gBREbCX39ZGo5YKy0tjaioKLp06eJU3qVLF3bs2JGvddjtdpKTk6lSpUqudVJTU0lKSnKaREREpGxS0klEpABsNujdG2JjzRuDZdq1y7wUb+JE+Ocf6+ITyWbMGHPnPHUKRoywOhqx0IkTJ8jIyCA4ONipPDg4mISEhHyt45VXXiElJYVevXrlWmf69OkEBAQ4pho1alxW3CIiIlJyKekkIlIIVarAggWweTPUr2+Wpaebd7Zr2hS++MLS8ESyeHnBwoXg6QkrV5rXhUqZZrPZnJ4bhpGtLCfLli1jypQprFixgqDM7p45GD9+PImJiY7pyJEjlx2ziIiIlExKOomIXIYOHWDvXnjmGfD2Nst++w06dYIBA+DECSujE/lXs2bw5JPm46FDzV5PUuYEBgbi6emZrVfTsWPHsvV+utiKFSsYNGgQH3zwAZ06dcqzro+PD5UqVXKaREREpGxS0klE5DL5+prD5uzdC+3aZZUvXgwNGsDcuWYvKBFLPf20uUMmJMDYsVZHIxYoV64cLVq0YNOmTU7lmzZtom3btrkut2zZMgYMGMDSpUvp2rVrUYcpIiIipYiSTiIiLtKoEWzdCm+8AQEBZtnJkzBsmHnJ3aef6q71YiFfX/NudjYbLFoEn39udURigdGjR/PWW2+xaNEiYmNjGTVqFHFxcQwZMgQwL43r16+fo/6yZcvo168fr7zyCjfccAMJCQkkJCSQmJho1VsQERGREkRJJxERF/LwgEcfNQcav+++rPLYWLjjDrjtNt3lTizUrp15u0WAhx+GlBRr45Fi17t3b2bNmsXUqVNp1qwZW7duZf369YSHhwMQHx9PXFyco/78+fNJT09n2LBhhISEOKbHH3/cqrcgIiIiJYjNMPR/9/xKSkoiICCAxMREl45PYLfbOXbsGEFBQXh4KA94MbVP3tQ+ebO6fXbuhNGjzbvbZfLwMO98N3UqXGIYlSJndfu4u1LZPmfOwDXXQFwcREbCq69e1urctY2K6jtbCk7bQkREpGQoiu9s9zk7FBEphdq0gR07YPly+LcjAXY7vPkmXH01TJ8O585ZG6OUMRUqmDsgwGuvmZlREREREZEioKSTiEgRs9mgd2/46Sd48UWoWNEsP3MGJkwwx3ZevlzjPUkxuvVW6N/f3OkGDYLUVKsjEhEREZFSSEknEZFi4utr3rX+t99gyBDzMjuAw4fh/vuhbVt1OpFiNHOmeX1nbCy88ILV0YiIiIhIKaSkk4hIMQsKgnnz4PvvzQ4nmXbtMhNP990Hhw5ZFp6UFVWqwJw55uPp0+GHH6yNR0RERERKHSWdREQs0rgxfPYZfPopNGqUVb5ihXnJ3VNPQVKSdfFJGXDPPdCjB6Snm5fZpadbHZGIiIiIlCJKOomIWOy228xeT/PmQbVqZllqKvz3v+Zg4/PnKxcgRWj2bKhcGfbsgVmzrI5GREREREoRJZ1ERNyAl5c5ztOvv5rjPpUrZ5YfP26WN2sGGzZYGqKUViEh5vhOAE8/be6EIiIiIiIuoKSTiIgbCQgw73D300/mHe8yxcSYPaJuvhm2bLEuPimlBgyATp3g3Dl4+GGw262OSERERERKASWdRETcUK1asHw57NgBrVtnlW/eDBERcMstsHWrVdFJqWOzwZtvQvnyZlZzwQKrIxIRERGRUkBJJxERN9amDezcCcuWQd26WeVffQUdOij5JC5UqxZMm2Y+HjcOjh61Nh4RERERKfGUdBIRcXM2G9x3H+zfD++9l3PyqWNH2LbNuhillBg+3Mx0Jiebg4kZhtURiYiIiEgJpqSTiEgJ4eUFDzxgJp/efdc5+fTll3DTTUo+yWXy9IS33jJHsl+3zrzGU0RERESkkJR0EhEpYby84MEHzeTT4sVw9dVZ8zKTT506wfbt1sUoJVijRuZd7ABGjjRvoSgiIiIiUghKOomIlFBeXtCvH8TGZk8+ffEFtG+v5JMU0hNPQNOmcOIEPP641dGIiIiISAmlpJOISAl3YfLpnXegTp2seZnJp86d4euvLQtRSppy5WDhQvDwMEex/+QTqyMSERERkRJISScRkVLCywv694effsqefPr8c7jxRjP5tGWLxoeWfGjZEsaMMR8/9hgkJlobj4iIiIiUOEo6iYiUMhcmn95+G2rXzpr3+ecQEQHXXw9Ll8L585aFKSXBs8+a123+8Qc8+aTV0YiIiIhICaOkk4hIKeXlBQMG5Jx8ioqCvn2hTh0bc+b4c+qUZWGKO/PzM+9mBzB/PmzebGk4IiIiIlKyKOkkIlLKeXtnJZ+WLIHrrsua98cfNp5/viLh4TZGjoQDBywLU9xVhw4wZIj5ePBgOHvW2nhEREREpMRQ0klEpIzw9jZ7N+3ZY47rdOedYLOZgzulpNj43//MK6nuucccdFzjPonDf/8LYWHw++8webLV0YiIiIhICaGkk4hIGWOzwU03wccfw/79BgMGpODnZ2aYDAM+/NAcdLxNG/jgA0hPtzhgsV6lSvDGG+bjmTNh925r4xERERGREkFJJxGRMqxePZg+PZnDhw2mTYOQkKx533wDvXubd8GbOVM3LyvzunaFPn3AbodBgyAtzeqIRERERMTNKekkIiJUrQrjx8OhQ7B4MVx7bda8uDgYMwZq1IBRoyA21rIwxWqvvQaBgbBvn3nJnYiIiIhIHpR0EhERh3LloF8/iI6GL74wO7dkSk6GWbOgUSPz8rz33oN//rEsVLFCYCD873/m4+eeg5gYa+MREREREbempJOIiGRjs8Ett8D//Z/Zs+mRR8DXN2v+tm1mcio0FEaOhB9/tC5WKWa9e0O3bnD+vHmZXUaG1RGJiIiIiJtS0klERPLUoAHMnw9//JHV0ynT6dNmx5cmTaBtW3jnHTh71qJApXjYbDB3rjm4+DffwOzZVkckIiIiIm5KSScREcmXKlXg8cfNXk3bt0P//s69n3buhIceMgcjHzYM9u61LFQpamFhMGMGALZJk/A8fNjigERERETEHSnpJCIiBWKzQbt2Zq+mP//M6umUKSnJ7AjTvDm0agULFpjjQUkpM3gwRERgO3uWSuPGgWFYHZGIiIiIuJkSl3SaPn06NpuNyMhIR5lhGEyZMoXQ0FD8/PyIiIgg5qLBTVNTUxkxYgSBgYH4+/tz5513cvTo0WKOXkSkdLniChg+HL7/HnbtgoEDoXz5rPm7d5vjQQUFmUMBrV0LaWnWxSsu5OEBCxZg+Pnhs20bvP221RGJiIiIiJspUUmn3bt38+abb9K0aVOn8pdeeomZM2cye/Zsdu/eTfXq1encuTPJF/xrPTIykjVr1rB8+XK2b9/OmTNn+M9//kOGBkAVEblsNhu0bg0LF0J8PMybB82aZc0/dw4++ADuuguqV4dHH4UtW8ButyxkcYWrr8aYOhUA29ixZtc3EREREZF/lZik05kzZ+jbty8LFizgiiuucJQbhsGsWbOYOHEiPXr0oHHjxixevJizZ8+ydOlSABITE1m4cCGvvPIKnTp1onnz5ixZsoR9+/bx+eefW/WWRERKpUqVYMgQ+O47s6fT0KFQtWrW/FOn4M03ISICwsPhiSfMnlK6OquEGjmStGbNsCUmmhtbG1JERERE/uVldQD5NWzYMLp27UqnTp14/vnnHeUHDx4kISGBLl26OMp8fHzo0KEDO3bs4NFHHyUqKorz58871QkNDaVx48bs2LGDW2+9NcfXTE1NJTU11fE8KSkJALvdjt2F/5632+0YhuHSdZYmap+8qX3ypvbJW1G3z3XXmdPMmbBpEyxdauPjj+HsWRsAR4+a41HPmAGNGhn06WNw331Qq1aRhFNg2n8uze7hQeIrrxB4663YPv4Y+wcfQM+eVoelbSYiIiLiBkpE0mn58uV899137N69O9u8hIQEAIKDg53Kg4ODOfzv3XQSEhIoV66cUw+pzDqZy+dk+vTpPPvss9nKjx8/zrlz5wr8PnJjt9tJTEzEMAw8PEpM57Nio/bJm9onb2qfvBVn+7RsaU7PP2/js898WLPGl82bfUhPNxNQ+/fbmDTJxqRJcN11adx2Wyq3336Oq6+27jJo7T+XZrfbSQwJwXfECCq++irG8OGcaNIEo0oVS+NK1uj1IiIiIpZz+6TTkSNHePzxx9m4cSO+F96b+yI2m83puWEY2coudqk648ePZ/To0Y7nSUlJ1KhRg2rVqlGpUqV8voNLs9vt2Gw2qlWrph81OVD75E3tkze1T96sap8hQ8zp+HGDVasMli2z8fXXWZ/H331Xju++K8e0aRVp2NDgrruge3eDli3N8aOKi/afS8tsI7/nnsPYsAHP/fsJevFFjHfesTSuvM4ZRERERKR4uH3SKSoqimPHjtGiRQtHWUZGBlu3bmX27Nn8/PPPgNmbKSQkxFHn2LFjjt5P1atXJy0tjVOnTjn1djp27Bht27bN9bV9fHzw8fHJVu7h4eHyHx82m61I1ltaqH3ypvbJm9onb1a2T3AwDBtmTocOwbJl5rRvX1ad2FgbsbHw4os2rrwSunc3pw4dwNu76GPU/nNpNpsNDz8/bIsWQZs22N57D1ufPnDbbZbFpO0lIiIiYj23PyPr2LEj+/btY+/evY6pZcuW9O3bl71791K7dm2qV6/Opk2bHMukpaWxZcsWR0KpRYsWeHt7O9WJj4/nxx9/zDPpJCIixadmTRg/Hn74AX77DV5+GW680bln0x9/wJw50LkzBAXBgw/CihXw99+WhS0Xat0aIiPNx48+CrrETURERKRMc/ueThUrVqRx48ZOZf7+/lStWtVRHhkZybRp06hbty5169Zl2rRplC9fnj59+gAQEBDAoEGDGDNmDFWrVqVKlSqMHTuWJk2a0KlTp2J/TyIikrc6dWDMGHP66y/45BNYswY+/xzS0sw6p0/DkiXm5OEBrVqZHWtuu80cO8rT09K3UHY99xx89BEcPGhmEWfPtjoiEREREbGI2/d0yo8nnniCyMhIhg4dSsuWLfnjjz/YuHEjFStWdNR59dVX6d69O7169aJdu3aUL1+eTz75BE/9KhERcWvBwTB4MKxbBydOmD2b7r8fLhxaz26HXbtgyhS44QazF9R998E770B8vFWRl1H+/rBggfl4zhzYts3aeERERETEMjbDMAyrgygpkpKSCAgIIDEx0eUDiR87doygoCCNQZEDtU/e1D55U/vkrSS3T2oqbN0KGzbAZ59BTEzudZs2hZtvhogIuOkmyO+N1Upy+xSXXNto8GBYuBDq1YPvv4diHti7qL6zpeC0LUREREqGovjO1hm0iIiUSD4+5thOL78MP/4IcXFmB5t774WAAOe6P/wAr70Gd98NgYHQrJk59NCaNXDypBXRlwEvvwwhIfDLLzB1qtXRiIiIiIgFlHQSEZFSoUYNs3PNypXmZXjbt8PTT5vjO104GLlhmB1vXnsNevQwk1DXXgvDh8P778OBA2YduUyVK8Pcuebjl16C6Gjz8fHjcOSIZWGJiIiISPFR0klEREodLy9o187sYLN7t3l3u7VrYfRoaNHCHHj8Qj/8YA4/9MAD5iDm1avDXXfBf/8LO3Z4k5Jizfso8bp3h169ICMDBg6E8+fNDdO4MSQlWR2diIiIiBQxt797nYiIyOWqXBm6dTMnMO98t307bN5sTtHR5mDkmY4dM5NUa9d6AFXx9DRo1Aiuu86cWrQwe0dVqFDsb6Xkef1187aDe/eal9wlJ5sJp99+MxtTREREREotJZ1ERKTMqVwZ/vMfcwJITIRvv4WdO81p1y4zMZUpI8PGvn2wbx8sXmyW2WzQoIGZN2neHJo0Mafq1Z0v5yvTMjLMbmYzZ8KAAfDss+bA4gkJ5iV2SjqJiIiIlGpKOomISJkXEGAOSt65s/ncbjfHv/76aztffXWOffv82L/fRnp61jKGAbGx5vT++1nlVatmJaAyp8aNy2ivqGnT4JlnoE0bc9q5E/7805yncZ1ERERESj0lnURERC7i4WH2YqpXD7p2TSIoyJe0NLO3U1QUfPedOe3bB2lpzsuePJl12d6FrrrKXGeDBtCwYdbj4OBS3DOqTRvw9zeTTTabOdhW5u0ClXQSERERKfWUdBIREckHX1+4/npzypSWBjEx5kDk+/Zl/U1IyL58XJw5bdzoXB4QAPXrQ926cPXV5kDmV19tToGBJTwh1amT2WXsiSfM7mAXdhX76Sfr4hIRERGRYqGkk4iISCGVK2eO59S8uXP5iRM4xoDatw9+/NG8DC8xMfs6MseT+vbb7PMqVjSTUDVrZk3h4Vl/K1cuAUmp0FBYsgSGDIERI8wBxQG++cbSsERERESk6CnpJCIi4mKBgXDzzeaUyTDMu+LFxpqdfC6cDh/OeT3JyWaOJjNPczF/fwgLgxo1zL9hYXDllRASYk6hoeble97ern6HhXDjjbBnjznO03PPQaNGVkckIiIiIkVMSScREZFiYLOZCaDgYIiIcJ73zz9w8CD89hv8/rv5N3M6fNi8CVxOUlLg55/NKS9Vq0JQkPnaQUFQrZqZGMucqlaFKlXM6YoroFIlc1wrl/P0hKefNicRERERKfWUdCqMtLTsI8eCeYbu5eVcLzc2m/O/njPXmdNZ/sV1z583/2Wen/W6qi6Y15EUpm56unkrqMLWtduz2sfHJ+takkut19u7cHUzMnL/hVfQul5eWdu0KOvmtf9cWNdudx5T5WKenubkLnUNw9zXLqdu5v6Tnp61r11qvRceywWpC3kf95f7GZHfugU97nPbf0rKZ8SFCnvc51Y3c/+58L0UwWeEnx80qp9Bo6uz101PN2/4duioF4fiPDh0COIOZnDkUAZ//mmOx332n4uWwQsDc3t6kEHSyQySTsJvsdlDuLCuDTtepGPDTDwFBJiX+FWqZP71r+RJ+Yqe+PtDhfJ2Kvim4+trJz3di2rV0vDz86CcD/iUA29fT3PyBm9Pc72ZH0ceHmYTZU4e3p40uMbFnxF5HTMiIiIiUiyUdCqMV14xkx8Xq1sX+vbNej5jRu4nwzVrwoABjqf+CxZgyzwLv1hoKDzySNbzOXPg9Omc11utGgwblvX8zTfh+PGc61auDJGRWc/ffjvrVtYXK1/eHAg20/vvw6FDOdf19oaJE7Oer1gBv/6ac12AKVOyHn/4Iezf7zTbZhhUSEnB5u9vrjfzB+j//V/u15wAjBtnXnsCsGED7N6de93ISLM9AL74AnbsyL3u0KFmVwGAbduy36LqQg8/bF7rArBrF2zalHvdAQPM/QLM22OtX5973T59zNtqAezbR4WlS832yWn/6dkTrrnGfBwbCytX5r7e7t2hWTPz8W+/wdKlude94w5o1cp8HBcH77yTe93OnaFdO/NxfDwsWJB73YiIrG4gx4/D3Lm5123bFrp0MR8nJsKsWdmqZO4/dOgA3bqZhWfPmsdnbpo1M9sCzGN42rTc6zZqBL16ZT3Pq+5lfEYwa5YZd04u5zNiwQIqHDqU8/5TQj4jnEyY4NLPCMf+M2GC2Q0Iiv0zwgu4CrhqwABuiqhpFn6b9RlhGHDuHCQlmVNyMuyq3Ycf0+oRHw8VfttHy6MfceYMnM8hl7OSnuzH/IxoSCw9+fczIunf6QIf0Z3vaQZAXX6jD0s58++8i+9Ft5472I35GRFOHAN4J9dm+KZiZz5NcvFnRGpq7usQERERkWKhpJOIiEgJZrOBn585BQebZdf1Af7NS7MX+Mh8mJZmXpJ39mzWVKsu/OYDf/8N5Q9CnZ/NfM25c+aUmppzskpERERE5FJshpHX9Q9yoaSkJAICAkg8fpxKlSplr1DIS2fsdjvHjh4lKCgID11el62u3W7n2LFjZvvo8rpsde3nz3MsPj73/aeMX17n2H+qV8dDl9dlq2tPTeXYX3/lvP+UkM8IJy6+vM6x/1x5JR6Z+1oJ+4woUN1cjs/z5+HMGTjzjydn/vEkJQXOJNk5dyadMyl2jv2VhLd3JdLSPEhNNXfX1HRPUtM9OX8eMs7bMc6nO5rZbjd3j8xdxNffk9dmu/YzIikpiYBq1UhMTMz5O1uKjeP8SdtCRETErRXFd7Z6OhVGuXLOP4LyqlfQdeZn5NaC3IbIHep6FWA3y6mu3Z7VPhde/nO5683NhT9oSkrd/O4/Hh753y/doa7Ndvl1M/efC/cBV6w3N+5Qt6DHcn73H3f9jCjKupn7z4WfPe5y3BdF3VyOT+9ycIU/XOFcGSj3b2LOTlBQuZwT3xfUvZwYcpTX8VmQY0ZEREREikRR3JtGRERERERERETKOCWdRERERERERETE5ZR0EhERERERERERl1PSSUREREREREREXE5JJxERERERERERcTklnURERERERERExOWUdBIREREREREREZdT0klERERERERERFxOSScREREREREREXE5JZ1ERERERERERMTllHQSERERERERERGXU9JJREREpAyZO3cutWrVwtfXlxYtWrBt27Y862/ZsoUWLVrg6+tL7dq1eeONN4opUhERESnplHQSERERKSNWrFhBZGQkEydOJDo6mvbt23P77bcTFxeXY/2DBw9yxx130L59e6Kjo5kwYQIjR45k9erVxRy5iIiIlERKOomIiIiUETNnzmTQoEEMHjyYhg0bMmvWLGrUqMG8efNyrP/GG29w1VVXMWvWLBo2bMjgwYMZOHAgL7/8cjFHLiIiIiWRl9UBlCSGYQCQlJTk0vXa7XaSk5Px9fXFw0N5wIupffKm9smb2idvap+8qX0uzV3bKPO7OvO7WyAtLY2oqCieeuopp/IuXbqwY8eOHJfZuXMnXbp0cSq79dZbWbhwIefPn8fb2zvbMqmpqaSmpjqeJyYmAq4/fxIRERHXKorzJyWdCiA5ORmAGjVqWByJiIiI5EdycjIBAQFWh+EWTpw4QUZGBsHBwU7lwcHBJCQk5LhMQkJCjvXT09M5ceIEISEh2ZaZPn06zz77bLZynT+JiIiUDCdPnnTZ+ZOSTgUQGhrKkSNHqFixIjabzWXrTUpKokaNGhw5coRKlSq5bL2lhdonb2qfvKl98qb2yZva59LctY0MwyA5OZnQ0FCrQ3E7F5/DGIaR53lNTvVzKs80fvx4Ro8e7Xh++vRpwsPDiYuLUwLQQu56rJZF2hbuQ9vCPWg7uI/ExESuuuoqqlSp4rJ1KulUAB4eHoSFhRXZ+itVqqSDLA9qn7ypffKm9smb2idvap9Lc8c2UoLDWWBgIJ6entl6NR07dixbb6ZM1atXz7G+l5cXVatWzXEZHx8ffHx8spUHBAS43T5SFrnjsVpWaVu4D20L96Dt4D5cOWSC+wy+ICIiIiJFply5crRo0YJNmzY5lW/atIm2bdvmuEybNm2y1d+4cSMtW7bMcTwnERERkQsp6SQiIiJSRowePZq33nqLRYsWERsby6hRo4iLi2PIkCGAeWlcv379HPWHDBnC4cOHGT16NLGxsSxatIiFCxcyduxYq96CiIiIlCC6vM4N+Pj4MHny5By7oova51LUPnlT++RN7ZM3tc+lqY1Klt69e3Py5EmmTp1KfHw8jRs3Zv369YSHhwMQHx9PXFyco36tWrVYv349o0aNYs6cOYSGhvL6669zzz335Ps1tY+4B20H96Ft4T60LdyDtoP7KIptYTN0L2EREREREREREXExXV4nIiIiIiIiIiIup6STiIiIiIiIiIi4nJJOIiIiIiIiIiLicko6iYiIiIiIiIiIyynp5Abmzp1LrVq18PX1pUWLFmzbts3qkNzC1q1b6datG6GhodhsNj766COrQ3Ir06dP5/rrr6dixYoEBQXRvXt3fv75Z6vDchvz5s2jadOmVKpUiUqVKtGmTRs+/fRTq8NyW9OnT8dmsxEZGWl1KG5hypQp2Gw2p6l69epWh+VW/vjjDx544AGqVq1K+fLladasGVFRUVaHJRYo6HnMli1baNGiBb6+vtSuXZs33nijmCIt/QqyLT788EM6d+5MtWrVHN+TGzZsKMZoS7fCnt9//fXXeHl50axZs6INsIwo6HZITU1l4sSJhIeH4+PjQ506dVi0aFExRVu6FXRbvP/++1x77bWUL1+ekJAQHnroIU6ePFlM0ZZOhfl97YrvbCWdLLZixQoiIyOZOHEi0dHRtG/fnttvv93pdsVlVUpKCtdeey2zZ8+2OhS3tGXLFoYNG8auXbvYtGkT6enpdOnShZSUFKtDcwthYWG8+OKL7Nmzhz179nDLLbdw1113ERMTY3Vobmf37t28+eabNG3a1OpQ3Mo111xDfHy8Y9q3b5/VIbmNU6dO0a5dO7y9vfn000/Zv38/r7zyCpUrV7Y6NClmBT2POXjwIHfccQft27cnOjqaCRMmMHLkSFavXl3MkZc+Bd0WW7dupXPnzqxfv56oqChuvvlmunXrRnR0dDFHXvoU9vw+MTGRfv360bFjx2KKtHQrzHbo1asXX3zxBQsXLuTnn39m2bJlNGjQoBijLp0Kui22b99Ov379GDRoEDExMaxcuZLdu3czePDgYo68dCno72uXfWcbYqlWrVoZQ4YMcSpr0KCB8dRTT1kUkXsCjDVr1lgdhls7duyYARhbtmyxOhS3dcUVVxhvvfWW1WG4leTkZKNu3brGpk2bjA4dOhiPP/641SG5hcmTJxvXXnut1WG4rSeffNK48cYbrQ5D3EBBz2OeeOIJo0GDBk5ljz76qHHDDTcUWYxlhSvOKRs1amQ8++yzrg6tzCnstujdu7cxadIkfQe5SEG3w6effmoEBAQYJ0+eLI7wypSCbosZM2YYtWvXdip7/fXXjbCwsCKLsazJz+9rV31nq6eThdLS0oiKiqJLly5O5V26dGHHjh0WRSUlVWJiIgBVqlSxOBL3k5GRwfLly0lJSaFNmzZWh+NWhg0bRteuXenUqZPVobidX3/9ldDQUGrVqsV9993HgQMHrA7Jbaxdu5aWLVvSs2dPgoKCaN68OQsWLLA6LClmhTmP2blzZ7b6t956K3v27OH8+fNFFmtp54pzSrvdTnJyss4jLlNht8Xbb7/N77//zuTJk4s6xDKhMNsh87vtpZde4sorr6RevXqMHTuWf/75pzhCLrUKsy3atm3L0aNHWb9+PYZh8Ndff7Fq1Sq6du1aHCHLv1z1ne3l6sAk/06cOEFGRgbBwcFO5cHBwSQkJFgUlZREhmEwevRobrzxRho3bmx1OG5j3759tGnThnPnzlGhQgXWrFlDo0aNrA7LbSxfvpzvvvuO3bt3Wx2K22ndujXvvvsu9erV46+//uL555+nbdu2xMTEULVqVavDs9yBAweYN28eo0ePZsKECXz77beMHDkSHx8f+vXrZ3V4UkwKcx6TkJCQY/309HROnDhBSEhIkcVbmrninPKVV14hJSWFXr16FUWIZUZhtsWvv/7KU089xbZt2/Dy0s8zVyjMdjhw4ADbt2/H19eXNWvWcOLECYYOHcrff/+tcZ0uQ2G2Rdu2bXn//ffp3bs3586dIz09nTvvvJP//e9/xRGy/MtV39n6VHMDNpvN6blhGNnKRPIyfPhwfvjhB7Zv3251KG6lfv367N27l9OnT7N69Wr69+/Pli1blHgCjhw5wuOPP87GjRvx9fW1Ohy3c/vttzseN2nShDZt2lCnTh0WL17M6NGjLYzMPdjtdlq2bMm0adMAaN68OTExMcybN09JpzKooOcxOdXPqVwKrrDnlMuWLWPKlCl8/PHHBAUFFVV4ZUp+t0VGRgZ9+vTh2WefpV69esUVXplRkGPCbrdjs9l4//33CQgIAGDmzJnce++9zJkzBz8/vyKPtzQryLbYv38/I0eO5JlnnuHWW28lPj6ecePGMWTIEBYuXFgc4cq/XPGdraSThQIDA/H09MyW4T127Fi2jKJIbkaMGMHatWvZunUrYWFhVofjVsqVK8fVV18NQMuWLdm9ezevvfYa8+fPtzgy60VFRXHs2DFatGjhKMvIyGDr1q3Mnj2b1NRUPD09LYzQvfj7+9OkSRN+/fVXq0NxCyEhIdmStw0bNtRg0GVMYc5jqlevnmN9Ly8v9SK8DJdzTrlixQoGDRrEypUrdam1CxR0WyQnJ7Nnzx6io6MZPnw4YCY/DMPAy8uLjRs3cssttxRL7KVJYY6JkJAQrrzySkfCCczvNsMwOHr0KHXr1i3SmEurwmyL6dOn065dO8aNGwdA06ZN8ff3p3379jz//PPqFVtMXPWdrTGdLFSuXDlatGjBpk2bnMo3bdpE27ZtLYpKSgrDMBg+fDgffvghX375JbVq1bI6JLdnGAapqalWh+EWOnbsyL59+9i7d69jatmyJX379mXv3r1KOF0kNTWV2NhYneT8q127dvz8889OZb/88gvh4eEWRSRWKMx5TJs2bbLV37hxIy1btsTb27vIYi3tCntOuWzZMgYMGMDSpUs1VoqLFHRbVKpUKdv38ZAhQxy9tVu3bl1coZcqhTkm2rVrx59//smZM2ccZb/88gseHh76x+5lKMy2OHv2LB4ezqmKzHPTzJ42UvRc9p1doGHHxeWWL19ueHt7GwsXLjT2799vREZGGv7+/sahQ4esDs1yycnJRnR0tBEdHW0AxsyZM43o6Gjj8OHDVofmFh577DEjICDA2Lx5sxEfH++Yzp49a3VobmH8+PHG1q1bjYMHDxo//PCDMWHCBMPDw8PYuHGj1aG5Ld29LsuYMWOMzZs3GwcOHDB27dpl/Oc//zEqVqyoz+Z/ffvtt4aXl5fxwgsvGL/++qvx/vvvG+XLlzeWLFlidWhSzC51HvPUU08ZDz74oKP+gQMHjPLlyxujRo0y9u/fbyxcuNDw9vY2Vq1aZdVbKDUKui2WLl1qeHl5GXPmzHE6jzh9+rRVb6HUKOi2uJjuXucaBd0OycnJRlhYmHHvvfcaMTExxpYtW4y6desagwcPtuotlBoF3RZvv/224eXlZcydO9f4/fffje3btxstW7Y0WrVqZdVbKBUu9fu6qL6zlXRyA3PmzDHCw8ONcuXKGdddd51uef+vr776ygCyTf3797c6NLeQU9sAxttvv211aG5h4MCBjuOqWrVqRseOHZVwugQlnbL07t3bCAkJMby9vY3Q0FCjR48eRkxMjNVhuZVPPvnEaNy4seHj42M0aNDAePPNN60OSSyS13lM//79jQ4dOjjV37x5s9G8eXOjXLlyRs2aNY158+YVc8SlV0G2RYcOHXSeVYQKelxcSEkn1ynodoiNjTU6depk+Pn5GWFhYcbo0aP1D10XKei2eP31141GjRoZfn5+RkhIiNG3b1/j6NGjxRx16XKp39dF9Z1tMwz1TxMREREREREREdfSmE4iIiIiIiIiIuJySjqJiIiIiIiIiIjLKekkIiIiIiIiIiIup6STiIiIiIiIiIi4nJJOIiIiIiIiIiLicko6iYiIiIiIiIiIyynpJCIiIiIiIiIiLqekk4iIiIiIiIiIuJySTiJuoGbNmthsthynQ4cOOepFREQwZcoUp2X/+usv7r//foKCgqhcuTIRERF8++23ub7WoUOHsq03L9dffz2vv/664/mAAQNo3Lhxnss899xzdO7cmYCAAGw2G3v27MnXa5VmmzZtomnTpvj4+FC5cmWrw3F44oknCAkJwcPDg8jISCDnWGvWrMnw4cMLtG6bzcbLL7/s4ohNH330EXPnzi3wcs8//zydO3cugohERERERORiSjqJuIEOHTrg6enJkiVL2Llzp9MUEhKS57KPPPIIGzZs4MUXX2TVqlX4+/tz5513cu7cucuO68MPP+Tw4cM8/PDDBVpu/vz5pKWl6cf9Bfr160dYWBiff/45n3/+udXhALBhwwZmzJjBk08+yddff82oUaOAnGNds2YNY8eOLdD6d+7cSd++fV0eNxQ+6TR8+HC++eYbvvzyyyKISkRERERELuRldQAiAm+88QY//vgj06ZNY9euXVSsWDFfy6Wnp7Nu3TqeeeYZBg4cCEBwcDBNmzYlNjaW5s2bX1Zcs2bNok+fPvj5+RVoubi4ODw8PNi8eTOrV6++rBhcxTAM0tLS8PHxKfbXPn36NAkJCdx77720b9++2F8/N7GxsQCMHDkSDw/zfxC5xVqYfemGG25wTaAuVLlyZe6++25ee+01brnlFqvDEREREREp1dTTSeRfMTEx3HHHHVStWpXy5ctTv359XnrppWJ5bT8/P9asWcPx48d54IEHMAwjX8vFx8eTkZFB/fr1HWUJCQkAeHldXk75wIEDbNu2jXvvvbfAy2YmMAoq89K9zZs307x5c/z9/WnVqhVRUVFO9c6dO8eYMWO48sor8fHxoUmTJixdujTHda1fv55rr70WHx8f1q5dy5QpU6hQoQJRUVG0bt0aPz8/mjdvTlRUFOfOneOxxx6jSpUqhIWFMWvWrHzF/eabb9KwYUN8fHy46qqrmDRpEunp6QC88847XHHFFQAMGjQIm83GgAEDcl1XamoqkyZNonbt2vj4+BAWFsZDDz3kVOejjz6iefPm+Pr6Ur16dYYNG8aZM2ec6pw+fZqhQ4cSEhKCj48PLVq0YOPGjY75ERERjp5Nnp6e2Gy2PGPN6fK6nTt30qVLFypVqkTFihVp3bo1mzZtcszP6fK6devWOdq9WrVqPPbYY6SkpDjmb968GZvNxsaNG+nTpw8VK1YkPDzc6VgcMGAAixcvJiYmxnEZamac+TmOe/bsyfr16zl+/Hiu20FERERERC6fkk4i/7rzzjs5deoUCxcuZN26dYwdO9bpx3BO7HY76enpl5zy46qrrmLVqlWsX7+eZ555Jl/LZGRkAGbSICUlxXGJ1NVXX80111yTr3Xk5osvvsDb25vrr7/+stZTUAkJCYwcOZJx48axYsUKzp49y91338358+cddfr27cvcuXMZPXo0a9eupWXLlvTt25f33nvPaV1//vknjz/+OKNHj+azzz6jWbNmAJw/f56BAwfy2GOPsXr1atLT0+nRoweDBg3Cz8+PFStW0L17d0aNGsWOHTvyjPd///sfjz76KLfccgtr165lyJAhvPTSSzz66KMAdO3alc8++wyASZMmsXPnTp5++ulc13fPPfcwc+ZMBg4cyLp165gxYwbJycmO+WvXrqVHjx7Uq1ePNWvW8PTTT/Pee+/RvXt3R53MSxv/7//+jxdeeIG1a9fSqFEjunbtyr59+wCYO3cuI0aMAHBcynnzzTfnO9avv/6aiIgIUlNTeeutt1i9ejV33XUXcXFxub63VatWceedd9KkSRPWrFnDSy+9xIcffsigQYOy1X3ssccc77Fr1648+eSTjtiefvpp7rjjDmrXru2IPTPO/BzH7dq1Iz09nc2bN+caq4iIiIiIuIAhIsbx48cNwFi7dm2Blps8ebIBXHI6ePBgvtf55JNPGjabzYiKiso2r0OHDsbkyZMdzw8ePGgAxsqVK42OHTs6Xu+9995zWq53795Gamqq0zKXiumRRx4xrrnmmmzl/fv3z7E8J1999ZUBGLt3785X/f79+xs2m8348ccfHWWbNm0yAGPbtm2GYRjG999/bwDGnDlznJbt0qWLER4e7rQuwPjmm2+c6mVus08//dRR9sknnxiA0bt3b0dZenq6ERQUZERGRuYab3p6uhEYGGj07NnTqXzatGmGzWYzfv/9d8Mwsvavt99+O8/3v3HjRgMwli5dmmud5s2bG61atXIqW7p0qQEYX331lWEYhrFo0SLDy8vLiImJcarXqlUrp1hnzJhhXPw1kFus4eHhxrBhwxzP27ZtazRq1MhIT0/PNVbAmDFjhmEYhmG3243w8HDj/vvvd6qzbt06p22euc+MGzfOUScjI8OoUaOGMWjQIEdZTvthQY7jq666yhgzZswl64mIiIiISOGpp5MIULVqVcLDwxk/fjyLFy/m6NGj+VrukUceYffu3ZecQkND87W+pKQkli1bxk033VTgMXRmzZrFqlWrePDBB3nwwQd59dVXHfOWL19OuXLlCrS++Ph4qlWrVqBlXCE0NNSpl1ajRo0AHNtk27ZtAPTu3dtpufvvv5/Dhw9z5MgRR1lgYCCtWrXK9hoeHh5O4/nUq1cPgE6dOjnKPD09qVOnjtP6LvbTTz9x4sSJHGMxDIOvv/467zd7kS+++ILy5ctz33335Tj/zJkz7N27l169ejmV9+zZEy8vL0fbbNy4kSZNmlCvXj2nHncdO3Zk9+7dBYopJ2fPnmXXrl30798fT0/PfC3zyy+/cPjwYXr16uUUU4cOHXK8w2GXLl0cjz08PGjQoMElj8uCHMeBgYGOS1FFRERERKRoaCBxEcyxZzZs2MCkSZMYNmwYKSkpXHfddbz66qvcdNNNuS5XvXp1goKCLrn+/I6vNHLkSP7++2/HuDYF0bhxYxo3bsw999xDhQoVmDRpEsOHD8fb25uaNWvy008/4evrm+/1nTt3zpJBtytXruz0PDNZlnk3vlOnTuHl5UXVqlWd6lWvXh2Av//+mxo1agDkum38/PycknCZj3N67bzuAnjq1Cmn184ploI4efIkISEhuW7706dPYxhGttfLbI/M1ztx4gTR0dF4e3tnW0d+k0R5OXXqFHa7Pd/J1MyYAO6+++4c51+c3MtpW1w8btXFCnIc+/r68s8//+Q7fhERERERKTj1dBL5V/369Vm5ciWnTp1i8+bN+Pr60q1btzx/6E6dOhVvb+9LTocOHbrk63/88ccsXryYmTNnUqtWrct6LzfccANnz57l9OnThV5HlSpVLmv5olKlShXS09OzJXQye61UqVLFUVbQxF1hYgH466+/LhlLflStWpX4+PhcB5KvXLkyNpst2+ulp6dz8uRJx+tVqVKFpk2b5tjrbteuXQWKKbc4PDw8+PPPP/O9TGZss2fPzjGuzLsvXq78HsenTp3KlrgUERERERHXUtJJ5CLe3t506NCBp556iqSkpDx/WLvq8rrjx4/zyCOPcPvtt/Pwww8XOObDhw87PY+JicHf3/+yLo+rX78+Bw8eLPTyReXGG28E4IMPPnAqX7FiBeHh4Y5eTsWhfv36VKtWLcdYbDabI9b86tSpE2fPns22vkwVKlSgWbNm2eZnDobevn17x3oOHDhAaGgoLVu2zDZdLn9/f9q0acO7777rGMz+Uho0aEBYWBgHDhzIMaaC9JqCS/dCy+s4ttvtxMXFOd31UUREREREXE+X14kAP/zwA2PGjKF3797UqVOHxMREpk+fTs2aNalTp06uy4WGhhb4x3JOhg0bxt9//83gwYOz9URp1KgRlSpVynP5CRMmcPbsWdq3b8/333/P7NmzGTx48GXF1K5dO6ZOncrRo0cJCwtzmpeUlMSqVauyLdOhQweqVavGli1bOH78ODExMQB8+eWXHDp0iJo1a1520qNp06bcc889jB49mrNnz3LNNdfwwQcf8Nlnn/Huu+9e1roLytPTk2eeeYYRI0ZQrVo1unXrxnfffcfkyZN56KGHCtxjrVOnTtxxxx0MHDiQ33//ndatW/P333+zevVqli9fDsCUKVPo3r07999/P/379+fAgQOMHz+ejh07EhERAUC/fv2YP38+ERERjB07lnr16nH69Gmio6NJS0tj+vTpl/3eX3zxRW655RY6derE0KFDueKKK/juu+8IDAzMsdeSzWZj5syZ9OnTh5SUFLp27Yq/vz+HDx9m3bp1TJs2zTG2Vn40bNiQRYsWsWzZMurWrUtgYCBJSUn5Oo73799PSkqKI0knIiIiIiJFQ0knEcwxeKpXr8706dP5448/CAgIoH379ixZssQlY+Bcyrfffkt6ejr33HNPtnlfffWVI5mQm+7du/Pee+8xbdo0QkNDGTFiBJMnT76smCIiIggMDOTTTz/N1vvqyJEj9OzZM9dYJ0+ezJYtWxzlTz75JAD9+/fnnXfeuay4AJYsWcLEiRN5+eWXOXHiBPXq1WPJkiX07dv3stddUJnjZr366qvMnz+f4OBgxo0bx5QpUwq1vtWrV/Pss88yf/58pkyZQnBwsNOg2nfeeSerV69m6tSp3HXXXVSuXJkHHniA//73v446Pj4+fPnll0yZMoUXXniB+Ph4AgMDad68OUOHDr3ctwyYPc42b97MpEmTGDBgAJ6enlxzzTU8//zzuS7Ts2dPKleuzAsvvMCSJUsAqFmzJrfddhvBwcEFev1Bgwbx7bffMmLECE6ePEn//v156aWX8nUcr1+/nvDwcK6//vrCvXkREREREckXm5Hb4CEi4nYiIiKIiIhwJDQOHTpErVq1WLlyJffee2+uy9WoUYPDhw/j4eHhWObgwYPUrFkzz9cbM2YM0dHRfPnlly58FyLWuu666+jevTvPPPOM1aGIiIiIiJRqGtNJpJS7++676dGjBx4eBT/cx40bxzfffEN0dHQRRCZS/LZs2cKhQ4cYOXKk1aGIiIiIiJR6urxOpJRbs2ZNoZetXr0677zzDsePH3dhRCLWSUpK4t1336Vy5cpWhyIiIiIiUuop6SRSgtWsWZOivkI2p7GbREqqbt26WR2CiIiIiEiZoTGdRERERERERETE5TSmk4iIiIiIiIiIuJySTiIiIiIiIiIi4nJKOomIiIiIiIiIiMsp6SQiIiIiIiIiIi6npJOIiIiIiIiIiLickk4iIiIiIiIiIuJySjqJiIiIiIiIiIjLKekkIiIiIiIiIiIu9/+9xDdUNduBxAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simulate LASSO path\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(42)\n",
    "n, p = 100, 5\n",
    "\n",
    "# Generate data\n",
    "X = np.random.randn(n, p)\n",
    "true_beta = np.array([3, -2, 1.5, 0, 0])\n",
    "y = X @ true_beta + np.random.randn(n) * 2\n",
    "\n",
    "# Standardize\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# Try different values of s (via alpha in sklearn)\n",
    "# Note: sklearn uses alpha (penalty), we convert to approximate s\n",
    "alphas = np.logspace(2, -3, 100)\n",
    "train_rss = []\n",
    "coef_norms = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=10000)\n",
    "    lasso.fit(X_scaled, y)\n",
    "    y_pred = lasso.predict(X_scaled)\n",
    "    rss = np.sum((y - y_pred) ** 2)\n",
    "    train_rss.append(rss)\n",
    "    coef_norms.append(np.sum(np.abs(lasso.coef_)))\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(coef_norms, train_rss, 'b-', linewidth=2)\n",
    "ax.set_xlabel('s = Σ|βⱼ| (L1 norm of coefficients)', fontsize=11)\n",
    "ax.set_ylabel('Training RSS', fontsize=11)\n",
    "ax.set_title('(a) Training RSS vs s: STEADILY DECREASES', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=min(train_rss), color='r', linestyle='--', alpha=0.5, label='Minimum (s→∞)')\n",
    "ax.legend()\n",
    "\n",
    "# Annotate\n",
    "ax.annotate('s = 0\\n(Null model)', xy=(0, train_rss[0]), \n",
    "            xytext=(1, train_rss[0] - 500),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=1.5),\n",
    "            fontsize=10, color='red')\n",
    "ax.annotate('s → ∞\\n(Least Squares)', xy=(coef_norms[-1], train_rss[-1]), \n",
    "            xytext=(coef_norms[-1] - 2, train_rss[-1] + 500),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=1.5),\n",
    "            fontsize=10, color='red')\n",
    "\n",
    "print(\"\\n[Creating visualization...]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c277258",
   "metadata": {},
   "source": [
    "(b) Test RSS as s increases\n",
    "\n",
    "**Answer: ii. Decrease initially, and then eventually start increasing in a U shape.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e3af8a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "(b) TEST RSS\n",
      "======================================================================\n",
      "\n",
      "Logical reasoning:\n",
      "  1. At s = 0: High bias (underfitting)\n",
      "     - Model too simple, poor test performance\n",
      "     - Test RSS is HIGH\n",
      "\n",
      "  2. As s increases initially: Bias decreases faster than variance increases\n",
      "     - Model can capture true signal\n",
      "     - Test RSS DECREASES\n",
      "\n",
      "  3. Optimal s: Bias-variance tradeoff is balanced\n",
      "     - Test RSS reaches MINIMUM\n",
      "\n",
      "  4. As s increases further: Variance increases faster than bias decreases\n",
      "     - Model starts overfitting\n",
      "     - Test RSS INCREASES\n",
      "\n",
      "  5. As s → ∞: Least squares (potential overfitting)\n",
      "     - High variance, low bias\n",
      "     - Test RSS may be high again\n",
      "\n",
      "Conclusion: Test RSS has U-SHAPE (decreases then increases) ✓\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(b) TEST RSS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nLogical reasoning:\")\n",
    "print(\"  1. At s = 0: High bias (underfitting)\")\n",
    "print(\"     - Model too simple, poor test performance\")\n",
    "print(\"     - Test RSS is HIGH\")\n",
    "print(\"\\n  2. As s increases initially: Bias decreases faster than variance increases\")\n",
    "print(\"     - Model can capture true signal\")\n",
    "print(\"     - Test RSS DECREASES\")\n",
    "print(\"\\n  3. Optimal s: Bias-variance tradeoff is balanced\")\n",
    "print(\"     - Test RSS reaches MINIMUM\")\n",
    "print(\"\\n  4. As s increases further: Variance increases faster than bias decreases\")\n",
    "print(\"     - Model starts overfitting\")\n",
    "print(\"     - Test RSS INCREASES\")\n",
    "print(\"\\n  5. As s → ∞: Least squares (potential overfitting)\")\n",
    "print(\"     - High variance, low bias\")\n",
    "print(\"     - Test RSS may be high again\")\n",
    "print(\"\\nConclusion: Test RSS has U-SHAPE (decreases then increases) ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e500ed",
   "metadata": {},
   "source": [
    "Simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf090f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Plot saved: 'lasso_s_effect_rss.png']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate test data\n",
    "X_test = np.random.randn(n, p)\n",
    "y_test = X_test @ true_beta + np.random.randn(n) * 2\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "test_rss = []\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=10000)\n",
    "    lasso.fit(X_scaled, y)\n",
    "    y_pred_test = lasso.predict(X_test_scaled)\n",
    "    rss = np.sum((y_test - y_pred_test) ** 2)\n",
    "    test_rss.append(rss)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(coef_norms, test_rss, 'r-', linewidth=2, label='Test RSS')\n",
    "ax.set_xlabel('s = Σ|βⱼ| (L1 norm of coefficients)', fontsize=11)\n",
    "ax.set_ylabel('Test RSS', fontsize=11)\n",
    "ax.set_title('(b) Test RSS vs s: U-SHAPED', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Find minimum\n",
    "min_idx = np.argmin(test_rss)\n",
    "ax.axvline(x=coef_norms[min_idx], color='g', linestyle='--', alpha=0.5, label='Optimal s')\n",
    "ax.plot(coef_norms[min_idx], test_rss[min_idx], 'go', markersize=10, label='Minimum')\n",
    "ax.legend()\n",
    "\n",
    "# Annotate regions\n",
    "ax.annotate('Underfitting\\n(High Bias)', xy=(coef_norms[5], test_rss[5]), \n",
    "            xytext=(coef_norms[5] - 1, test_rss[5] + 500),\n",
    "            arrowprops=dict(arrowstyle='->', color='blue', lw=1.5),\n",
    "            fontsize=9, color='blue')\n",
    "ax.annotate('Overfitting\\n(High Variance)', xy=(coef_norms[-10], test_rss[-10]), \n",
    "            xytext=(coef_norms[-10] - 2, test_rss[-10] + 500),\n",
    "            arrowprops=dict(arrowstyle='->', color='blue', lw=1.5),\n",
    "            fontsize=9, color='blue')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('lasso_s_effect_rss.png', dpi=150, bbox_inches='tight')\n",
    "print(\"[Plot saved: 'lasso_s_effect_rss.png']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8441dfa",
   "metadata": {},
   "source": [
    "(c) Variance as s increases\n",
    "\n",
    "\n",
    "**Answer: iii. Steadily increase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6010e61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "(c) VARIANCE\n",
      "======================================================================\n",
      "\n",
      "Definition: Variance = E[(f̂(x₀) - E[f̂(x₀)])²]\n",
      "  → Measures variability of predictions across different training sets\n",
      "\n",
      "Logical reasoning:\n",
      "  1. At s = 0: No flexibility\n",
      "     - f̂(x) = β₀ (constant)\n",
      "     - Predictions don't vary with training data\n",
      "     - Variance = 0 (minimum)\n",
      "\n",
      "  2. As s increases: Model becomes more flexible\n",
      "     - Coefficients can be larger\n",
      "     - Model more sensitive to training data\n",
      "     - Variance INCREASES\n",
      "\n",
      "  3. As s → ∞: Least squares (maximum flexibility)\n",
      "     - Most sensitive to training data\n",
      "     - Variance = maximum\n",
      "\n",
      "Conclusion: Variance STEADILY INCREASES ✓\n",
      "\n",
      "Key principle:\n",
      "  More flexibility → More variance\n",
      "  Less constraint → More variance\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(c) VARIANCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nDefinition: Variance = E[(f̂(x₀) - E[f̂(x₀)])²]\")\n",
    "print(\"  → Measures variability of predictions across different training sets\")\n",
    "print(\"\\nLogical reasoning:\")\n",
    "print(\"  1. At s = 0: No flexibility\")\n",
    "print(\"     - f̂(x) = β₀ (constant)\")\n",
    "print(\"     - Predictions don't vary with training data\")\n",
    "print(\"     - Variance = 0 (minimum)\")\n",
    "print(\"\\n  2. As s increases: Model becomes more flexible\")\n",
    "print(\"     - Coefficients can be larger\")\n",
    "print(\"     - Model more sensitive to training data\")\n",
    "print(\"     - Variance INCREASES\")\n",
    "print(\"\\n  3. As s → ∞: Least squares (maximum flexibility)\")\n",
    "print(\"     - Most sensitive to training data\")\n",
    "print(\"     - Variance = maximum\")\n",
    "print(\"\\nConclusion: Variance STEADILY INCREASES ✓\")\n",
    "print(\"\\nKey principle:\")\n",
    "print(\"  More flexibility → More variance\")\n",
    "print(\"  Less constraint → More variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24845347",
   "metadata": {},
   "source": [
    "Conceptual Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8df89fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Creating bias-variance visualization...]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Variance illustration\n",
    "ax = axes[0, 0]\n",
    "s_values = np.linspace(0, 10, 100)\n",
    "variance = 0.1 + 0.5 * s_values  # Steadily increasing\n",
    "ax.plot(s_values, variance, 'b-', linewidth=3)\n",
    "ax.set_xlabel('s', fontsize=12)\n",
    "ax.set_ylabel('Variance', fontsize=12)\n",
    "ax.set_title('(c) Variance vs s: STEADILY INCREASES', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.fill_between(s_values, 0, variance, alpha=0.3)\n",
    "\n",
    "# Annotate\n",
    "ax.annotate('s = 0\\n(No flexibility)', xy=(0, variance[0]), \n",
    "            xytext=(2, variance[0] + 1),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=1.5),\n",
    "            fontsize=10, color='red')\n",
    "ax.annotate('s → ∞\\n(Max flexibility)', xy=(s_values[-1], variance[-1]), \n",
    "            xytext=(s_values[-1] - 3, variance[-1] - 1),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=1.5),\n",
    "            fontsize=10, color='red')\n",
    "\n",
    "print(\"\\n[Creating bias-variance visualization...]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc28134a",
   "metadata": {},
   "source": [
    "(d) (Squared) Bias as s increases\n",
    "\n",
    "**Answer: iv. Steadily decrease**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d10791bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "(d) (SQUARED) BIAS\n",
      "======================================================================\n",
      "\n",
      "Definition: Bias² = [E[f̂(x₀)] - f(x₀)]²\n",
      "  → Measures how far expected prediction is from true function\n",
      "\n",
      "Logical reasoning:\n",
      "  1. At s = 0: Maximum constraint\n",
      "     - f̂(x) = β₀ (overly simplistic)\n",
      "     - Cannot capture true relationship\n",
      "     - Bias² = maximum (high bias)\n",
      "\n",
      "  2. As s increases: Constraint relaxes\n",
      "     - Model can use more predictors\n",
      "     - Can better approximate true function f(x)\n",
      "     - Bias² DECREASES\n",
      "\n",
      "  3. As s → ∞: Least squares (unbiased)\n",
      "     - If model is correctly specified, bias → 0\n",
      "     - Bias² = minimum\n",
      "\n",
      "Conclusion: Bias² STEADILY DECREASES ✓\n",
      "\n",
      "Key principle:\n",
      "  More flexibility → Less bias\n",
      "  Less constraint → Less bias\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(d) (SQUARED) BIAS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nDefinition: Bias² = [E[f̂(x₀)] - f(x₀)]²\")\n",
    "print(\"  → Measures how far expected prediction is from true function\")\n",
    "print(\"\\nLogical reasoning:\")\n",
    "print(\"  1. At s = 0: Maximum constraint\")\n",
    "print(\"     - f̂(x) = β₀ (overly simplistic)\")\n",
    "print(\"     - Cannot capture true relationship\")\n",
    "print(\"     - Bias² = maximum (high bias)\")\n",
    "print(\"\\n  2. As s increases: Constraint relaxes\")\n",
    "print(\"     - Model can use more predictors\")\n",
    "print(\"     - Can better approximate true function f(x)\")\n",
    "print(\"     - Bias² DECREASES\")\n",
    "print(\"\\n  3. As s → ∞: Least squares (unbiased)\")\n",
    "print(\"     - If model is correctly specified, bias → 0\")\n",
    "print(\"     - Bias² = minimum\")\n",
    "print(\"\\nConclusion: Bias² STEADILY DECREASES ✓\")\n",
    "print(\"\\nKey principle:\")\n",
    "print(\"  More flexibility → Less bias\")\n",
    "print(\"  Less constraint → Less bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fc389b",
   "metadata": {},
   "source": [
    "\n",
    "Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0b2b79bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(7.0, 2.4761904761904763, 's → ∞\\n(Low bias)')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bias illustration\n",
    "ax = axes[0, 1]\n",
    "bias_squared = 5 / (s_values + 0.5)  # Steadily decreasing\n",
    "ax.plot(s_values, bias_squared, 'r-', linewidth=3)\n",
    "ax.set_xlabel('s', fontsize=12)\n",
    "ax.set_ylabel('Bias²', fontsize=12)\n",
    "ax.set_title('(d) Bias² vs s: STEADILY DECREASES', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.fill_between(s_values, 0, bias_squared, alpha=0.3, color='red')\n",
    "\n",
    "# Annotate\n",
    "ax.annotate('s = 0\\n(High bias)', xy=(0, bias_squared[0]), \n",
    "            xytext=(2, bias_squared[0] - 2),\n",
    "            arrowprops=dict(arrowstyle='->', color='blue', lw=1.5),\n",
    "            fontsize=10, color='blue')\n",
    "ax.annotate('s → ∞\\n(Low bias)', xy=(s_values[-1], bias_squared[-1]), \n",
    "            xytext=(s_values[-1] - 3, bias_squared[-1] + 2),\n",
    "            arrowprops=dict(arrowstyle='->', color='blue', lw=1.5),\n",
    "            fontsize=10, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64920ca",
   "metadata": {},
   "source": [
    "(e) Irreducible Error as s increases\n",
    "\n",
    "**Answer: v. Remain constant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c25596ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "(e) IRREDUCIBLE ERROR\n",
      "======================================================================\n",
      "\n",
      "Definition: Irreducible Error = Var(ε)\n",
      "  → The inherent noise in the relationship Y = f(X) + ε\n",
      "\n",
      "Logical reasoning:\n",
      "  1. Irreducible error is a property of the DATA GENERATING PROCESS\n",
      "     - It's the variance of the error term ε\n",
      "     - It exists regardless of the model we fit\n",
      "\n",
      "  2. No model can reduce irreducible error:\n",
      "     - Even if we knew f(X) perfectly: E[(Y - f(X))²] = Var(ε)\n",
      "     - This is the best possible test MSE we could achieve\n",
      "\n",
      "  3. Changing s only affects the MODEL, not the data:\n",
      "     - s controls model complexity\n",
      "     - Does not change the noise in Y\n",
      "\n",
      "Conclusion: Irreducible Error REMAINS CONSTANT ✓\n",
      "\n",
      "Expected Test MSE Decomposition:\n",
      "  E[Test MSE] = Bias² + Variance + Irreducible Error\n",
      "                   ↓        ↑            =\n",
      "               (as s↑)  (as s↑)    (constant)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(e) IRREDUCIBLE ERROR\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nDefinition: Irreducible Error = Var(ε)\")\n",
    "print(\"  → The inherent noise in the relationship Y = f(X) + ε\")\n",
    "print(\"\\nLogical reasoning:\")\n",
    "print(\"  1. Irreducible error is a property of the DATA GENERATING PROCESS\")\n",
    "print(\"     - It's the variance of the error term ε\")\n",
    "print(\"     - It exists regardless of the model we fit\")\n",
    "print(\"\\n  2. No model can reduce irreducible error:\")\n",
    "print(\"     - Even if we knew f(X) perfectly: E[(Y - f(X))²] = Var(ε)\")\n",
    "print(\"     - This is the best possible test MSE we could achieve\")\n",
    "print(\"\\n  3. Changing s only affects the MODEL, not the data:\")\n",
    "print(\"     - s controls model complexity\")\n",
    "print(\"     - Does not change the noise in Y\")\n",
    "print(\"\\nConclusion: Irreducible Error REMAINS CONSTANT ✓\")\n",
    "print(\"\\nExpected Test MSE Decomposition:\")\n",
    "print(\"  E[Test MSE] = Bias² + Variance + Irreducible Error\")\n",
    "print(\"                   ↓        ↑            =\")\n",
    "print(\"               (as s↑)  (as s↑)    (constant)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50685e00",
   "metadata": {},
   "source": [
    "Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "62b42a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Plot saved: 'lasso_s_effect_components.png']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Irreducible error illustration\n",
    "ax = axes[1, 0]\n",
    "irreducible_error = np.ones_like(s_values) * 2.0  # Constant\n",
    "ax.plot(s_values, irreducible_error, 'g-', linewidth=3)\n",
    "ax.set_xlabel('s', fontsize=12)\n",
    "ax.set_ylabel('Irreducible Error', fontsize=12)\n",
    "ax.set_title('(e) Irreducible Error vs s: CONSTANT', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 4])\n",
    "ax.axhline(y=2.0, color='g', linestyle='--', alpha=0.5, linewidth=2)\n",
    "\n",
    "# Annotate\n",
    "ax.text(5, 2.5, 'Var(ε) = constant\\n(Independent of s)', \n",
    "        fontsize=11, ha='center', \n",
    "        bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
    "\n",
    "# Combined view: Test MSE decomposition\n",
    "ax = axes[1, 1]\n",
    "test_mse = bias_squared + variance + irreducible_error\n",
    "ax.plot(s_values, bias_squared, 'r--', linewidth=2, label='Bias²', alpha=0.7)\n",
    "ax.plot(s_values, variance, 'b--', linewidth=2, label='Variance', alpha=0.7)\n",
    "ax.plot(s_values, irreducible_error, 'g--', linewidth=2, label='Irreducible Error', alpha=0.7)\n",
    "ax.plot(s_values, test_mse, 'k-', linewidth=3, label='Test MSE (Total)')\n",
    "ax.set_xlabel('s', fontsize=12)\n",
    "ax.set_ylabel('Error Components', fontsize=12)\n",
    "ax.set_title('Bias-Variance-Irreducible Error Decomposition', fontsize=12, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Mark optimal point\n",
    "optimal_idx = np.argmin(test_mse)\n",
    "ax.plot(s_values[optimal_idx], test_mse[optimal_idx], 'ro', markersize=12, \n",
    "        label='Optimal s', zorder=5)\n",
    "ax.axvline(x=s_values[optimal_idx], color='gray', linestyle=':', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('lasso_s_effect_components.png', dpi=150, bbox_inches='tight')\n",
    "print(\"[Plot saved: 'lasso_s_effect_components.png']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd1961b",
   "metadata": {},
   "source": [
    "Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "57678e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SUMMARY: Effect of Increasing s from 0\n",
      "======================================================================\n",
      "Quantity             Behavior as s ↑      Answer Reason                             \n",
      "-------------------- -------------------- ------ -----------------------------------\n",
      "Training RSS         Steadily Decrease    iv     More flexibility → better fit      \n",
      "Test RSS             U-shaped             ii     Bias-variance tradeoff             \n",
      "Variance             Steadily Increase    iii    More flexibility → more variance   \n",
      "Bias²                Steadily Decrease    iv     More flexibility → less bias       \n",
      "Irreducible Error    Constant             v      Independent of model choice        \n",
      "\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "======================================================================\n",
      "1. s = 0:     Maximum constraint → High bias, Low variance\n",
      "2. s optimal: Balanced tradeoff → Minimum test error\n",
      "3. s → ∞:     No constraint (LS) → Low bias, High variance\n",
      "\n",
      "Training RSS: Monotonically decreases (always fits better)\n",
      "Test RSS:     U-shaped (optimal exists in middle)\n",
      "Variance:     Monotonically increases (more flexibility)\n",
      "Bias²:        Monotonically decreases (less constraint)\n",
      "Irreducible:  Constant (property of data, not model)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY: Effect of Increasing s from 0\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary_data = [\n",
    "    [\"Quantity\", \"Behavior as s ↑\", \"Answer\", \"Reason\"],\n",
    "    [\"-\" * 20, \"-\" * 20, \"-\" * 6, \"-\" * 35],\n",
    "    [\"Training RSS\", \"Steadily Decrease\", \"iv\", \"More flexibility → better fit\"],\n",
    "    [\"Test RSS\", \"U-shaped\", \"ii\", \"Bias-variance tradeoff\"],\n",
    "    [\"Variance\", \"Steadily Increase\", \"iii\", \"More flexibility → more variance\"],\n",
    "    [\"Bias²\", \"Steadily Decrease\", \"iv\", \"More flexibility → less bias\"],\n",
    "    [\"Irreducible Error\", \"Constant\", \"v\", \"Independent of model choice\"]\n",
    "]\n",
    "\n",
    "for row in summary_data:\n",
    "    print(f\"{row[0]:<20} {row[1]:<20} {row[2]:<6} {row[3]:<35}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"1. s = 0:     Maximum constraint → High bias, Low variance\")\n",
    "print(\"2. s optimal: Balanced tradeoff → Minimum test error\")\n",
    "print(\"3. s → ∞:     No constraint (LS) → Low bias, High variance\")\n",
    "print(\"\\nTraining RSS: Monotonically decreases (always fits better)\")\n",
    "print(\"Test RSS:     U-shaped (optimal exists in middle)\")\n",
    "print(\"Variance:     Monotonically increases (more flexibility)\")\n",
    "print(\"Bias²:        Monotonically decreases (less constraint)\")\n",
    "print(\"Irreducible:  Constant (property of data, not model)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2524c1e",
   "metadata": {},
   "source": [
    "Mathematical Note:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "01acb704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MATHEMATICAL DECOMPOSITION\n",
      "======================================================================\n",
      "\n",
      "For a test point x₀:\n",
      "\n",
      "  E[(y₀ - f̂(x₀))²] = [E[f̂(x₀)] - f(x₀)]²  +  E[(f̂(x₀) - E[f̂(x₀)])²]  +  Var(ε)\n",
      "                      ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾     ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾     ‾‾‾‾‾\n",
      "                           Bias²                    Variance         Irreducible\n",
      "                             ↓                          ↑                  =\n",
      "                         (as s↑)                    (as s↑)          (constant)\n",
      "\n",
      "Optimal s* minimizes: Bias²(s) + Variance(s) + Irreducible Error\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MATHEMATICAL DECOMPOSITION\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nFor a test point x₀:\")\n",
    "print(\"\\n  E[(y₀ - f̂(x₀))²] = [E[f̂(x₀)] - f(x₀)]²  +  E[(f̂(x₀) - E[f̂(x₀)])²]  +  Var(ε)\")\n",
    "print(\"                      ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾     ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾     ‾‾‾‾‾\")\n",
    "print(\"                           Bias²                    Variance         Irreducible\")\n",
    "print(\"                             ↓                          ↑                  =\")\n",
    "print(\"                         (as s↑)                    (as s↑)          (constant)\")\n",
    "print(\"\\nOptimal s* minimizes: Bias²(s) + Variance(s) + Irreducible Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f4ecd128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ All visualizations complete!\n"
     ]
    }
   ],
   "source": [
    "plt.show()\n",
    "print(\"\\n✓ All visualizations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65a875a",
   "metadata": {},
   "source": [
    "4. Suppose we estimate the regression coefficients in a linear regression model by minimizing\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} \\left( y_i - \\beta_0 \\sum_{j=1}^{p} \\beta_j x_{ij} \\right)^2 + \\lambda\\sum_{j=1}^{p} \\beta_j^2\n",
    "$$\n",
    "\n",
    "for a particular value of $\\lambda$. For parts (a) through (e), indicate which of i. through v. is correct. Justify your answer.\n",
    "\n",
    "   (a) As we increase $\\lambda$ from 0, the training RSS will:  \n",
    "   i. Increase initially, and then eventually start decreasing in an inverted U shape.  \n",
    "   ii. Decrease initially, and then eventually start increasing in a U shape.  \n",
    "   iii. Steadily increase.  \n",
    "   iv. Steadily decrease.  \n",
    "   v. Remain constant.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa7859",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecc4d459",
   "metadata": {},
   "source": [
    "# Ridge Regression: Effect of Penalty Parameter λ\n",
    "\n",
    "## Setup\n",
    "\n",
    "The optimization problem is Ridge Regression:\n",
    "$$\\min_{\\beta_0, \\beta_1, \\ldots, \\beta_p} \\sum_{i=1}^{n} \\left( y_i - \\beta_0 - \\sum_{j=1}^{p} \\beta_j x_{ij} \\right)^2 + \\lambda\\sum_{j=1}^{p} \\beta_j^2$$\n",
    "\n",
    "**Note:** Again, there appears to be a typo in the problem statement. The correct formulation should have $\\beta_0 + \\sum_{j=1}^{p} \\beta_j x_{ij}$ in the residual sum of squares.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"RIDGE REGRESSION: Effect of Penalty Parameter λ\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nKey relationships:\")\n",
    "print(\"  λ = 0     → No penalty (least squares, maximum flexibility)\")\n",
    "print(\"  λ small   → Light penalty (close to least squares)\")\n",
    "print(\"  λ large   → Heavy penalty (coefficients shrink toward 0)\")\n",
    "print(\"  λ → ∞     → All βⱼ → 0 (null model, minimum flexibility)\")\n",
    "print(\"\\nAs λ increases: penalty increases, model becomes LESS FLEXIBLE\")\n",
    "print(\"\\nIMPORTANT: Ridge is OPPOSITE to LASSO's s parameter!\")\n",
    "print(\"  - LASSO s: s↑ → more flexible\")\n",
    "print(\"  - Ridge λ: λ↑ → less flexible\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (a) Training RSS as λ increases\n",
    "\n",
    "**Answer: iii. Steadily increase**\n",
    "\n",
    "### Justification:\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(a) TRAINING RSS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nLogical reasoning:\")\n",
    "print(\"  1. At λ = 0: No penalty\")\n",
    "print(\"     - Equivalent to least squares\")\n",
    "print(\"     - Minimizes training RSS\")\n",
    "print(\"     - Training RSS is at MINIMUM\")\n",
    "print(\"\\n  2. As λ increases: Penalty term λΣβⱼ² becomes more important\")\n",
    "print(\"     - Optimizer must balance RSS and penalty\")\n",
    "print(\"     - Coefficients shrink toward 0\")\n",
    "print(\"     - Model fits training data WORSE\")\n",
    "print(\"     - Training RSS INCREASES\")\n",
    "print(\"\\n  3. As λ → ∞: All βⱼ → 0\")\n",
    "print(\"     - f̂(x) = β₀ = ȳ (null model)\")\n",
    "print(\"     - Training RSS is at MAXIMUM\")\n",
    "print(\"\\nConclusion: Training RSS STEADILY INCREASES ✓\")\n",
    "print(\"\\nWhy not U-shaped?\")\n",
    "print(\"  - The penalty ALWAYS makes it harder to fit training data\")\n",
    "print(\"  - No benefit to training RSS from shrinkage\")\n",
    "print(\"  - Training RSS is monotonically non-decreasing in λ\")\n",
    "```\n",
    "\n",
    "**Simulation:**\n",
    "\n",
    "```python\n",
    "# Generate data\n",
    "np.random.seed(42)\n",
    "n, p = 100, 5\n",
    "\n",
    "X = np.random.randn(n, p)\n",
    "true_beta = np.array([3, -2, 1.5, 0, 0])\n",
    "y = X @ true_beta + np.random.randn(n) * 2\n",
    "\n",
    "# Standardize\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# Try different values of λ\n",
    "lambdas = np.logspace(-3, 3, 100)\n",
    "train_rss = []\n",
    "coef_norms = []\n",
    "\n",
    "for lam in lambdas:\n",
    "    ridge = Ridge(alpha=lam)\n",
    "    ridge.fit(X_scaled, y)\n",
    "    y_pred = ridge.predict(X_scaled)\n",
    "    rss = np.sum((y - y_pred) ** 2)\n",
    "    train_rss.append(rss)\n",
    "    coef_norms.append(np.sum(ridge.coef_ ** 2))  # L2 norm squared\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(lambdas, train_rss, 'b-', linewidth=2)\n",
    "ax.set_xlabel('λ (Penalty parameter)', fontsize=11)\n",
    "ax.set_ylabel('Training RSS', fontsize=11)\n",
    "ax.set_title('(a) Training RSS vs λ: STEADILY INCREASES', fontsize=12, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=train_rss[0], color='r', linestyle='--', alpha=0.5, label='Minimum (λ=0)')\n",
    "ax.legend()\n",
    "\n",
    "# Annotate\n",
    "ax.annotate('λ = 0\\n(Least Squares)', xy=(lambdas[0], train_rss[0]), \n",
    "            xytext=(lambdas[10], train_rss[0] + 200),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=1.5),\n",
    "            fontsize=10, color='red')\n",
    "ax.annotate('λ → ∞\\n(Null model)', xy=(lambdas[-1], train_rss[-1]), \n",
    "            xytext=(lambdas[-20], train_rss[-1] - 500),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=1.5),\n",
    "            fontsize=10, color='red')\n",
    "\n",
    "print(\"\\n[Creating visualization...]\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (b) Test RSS as λ increases\n",
    "\n",
    "**Answer: ii. Decrease initially, and then eventually start increasing in a U shape.**\n",
    "\n",
    "### Justification:\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(b) TEST RSS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nLogical reasoning:\")\n",
    "print(\"  1. At λ = 0: Least squares (potential overfitting)\")\n",
    "print(\"     - High variance, low bias\")\n",
    "print(\"     - Test RSS may be HIGH (if overfitting occurs)\")\n",
    "print(\"\\n  2. As λ increases initially: Variance decreases faster than bias increases\")\n",
    "print(\"     - Regularization reduces overfitting\")\n",
    "print(\"     - Coefficients shrink, reducing variance\")\n",
    "print(\"     - Test RSS DECREASES\")\n",
    "print(\"\\n  3. Optimal λ: Bias-variance tradeoff is balanced\")\n",
    "print(\"     - Test RSS reaches MINIMUM\")\n",
    "print(\"\\n  4. As λ increases further: Bias increases faster than variance decreases\")\n",
    "print(\"     - Model becomes too simple (underfitting)\")\n",
    "print(\"     - Cannot capture true signal\")\n",
    "print(\"     - Test RSS INCREASES\")\n",
    "print(\"\\n  5. As λ → ∞: All βⱼ → 0 (extreme underfitting)\")\n",
    "print(\"     - High bias, low variance\")\n",
    "print(\"     - Test RSS is HIGH again\")\n",
    "print(\"\\nConclusion: Test RSS has U-SHAPE (decreases then increases) ✓\")\n",
    "```\n",
    "\n",
    "**Simulation:**\n",
    "\n",
    "```python\n",
    "# Generate test data\n",
    "X_test = np.random.randn(n, p)\n",
    "y_test = X_test @ true_beta + np.random.randn(n) * 2\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "test_rss = []\n",
    "for lam in lambdas:\n",
    "    ridge = Ridge(alpha=lam)\n",
    "    ridge.fit(X_scaled, y)\n",
    "    y_pred_test = ridge.predict(X_test_scaled)\n",
    "    rss = np.sum((y_test - y_pred_test) ** 2)\n",
    "    test_rss.append(rss)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(lambdas, test_rss, 'r-', linewidth=2, label='Test RSS')\n",
    "ax.set_xlabel('λ (Penalty parameter)', fontsize=11)\n",
    "ax.set_ylabel('Test RSS', fontsize=11)\n",
    "ax.set_title('(b) Test RSS vs λ: U-SHAPED', fontsize=12, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Find minimum\n",
    "min_idx = np.argmin(test_rss)\n",
    "ax.axvline(x=lambdas[min_idx], color='g', linestyle='--', alpha=0.5, label='Optimal λ')\n",
    "ax.plot(lambdas[min_idx], test_rss[min_idx], 'go', markersize=10, label='Minimum')\n",
    "ax.legend()\n",
    "\n",
    "# Annotate regions\n",
    "ax.annotate('Overfitting\\n(λ too small)', xy=(lambdas[5], test_rss[5]), \n",
    "            xytext=(lambdas[2], test_rss[5] + 400),\n",
    "            arrowprops=dict(arrowstyle='->', color='blue', lw=1.5),\n",
    "            fontsize=9, color='blue')\n",
    "ax.annotate('Underfitting\\n(λ too large)', xy=(lambdas[-10], test_rss[-10]), \n",
    "            xytext=(lambdas[-30], test_rss[-10] + 400),\n",
    "            arrowprops=dict(arrowstyle='->', color='blue', lw=1.5),\n",
    "            fontsize=9, color='blue')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ridge_lambda_effect_rss.png', dpi=150, bbox_inches='tight')\n",
    "print(\"[Plot saved: 'ridge_lambda_effect_rss.png']\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (c) Variance as λ increases\n",
    "\n",
    "**Answer: iv. Steadily decrease**\n",
    "\n",
    "### Justification:\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(c) VARIANCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nDefinition: Variance = E[(f̂(x₀) - E[f̂(x₀)])²]\")\n",
    "print(\"  → Measures variability of predictions across different training sets\")\n",
    "print(\"\\nLogical reasoning:\")\n",
    "print(\"  1. At λ = 0: Least squares (maximum flexibility)\")\n",
    "print(\"     - Most sensitive to training data\")\n",
    "print(\"     - Coefficients can be large and variable\")\n",
    "print(\"     - Variance = MAXIMUM\")\n",
    "print(\"\\n  2. As λ increases: Coefficients shrink\")\n",
    "print(\"     - βⱼ values constrained toward 0\")\n",
    "print(\"     - Model less sensitive to training data noise\")\n",
    "print(\"     - Variance DECREASES\")\n",
    "print(\"\\n  3. As λ → ∞: All βⱼ → 0\")\n",
    "print(\"     - f̂(x) = β₀ = ȳ (constant prediction)\")\n",
    "print(\"     - No variability in predictions\")\n",
    "print(\"     - Variance → 0 (minimum)\")\n",
    "print(\"\\nConclusion: Variance STEADILY DECREASES ✓\")\n",
    "print(\"\\nKey principle:\")\n",
    "print(\"  More regularization (λ↑) → Less flexibility → Less variance\")\n",
    "```\n",
    "\n",
    "**Conceptual Visualization:**\n",
    "\n",
    "```python\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Variance illustration\n",
    "ax = axes[0, 0]\n",
    "lambda_values = np.logspace(-2, 2, 100)\n",
    "# Variance decreases as lambda increases\n",
    "variance = 5 / (1 + lambda_values)\n",
    "ax.plot(lambda_values, variance, 'b-', linewidth=3)\n",
    "ax.set_xlabel('λ', fontsize=12)\n",
    "ax.set_ylabel('Variance', fontsize=12)\n",
    "ax.set_title('(c) Variance vs λ: STEADILY DECREASES', fontsize=12, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.fill_between(lambda_values, 0, variance, alpha=0.3)\n",
    "\n",
    "# Annotate\n",
    "ax.annotate('λ = 0\\n(Max variance)', xy=(lambda_values[0], variance[0]), \n",
    "            xytext=(lambda_values[20], variance[0] - 1),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=1.5),\n",
    "            fontsize=10, color='red')\n",
    "ax.annotate('λ → ∞\\n(Min variance)', xy=(lambda_values[-1], variance[-1]), \n",
    "            xytext=(lambda_values[-40], variance[-1] + 1),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=1.5),\n",
    "            fontsize=10, color='red')\n",
    "\n",
    "print(\"\\n[Creating bias-variance visualization...]\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (d) (Squared) Bias as λ increases\n",
    "\n",
    "**Answer: iii. Steadily increase**\n",
    "\n",
    "### Justification:\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(d) (SQUARED) BIAS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nDefinition: Bias² = [E[f̂(x₀)] - f(x₀)]²\")\n",
    "print(\"  → Measures how far expected prediction is from true function\")\n",
    "print(\"\\nLogical reasoning:\")\n",
    "print(\"  1. At λ = 0: Least squares\")\n",
    "print(\"     - No constraint on coefficients\")\n",
    "print(\"     - If model correctly specified, E[β̂] = β_true\")\n",
    "print(\"     - Bias² = 0 or near minimum\")\n",
    "print(\"\\n  2. As λ increases: Coefficients shrink toward 0\")\n",
    "print(\"     - Even true non-zero coefficients are shrunk\")\n",
    "print(\"     - E[β̂ⱼ] ≠ βⱼ (biased estimates)\")\n",
    "print(\"     - Model systematically underestimates relationships\")\n",
    "print(\"     - Bias² INCREASES\")\n",
    "print(\"\\n  3. As λ → ∞: All βⱼ → 0\")\n",
    "print(\"     - f̂(x) = ȳ (ignores all predictors)\")\n",
    "print(\"     - Maximum bias (unless true function is constant)\")\n",
    "print(\"     - Bias² = MAXIMUM\")\n",
    "print(\"\\nConclusion: Bias² STEADILY INCREASES ✓\")\n",
    "print(\"\\nKey principle:\")\n",
    "print(\"  More regularization (λ↑) → More shrinkage → More bias\")\n",
    "```\n",
    "\n",
    "**Visualization:**\n",
    "\n",
    "```python\n",
    "# Bias illustration\n",
    "ax = axes[0, 1]\n",
    "# Bias² increases as lambda increases\n",
    "bias_squared = 0.1 + 2 * np.log(1 + lambda_values)\n",
    "ax.plot(lambda_values, bias_squared, 'r-', linewidth=3)\n",
    "ax.set_xlabel('λ', fontsize=12)\n",
    "ax.set_ylabel('Bias²', fontsize=12)\n",
    "ax.set_title('(d) Bias² vs λ: STEADILY INCREASES', fontsize=12, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.fill_between(lambda_values, 0, bias_squared, alpha=0.3, color='red')\n",
    "\n",
    "# Annotate\n",
    "ax.annotate('λ = 0\\n(Low bias)', xy=(lambda_values[0], bias_squared[0]), \n",
    "            xytext=(lambda_values[20], bias_squared[0] + 2),\n",
    "            arrowprops=dict(arrowstyle='->', color='blue', lw=1.5),\n",
    "            fontsize=10, color='blue')\n",
    "ax.annotate('λ → ∞\\n(High bias)', xy=(lambda_values[-1], bias_squared[-1]), \n",
    "            xytext=(lambda_values[-40], bias_squared[-1] - 2),\n",
    "            arrowprops=dict(arrowstyle='->', color='blue', lw=1.5),\n",
    "            fontsize=10, color='blue')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (e) Irreducible Error as λ increases\n",
    "\n",
    "**Answer: v. Remain constant**\n",
    "\n",
    "### Justification:\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(e) IRREDUCIBLE ERROR\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nDefinition: Irreducible Error = Var(ε)\")\n",
    "print(\"  → The inherent noise in the relationship Y = f(X) + ε\")\n",
    "print(\"\\nLogical reasoning:\")\n",
    "print(\"  1. Irreducible error is a property of the DATA GENERATING PROCESS\")\n",
    "print(\"     - It's the variance of the error term ε in Y = f(X) + ε\")\n",
    "print(\"     - Exists regardless of what model we fit\")\n",
    "print(\"\\n  2. No model can reduce irreducible error:\")\n",
    "print(\"     - Even with perfect knowledge of f(X)\")\n",
    "print(\"     - Still have: E[(Y - f(X))²] = Var(ε)\")\n",
    "print(\"     - This is the fundamental limit of prediction\")\n",
    "print(\"\\n  3. Changing λ only affects the MODEL, not the data:\")\n",
    "print(\"     - λ controls regularization strength\")\n",
    "print(\"     - Does not change the noise distribution in Y\")\n",
    "print(\"     - Does not change the data generating process\")\n",
    "print(\"\\nConclusion: Irreducible Error REMAINS CONSTANT ✓\")\n",
    "print(\"\\nKey insight:\")\n",
    "print(\"  Irreducible error is the Bayes error rate\")\n",
    "print(\"  No amount of regularization (or lack thereof) can change it\")\n",
    "```\n",
    "\n",
    "**Visualization:**\n",
    "\n",
    "```python\n",
    "# Irreducible error illustration\n",
    "ax = axes[1, 0]\n",
    "irreducible_error = np.ones_like(lambda_values) * 2.0  # Constant\n",
    "ax.plot(lambda_values, irreducible_error, 'g-', linewidth=3)\n",
    "ax.set_xlabel('λ', fontsize=12)\n",
    "ax.set_ylabel('Irreducible Error', fontsize=12)\n",
    "ax.set_title('(e) Irreducible Error vs λ: CONSTANT', fontsize=12, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 4])\n",
    "ax.axhline(y=2.0, color='g', linestyle='--', alpha=0.5, linewidth=2)\n",
    "\n",
    "# Annotate\n",
    "ax.text(1, 2.5, 'Var(ε) = constant\\n(Independent of λ)', \n",
    "        fontsize=11, ha='center', \n",
    "        bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
    "\n",
    "# Combined view: Test MSE decomposition\n",
    "ax = axes[1, 1]\n",
    "test_mse = bias_squared + variance + irreducible_error\n",
    "ax.plot(lambda_values, bias_squared, 'r--', linewidth=2, label='Bias²', alpha=0.7)\n",
    "ax.plot(lambda_values, variance, 'b--', linewidth=2, label='Variance', alpha=0.7)\n",
    "ax.plot(lambda_values, irreducible_error, 'g--', linewidth=2, label='Irreducible Error', alpha=0.7)\n",
    "ax.plot(lambda_values, test_mse, 'k-', linewidth=3, label='Test MSE (Total)')\n",
    "ax.set_xlabel('λ', fontsize=12)\n",
    "ax.set_ylabel('Error Components', fontsize=12)\n",
    "ax.set_title('Bias-Variance-Irreducible Error Decomposition', fontsize=12, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Mark optimal point\n",
    "optimal_idx = np.argmin(test_mse)\n",
    "ax.plot(lambda_values[optimal_idx], test_mse[optimal_idx], 'ro', markersize=12, zorder=5)\n",
    "ax.axvline(x=lambda_values[optimal_idx], color='gray', linestyle=':', alpha=0.5)\n",
    "ax.text(lambda_values[optimal_idx] * 2, test_mse[optimal_idx] + 1, \n",
    "        f'Optimal λ ≈ {lambda_values[optimal_idx]:.2f}',\n",
    "        fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ridge_lambda_effect_components.png', dpi=150, bbox_inches='tight')\n",
    "print(\"[Plot saved: 'ridge_lambda_effect_components.png']\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Table\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY: Effect of Increasing λ from 0\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary_data = [\n",
    "    [\"Quantity\", \"Behavior as λ ↑\", \"Answer\", \"Reason\"],\n",
    "    [\"-\" * 20, \"-\" * 20, \"-\" * 6, \"-\" * 40],\n",
    "    [\"Training RSS\", \"Steadily Increase\", \"iii\", \"Penalty makes fitting harder\"],\n",
    "    [\"Test RSS\", \"U-shaped\", \"ii\", \"Bias-variance tradeoff\"],\n",
    "    [\"Variance\", \"Steadily Decrease\", \"iv\", \"Less flexibility → less variance\"],\n",
    "    [\"Bias²\", \"Steadily Increase\", \"iii\", \"Shrinkage → more bias\"],\n",
    "    [\"Irreducible Error\", \"Constant\", \"v\", \"Independent of model choice\"]\n",
    "]\n",
    "\n",
    "for row in summary_data:\n",
    "    print(f\"{row[0]:<20} {row[1]:<20} {row[2]:<6} {row[3]:<40}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"1. λ = 0:     No penalty (LS)    → Low bias,  High variance\")\n",
    "print(\"2. λ optimal: Balanced tradeoff  → Minimum test error\")\n",
    "print(\"3. λ → ∞:     Maximum penalty    → High bias, Low variance\")\n",
    "print(\"\\nTraining RSS: Monotonically increases (penalty hurts fit)\")\n",
    "print(\"Test RSS:     U-shaped (optimal exists in middle)\")\n",
    "print(\"Variance:     Monotonically decreases (less flexibility)\")\n",
    "print(\"Bias²:        Monotonically increases (more shrinkage)\")\n",
    "print(\"Irreducible:  Constant (property of data, not model)\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Comparison: Ridge (λ) vs LASSO (s)\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPARISON: Ridge λ vs LASSO s\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "comparison_data = [\n",
    "    [\"\", \"Ridge λ ↑\", \"LASSO s ↑\"],\n",
    "    [\"-\" * 20, \"-\" * 20, \"-\" * 20],\n",
    "    [\"Flexibility\", \"DECREASES\", \"INCREASES\"],\n",
    "    [\"Training RSS\", \"INCREASES\", \"DECREASES\"],\n",
    "    [\"Test RSS\", \"U-shaped\", \"U-shaped\"],\n",
    "    [\"Variance\", \"DECREASES\", \"INCREASES\"],\n",
    "    [\"Bias²\", \"INCREASES\", \"DECREASES\"],\n",
    "    [\"Irreducible Error\", \"Constant\", \"Constant\"],\n",
    "    [\"\", \"\", \"\"],\n",
    "    [\"At minimum value\", \"λ=0: Least Squares\", \"s=0: Null model\"],\n",
    "    [\"At maximum value\", \"λ→∞: Null model\", \"s→∞: Least Squares\"]\n",
    "]\n",
    "\n",
    "for row in comparison_data:\n",
    "    print(f\"{row[0]:<20} {row[1]:<20} {row[2]:<20}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY DIFFERENCE:\")\n",
    "print(\"  Ridge λ: Larger λ → MORE regularization → LESS flexible\")\n",
    "print(\"  LASSO s: Larger s → LESS constraint   → MORE flexible\")\n",
    "print(\"\\n  They work in OPPOSITE directions!\")\n",
    "```\n",
    "\n",
    "**Mathematical Note:**\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MATHEMATICAL FORMULATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nRidge Regression (Penalty form):\")\n",
    "print(\"  min Σ(yᵢ - β₀ - Σβⱼxᵢⱼ)² + λΣβⱼ²\")\n",
    "print(\"  λ↑ → more penalty → coefficients shrink\")\n",
    "\n",
    "print(\"\\nRidge Regression (Constraint form):\")\n",
    "print(\"  min Σ(yᵢ - β₀ - Σβⱼxᵢⱼ)²  subject to  Σβⱼ² ≤ t\")\n",
    "print(\"  Equivalence: Large λ ↔ Small t\")\n",
    "print(\"              Small λ ↔ Large t\")\n",
    "\n",
    "print(\"\\nLASSO (Constraint form):\")\n",
    "print(\"  min Σ(yᵢ - β₀ - Σβⱼxᵢⱼ)²  subject to  Σ|βⱼ| ≤ s\")\n",
    "print(\"  s is the constraint budget (larger s → less constraint)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPECTED TEST MSE DECOMPOSITION:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n  E[(y₀ - f̂(x₀))²] = Bias²(λ) + Variance(λ) + Irreducible Error\")\n",
    "print(\"                        ↑           ↓              =\")\n",
    "print(\"                     (as λ↑)     (as λ↑)      (constant)\")\n",
    "print(\"\\n  Optimal λ* minimizes: Bias²(λ) + Variance(λ)\")\n",
    "```\n",
    "\n",
    "plt.show()\n",
    "print(\"\\n✓ All visualizations complete!\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8128873",
   "metadata": {},
   "source": [
    "(b) Repeat (a) for test RSS.  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f80e11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3935225",
   "metadata": {},
   "source": [
    "(c) Repeat (a) for variance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6590cbae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "facbc3f5",
   "metadata": {},
   "source": [
    "(d) Repeat (a) for (squared) bias.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e59dc7a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9b6f1a0",
   "metadata": {},
   "source": [
    "(e) Repeat (a) for the irreducible error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23257a86",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f584d925",
   "metadata": {},
   "source": [
    "5. It is well-known that ridge regression tends to give similar coefficient values to correlated variables, whereas the lasso may give quite different coefficient values to correlated variables. We will now explore this property in a very simple setting. Suppose that $n = 2$, $p = 2$, $x_{11} = x_{12}$, $x_{21} = x_{22}$. Furthermore, suppose that $y_1+y_2 = 0$ and $x_{11}+x_{21} = 0$ and $x_{12}+x_{22} = 0$, so that the estimate for the intercept in a least squares, ridge regression, or lasso model is zero: $\\hat{\\beta_0} = 0$.\n",
    "\n",
    "   (a) Write out the ridge regression optimization problem in this setting.  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0965dab7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61bdf1d1",
   "metadata": {},
   "source": [
    "# Ridge vs LASSO: Correlated Variables\n",
    "\n",
    "## Problem Setup\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "print(\"EXPLORING RIDGE VS LASSO WITH CORRELATED VARIABLES\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nGiven constraints:\")\n",
    "print(\"  • n = 2, p = 2\")\n",
    "print(\"  • x₁₁ = x₁₂ (first observation: both predictors equal)\")\n",
    "print(\"  • x₂₁ = x₂₂ (second observation: both predictors equal)\")\n",
    "print(\"  • y₁ + y₂ = 0\")\n",
    "print(\"  • x₁₁ + x₂₁ = 0\")\n",
    "print(\"  • x₁₂ + x₂₂ = 0\")\n",
    "print(\"  • β₀ = 0 (intercept is zero)\")\n",
    "print(\"\\nImplication: The two predictors are PERFECTLY CORRELATED\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (a) Ridge Regression Optimization Problem\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(a) RIDGE REGRESSION OPTIMIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nGeneral form:\")\n",
    "print(\"  min RSS + λΣβⱼ²\")\n",
    "print(\"\\nWith our constraints (β₀ = 0, n = 2, p = 2):\")\n",
    "print(\"\\n  RSS = Σᵢ₌₁² (yᵢ - β₁x_{i1} - β₂x_{i2})²\")\n",
    "print(\"      = (y₁ - β₁x₁₁ - β₂x₁₂)² + (y₂ - β₁x₂₁ - β₂x₂₂)²\")\n",
    "print(\"\\nSince x₁₁ = x₁₂ and x₂₁ = x₂₂:\")\n",
    "print(\"\\n  RSS = (y₁ - β₁x₁₁ - β₂x₁₁)² + (y₂ - β₁x₂₁ - β₂x₂₁)²\")\n",
    "print(\"      = (y₁ - x₁₁(β₁ + β₂))² + (y₂ - x₂₁(β₁ + β₂))²\")\n",
    "print(\"\\nPenalty term:\")\n",
    "print(\"  λ(β₁² + β₂²)\")\n",
    "```\n",
    "\n",
    "### Ridge Optimization Problem\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"RIDGE REGRESSION OPTIMIZATION PROBLEM:\")\n",
    "print(\"─\" * 70)\n",
    "print(\"\\n  min_{β₁,β₂} (y₁ - x₁₁(β₁ + β₂))² + (y₂ - x₂₁(β₁ + β₂))² + λ(β₁² + β₂²)\")\n",
    "print(\"\\nwhere x₁₁ + x₂₁ = 0 and y₁ + y₂ = 0\")\n",
    "print(\"=\" * 70)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (b) Ridge Coefficients are Equal: β̂₁ = β̂₂\n",
    "\n",
    "### Proof by First-Order Conditions\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(b) PROVING β̂₁ = β̂₂ FOR RIDGE REGRESSION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nMethod 1: First-Order Conditions\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nDefine the objective function:\")\n",
    "print(\"  f(β₁, β₂) = (y₁ - x₁₁(β₁ + β₂))² + (y₂ - x₂₁(β₁ + β₂))² + λ(β₁² + β₂²)\")\n",
    "\n",
    "print(\"\\nTake partial derivatives and set to zero:\")\n",
    "print(\"\\n∂f/∂β₁ = 0:\")\n",
    "print(\"  2(y₁ - x₁₁(β₁ + β₂))(-x₁₁) + 2(y₂ - x₂₁(β₁ + β₂))(-x₂₁) + 2λβ₁ = 0\")\n",
    "\n",
    "print(\"\\n∂f/∂β₂ = 0:\")\n",
    "print(\"  2(y₁ - x₁₁(β₁ + β₂))(-x₁₁) + 2(y₂ - x₂₁(β₁ + β₂))(-x₂₁) + 2λβ₂ = 0\")\n",
    "\n",
    "print(\"\\nNotice: The first two terms in both equations are IDENTICAL!\")\n",
    "print(\"\\nSubtracting the second equation from the first:\")\n",
    "print(\"  2λβ₁ - 2λβ₂ = 0\")\n",
    "print(\"  λ(β₁ - β₂) = 0\")\n",
    "\n",
    "print(\"\\nSince λ > 0 (for ridge regression):\")\n",
    "print(\"  β₁ - β₂ = 0\")\n",
    "print(\"  β₁ = β₂  ✓\")\n",
    "```\n",
    "\n",
    "### Alternative Proof: Symmetry Argument\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Method 2: Symmetry Argument\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nObserve the objective function:\")\n",
    "print(\"  f(β₁, β₂) = (y₁ - x₁₁(β₁ + β₂))² + (y₂ - x₂₁(β₁ + β₂))² + λ(β₁² + β₂²)\")\n",
    "\n",
    "print(\"\\nKey observations:\")\n",
    "print(\"  1. RSS depends only on (β₁ + β₂), not on β₁ and β₂ individually\")\n",
    "print(\"  2. Penalty term: β₁² + β₂² is symmetric in β₁ and β₂\")\n",
    "\n",
    "print(\"\\nFor any fixed value of s = β₁ + β₂:\")\n",
    "print(\"  • RSS is constant (depends only on s)\")\n",
    "print(\"  • Penalty = β₁² + β₂² needs to be minimized\")\n",
    "\n",
    "print(\"\\nMinimize β₁² + β₂² subject to β₁ + β₂ = s:\")\n",
    "print(\"  This is equivalent to minimizing β₁² + (s - β₁)²\")\n",
    "print(\"  Taking derivative: 2β₁ - 2(s - β₁) = 0\")\n",
    "print(\"  → 4β₁ = 2s\")\n",
    "print(\"  → β₁ = s/2\")\n",
    "print(\"  → β₂ = s - s/2 = s/2\")\n",
    "print(\"  → β₁ = β₂  ✓\")\n",
    "\n",
    "print(\"\\nIntuition: For a fixed sum, the sum of squares is minimized\")\n",
    "print(\"          when the values are equal.\")\n",
    "```\n",
    "\n",
    "### Geometric Interpretation\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Method 3: Geometric Interpretation\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nThe ridge penalty creates circular contours in (β₁, β₂) space\")\n",
    "print(\"The RSS creates linear contours (lines β₁ + β₂ = constant)\")\n",
    "print(\"\\nThe optimal solution occurs where:\")\n",
    "print(\"  • A circle β₁² + β₂² = c\")\n",
    "print(\"  • Touches a line β₁ + β₂ = s\")\n",
    "print(\"\\nBy symmetry, this tangent point must be on the line β₁ = β₂\")\n",
    "\n",
    "# Visualization\n",
    "fig = plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Left plot: Contours\n",
    "ax1 = fig.add_subplot(121)\n",
    "\n",
    "# Create grid\n",
    "beta1 = np.linspace(-3, 3, 400)\n",
    "beta2 = np.linspace(-3, 3, 400)\n",
    "B1, B2 = np.meshgrid(beta1, beta2)\n",
    "\n",
    "# Ridge penalty contours (circles)\n",
    "penalty_levels = [1, 2, 3, 4, 5]\n",
    "for level in penalty_levels:\n",
    "    circle = plt.Circle((0, 0), np.sqrt(level), fill=False, \n",
    "                        color='blue', alpha=0.5, linewidth=1.5)\n",
    "    ax1.add_patch(circle)\n",
    "\n",
    "# RSS contours (lines β₁ + β₂ = constant)\n",
    "for s in [-2, -1, 0, 1, 2]:\n",
    "    ax1.plot(beta1, s - beta1, 'r--', alpha=0.6, linewidth=1.5)\n",
    "\n",
    "# Line β₁ = β₂\n",
    "ax1.plot(beta1, beta1, 'g-', linewidth=3, label='β₁ = β₂', alpha=0.8)\n",
    "\n",
    "# Mark optimal point (example)\n",
    "ax1.plot(1, 1, 'ko', markersize=12, label='Optimal (β̂₁, β̂₂)')\n",
    "\n",
    "ax1.set_xlabel('β₁', fontsize=12)\n",
    "ax1.set_ylabel('β₂', fontsize=12)\n",
    "ax1.set_title('Ridge: Contours & Optimal Solution', fontsize=12, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim([-3, 3])\n",
    "ax1.set_ylim([-3, 3])\n",
    "ax1.axhline(y=0, color='k', linewidth=0.5)\n",
    "ax1.axvline(x=0, color='k', linewidth=0.5)\n",
    "ax1.legend()\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "# Add text annotations\n",
    "ax1.text(2.2, 1.8, 'Penalty\\ncontours\\n(circles)', fontsize=9, color='blue',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "ax1.text(1.5, -2.5, 'RSS contours\\n(lines)', fontsize=9, color='red',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "print(\"\\n[Creating visualization...]\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (c) LASSO Optimization Problem\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(c) LASSO OPTIMIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nGeneral form:\")\n",
    "print(\"  min RSS  subject to  Σ|βⱼ| ≤ s\")\n",
    "print(\"\\nOr equivalently (Lagrangian form):\")\n",
    "print(\"  min RSS + λΣ|βⱼ|\")\n",
    "\n",
    "print(\"\\nWith our constraints (β₀ = 0, n = 2, p = 2):\")\n",
    "print(\"\\n  RSS = (y₁ - x₁₁(β₁ + β₂))² + (y₂ - x₂₁(β₁ + β₂))²\")\n",
    "print(\"\\nPenalty term:\")\n",
    "print(\"  λ(|β₁| + |β₂|)\")\n",
    "```\n",
    "\n",
    "### LASSO Optimization Problem\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"LASSO OPTIMIZATION PROBLEM:\")\n",
    "print(\"─\" * 70)\n",
    "print(\"\\n  min_{β₁,β₂} (y₁ - x₁₁(β₁ + β₂))² + (y₂ - x₂₁(β₁ + β₂))² + λ(|β₁| + |β₂|)\")\n",
    "print(\"\\nOR in constraint form:\")\n",
    "print(\"\\n  min_{β₁,β₂} (y₁ - x₁₁(β₁ + β₂))² + (y₂ - x₂₁(β₁ + β₂))²\")\n",
    "print(\"  subject to  |β₁| + |β₂| ≤ s\")\n",
    "print(\"\\nwhere x₁₁ + x₂₁ = 0 and y₁ + y₂ = 0\")\n",
    "print(\"=\" * 70)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (d) LASSO Solutions are Not Unique\n",
    "\n",
    "### Main Argument\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(d) LASSO COEFFICIENTS ARE NOT UNIQUE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nKey Observation:\")\n",
    "print(\"  RSS = (y₁ - x₁₁(β₁ + β₂))² + (y₂ - x₂₁(β₁ + β₂))²\")\n",
    "print(\"\\n  → RSS depends ONLY on (β₁ + β₂), not on β₁ and β₂ individually!\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Proof of Non-Uniqueness:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nFor the constraint form: min RSS  s.t.  |β₁| + |β₂| ≤ s\")\n",
    "print(\"\\n1. Let β̂₁ + β̂₂ = c* be the optimal sum\")\n",
    "print(\"   (determined by minimizing RSS)\")\n",
    "\n",
    "print(\"\\n2. ANY combination (β₁, β₂) satisfying:\")\n",
    "print(\"   • β₁ + β₂ = c*  (gives same RSS)\")\n",
    "print(\"   • |β₁| + |β₂| ≤ s  (satisfies constraint)\")\n",
    "print(\"   is an optimal solution!\")\n",
    "\n",
    "print(\"\\n3. If the constraint is active (|β₁| + |β₂| = s), then:\")\n",
    "print(\"   β₁ + β₂ = c*\")\n",
    "print(\"   |β₁| + |β₂| = s\")\n",
    "```\n",
    "\n",
    "### Description of Solutions\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Description of All Optimal Solutions:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nCase 1: Both coefficients have the same sign\")\n",
    "print(\"-\" * 35)\n",
    "print(\"If c* > 0 (both positive):\")\n",
    "print(\"  β₁ + β₂ = c*\")\n",
    "print(\"  β₁ + β₂ = s  (since |β₁| + |β₂| = β₁ + β₂ when both positive)\")\n",
    "print(\"  → c* = s\")\n",
    "print(\"\\n  Solutions: ALL (β₁, β₂) where β₁ + β₂ = s, β₁ ≥ 0, β₂ ≥ 0\")\n",
    "print(\"  → Line segment from (0, s) to (s, 0)\")\n",
    "\n",
    "print(\"\\nIf c* < 0 (both negative):\")\n",
    "print(\"  β₁ + β₂ = c*\")\n",
    "print(\"  -β₁ - β₂ = s  (since |β₁| + |β₂| = -β₁ - β₂ when both negative)\")\n",
    "print(\"  → c* = -s\")\n",
    "print(\"\\n  Solutions: ALL (β₁, β₂) where β₁ + β₂ = -s, β₁ ≤ 0, β₂ ≤ 0\")\n",
    "print(\"  → Line segment from (0, -s) to (-s, 0)\")\n",
    "\n",
    "print(\"\\nCase 2: Coefficients have opposite signs\")\n",
    "print(\"-\" * 35)\n",
    "print(\"If β₁ ≥ 0 and β₂ ≤ 0:\")\n",
    "print(\"  β₁ + β₂ = c*\")\n",
    "print(\"  β₁ - β₂ = s\")\n",
    "print(\"  → β₁ = (c* + s)/2,  β₂ = (c* - s)/2\")\n",
    "print(\"\\n  This gives a UNIQUE solution (if it satisfies the sign constraints)\")\n",
    "\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"GENERAL CHARACTERIZATION:\")\n",
    "print(\"─\" * 70)\n",
    "print(\"\\nThe set of optimal LASSO solutions is:\")\n",
    "print(\"\\n  {(β₁, β₂) : β₁ + β₂ = c* AND |β₁| + |β₂| = s}\")\n",
    "print(\"\\nwhere c* is the value that minimizes RSS.\")\n",
    "print(\"\\nThis is the INTERSECTION of:\")\n",
    "print(\"  • A line: β₁ + β₂ = c*\")\n",
    "print(\"  • A diamond: |β₁| + |β₂| = s\")\n",
    "print(\"\\nDepending on c* and s, this can be:\")\n",
    "print(\"  • A line segment (infinite solutions)\")\n",
    "print(\"  • A single point (unique solution)\")\n",
    "print(\"  • Two points (two solutions)\")\n",
    "```\n",
    "\n",
    "### Geometric Visualization\n",
    "\n",
    "```python\n",
    "# Right plot: LASSO geometry\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "# LASSO constraint (diamond)\n",
    "s_val = 2\n",
    "diamond_x = np.array([s_val, 0, -s_val, 0, s_val])\n",
    "diamond_y = np.array([0, s_val, 0, -s_val, 0])\n",
    "ax2.plot(diamond_x, diamond_y, 'b-', linewidth=3, label=f'|β₁| + |β₂| = {s_val}')\n",
    "ax2.fill(diamond_x, diamond_y, alpha=0.2, color='blue')\n",
    "\n",
    "# RSS contours (lines β₁ + β₂ = constant)\n",
    "for c in [-3, -2, -1, 0, 1, 2, 3]:\n",
    "    ax2.plot(beta1, c - beta1, 'r--', alpha=0.4, linewidth=1)\n",
    "\n",
    "# Optimal line (example: c* = 2)\n",
    "c_star = 2\n",
    "ax2.plot(beta1, c_star - beta1, 'r-', linewidth=3, \n",
    "         label=f'β₁ + β₂ = {c_star} (optimal)', alpha=0.8)\n",
    "\n",
    "# Intersection (infinite solutions along segment)\n",
    "# For c* = 2 and s = 2: intersection from (0, 2) to (2, 0)\n",
    "ax2.plot([0, s_val], [s_val, 0], 'go', markersize=10, linewidth=4,\n",
    "         label='Optimal solutions (infinitely many!)', zorder=5)\n",
    "ax2.plot([0, s_val], [s_val, 0], 'g-', linewidth=5, alpha=0.6, zorder=4)\n",
    "\n",
    "ax2.set_xlabel('β₁', fontsize=12)\n",
    "ax2.set_ylabel('β₂', fontsize=12)\n",
    "ax2.set_title('LASSO: Non-unique Solutions', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xlim([-3, 3])\n",
    "ax2.set_ylim([-3, 3])\n",
    "ax2.axhline(y=0, color='k', linewidth=0.5)\n",
    "ax2.axvline(x=0, color='k', linewidth=0.5)\n",
    "ax2.legend(loc='lower left', fontsize=9)\n",
    "ax2.set_aspect('equal')\n",
    "\n",
    "# Annotate the solution segment\n",
    "ax2.annotate('', xy=(2, 0), xytext=(0, 2),\n",
    "            arrowprops=dict(arrowstyle='<->', color='green', lw=3))\n",
    "ax2.text(1.3, 1.3, 'Infinite\\nsolutions!', fontsize=10, color='green',\n",
    "         fontweight='bold',\n",
    "         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ridge_vs_lasso_correlated.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n[Plot saved: 'ridge_vs_lasso_correlated.png']\")\n",
    "```\n",
    "\n",
    "### Numerical Example\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"NUMERICAL EXAMPLE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Concrete example\n",
    "print(\"\\nSuppose:\")\n",
    "print(\"  x₁₁ = x₁₂ = 1\")\n",
    "print(\"  x₂₁ = x₂₂ = -1\")\n",
    "print(\"  y₁ = 2\")\n",
    "print(\"  y₂ = -2\")\n",
    "print(\"  λ = 1 (or equivalently, s for constraint form)\")\n",
    "\n",
    "print(\"\\nVerify constraints:\")\n",
    "print(f\"  x₁₁ = x₁₂? {1 == 1} ✓\")\n",
    "print(f\"  x₂₁ = x₂₂? {-1 == -1} ✓\")\n",
    "print(f\"  y₁ + y₂ = 0? {2 + (-2) == 0} ✓\")\n",
    "print(f\"  x₁₁ + x₂₁ = 0? {1 + (-1) == 0} ✓\")\n",
    "print(f\"  x₁₂ + x₂₂ = 0? {1 + (-1) == 0} ✓\")\n",
    "\n",
    "# RSS calculation\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"RSS Calculation:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "def calc_rss(beta1, beta2, y1=2, y2=-2, x11=1, x21=-1):\n",
    "    return (y1 - x11*(beta1 + beta2))**2 + (y2 - x21*(beta1 + beta2))**2\n",
    "\n",
    "print(\"\\nRSS = (y₁ - 1·(β₁ + β₂))² + (y₂ - (-1)·(β₁ + β₂))²\")\n",
    "print(\"    = (2 - (β₁ + β₂))² + (-2 + (β₁ + β₂))²\")\n",
    "print(\"    = (2 - (β₁ + β₂))² + ((β₁ + β₂) - 2)²\")\n",
    "print(\"    = 2(2 - (β₁ + β₂))²\")\n",
    "\n",
    "print(\"\\nMinimizing RSS:\")\n",
    "print(\"  This is minimized when β₁ + β₂ = 2\")\n",
    "print(\"  → c* = 2\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"LASSO Solutions (with s = 2):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nWe need: β₁ + β₂ = 2 AND |β₁| + |β₂| = 2\")\n",
    "\n",
    "print(\"\\nSince c* = 2 > 0, both coefficients should be non-negative:\")\n",
    "print(\"  β₁ + β₂ = 2\")\n",
    "print(\"  β₁ + β₂ = 2  (when both non-negative)\")\n",
    "print(\"\\nSolutions: ALL (β₁, β₂) where β₁ + β₂ = 2, β₁ ≥ 0, β₂ ≥ 0\")\n",
    "\n",
    "print(\"\\nExamples of valid solutions:\")\n",
    "solutions = [(0, 2), (0.5, 1.5), (1, 1), (1.5, 0.5), (2, 0)]\n",
    "for b1, b2 in solutions:\n",
    "    rss = calc_rss(b1, b2)\n",
    "    l1_norm = abs(b1) + abs(b2)\n",
    "    print(f\"  (β₁, β₂) = ({b1:3.1f}, {b2:3.1f})  →  RSS = {rss:.1f},  |β₁|+|β₂| = {l1_norm:.1f}\")\n",
    "\n",
    "print(\"\\nAll these solutions give the SAME objective value!\")\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"RIDGE Solution (for comparison, with λ = 1):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# For Ridge, we showed β₁ = β₂\n",
    "print(\"\\nRidge gives: β̂₁ = β̂₂ = 1.0 (unique solution)\")\n",
    "print(\"  → Only one point on the line β₁ + β₂ = 2\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Summary and Key Insights\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY: RIDGE vs LASSO WITH CORRELATED PREDICTORS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary = \"\"\"\n",
    "╔═══════════════════════════════════════════════════════════════════╗\n",
    "║                    RIDGE REGRESSION                               ║\n",
    "╠═══════════════════════════════════════════════════════════════════╣\n",
    "║ • Penalty: L2 (β₁² + β₂²) → circular contours                    ║\n",
    "║ • With perfect correlation: β̂₁ = β̂₂ (UNIQUE solution)            ║\n",
    "║ • Gives SIMILAR coefficients to correlated variables              ║\n",
    "║ • Optimal point: where line β₁+β₂=c* is tangent to circle        ║\n",
    "║ • By symmetry, tangent point is on line β₁ = β₂                  ║\n",
    "╚═══════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "╔═══════════════════════════════════════════════════════════════════╗\n",
    "║                      LASSO                                        ║\n",
    "╠═══════════════════════════════════════════════════════════════════╣\n",
    "║ • Penalty: L1 (|β₁| + |β₂|) → diamond-shaped contours            ║\n",
    "║ • With perfect correlation: MULTIPLE solutions                    ║\n",
    "║ • Any point on line β₁+β₂=c* that touches diamond is optimal     ║\n",
    "║ • Typically gives DIFFERENT coefficients to correlated variables  ║\n",
    "║ • Can result in one coefficient being 0 (variable selection)      ║\n",
    "╚═══════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "KEY INSIGHT:\n",
    "  When RSS depends only on β₁ + β₂:\n",
    "  \n",
    "  Ridge: Minimizes β₁² + β₂² → forces β₁ = β₂ (equal sharing)\n",
    "  LASSO: Minimizes |β₁| + |β₂| → allows any β₁ + β₂ = constant\n",
    "                                  (infinitely many solutions)\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"GEOMETRIC INTERPRETATION:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "Ridge (L2 penalty):\n",
    "  • Circular constraint region\n",
    "  • Smooth, differentiable everywhere\n",
    "  • Solution typically has all non-zero coefficients\n",
    "  • Spreads weight equally among correlated predictors\n",
    "\n",
    "LASSO (L1 penalty):\n",
    "  • Diamond constraint region  \n",
    "  • Has corners (non-differentiable at axes)\n",
    "  • Solution often has some zero coefficients\n",
    "  • Picks one predictor from correlated group (arbitrary choice)\n",
    "  • This is why LASSO does variable selection!\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PRACTICAL IMPLICATIONS:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "1. With correlated predictors:\n",
    "   • Ridge: Distributes coefficients equally (stable)\n",
    "   • LASSO: Arbitrarily picks one (unstable across samples)\n",
    "\n",
    "2. For prediction:\n",
    "   • Both may give similar predictions (same β₁ + β₂)\n",
    "   • Different interpretations of individual coefficients\n",
    "\n",
    "3. For interpretation:\n",
    "   • Ridge: All correlated predictors have similar importance\n",
    "   • LASSO: Appears to select one, but choice is arbitrary\n",
    "   \n",
    "4. This demonstrates why LASSO is used for feature selection\n",
    "   and Ridge is preferred when you want to keep all features\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "plt.show()\n",
    "print(\"\\n✓ Analysis complete!\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30687cf0",
   "metadata": {},
   "source": [
    "(b) Argue that in this setting, the ridge coefficient estimates satisfy $\\hat{\\beta_1} = \\hat{\\beta_2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc9f935",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Write out the lasso optimization problem in this setting.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c322311",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d60697c3",
   "metadata": {},
   "source": [
    "(d) Argue that in this setting, the lasso coefficients $\\hat{\\beta_1}$ and $\\hat{\\beta_2}$ are not unique—in other words, there are many possible solutions to the optimization problem in (c). Describe these solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9903921",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca37acce",
   "metadata": {},
   "source": [
    "6. We will now explore (6.12) and (6.13) further.  \n",
    "   (a) Consider \n",
    "$\n",
    "\\sum_{j=1}^{p} (y_j - \\beta_j)^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2\n",
    "$  (6.12) with $p = 1$. For some choice of $y_1$ and $\\lambda > 0$, plot (6.12) as a function of $\\beta_1$. Your plot should confirm that (6.12) is solved by $\n",
    "\\hat{\\beta}_j^R = \\frac{y_j}{(1 + \\lambda)}\n",
    "$ (6.14). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e3df3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8448c748",
   "metadata": {},
   "source": [
    "# Exploring Ridge and LASSO Solutions (Equations 6.12-6.15)\n",
    "\n",
    "## Setup and Context\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"EXPLORING RIDGE AND LASSO OPTIMIZATION\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nContext: These are special cases where p = 1 and X is orthonormal\")\n",
    "print(\"In this setting, the optimization problems simplify dramatically\")\n",
    "print(\"\\nRidge (6.12): Σ(yⱼ - βⱼ)² + λΣβⱼ²\")\n",
    "print(\"LASSO (6.13): Σ(yⱼ - βⱼ)² + λΣ|βⱼ|\")\n",
    "print(\"\\nWith p = 1, these become single-variable optimization problems\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (a) Ridge Regression: Equation 6.12 and 6.14\n",
    "\n",
    "### Analytical Derivation\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(a) RIDGE REGRESSION WITH p = 1\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nObjective function:\")\n",
    "print(\"  f(β₁) = (y₁ - β₁)² + λβ₁²\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Analytical Solution:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nTo find the minimum, take the derivative and set to zero:\")\n",
    "print(\"\\n  df/dβ₁ = 2(y₁ - β₁)(-1) + 2λβ₁\")\n",
    "print(\"         = -2(y₁ - β₁) + 2λβ₁\")\n",
    "print(\"         = -2y₁ + 2β₁ + 2λβ₁\")\n",
    "print(\"         = -2y₁ + 2β₁(1 + λ)\")\n",
    "\n",
    "print(\"\\nSet equal to zero:\")\n",
    "print(\"  -2y₁ + 2β₁(1 + λ) = 0\")\n",
    "print(\"  2β₁(1 + λ) = 2y₁\")\n",
    "print(\"  β₁(1 + λ) = y₁\")\n",
    "\n",
    "print(\"\\n  β̂₁ᴿ = y₁/(1 + λ)  ✓  (Equation 6.14)\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Second derivative test (confirm it's a minimum):\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\\n  d²f/dβ₁² = 2(1 + λ)\")\n",
    "print(\"\\nSince λ > 0:\")\n",
    "print(\"  d²f/dβ₁² = 2(1 + λ) > 0  ✓  (confirms minimum)\")\n",
    "```\n",
    "\n",
    "### Visualization\n",
    "\n",
    "```python\n",
    "# Set parameters\n",
    "y1 = 5.0\n",
    "lambda_ridge = 2.0\n",
    "\n",
    "print(f\"\\n\" + \"-\" * 70)\n",
    "print(f\"Numerical Example: y₁ = {y1}, λ = {lambda_ridge}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Calculate optimal beta\n",
    "beta_opt_ridge = y1 / (1 + lambda_ridge)\n",
    "print(f\"\\nOptimal solution:\")\n",
    "print(f\"  β̂₁ᴿ = {y1}/({1 + lambda_ridge}) = {beta_opt_ridge:.4f}\")\n",
    "\n",
    "# Create plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Ridge plot\n",
    "ax = axes[0]\n",
    "beta_range = np.linspace(-2, 8, 500)\n",
    "\n",
    "# Calculate objective function components\n",
    "squared_error = (y1 - beta_range)**2\n",
    "penalty = lambda_ridge * beta_range**2\n",
    "objective = squared_error + penalty\n",
    "\n",
    "# Plot components\n",
    "ax.plot(beta_range, squared_error, 'b--', linewidth=2, alpha=0.7, \n",
    "        label=f'(y₁ - β₁)² = ({y1} - β₁)²')\n",
    "ax.plot(beta_range, penalty, 'r--', linewidth=2, alpha=0.7,\n",
    "        label=f'λβ₁² = {lambda_ridge}β₁²')\n",
    "ax.plot(beta_range, objective, 'k-', linewidth=3,\n",
    "        label='Total: (y₁ - β₁)² + λβ₁²')\n",
    "\n",
    "# Mark optimal point\n",
    "ax.plot(beta_opt_ridge, (y1 - beta_opt_ridge)**2 + lambda_ridge * beta_opt_ridge**2,\n",
    "        'ro', markersize=12, label=f'Optimal: β̂₁ᴿ = {beta_opt_ridge:.3f}', zorder=5)\n",
    "\n",
    "# Add vertical line at optimal\n",
    "ax.axvline(beta_opt_ridge, color='red', linestyle=':', alpha=0.5, linewidth=2)\n",
    "\n",
    "# Mark OLS solution for comparison\n",
    "beta_ols = y1\n",
    "ax.axvline(beta_ols, color='blue', linestyle=':', alpha=0.5, linewidth=2)\n",
    "ax.plot(beta_ols, 0, 'bs', markersize=10, label=f'OLS: β̂₁ᴼᴸˢ = {beta_ols:.1f}', zorder=5)\n",
    "\n",
    "ax.set_xlabel('β₁', fontsize=13)\n",
    "ax.set_ylabel('Objective Function Value', fontsize=13)\n",
    "ax.set_title(f'(a) Ridge: (y₁ - β₁)² + λβ₁² with y₁={y1}, λ={lambda_ridge}', \n",
    "             fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(bottom=-2)\n",
    "\n",
    "# Add annotation\n",
    "ax.annotate(f'β̂₁ᴿ = y₁/(1+λ)\\n= {y1}/{1+lambda_ridge}\\n= {beta_opt_ridge:.3f}',\n",
    "            xy=(beta_opt_ridge, (y1 - beta_opt_ridge)**2 + lambda_ridge * beta_opt_ridge**2),\n",
    "            xytext=(beta_opt_ridge + 1.5, 10),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=2),\n",
    "            fontsize=11, color='red',\n",
    "            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))\n",
    "\n",
    "print(\"\\n[Ridge plot created]\")\n",
    "```\n",
    "\n",
    "### Key Observations for Ridge\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Key Observations for Ridge:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(f\"\\n1. OLS solution (λ = 0): β̂₁ᴼᴸˢ = y₁ = {y1}\")\n",
    "print(f\"   - Minimizes only the squared error term\")\n",
    "\n",
    "print(f\"\\n2. Ridge solution (λ = {lambda_ridge}): β̂₁ᴿ = {beta_opt_ridge:.3f}\")\n",
    "print(f\"   - Shrinks coefficient toward zero\")\n",
    "print(f\"   - Shrinkage factor: 1/(1+λ) = {1/(1+lambda_ridge):.3f}\")\n",
    "\n",
    "print(f\"\\n3. Effect of λ:\")\n",
    "print(f\"   - λ = 0: β̂₁ᴿ = y₁ (no shrinkage)\")\n",
    "print(f\"   - λ → ∞: β̂₁ᴿ → 0 (complete shrinkage)\")\n",
    "print(f\"   - Current: β̂₁ᴿ/β̂₁ᴼᴸˢ = {beta_opt_ridge/y1:.3f} (shrunk by {100*(1-beta_opt_ridge/y1):.1f}%)\")\n",
    "\n",
    "print(f\"\\n4. The ridge penalty 'pulls' the solution toward zero\")\n",
    "print(f\"   - Trades increased bias for decreased variance\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (b) LASSO: Equation 6.13 and 6.15\n",
    "\n",
    "### Analytical Derivation\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(b) LASSO WITH p = 1\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nObjective function:\")\n",
    "print(\"  f(β₁) = (y₁ - β₁)² + λ|β₁|\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Analytical Solution (using subdifferential):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nThe absolute value function |β₁| is not differentiable at β₁ = 0\")\n",
    "print(\"We need to consider three cases:\")\n",
    "\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"Case 1: β₁ > 0\")\n",
    "print(\"─\" * 70)\n",
    "print(\"  f(β₁) = (y₁ - β₁)² + λβ₁\")\n",
    "print(\"  df/dβ₁ = -2(y₁ - β₁) + λ = 0\")\n",
    "print(\"  -2y₁ + 2β₁ + λ = 0\")\n",
    "print(\"  β₁ = y₁ - λ/2\")\n",
    "print(\"\\n  Valid when: β₁ > 0  ⟹  y₁ - λ/2 > 0  ⟹  y₁ > λ/2\")\n",
    "\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"Case 2: β₁ < 0\")\n",
    "print(\"─\" * 70)\n",
    "print(\"  f(β₁) = (y₁ - β₁)² - λβ₁\")\n",
    "print(\"  df/dβ₁ = -2(y₁ - β₁) - λ = 0\")\n",
    "print(\"  -2y₁ + 2β₁ - λ = 0\")\n",
    "print(\"  β₁ = y₁ + λ/2\")\n",
    "print(\"\\n  Valid when: β₁ < 0  ⟹  y₁ + λ/2 < 0  ⟹  y₁ < -λ/2\")\n",
    "\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"Case 3: β₁ = 0\")\n",
    "print(\"─\" * 70)\n",
    "print(\"  Need to check if 0 is optimal when |y₁| ≤ λ/2\")\n",
    "print(\"  At β₁ = 0: f(0) = y₁²\")\n",
    "print(\"  Moving away from 0 increases the objective\")\n",
    "print(\"  (subdifferential condition satisfied)\")\n",
    "\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"Summary (Equation 6.15):\")\n",
    "print(\"─\" * 70)\n",
    "print(\"\"\"\n",
    "         ⎧ y₁ - λ/2   if y₁ > λ/2\n",
    "  β̂₁ᴸ = ⎨ y₁ + λ/2   if y₁ < -λ/2\n",
    "         ⎩ 0          if |y₁| ≤ λ/2\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nThis is called 'soft-thresholding':\")\n",
    "print(\"  - Shrinks coefficient by λ/2\")\n",
    "print(\"  - Sets to exactly 0 if |y₁| ≤ λ/2\")\n",
    "```\n",
    "\n",
    "### Visualization\n",
    "\n",
    "```python\n",
    "# LASSO parameters\n",
    "y1_lasso = 5.0\n",
    "lambda_lasso = 3.0\n",
    "\n",
    "print(f\"\\n\" + \"-\" * 70)\n",
    "print(f\"Numerical Example: y₁ = {y1_lasso}, λ = {lambda_lasso}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Calculate optimal beta using soft-thresholding\n",
    "if y1_lasso > lambda_lasso/2:\n",
    "    beta_opt_lasso = y1_lasso - lambda_lasso/2\n",
    "    case = f\"y₁ > λ/2 ({y1_lasso} > {lambda_lasso/2})\"\n",
    "elif y1_lasso < -lambda_lasso/2:\n",
    "    beta_opt_lasso = y1_lasso + lambda_lasso/2\n",
    "    case = f\"y₁ < -λ/2 ({y1_lasso} < {-lambda_lasso/2})\"\n",
    "else:\n",
    "    beta_opt_lasso = 0\n",
    "    case = f\"|y₁| ≤ λ/2 (|{y1_lasso}| ≤ {lambda_lasso/2})\"\n",
    "\n",
    "print(f\"\\nCase: {case}\")\n",
    "print(f\"Optimal solution: β̂₁ᴸ = {beta_opt_lasso:.4f}\")\n",
    "\n",
    "# LASSO plot\n",
    "ax = axes[1]\n",
    "beta_range_lasso = np.linspace(-2, 8, 1000)\n",
    "\n",
    "# Calculate objective function (need to handle absolute value)\n",
    "squared_error_lasso = (y1_lasso - beta_range_lasso)**2\n",
    "penalty_lasso = lambda_lasso * np.abs(beta_range_lasso)\n",
    "objective_lasso = squared_error_lasso + penalty_lasso\n",
    "\n",
    "# Plot components\n",
    "ax.plot(beta_range_lasso, squared_error_lasso, 'b--', linewidth=2, alpha=0.7,\n",
    "        label=f'(y₁ - β₁)² = ({y1_lasso} - β₁)²')\n",
    "ax.plot(beta_range_lasso, penalty_lasso, 'r--', linewidth=2, alpha=0.7,\n",
    "        label=f'λ|β₁| = {lambda_lasso}|β₁|')\n",
    "ax.plot(beta_range_lasso, objective_lasso, 'k-', linewidth=3,\n",
    "        label='Total: (y₁ - β₁)² + λ|β₁|')\n",
    "\n",
    "# Mark optimal point\n",
    "opt_value_lasso = (y1_lasso - beta_opt_lasso)**2 + lambda_lasso * np.abs(beta_opt_lasso)\n",
    "ax.plot(beta_opt_lasso, opt_value_lasso, 'ro', markersize=12,\n",
    "        label=f'Optimal: β̂₁ᴸ = {beta_opt_lasso:.3f}', zorder=5)\n",
    "\n",
    "# Add vertical line at optimal\n",
    "ax.axvline(beta_opt_lasso, color='red', linestyle=':', alpha=0.5, linewidth=2)\n",
    "\n",
    "# Mark OLS solution for comparison\n",
    "beta_ols_lasso = y1_lasso\n",
    "ax.axvline(beta_ols_lasso, color='blue', linestyle=':', alpha=0.5, linewidth=2)\n",
    "ax.plot(beta_ols_lasso, 0, 'bs', markersize=10, \n",
    "        label=f'OLS: β̂₁ᴼᴸˢ = {beta_ols_lasso:.1f}', zorder=5)\n",
    "\n",
    "# Highlight the region where β = 0\n",
    "threshold = lambda_lasso / 2\n",
    "ax.axvspan(-threshold, threshold, alpha=0.2, color='yellow',\n",
    "          label=f'Zero region: |β₁| when |y₁| ≤ {threshold:.1f}')\n",
    "\n",
    "ax.set_xlabel('β₁', fontsize=13)\n",
    "ax.set_ylabel('Objective Function Value', fontsize=13)\n",
    "ax.set_title(f'(b) LASSO: (y₁ - β₁)² + λ|β₁| with y₁={y1_lasso}, λ={lambda_lasso}',\n",
    "            fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(bottom=-2)\n",
    "\n",
    "# Add annotation\n",
    "if beta_opt_lasso != 0:\n",
    "    formula = f\"y₁ - λ/2\\n= {y1_lasso} - {lambda_lasso/2}\\n= {beta_opt_lasso:.3f}\"\n",
    "else:\n",
    "    formula = \"0\\n(soft-thresholding)\"\n",
    "\n",
    "ax.annotate(f'β̂₁ᴸ = {formula}',\n",
    "            xy=(beta_opt_lasso, opt_value_lasso),\n",
    "            xytext=(beta_opt_lasso + 1.5, 10),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=2),\n",
    "            fontsize=11, color='red',\n",
    "            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ridge_lasso_optimization.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n[LASSO plot created]\")\n",
    "print(\"[Plot saved: 'ridge_lasso_optimization.png']\")\n",
    "```\n",
    "\n",
    "### Key Observations for LASSO\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Key Observations for LASSO:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(f\"\\n1. OLS solution (λ = 0): β̂₁ᴼᴸˢ = y₁ = {y1_lasso}\")\n",
    "\n",
    "print(f\"\\n2. LASSO solution (λ = {lambda_lasso}): β̂₁ᴸ = {beta_opt_lasso:.3f}\")\n",
    "print(f\"   - Soft-thresholding: shrinks by λ/2 = {lambda_lasso/2}\")\n",
    "\n",
    "print(f\"\\n3. Threshold effect:\")\n",
    "print(f\"   - If |y₁| ≤ λ/2 = {lambda_lasso/2}: β̂₁ᴸ = 0 (exactly zero!)\")\n",
    "print(f\"   - If |y₁| > λ/2 = {lambda_lasso/2}: β̂₁ᴸ = y₁ - sign(y₁)·λ/2\")\n",
    "print(f\"   - Current: |y₁| = {abs(y1_lasso)} > {lambda_lasso/2}, so β̂₁ᴸ ≠ 0\")\n",
    "\n",
    "print(f\"\\n4. Shrinkage comparison:\")\n",
    "print(f\"   - Ridge: β̂₁ᴿ = {y1/(1+lambda_ridge):.3f} (proportional shrinkage)\")\n",
    "print(f\"   - LASSO: β̂₁ᴸ = {beta_opt_lasso:.3f} (constant shrinkage)\")\n",
    "\n",
    "print(f\"\\n5. Variable selection property:\")\n",
    "print(f\"   - LASSO can set coefficients to EXACTLY zero\")\n",
    "print(f\"   - Ridge can only shrink toward zero\")\n",
    "print(f\"   - This is why LASSO performs automatic feature selection!\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Visualizations\n",
    "\n",
    "### Comparison of Ridge and LASSO Solutions\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPREHENSIVE COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create comprehensive comparison plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Different y values to explore\n",
    "y_values = [1.0, 3.0, 5.0, 7.0]\n",
    "lambda_val = 3.0\n",
    "\n",
    "# Plot 1: Ridge solutions for different y values\n",
    "ax = axes[0, 0]\n",
    "for y_val in y_values:\n",
    "    beta_ridge = y_val / (1 + lambda_val)\n",
    "    betas = np.linspace(-2, 8, 500)\n",
    "    obj = (y_val - betas)**2 + lambda_val * betas**2\n",
    "    ax.plot(betas, obj, linewidth=2, label=f'y₁={y_val}, β̂ᴿ={beta_ridge:.2f}', alpha=0.7)\n",
    "    ax.plot(beta_ridge, (y_val - beta_ridge)**2 + lambda_val * beta_ridge**2, \n",
    "            'o', markersize=8)\n",
    "\n",
    "ax.set_xlabel('β₁', fontsize=12)\n",
    "ax.set_ylabel('Ridge Objective', fontsize=12)\n",
    "ax.set_title(f'Ridge: Different y₁ values (λ={lambda_val})', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: LASSO solutions for different y values\n",
    "ax = axes[0, 1]\n",
    "for y_val in y_values:\n",
    "    if y_val > lambda_val/2:\n",
    "        beta_lasso = y_val - lambda_val/2\n",
    "    else:\n",
    "        beta_lasso = 0\n",
    "    betas = np.linspace(-2, 8, 500)\n",
    "    obj = (y_val - betas)**2 + lambda_val * np.abs(betas)\n",
    "    ax.plot(betas, obj, linewidth=2, label=f'y₁={y_val}, β̂ᴸ={beta_lasso:.2f}', alpha=0.7)\n",
    "    ax.plot(beta_lasso, (y_val - beta_lasso)**2 + lambda_val * np.abs(beta_lasso),\n",
    "            'o', markersize=8)\n",
    "\n",
    "ax.axvspan(-lambda_val/2, lambda_val/2, alpha=0.15, color='yellow', \n",
    "          label=f'Zero region')\n",
    "ax.set_xlabel('β₁', fontsize=12)\n",
    "ax.set_ylabel('LASSO Objective', fontsize=12)\n",
    "ax.set_title(f'LASSO: Different y₁ values (λ={lambda_val})', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Solution paths as function of λ\n",
    "ax = axes[1, 0]\n",
    "lambdas = np.linspace(0, 10, 200)\n",
    "y_fixed = 5.0\n",
    "\n",
    "beta_ridge_path = y_fixed / (1 + lambdas)\n",
    "beta_lasso_path = np.maximum(0, y_fixed - lambdas/2)\n",
    "\n",
    "ax.plot(lambdas, beta_ridge_path, 'b-', linewidth=3, label='Ridge: y₁/(1+λ)')\n",
    "ax.plot(lambdas, beta_lasso_path, 'r-', linewidth=3, label='LASSO: max(0, y₁-λ/2)')\n",
    "ax.axhline(y_fixed, color='g', linestyle='--', linewidth=2, label=f'OLS: y₁={y_fixed}')\n",
    "ax.axhline(0, color='k', linestyle='-', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('λ (Penalty parameter)', fontsize=12)\n",
    "ax.set_ylabel('Coefficient estimate', fontsize=12)\n",
    "ax.set_title(f'Solution Paths: β̂ vs λ (y₁={y_fixed})', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight where LASSO becomes zero\n",
    "lambda_threshold = 2 * y_fixed\n",
    "ax.axvline(lambda_threshold, color='r', linestyle=':', alpha=0.5, linewidth=2)\n",
    "ax.text(lambda_threshold, y_fixed/2, f'LASSO → 0\\nat λ={lambda_threshold}',\n",
    "        fontsize=10, ha='right', bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "# Plot 4: Shrinkage comparison\n",
    "ax = axes[1, 1]\n",
    "y_range = np.linspace(-8, 8, 200)\n",
    "lambda_comp = 3.0\n",
    "\n",
    "beta_ridge_comp = y_range / (1 + lambda_comp)\n",
    "beta_lasso_comp = np.where(y_range > lambda_comp/2, y_range - lambda_comp/2,\n",
    "                           np.where(y_range < -lambda_comp/2, y_range + lambda_comp/2, 0))\n",
    "\n",
    "ax.plot(y_range, y_range, 'g--', linewidth=2, label='OLS (no shrinkage)')\n",
    "ax.plot(y_range, beta_ridge_comp, 'b-', linewidth=3, label=f'Ridge (λ={lambda_comp})')\n",
    "ax.plot(y_range, beta_lasso_comp, 'r-', linewidth=3, label=f'LASSO (λ={lambda_comp})')\n",
    "\n",
    "# Highlight threshold region\n",
    "ax.axvspan(-lambda_comp/2, lambda_comp/2, alpha=0.2, color='yellow',\n",
    "          label=f'LASSO zero region')\n",
    "ax.axhline(0, color='k', linestyle='-', linewidth=0.5)\n",
    "ax.axvline(0, color='k', linestyle='-', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('y₁ (OLS estimate)', fontsize=12)\n",
    "ax.set_ylabel('β̂ (Regularized estimate)', fontsize=12)\n",
    "ax.set_title('Shrinkage Functions: Ridge vs LASSO', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ridge_lasso_comprehensive.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n[Comprehensive comparison plot created]\")\n",
    "print(\"[Plot saved: 'ridge_lasso_comprehensive.png']\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Table\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY: RIDGE vs LASSO (p = 1 case)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary_table = \"\"\"\n",
    "╔═══════════════════════════════════════════════════════════════════╗\n",
    "║                    RIDGE (Equation 6.14)                          ║\n",
    "╠═══════════════════════════════════════════════════════════════════╣\n",
    "║ Objective:    (y₁ - β₁)² + λβ₁²                                  ║\n",
    "║ Solution:     β̂₁ᴿ = y₁/(1 + λ)                                   ║\n",
    "║ Shrinkage:    PROPORTIONAL (multiply by 1/(1+λ))                 ║\n",
    "║ Properties:   • Smooth, differentiable                            ║\n",
    "║               • Always shrinks toward zero                        ║\n",
    "║               • NEVER exactly zero (unless y₁ = 0)                ║\n",
    "║               • More λ → more shrinkage                           ║\n",
    "╚═══════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "╔═══════════════════════════════════════════════════════════════════╗\n",
    "║                    LASSO (Equation 6.15)                          ║\n",
    "╠═══════════════════════════════════════════════════════════════════╣\n",
    "║ Objective:    (y₁ - β₁)² + λ|β₁|                                 ║\n",
    "║ Solution:     β̂₁ᴸ = sign(y₁)·max(0, |y₁| - λ/2)                 ║\n",
    "║               (soft-thresholding operator)                        ║\n",
    "║ Shrinkage:    CONSTANT (subtract λ/2)                            ║\n",
    "║ Properties:   • Non-differentiable at β₁ = 0                     ║\n",
    "║               • Hard threshold at |y₁| = λ/2                      ║\n",
    "║               • CAN BE exactly zero (when |y₁| ≤ λ/2)            ║\n",
    "║               • Performs automatic variable selection             ║\n",
    "╚═══════════════════════════════════════════════════════════════════╝\n",
    "\"\"\"\n",
    "\n",
    "print(summary_table)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY DIFFERENCES:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "differences = [\n",
    "    [\"Property\", \"Ridge\", \"LASSO\"],\n",
    "    [\"-\" * 25, \"-\" * 30, \"-\" * 30],\n",
    "    [\"Shrinkage type\", \"Proportional scaling\", \"Constant subtraction\"],\n",
    "    [\"Zero coefficients?\", \"No (only approaches 0)\", \"Yes (exactly 0 possible)\"],\n",
    "    [\"Differentiability\", \"Smooth everywhere\", \"Non-smooth at 0\"],\n",
    "    [\"Variable selection\", \"No\", \"Yes\"],\n",
    "    [\"Shrinkage at y₁=4, λ=2\", \"4/(1+2) = 1.33\", \"4 - 2/2 = 3.0\"],\n",
    "    [\"When is β̂=0?\", \"Never (unless y₁=0)\", \"When |y₁| ≤ λ/2\"]\n",
    "]\n",
    "\n",
    "for row in differences:\n",
    "    print(f\"{row[0]:<25} {row[1]:<30} {row[2]:<30}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PRACTICAL IMPLICATIONS:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "1. RIDGE is better when:\n",
    "   • You want to keep all variables\n",
    "   • Variables are all potentially relevant\n",
    "   • Prediction accuracy is the main goal\n",
    "\n",
    "2. LASSO is better when:\n",
    "   • You want automatic feature selection\n",
    "   • You believe many variables are irrelevant\n",
    "   • Interpretability is important\n",
    "   • Sparse solutions are desired\n",
    "\n",
    "3. Both methods:\n",
    "   • Shrink coefficients toward zero\n",
    "   • Reduce variance at the cost of increased bias\n",
    "   • Require tuning λ (via cross-validation)\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "plt.show()\n",
    "print(\"\\n✓ All visualizations complete!\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ecc0dc",
   "metadata": {},
   "source": [
    "(b) Consider $\n",
    "\\sum_{j=1}^{p} (y_j - \\beta_j)^2 + \\lambda \\sum_{j=1}^{p} |\\beta_j|\n",
    "$ (6.13) with $p = 1$. For some choice of $y_1$ and $\\lambda > 0$, plot (6.13) as a function of $\\beta_1$. Your plot should confirm that (6.13) is solved by (6.15)\n",
    "$$\n",
    "\\hat{\\beta}_j^L = \n",
    "\\begin{cases} \n",
    "y_j - \\lambda/2 & \\text{if } y_j > \\lambda/2; \\\\ \n",
    "y_j + \\lambda/2 & \\text{if } y_j < -\\lambda/2; \\\\ \n",
    "0 & \\text{if } |y_j| \\leq \\lambda/2.\n",
    "\\end{cases}\n",
    "$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d50c950",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d18d19a",
   "metadata": {},
   "source": [
    "7. We will now derive the Bayesian connection to the lasso and ridge regression discussed in Section 6.2.2.  \n",
    "   (a) Suppose that $y_i = \\beta_0 + \\sum_{j=1}^{p} x_{ij} \\beta_j + \\epsilon_i$ where $\\epsilon_1, \\ldots, \\epsilon_n$ are independent and identically distributed from a $N(0, \\sigma^2)$ distribution. Write out the likelihood for the data.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6197b7dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "167cffe0",
   "metadata": {},
   "source": [
    "# Bayesian Connection to LASSO and Ridge Regression\n",
    "\n",
    "## Setup\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "print(\"BAYESIAN INTERPRETATION OF LASSO AND RIDGE REGRESSION\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nWe'll show that:\")\n",
    "print(\"  • LASSO = MAP estimate with Laplace (double-exponential) prior\")\n",
    "print(\"  • Ridge = MAP estimate with Gaussian prior\")\n",
    "print(\"\\nThis provides a Bayesian interpretation of regularization!\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (a) Likelihood for the Data\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(a) LIKELIHOOD FOR THE DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nModel:\")\n",
    "print(\"  yᵢ = β₀ + Σⱼ xᵢⱼβⱼ + εᵢ,  where εᵢ ~ N(0, σ²) i.i.d.\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Derivation:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nSince εᵢ ~ N(0, σ²), we have:\")\n",
    "print(\"  yᵢ | X, β ~ N(β₀ + Σⱼ xᵢⱼβⱼ, σ²)\")\n",
    "\n",
    "print(\"\\nProbability density for a single observation:\")\n",
    "print(\"  p(yᵢ | xᵢ, β) = (1/√(2πσ²)) exp(-(yᵢ - β₀ - Σⱼ xᵢⱼβⱼ)²/(2σ²))\")\n",
    "\n",
    "print(\"\\nSince observations are independent, the likelihood is:\")\n",
    "print(\"\\n  L(β | y, X) = ∏ᵢ₌₁ⁿ p(yᵢ | xᵢ, β)\")\n",
    "\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"LIKELIHOOD:\")\n",
    "print(\"─\" * 70)\n",
    "print(\"\"\"\n",
    "  L(β | y, X) = ∏ᵢ₌₁ⁿ (1/√(2πσ²)) exp(-(yᵢ - β₀ - Σⱼ xᵢⱼβⱼ)²/(2σ²))\n",
    "\n",
    "              = (1/(2πσ²))^(n/2) exp(-1/(2σ²) Σᵢ₌₁ⁿ (yᵢ - β₀ - Σⱼ xᵢⱼβⱼ)²)\n",
    "\n",
    "              = (1/(2πσ²))^(n/2) exp(-RSS/(2σ²))\n",
    "\"\"\")\n",
    "\n",
    "print(\"where RSS = Σᵢ₌₁ⁿ (yᵢ - β₀ - Σⱼ xᵢⱼβⱼ)²\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Log-likelihood:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "  log L(β | y, X) = -(n/2)log(2πσ²) - RSS/(2σ²)\n",
    "\n",
    "                  ∝ -RSS  (treating σ² as constant)\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (b) Posterior with Laplace Prior (LASSO Connection)\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(b) POSTERIOR WITH LAPLACE (DOUBLE-EXPONENTIAL) PRIOR\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nPrior distribution:\")\n",
    "print(\"  βⱼ ~ Double-Exponential(0, b)  independently for j = 1, ..., p\")\n",
    "print(\"\\n  p(βⱼ) = (1/(2b)) exp(-|βⱼ|/b)\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Joint Prior:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nSince β₁, ..., βₚ are independent:\")\n",
    "print(\"\\n  p(β) = ∏ⱼ₌₁ᵖ p(βⱼ)\")\n",
    "print(\"       = ∏ⱼ₌₁ᵖ (1/(2b)) exp(-|βⱼ|/b)\")\n",
    "print(\"       = (1/(2b))ᵖ exp(-1/b · Σⱼ₌₁ᵖ |βⱼ|)\")\n",
    "\n",
    "print(\"\\nNote: We typically assume a flat/improper prior for β₀, or treat it separately\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Posterior Distribution (using Bayes' Theorem):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nBayes' Theorem:\")\n",
    "print(\"  p(β | y, X) ∝ p(y | X, β) · p(β)\")\n",
    "print(\"              = Likelihood × Prior\")\n",
    "\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"POSTERIOR:\")\n",
    "print(\"─\" * 70)\n",
    "print(\"\"\"\n",
    "  p(β | y, X) ∝ (1/(2πσ²))^(n/2) exp(-RSS/(2σ²)) · (1/(2b))ᵖ exp(-Σⱼ|βⱼ|/b)\n",
    "\n",
    "              ∝ exp(-RSS/(2σ²) - Σⱼ|βⱼ|/b)\n",
    "\n",
    "              ∝ exp(-1/(2σ²) · [RSS + (2σ²/b)Σⱼ|βⱼ|])\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Log-posterior:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "  log p(β | y, X) ∝ -RSS/(2σ²) - Σⱼ|βⱼ|/b\n",
    "\n",
    "                  ∝ -RSS - λΣⱼ|βⱼ|\n",
    "\n",
    "  where λ = 2σ²/b\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nNote: Maximizing log-posterior is equivalent to minimizing\")\n",
    "print(\"      RSS + λΣⱼ|βⱼ|  ← This is the LASSO objective!\")\n",
    "```\n",
    "\n",
    "### Visualization of Laplace Prior\n",
    "\n",
    "```python\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Plot Laplace distribution\n",
    "ax = axes[0]\n",
    "b_val = 1.0\n",
    "beta_range = np.linspace(-5, 5, 1000)\n",
    "laplace_pdf = (1/(2*b_val)) * np.exp(-np.abs(beta_range)/b_val)\n",
    "\n",
    "ax.plot(beta_range, laplace_pdf, 'r-', linewidth=3, label=f'Laplace(0, b={b_val})')\n",
    "ax.fill_between(beta_range, 0, laplace_pdf, alpha=0.3, color='red')\n",
    "\n",
    "# Compare with Gaussian\n",
    "c_val = 1.0\n",
    "gaussian_pdf = (1/np.sqrt(2*np.pi*c_val)) * np.exp(-beta_range**2/(2*c_val))\n",
    "ax.plot(beta_range, gaussian_pdf, 'b--', linewidth=2, label=f'Gaussian(0, c={c_val})')\n",
    "\n",
    "ax.set_xlabel('β', fontsize=12)\n",
    "ax.set_ylabel('Prior density p(β)', fontsize=12)\n",
    "ax.set_title('(b) Laplace Prior for LASSO', fontweight='bold', fontsize=13)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axvline(0, color='k', linewidth=0.5)\n",
    "\n",
    "# Highlight key property\n",
    "ax.text(0, 0.55, 'Sharp peak at 0\\n→ Encourages sparsity', \n",
    "        fontsize=10, ha='center',\n",
    "        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))\n",
    "\n",
    "print(\"\\n[Creating visualizations...]\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (c) LASSO Estimate as Posterior Mode (MAP)\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(c) LASSO ESTIMATE IS THE POSTERIOR MODE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nDefinition: The Maximum A Posteriori (MAP) estimate is:\")\n",
    "print(\"  β̂ᴹᴬᴾ = argmax_β p(β | y, X)\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Proof:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nFrom part (b), we have:\")\n",
    "print(\"  p(β | y, X) ∝ exp(-RSS/(2σ²) - Σⱼ|βⱼ|/b)\")\n",
    "\n",
    "print(\"\\nTaking logarithm:\")\n",
    "print(\"  log p(β | y, X) ∝ -RSS/(2σ²) - Σⱼ|βⱼ|/b\")\n",
    "\n",
    "print(\"\\nMaximizing log-posterior is equivalent to minimizing:\")\n",
    "print(\"  -log p(β | y, X) ∝ RSS/(2σ²) + Σⱼ|βⱼ|/b\")\n",
    "\n",
    "print(\"\\nMultiplying by 2σ² (doesn't change argmin):\")\n",
    "print(\"  RSS + (2σ²/b)Σⱼ|βⱼ|\")\n",
    "\n",
    "print(\"\\nLet λ = 2σ²/b, then we minimize:\")\n",
    "print(\"  RSS + λΣⱼ|βⱼ|\")\n",
    "\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"CONCLUSION:\")\n",
    "print(\"─\" * 70)\n",
    "print(\"\"\"\n",
    "  β̂ᴹᴬᴾ = argmin_β [RSS + λΣⱼ|βⱼ|]\n",
    "\n",
    "This is EXACTLY the LASSO optimization problem! ✓\n",
    "\n",
    "Therefore:\n",
    "  • LASSO estimate = MAP estimate under Laplace prior\n",
    "  • The penalty parameter λ relates to prior: λ = 2σ²/b\n",
    "  • Larger b (more diffuse prior) → smaller λ (less regularization)\n",
    "  • Smaller b (more concentrated prior) → larger λ (more regularization)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Intuition:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "The Laplace prior has a sharp peak at zero:\n",
    "  • Assigns high probability to β = 0\n",
    "  • This \"encourages\" sparse solutions\n",
    "  • The L1 penalty in LASSO reflects this prior belief\n",
    "  • MAP estimation balances fit to data (RSS) with prior belief (sparsity)\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (d) Posterior with Gaussian Prior (Ridge Connection)\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(d) POSTERIOR WITH GAUSSIAN PRIOR\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nPrior distribution:\")\n",
    "print(\"  βⱼ ~ N(0, c)  independently for j = 1, ..., p\")\n",
    "print(\"\\n  p(βⱼ) = (1/√(2πc)) exp(-βⱼ²/(2c))\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Joint Prior:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nSince β₁, ..., βₚ are independent:\")\n",
    "print(\"\\n  p(β) = ∏ⱼ₌₁ᵖ p(βⱼ)\")\n",
    "print(\"       = ∏ⱼ₌₁ᵖ (1/√(2πc)) exp(-βⱼ²/(2c))\")\n",
    "print(\"       = (1/(2πc))^(p/2) exp(-1/(2c) · Σⱼ₌₁ᵖ βⱼ²)\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Posterior Distribution:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nUsing Bayes' Theorem:\")\n",
    "print(\"  p(β | y, X) ∝ p(y | X, β) · p(β)\")\n",
    "\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"POSTERIOR:\")\n",
    "print(\"─\" * 70)\n",
    "print(\"\"\"\n",
    "  p(β | y, X) ∝ exp(-RSS/(2σ²)) · exp(-Σⱼβⱼ²/(2c))\n",
    "\n",
    "              ∝ exp(-RSS/(2σ²) - Σⱼβⱼ²/(2c))\n",
    "\n",
    "              ∝ exp(-1/(2σ²) · [RSS + (σ²/c)Σⱼβⱼ²])\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Log-posterior:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "  log p(β | y, X) ∝ -RSS/(2σ²) - Σⱼβⱼ²/(2c)\n",
    "\n",
    "                  ∝ -RSS - λΣⱼβⱼ²\n",
    "\n",
    "  where λ = σ²/c\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nNote: The posterior is still Gaussian (conjugate prior)!\")\n",
    "```\n",
    "\n",
    "### Visualization of Gaussian Prior\n",
    "\n",
    "```python\n",
    "# Plot Gaussian prior\n",
    "ax = axes[1]\n",
    "c_vals = [0.5, 1.0, 2.0]\n",
    "colors = ['darkblue', 'blue', 'lightblue']\n",
    "\n",
    "for c_val, color in zip(c_vals, colors):\n",
    "    gaussian_pdf = (1/np.sqrt(2*np.pi*c_val)) * np.exp(-beta_range**2/(2*c_val))\n",
    "    ax.plot(beta_range, gaussian_pdf, linewidth=3, color=color, \n",
    "            label=f'N(0, c={c_val})', alpha=0.8)\n",
    "    ax.fill_between(beta_range, 0, gaussian_pdf, alpha=0.2, color=color)\n",
    "\n",
    "ax.set_xlabel('β', fontsize=12)\n",
    "ax.set_ylabel('Prior density p(β)', fontsize=12)\n",
    "ax.set_title('(d) Gaussian Prior for Ridge', fontweight='bold', fontsize=13)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axvline(0, color='k', linewidth=0.5)\n",
    "\n",
    "# Highlight key property\n",
    "ax.text(0, 0.85, 'Smooth at 0\\n→ Shrinkage but not sparsity', \n",
    "        fontsize=10, ha='center',\n",
    "        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (e) Ridge Estimate as Posterior Mode and Mean\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(e) RIDGE ESTIMATE IS BOTH MODE AND MEAN OF POSTERIOR\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"Part 1: Ridge Estimate is the Posterior Mode (MAP)\")\n",
    "print(\"─\" * 70)\n",
    "\n",
    "print(\"\\nFrom part (d), we have:\")\n",
    "print(\"  p(β | y, X) ∝ exp(-RSS/(2σ²) - Σⱼβⱼ²/(2c))\")\n",
    "\n",
    "print(\"\\nTaking logarithm:\")\n",
    "print(\"  log p(β | y, X) ∝ -RSS/(2σ²) - Σⱼβⱼ²/(2c)\")\n",
    "\n",
    "print(\"\\nMaximizing log-posterior is equivalent to minimizing:\")\n",
    "print(\"  RSS/(2σ²) + Σⱼβⱼ²/(2c)\")\n",
    "\n",
    "print(\"\\nMultiplying by 2σ² (doesn't change argmin):\")\n",
    "print(\"  RSS + (σ²/c)Σⱼβⱼ²\")\n",
    "\n",
    "print(\"\\nLet λ = σ²/c, then we minimize:\")\n",
    "print(\"  RSS + λΣⱼβⱼ²\")\n",
    "\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"CONCLUSION (Mode):\")\n",
    "print(\"─\" * 70)\n",
    "print(\"\"\"\n",
    "  β̂ᴹᴬᴾ = argmin_β [RSS + λΣⱼβⱼ²]\n",
    "\n",
    "This is EXACTLY the Ridge regression problem! ✓\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"Part 2: Ridge Estimate is Also the Posterior Mean\")\n",
    "print(\"─\" * 70)\n",
    "\n",
    "print(\"\\nKey fact: When both likelihood and prior are Gaussian,\")\n",
    "print(\"         the posterior is also Gaussian (conjugacy)!\")\n",
    "\n",
    "print(\"\\nFor Gaussian distributions:\")\n",
    "print(\"  Mode = Mean = Median\")\n",
    "\n",
    "print(\"\\nTherefore, the posterior mean equals the posterior mode:\")\n",
    "print(\"  E[β | y, X] = Mode[β | y, X] = β̂ᴿⁱᵈᵍᵉ\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Mathematical Details:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "The posterior is:\n",
    "  p(β | y, X) ∝ exp(-1/(2σ²)[RSS + λΣⱼβⱼ²])\n",
    "\n",
    "This can be rewritten as:\n",
    "  p(β | y, X) ∝ exp(-1/(2σ²)[(β - β̂)ᵀA(β - β̂)])\n",
    "\n",
    "where:\n",
    "  • β̂ is the ridge estimate (minimizer of RSS + λΣβⱼ²)\n",
    "  • A = XᵀX + λI is the Hessian\n",
    "\n",
    "Since this is a quadratic form in β, the posterior is Gaussian:\n",
    "  β | y, X ~ N(β̂, σ²A⁻¹)\n",
    "\n",
    "For a Gaussian distribution:\n",
    "  • Mode = β̂  (the ridge estimate)\n",
    "  • Mean = β̂  (same!)\n",
    "  • The distribution is symmetric around β̂\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"SUMMARY:\")\n",
    "print(\"─\" * 70)\n",
    "print(\"\"\"\n",
    "Ridge regression estimate is:\n",
    "  1. The MAP (Maximum A Posteriori) estimate ✓\n",
    "  2. The posterior mean estimate ✓\n",
    "  3. The posterior median estimate ✓\n",
    "\n",
    "This is a special property of Gaussian priors!\n",
    "(LASSO does NOT have this property - mode ≠ mean for Laplace prior)\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "### Comparison of Posterior Distributions\n",
    "\n",
    "```python\n",
    "# Compare posterior shapes\n",
    "ax = axes[2]\n",
    "\n",
    "# Simulate posteriors (simplified 1D case)\n",
    "beta_range_narrow = np.linspace(-3, 5, 1000)\n",
    "\n",
    "# Ridge posterior (Gaussian)\n",
    "beta_ridge = 2.0\n",
    "sigma_ridge = 0.8\n",
    "ridge_posterior = stats.norm.pdf(beta_range_narrow, beta_ridge, sigma_ridge)\n",
    "\n",
    "# LASSO posterior (not Gaussian - asymmetric)\n",
    "# Approximate as mixture for visualization\n",
    "# The actual posterior with Laplace prior is complex\n",
    "y_data = 2.5\n",
    "b_lasso = 1.0\n",
    "sigma_lasso = 1.0\n",
    "\n",
    "# Simplified representation (not exact)\n",
    "lasso_posterior = np.exp(-0.5*((beta_range_narrow - y_data)**2)/sigma_lasso**2 \n",
    "                         - np.abs(beta_range_narrow)/b_lasso)\n",
    "lasso_posterior = lasso_posterior / np.trapz(lasso_posterior, beta_range_narrow)\n",
    "\n",
    "ax.plot(beta_range_narrow, ridge_posterior, 'b-', linewidth=3, \n",
    "        label='Ridge posterior (Gaussian)', alpha=0.8)\n",
    "ax.fill_between(beta_range_narrow, 0, ridge_posterior, alpha=0.3, color='blue')\n",
    "\n",
    "ax.plot(beta_range_narrow, lasso_posterior, 'r-', linewidth=3,\n",
    "        label='LASSO posterior (non-Gaussian)', alpha=0.8)\n",
    "ax.fill_between(beta_range_narrow, 0, lasso_posterior, alpha=0.3, color='red')\n",
    "\n",
    "# Mark mode and mean for Ridge\n",
    "ax.axvline(beta_ridge, color='blue', linestyle='--', linewidth=2, \n",
    "          label='Ridge: Mode = Mean')\n",
    "\n",
    "# Mark mode for LASSO (would be different from mean)\n",
    "lasso_mode = beta_range_narrow[np.argmax(lasso_posterior)]\n",
    "lasso_mean = np.trapz(beta_range_narrow * lasso_posterior, beta_range_narrow)\n",
    "ax.axvline(lasso_mode, color='red', linestyle='--', linewidth=2, \n",
    "          label=f'LASSO: Mode')\n",
    "ax.axvline(lasso_mean, color='darkred', linestyle=':', linewidth=2,\n",
    "          label=f'LASSO: Mean')\n",
    "\n",
    "ax.set_xlabel('β', fontsize=12)\n",
    "ax.set_ylabel('Posterior density p(β|y,X)', fontsize=12)\n",
    "ax.set_title('(e) Posterior Distributions: Ridge vs LASSO', \n",
    "            fontweight='bold', fontsize=13)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('bayesian_interpretation.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n[Plot saved: 'bayesian_interpretation.png']\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Summary and Comparison\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPLETE SUMMARY: BAYESIAN INTERPRETATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary_table = \"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════════╗\n",
    "║                              LASSO                                   ║\n",
    "╠══════════════════════════════════════════════════════════════════════╣\n",
    "║ Prior:           βⱼ ~ Laplace(0, b) = (1/(2b))exp(-|βⱼ|/b)         ║\n",
    "║ Posterior:       p(β|y,X) ∝ exp(-RSS/(2σ²) - Σ|βⱼ|/b)              ║\n",
    "║ MAP Estimate:    argmin [RSS + λΣ|βⱼ|], λ = 2σ²/b                  ║\n",
    "║ Properties:      • Sharp peak at 0 in prior                         ║\n",
    "║                  • Encourages sparsity                               ║\n",
    "║                  • Mode ≠ Mean (asymmetric posterior)                ║\n",
    "║                  • LASSO = MAP estimate                              ║\n",
    "╚══════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "╔══════════════════════════════════════════════════════════════════════╗\n",
    "║                             RIDGE                                    ║\n",
    "╠══════════════════════════════════════════════════════════════════════╣\n",
    "║ Prior:           βⱼ ~ N(0, c) = (1/√(2πc))exp(-βⱼ²/(2c))           ║\n",
    "║ Posterior:       p(β|y,X) ∝ exp(-RSS/(2σ²) - Σβⱼ²/(2c))            ║\n",
    "║                  β|y,X ~ N(β̂ᴿⁱᵈᵍᵉ, σ²(XᵀX + λI)⁻¹)                 ║\n",
    "║ MAP Estimate:    argmin [RSS + λΣβⱼ²], λ = σ²/c                    ║\n",
    "║ Properties:      • Smooth at 0 in prior                             ║\n",
    "║                  • Shrinkage without sparsity                        ║\n",
    "║                  • Mode = Mean = Median (symmetric posterior)        ║\n",
    "║                  • Ridge = MAP = Posterior Mean                      ║\n",
    "╚══════════════════════════════════════════════════════════════════════╝\n",
    "\"\"\"\n",
    "\n",
    "print(summary_table)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "insights = \"\"\"\n",
    "1. REGULARIZATION AS PRIOR BELIEF:\n",
    "   • Ridge penalty λΣβⱼ² ↔ Gaussian prior belief that βⱼ ≈ 0\n",
    "   • LASSO penalty λΣ|βⱼ| ↔ Laplace prior belief that βⱼ = 0 (sparse)\n",
    "\n",
    "2. PENALTY PARAMETER λ:\n",
    "   • Ridge: λ = σ²/c (larger c → smaller λ → less regularization)\n",
    "   • LASSO: λ = 2σ²/b (larger b → smaller λ → less regularization)\n",
    "   • Both: λ balances data fit (likelihood) vs prior belief\n",
    "\n",
    "3. POINT ESTIMATES:\n",
    "   • Ridge: Mode = Mean (Gaussian posterior, symmetric)\n",
    "   • LASSO: Mode only (non-Gaussian posterior, asymmetric)\n",
    "   • Both: Maximum A Posteriori (MAP) estimation\n",
    "\n",
    "4. PHILOSOPHICAL INTERPRETATION:\n",
    "   • Frequentist view: Regularization prevents overfitting\n",
    "   • Bayesian view: Regularization encodes prior knowledge\n",
    "   • Same solutions, different interpretations!\n",
    "\n",
    "5. PRACTICAL IMPLICATIONS:\n",
    "   • Can use Bayesian methods to choose λ (empirical Bayes)\n",
    "   • Posterior distribution gives uncertainty quantification\n",
    "   • Ridge: Can compute credible intervals easily (Gaussian)\n",
    "   • LASSO: More complex posterior, harder inference\n",
    "\"\"\"\n",
    "\n",
    "print(insights)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Visual Summary: Prior Shapes\n",
    "\n",
    "```python\n",
    "# Create a comprehensive visual summary\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Plot 1: Prior comparison (log scale)\n",
    "ax = axes[0, 0]\n",
    "beta_range_log = np.linspace(-5, 5, 1000)\n",
    "\n",
    "b_val = 1.0\n",
    "c_val = 1.0\n",
    "\n",
    "laplace_prior = (1/(2*b_val)) * np.exp(-np.abs(beta_range_log)/b_val)\n",
    "gaussian_prior = (1/np.sqrt(2*np.pi*c_val)) * np.exp(-beta_range_log**2/(2*c_val))\n",
    "\n",
    "ax.semilogy(beta_range_log, laplace_prior, 'r-', linewidth=3, \n",
    "            label='Laplace (LASSO)', alpha=0.8)\n",
    "ax.semilogy(beta_range_log, gaussian_prior, 'b-', linewidth=3,\n",
    "            label='Gaussian (Ridge)', alpha=0.8)\n",
    "ax.set_xlabel('β', fontsize=12)\n",
    "ax.set_ylabel('Prior density (log scale)', fontsize=12)\n",
    "ax.set_title('Prior Distributions (Log Scale)', fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3, which='both')\n",
    "ax.axvline(0, color='k', linewidth=0.5)\n",
    "\n",
    "# Plot 2: Negative log prior (penalty)\n",
    "ax = axes[0, 1]\n",
    "laplace_penalty = np.abs(beta_range_log) / b_val\n",
    "gaussian_penalty = beta_range_log**2 / (2*c_val)\n",
    "\n",
    "ax.plot(beta_range_log, laplace_penalty, 'r-', linewidth=3,\n",
    "       label='LASSO: |β|/b', alpha=0.8)\n",
    "ax.plot(beta_range_log, gaussian_penalty, 'b-', linewidth=3,\n",
    "       label='Ridge: β²/(2c)', alpha=0.8)\n",
    "ax.set_xlabel('β', fontsize=12)\n",
    "ax.set_ylabel('Penalty: -log p(β)', fontsize=12)\n",
    "ax.set_title('Penalty Functions (Negative Log Prior)', fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axvline(0, color='k', linewidth=0.5)\n",
    "\n",
    "# Highlight different behavior at 0\n",
    "ax.text(2, 0.5, 'LASSO: Non-differentiable at 0\\n(sharp corner)', \n",
    "       fontsize=10, color='red',\n",
    "       bbox=dict(boxstyle='round', facecolor='pink', alpha=0.7))\n",
    "ax.text(-3.5, 3, 'Ridge: Smooth at 0\\n(differentiable)', \n",
    "       fontsize=10, color='blue',\n",
    "       bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "\n",
    "# Plot 3: Effect of prior strength\n",
    "ax = axes[1, 0]\n",
    "lambda_vals = np.array([0.1, 0.5, 1.0, 2.0, 5.0])\n",
    "y_ols = 3.0\n",
    "\n",
    "ridge_estimates = y_ols / (1 + lambda_vals)\n",
    "lasso_estimates = np.maximum(0, y_ols - lambda_vals/2)\n",
    "\n",
    "ax.plot(lambda_vals, ridge_estimates, 'b-o', linewidth=3, markersize=8,\n",
    "       label='Ridge: y/(1+λ)', alpha=0.8)\n",
    "ax.plot(lambda_vals, lasso_estimates, 'r-o', linewidth=3, markersize=8,\n",
    "       label='LASSO: max(0, y-λ/2)', alpha=0.8)\n",
    "ax.axhline(y_ols, color='g', linestyle='--', linewidth=2,\n",
    "          label=f'OLS: y={y_ols}')\n",
    "ax.axhline(0, color='k', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('λ (Penalty strength)', fontsize=12)\n",
    "ax.set_ylabel('Coefficient estimate', fontsize=12)\n",
    "ax.set_title(f'MAP Estimates vs λ (y={y_ols})', fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight LASSO threshold\n",
    "threshold_lambda = 2 * y_ols\n",
    "ax.axvline(threshold_lambda, color='r', linestyle=':', alpha=0.5, linewidth=2)\n",
    "ax.text(threshold_lambda + 0.2, 1.5, f'LASSO→0\\nat λ={threshold_lambda}',\n",
    "       fontsize=10, color='red')\n",
    "\n",
    "# Plot 4: Posterior uncertainty (Ridge only)\n",
    "ax = axes[1, 1]\n",
    "\n",
    "# Ridge posterior with different λ\n",
    "lambda_ridge_vals = [0.5, 2.0, 5.0]\n",
    "y_obs = 2.0\n",
    "sigma = 1.0\n",
    "\n",
    "for lam in lambda_ridge_vals:\n",
    "    # Posterior mean\n",
    "    post_mean = y_obs / (1 + lam)\n",
    "    # Posterior variance (simplified)\n",
    "    post_var = sigma**2 / (1 + lam)\n",
    "    post_std = np.sqrt(post_var)\n",
    "    \n",
    "    # Plot posterior\n",
    "    posterior = stats.norm.pdf(beta_range_narrow, post_mean, post_std)\n",
    "    ax.plot(beta_range_narrow, posterior, linewidth=2.5,\n",
    "           label=f'λ={lam}: β̂={post_mean:.2f}, σ={post_std:.2f}', alpha=0.8)\n",
    "\n",
    "ax.axvline(y_obs, color='g', linestyle='--', linewidth=2, label=f'OLS: {y_obs}')\n",
    "ax.set_xlabel('β', fontsize=12)\n",
    "ax.set_ylabel('Posterior density', fontsize=12)\n",
    "ax.set_title('Ridge: Posterior Distribution (Bayesian Uncertainty)', fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('bayesian_comprehensive.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n[Comprehensive plot saved: 'bayesian_comprehensive.png']\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Connection to Model Selection\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BONUS: CONNECTION TO MODEL SELECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "From a Bayesian perspective:\n",
    "\n",
    "1. MARGINAL LIKELIHOOD (Model Evidence):\n",
    "   p(y | X, λ) = ∫ p(y | X, β) p(β | λ) dβ\n",
    "   \n",
    "   This integrates out the parameters β\n",
    "   Can be used to select λ via empirical Bayes\n",
    "\n",
    "2. CROSS-VALIDATION AS APPROXIMATION:\n",
    "   • k-fold CV approximates the marginal likelihood\n",
    "   • Provides practical way to choose λ\n",
    "   • Frequentist method with Bayesian interpretation\n",
    "\n",
    "3. FULL BAYESIAN APPROACH:\n",
    "   • Put hyperprior on λ: p(λ)\n",
    "   • Sample from p(β, λ | y, X) using MCMC\n",
    "   • Get full posterior distribution\n",
    "   • More computationally intensive but complete uncertainty\n",
    "\n",
    "4. EMPIRICAL BAYES (TYPE II MAXIMUM LIKELIHOOD):\n",
    "   λ̂ = argmax_λ p(y | X, λ)\n",
    "   • Estimate λ from data\n",
    "   • Then do MAP with fixed λ\n",
    "   • Common practical compromise\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL TAKEAWAY:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "The Bayesian framework provides:\n",
    "  ✓ Principled interpretation of regularization\n",
    "  ✓ Methods to choose regularization parameter λ\n",
    "  ✓ Uncertainty quantification (especially for Ridge)\n",
    "  ✓ Connection between optimization and probability\n",
    "\n",
    "Regularization penalty = Negative log prior probability\n",
    "\n",
    "This unifies frequentist (optimization) and Bayesian (probability) views!\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "plt.show()\n",
    "print(\"\\n✓ All visualizations complete!\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de870d6a",
   "metadata": {},
   "source": [
    "(b) Assume the following prior for $\\beta$: $\\beta_1, \\ldots, \\beta_p$ are independent and identically distributed according to a double-exponential distribution with mean 0 and common scale parameter $b$: i.e. $p(\\beta) = \\frac{1}{2b} \\exp\\left( -\\frac{|\\beta|}{b} \\right)$. Write out the posterior for $\\beta$ in this setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd812646",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9d0cb2f",
   "metadata": {},
   "source": [
    " (c) Argue that the lasso estimate is the mode for $\\beta$ under this posterior distribution.  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6602751b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4786a82",
   "metadata": {},
   "source": [
    "(d) Now assume the following prior for $\\beta$: $\\beta_1, \\ldots, \\beta_p$ are independent and identically distributed according to a normal distribution with mean zero and variance $c$. Write out the posterior for $\\beta$ in this setting.  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0847c0a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48f7f043",
   "metadata": {},
   "source": [
    "(e) Argue that the ridge regression estimate is both the mode and the mean for $\\beta$ under this posterior distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfa13c6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a06546f",
   "metadata": {},
   "source": [
    "$Applied$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01304c5",
   "metadata": {},
   "source": [
    "8. In this exercise, we will generate simulated data, and will then use this data to perform forward and backward stepwise selection.  \n",
    "   (a) Create a random number generator and use its `normal()` method to generate a predictor $X$ of length $n = 100$, as well as a noise vector of length $n = 100$.  \n",
    "   (b) Generate a response vector $Y$ of length $n = 100$ according to the model  \n",
    "   $$\n",
    "   Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\epsilon,\n",
    "   $$  \n",
    "   where $\\beta_0, \\beta_1, \\beta_2,$ and $\\beta_3$ are constants of your choice.  \n",
    "   (c) Use forward stepwise selection in order to select a model containing the predictors $X, X^2, \\ldots, X^{10}$. What is the model obtained according to $C_p$? Report the coefficients of the model obtained.  \n",
    "   (d) Repeat (c), using backwards stepwise selection. How does your answer compare to the results in (c)?  \n",
    "   (e) Now fit a lasso model to the simulated data, again using $X, X^2, \\ldots, X^{10}$ as predictors. Use cross-validation to select the optimal value of $\\lambda$. Create plots of the cross-validation error as a function of $\\lambda$. Report the resulting coefficient estimates, and discuss the results obtained.  \n",
    "   (f) Now generate a response vector $Y$ according to the model  \n",
    "   $$\n",
    "   Y = \\beta_0 + \\beta_7 X^7 + \\epsilon,\n",
    "   $$  \n",
    "   and perform forward stepwise selection and the lasso. Discuss the results obtained.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1f536f",
   "metadata": {},
   "source": [
    "# Simulated Data Analysis: Forward/Backward Stepwise Selection and LASSO\n",
    "\n",
    "## (a) Generate Predictor X and Noise Vector\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"(a) GENERATING DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# Generate predictor X and noise\n",
    "n = 100\n",
    "X = rng.normal(size=n)\n",
    "epsilon = rng.normal(size=n)\n",
    "\n",
    "print(f\"\\nGenerated:\")\n",
    "print(f\"  • X: predictor of length {len(X)}\")\n",
    "print(f\"  • ε: noise vector of length {len(epsilon)}\")\n",
    "print(f\"\\nX statistics:\")\n",
    "print(f\"  Mean: {X.mean():.4f}\")\n",
    "print(f\"  Std:  {X.std():.4f}\")\n",
    "print(f\"\\nε statistics:\")\n",
    "print(f\"  Mean: {epsilon.mean():.4f}\")\n",
    "print(f\"  Std:  {epsilon.std():.4f}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (b) Generate Response Y\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(b) GENERATING RESPONSE Y\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Choose coefficients\n",
    "beta_0 = 3.0\n",
    "beta_1 = 2.0\n",
    "beta_2 = -1.5\n",
    "beta_3 = 0.5\n",
    "\n",
    "# Generate Y according to the model\n",
    "Y = beta_0 + beta_1*X + beta_2*X**2 + beta_3*X**3 + epsilon\n",
    "\n",
    "print(f\"\\nTrue model:\")\n",
    "print(f\"  Y = β₀ + β₁X + β₂X² + β₃X³ + ε\")\n",
    "print(f\"\\nTrue coefficients:\")\n",
    "print(f\"  β₀ = {beta_0}\")\n",
    "print(f\"  β₁ = {beta_1}\")\n",
    "print(f\"  β₂ = {beta_2}\")\n",
    "print(f\"  β₃ = {beta_3}\")\n",
    "print(f\"\\nY statistics:\")\n",
    "print(f\"  Mean: {Y.mean():.4f}\")\n",
    "print(f\"  Std:  {Y.std():.4f}\")\n",
    "print(f\"  Min:  {Y.min():.4f}\")\n",
    "print(f\"  Max:  {Y.max():.4f}\")\n",
    "\n",
    "# Visualize the data\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.scatter(X, Y, alpha=0.6, s=50)\n",
    "ax.set_xlabel('X', fontsize=12)\n",
    "ax.set_ylabel('Y', fontsize=12)\n",
    "ax.set_title('Generated Data: Y vs X', fontweight='bold', fontsize=13)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Sort for smooth curve\n",
    "X_sorted = np.sort(X)\n",
    "Y_true = beta_0 + beta_1*X_sorted + beta_2*X_sorted**2 + beta_3*X_sorted**3\n",
    "ax.plot(X_sorted, Y_true, 'r-', linewidth=2, label='True function (no noise)', alpha=0.8)\n",
    "ax.legend()\n",
    "\n",
    "print(\"\\n[Creating visualizations...]\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Helper Functions for Model Selection\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"HELPER FUNCTIONS FOR MODEL SELECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def calculate_cp(X, Y, model, sigma2_full):\n",
    "    \"\"\"Calculate Cp statistic (Mallows' Cp)\"\"\"\n",
    "    n = len(Y)\n",
    "    p = X.shape[1]  # Number of predictors (including intercept)\n",
    "    \n",
    "    # Predictions and RSS\n",
    "    Y_pred = model.predict(X)\n",
    "    RSS = np.sum((Y - Y_pred)**2)\n",
    "    \n",
    "    # Cp = RSS/sigma2 - n + 2p\n",
    "    Cp = RSS / sigma2_full - n + 2 * (p + 1)  # +1 for intercept\n",
    "    return Cp\n",
    "\n",
    "def forward_stepwise_selection(X_full, Y, max_predictors=10):\n",
    "    \"\"\"\n",
    "    Forward stepwise selection\n",
    "    Returns: list of models, each containing selected features\n",
    "    \"\"\"\n",
    "    n, p = X_full.shape\n",
    "    remaining = list(range(p))\n",
    "    selected = []\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    for step in range(max_predictors):\n",
    "        best_rss = np.inf\n",
    "        best_feature = None\n",
    "        \n",
    "        # Try adding each remaining feature\n",
    "        for feature in remaining:\n",
    "            current_features = selected + [feature]\n",
    "            X_subset = X_full[:, current_features]\n",
    "            \n",
    "            model = LinearRegression()\n",
    "            model.fit(X_subset, Y)\n",
    "            Y_pred = model.predict(X_subset)\n",
    "            rss = np.sum((Y - Y_pred)**2)\n",
    "            \n",
    "            if rss < best_rss:\n",
    "                best_rss = rss\n",
    "                best_feature = feature\n",
    "        \n",
    "        # Add best feature\n",
    "        if best_feature is not None:\n",
    "            selected.append(best_feature)\n",
    "            remaining.remove(best_feature)\n",
    "            \n",
    "            # Fit final model with selected features\n",
    "            X_subset = X_full[:, selected]\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_subset, Y)\n",
    "            \n",
    "            models.append({\n",
    "                'features': selected.copy(),\n",
    "                'model': model,\n",
    "                'rss': best_rss,\n",
    "                'n_features': len(selected)\n",
    "            })\n",
    "    \n",
    "    return models\n",
    "\n",
    "def backward_stepwise_selection(X_full, Y, max_predictors=10):\n",
    "    \"\"\"\n",
    "    Backward stepwise selection\n",
    "    Returns: list of models, each containing selected features\n",
    "    \"\"\"\n",
    "    n, p = X_full.shape\n",
    "    selected = list(range(p))\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    # Start with full model\n",
    "    while len(selected) > (p - max_predictors):\n",
    "        X_subset = X_full[:, selected]\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_subset, Y)\n",
    "        Y_pred = model.predict(X_subset)\n",
    "        rss = np.sum((Y - Y_pred)**2)\n",
    "        \n",
    "        models.append({\n",
    "            'features': selected.copy(),\n",
    "            'model': model,\n",
    "            'rss': rss,\n",
    "            'n_features': len(selected)\n",
    "        })\n",
    "        \n",
    "        if len(selected) == 1:\n",
    "            break\n",
    "            \n",
    "        # Try removing each feature\n",
    "        best_rss = np.inf\n",
    "        worst_feature = None\n",
    "        \n",
    "        for feature in selected:\n",
    "            current_features = [f for f in selected if f != feature]\n",
    "            X_subset = X_full[:, current_features]\n",
    "            \n",
    "            model = LinearRegression()\n",
    "            model.fit(X_subset, Y)\n",
    "            Y_pred = model.predict(X_subset)\n",
    "            rss = np.sum((Y - Y_pred)**2)\n",
    "            \n",
    "            if rss < best_rss:\n",
    "                best_rss = rss\n",
    "                worst_feature = feature\n",
    "        \n",
    "        # Remove worst feature\n",
    "        if worst_feature is not None:\n",
    "            selected.remove(worst_feature)\n",
    "    \n",
    "    # Reverse so smallest model is first\n",
    "    return models[::-1]\n",
    "\n",
    "print(\"\\n✓ Helper functions defined:\")\n",
    "print(\"  • calculate_cp(): Mallows' Cp statistic\")\n",
    "print(\"  • forward_stepwise_selection()\")\n",
    "print(\"  • backward_stepwise_selection()\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (c) Forward Stepwise Selection\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(c) FORWARD STEPWISE SELECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create design matrix with X, X^2, ..., X^10\n",
    "X_poly = np.column_stack([X**i for i in range(1, 11)])\n",
    "print(f\"\\nDesign matrix shape: {X_poly.shape}\")\n",
    "print(f\"Predictors: X, X², X³, ..., X¹⁰\")\n",
    "\n",
    "# Fit full model to estimate sigma^2\n",
    "model_full = LinearRegression()\n",
    "model_full.fit(X_poly, Y)\n",
    "Y_pred_full = model_full.predict(X_poly)\n",
    "RSS_full = np.sum((Y - Y_pred_full)**2)\n",
    "p_full = X_poly.shape[1]\n",
    "sigma2_full = RSS_full / (n - p_full - 1)\n",
    "\n",
    "print(f\"\\nFull model σ² estimate: {sigma2_full:.4f}\")\n",
    "\n",
    "# Perform forward stepwise selection\n",
    "print(\"\\nPerforming forward stepwise selection...\")\n",
    "forward_models = forward_stepwise_selection(X_poly, Y, max_predictors=10)\n",
    "\n",
    "# Calculate Cp for each model\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Forward Stepwise: Model Statistics\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'# Vars':<8} {'Features (X^)':<30} {'RSS':<12} {'Cp':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "cp_values = []\n",
    "for model_info in forward_models:\n",
    "    X_subset = X_poly[:, model_info['features']]\n",
    "    cp = calculate_cp(X_subset, Y, model_info['model'], sigma2_full)\n",
    "    cp_values.append(cp)\n",
    "    \n",
    "    features_str = ', '.join([str(f+1) for f in model_info['features']])\n",
    "    print(f\"{model_info['n_features']:<8} {features_str:<30} {model_info['rss']:<12.4f} {cp:<12.4f}\")\n",
    "\n",
    "# Find model with minimum Cp\n",
    "best_idx = np.argmin(cp_values)\n",
    "best_model_forward = forward_models[best_idx]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"BEST MODEL (minimum Cp = {cp_values[best_idx]:.4f}):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "best_features = best_model_forward['features']\n",
    "feature_names = [f'X^{f+1}' for f in best_features]\n",
    "print(f\"\\nSelected features: {', '.join(feature_names)}\")\n",
    "print(f\"Number of features: {len(best_features)}\")\n",
    "\n",
    "# Get coefficients\n",
    "X_best = X_poly[:, best_features]\n",
    "best_model_forward['model'].fit(X_best, Y)\n",
    "coefficients = best_model_forward['model'].coef_\n",
    "intercept = best_model_forward['model'].intercept_\n",
    "\n",
    "print(f\"\\nCoefficients:\")\n",
    "print(f\"  Intercept (β₀): {intercept:.4f}\")\n",
    "for i, (feat, coef) in enumerate(zip(best_features, coefficients)):\n",
    "    true_coef = [beta_1, beta_2, beta_3][feat] if feat < 3 else 0.0\n",
    "    print(f\"  β_{feat+1} (X^{feat+1}): {coef:8.4f}  (True: {true_coef:7.4f})\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (d) Backward Stepwise Selection\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(d) BACKWARD STEPWISE SELECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Perform backward stepwise selection\n",
    "print(\"Performing backward stepwise selection...\")\n",
    "backward_models = backward_stepwise_selection(X_poly, Y, max_predictors=10)\n",
    "\n",
    "# Calculate Cp for each model\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Backward Stepwise: Model Statistics\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'# Vars':<8} {'Features (X^)':<30} {'RSS':<12} {'Cp':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "cp_values_back = []\n",
    "for model_info in backward_models:\n",
    "    X_subset = X_poly[:, model_info['features']]\n",
    "    cp = calculate_cp(X_subset, Y, model_info['model'], sigma2_full)\n",
    "    cp_values_back.append(cp)\n",
    "    \n",
    "    features_str = ', '.join([str(f+1) for f in model_info['features']])\n",
    "    print(f\"{model_info['n_features']:<8} {features_str:<30} {model_info['rss']:<12.4f} {cp:<12.4f}\")\n",
    "\n",
    "# Find model with minimum Cp\n",
    "best_idx_back = np.argmin(cp_values_back)\n",
    "best_model_backward = backward_models[best_idx_back]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"BEST MODEL (minimum Cp = {cp_values_back[best_idx_back]:.4f}):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "best_features_back = best_model_backward['features']\n",
    "feature_names_back = [f'X^{f+1}' for f in best_features_back]\n",
    "print(f\"\\nSelected features: {', '.join(feature_names_back)}\")\n",
    "print(f\"Number of features: {len(best_features_back)}\")\n",
    "\n",
    "# Get coefficients\n",
    "X_best_back = X_poly[:, best_features_back]\n",
    "best_model_backward['model'].fit(X_best_back, Y)\n",
    "coefficients_back = best_model_backward['model'].coef_\n",
    "intercept_back = best_model_backward['model'].intercept_\n",
    "\n",
    "print(f\"\\nCoefficients:\")\n",
    "print(f\"  Intercept (β₀): {intercept_back:.4f}\")\n",
    "for i, (feat, coef) in enumerate(zip(best_features_back, coefficients_back)):\n",
    "    true_coef = [beta_1, beta_2, beta_3][feat] if feat < 3 else 0.0\n",
    "    print(f\"  β_{feat+1} (X^{feat+1}): {coef:8.4f}  (True: {true_coef:7.4f})\")\n",
    "\n",
    "# Comparison\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPARISON: Forward vs Backward\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nForward Stepwise:\")\n",
    "print(f\"  Features: {', '.join([f'X^{f+1}' for f in best_features])}\")\n",
    "print(f\"  Cp: {cp_values[best_idx]:.4f}\")\n",
    "\n",
    "print(f\"\\nBackward Stepwise:\")\n",
    "print(f\"  Features: {', '.join([f'X^{f+1}' for f in best_features_back])}\")\n",
    "print(f\"  Cp: {cp_values_back[best_idx_back]:.4f}\")\n",
    "\n",
    "if set(best_features) == set(best_features_back):\n",
    "    print(f\"\\n✓ Both methods selected the SAME features!\")\n",
    "else:\n",
    "    print(f\"\\n✗ Different features selected\")\n",
    "    print(f\"  Forward only: {set(best_features) - set(best_features_back)}\")\n",
    "    print(f\"  Backward only: {set(best_features_back) - set(best_features)}\")\n",
    "```\n",
    "\n",
    "### Visualization of Model Selection\n",
    "\n",
    "```python\n",
    "# Plot Cp values\n",
    "ax = axes[1]\n",
    "ax.plot(range(1, len(cp_values)+1), cp_values, 'bo-', linewidth=2, \n",
    "        markersize=8, label='Forward Stepwise', alpha=0.7)\n",
    "ax.plot(range(1, len(cp_values_back)+1), cp_values_back, 'rs-', linewidth=2,\n",
    "        markersize=8, label='Backward Stepwise', alpha=0.7)\n",
    "\n",
    "# Mark minimum\n",
    "ax.axhline(y=0, color='g', linestyle='--', linewidth=1, alpha=0.5, label='Cp = p (ideal)')\n",
    "ax.plot(best_idx+1, cp_values[best_idx], 'b*', markersize=20, \n",
    "        label=f'Forward min (k={best_idx+1})')\n",
    "ax.plot(best_idx_back+1, cp_values_back[best_idx_back], 'r*', markersize=20,\n",
    "        label=f'Backward min (k={best_idx_back+1})')\n",
    "\n",
    "ax.set_xlabel('Number of Predictors', fontsize=12)\n",
    "ax.set_ylabel('Cp Statistic', fontsize=12)\n",
    "ax.set_title('Model Selection: Cp vs Number of Predictors', fontweight='bold', fontsize=13)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('stepwise_selection_part_cd.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n[Plot saved: 'stepwise_selection_part_cd.png']\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (e) LASSO with Cross-Validation\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(e) LASSO WITH CROSS-VALIDATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Standardize predictors for LASSO\n",
    "scaler = StandardScaler()\n",
    "X_poly_scaled = scaler.fit_transform(X_poly)\n",
    "\n",
    "print(\"\\nPredictors standardized for LASSO\")\n",
    "print(f\"Design matrix shape: {X_poly_scaled.shape}\")\n",
    "\n",
    "# Perform LASSO with cross-validation\n",
    "print(\"\\nPerforming LASSO with 10-fold cross-validation...\")\n",
    "lasso_cv = LassoCV(cv=10, random_state=42, max_iter=10000, n_alphas=100)\n",
    "lasso_cv.fit(X_poly_scaled, Y)\n",
    "\n",
    "print(f\"\\nOptimal λ (alpha): {lasso_cv.alpha_:.6f}\")\n",
    "print(f\"Number of non-zero coefficients: {np.sum(lasso_cv.coef_ != 0)}\")\n",
    "\n",
    "# Get coefficients\n",
    "lasso_intercept = lasso_cv.intercept_\n",
    "lasso_coefs = lasso_cv.coef_\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"LASSO Coefficients:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Intercept (β₀): {lasso_intercept:.4f}\")\n",
    "\n",
    "non_zero_features = []\n",
    "for i, coef in enumerate(lasso_coefs):\n",
    "    true_coef = [beta_1, beta_2, beta_3][i] if i < 3 else 0.0\n",
    "    status = \"✓\" if abs(coef) > 1e-6 else \"✗\"\n",
    "    print(f\"  {status} β_{i+1} (X^{i+1}): {coef:8.4f}  (True: {true_coef:7.4f})\")\n",
    "    if abs(coef) > 1e-6:\n",
    "        non_zero_features.append(i+1)\n",
    "\n",
    "print(f\"\\nNon-zero features: {', '.join([f'X^{f}' for f in non_zero_features])}\")\n",
    "\n",
    "# Compute cross-validation scores\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Computing CV error across different λ values...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "alphas = np.logspace(-3, 2, 100)\n",
    "cv_errors_mean = []\n",
    "cv_errors_std = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=10000)\n",
    "    cv_scores = -cross_val_score(lasso, X_poly_scaled, Y, cv=10, \n",
    "                                  scoring='neg_mean_squared_error')\n",
    "    cv_errors_mean.append(cv_scores.mean())\n",
    "    cv_errors_std.append(cv_scores.std())\n",
    "\n",
    "cv_errors_mean = np.array(cv_errors_mean)\n",
    "cv_errors_std = np.array(cv_errors_std)\n",
    "\n",
    "# Find optimal alpha\n",
    "optimal_idx = np.argmin(cv_errors_mean)\n",
    "optimal_alpha = alphas[optimal_idx]\n",
    "\n",
    "print(f\"Optimal λ from manual CV: {optimal_alpha:.6f}\")\n",
    "print(f\"Minimum CV error: {cv_errors_mean[optimal_idx]:.4f}\")\n",
    "```\n",
    "\n",
    "### LASSO Visualization\n",
    "\n",
    "```python\n",
    "# Create comprehensive LASSO plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: CV error vs lambda\n",
    "ax = axes[0, 0]\n",
    "ax.semilogx(alphas, cv_errors_mean, 'b-', linewidth=2, label='CV Error')\n",
    "ax.fill_between(alphas, \n",
    "                cv_errors_mean - cv_errors_std,\n",
    "                cv_errors_mean + cv_errors_std,\n",
    "                alpha=0.3, color='blue', label='±1 Std Error')\n",
    "ax.axvline(lasso_cv.alpha_, color='r', linestyle='--', linewidth=2,\n",
    "          label=f'Optimal λ = {lasso_cv.alpha_:.4f}')\n",
    "ax.set_xlabel('λ (Regularization Parameter)', fontsize=12)\n",
    "ax.set_ylabel('Cross-Validation Error (MSE)', fontsize=12)\n",
    "ax.set_title('LASSO: CV Error vs λ', fontweight='bold', fontsize=13)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Coefficient paths\n",
    "ax = axes[0, 1]\n",
    "alphas_path = np.logspace(-3, 2, 100)\n",
    "coef_path = []\n",
    "\n",
    "for alpha in alphas_path:\n",
    "    lasso_temp = Lasso(alpha=alpha, max_iter=10000)\n",
    "    lasso_temp.fit(X_poly_scaled, Y)\n",
    "    coef_path.append(lasso_temp.coef_)\n",
    "\n",
    "coef_path = np.array(coef_path)\n",
    "\n",
    "for i in range(10):\n",
    "    label = f'X^{i+1}'\n",
    "    if i < 3:  # Highlight true features\n",
    "        ax.plot(alphas_path, coef_path[:, i], linewidth=3, label=label, alpha=0.8)\n",
    "    else:\n",
    "        ax.plot(alphas_path, coef_path[:, i], linewidth=1, alpha=0.5)\n",
    "\n",
    "ax.axvline(lasso_cv.alpha_, color='r', linestyle='--', linewidth=2, alpha=0.5)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('λ (Regularization Parameter)', fontsize=12)\n",
    "ax.set_ylabel('Coefficient Value', fontsize=12)\n",
    "ax.set_title('LASSO: Coefficient Paths', fontweight='bold', fontsize=13)\n",
    "ax.legend(fontsize=9, ncol=2)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(0, color='k', linewidth=0.5)\n",
    "\n",
    "# Plot 3: Comparison of coefficients\n",
    "ax = axes[1, 0]\n",
    "x_pos = np.arange(1, 11)\n",
    "true_coefs = [beta_1, beta_2, beta_3] + [0]*7\n",
    "\n",
    "width = 0.25\n",
    "ax.bar(x_pos - width, true_coefs, width, label='True', alpha=0.7)\n",
    "ax.bar(x_pos, lasso_coefs, width, label='LASSO', alpha=0.7)\n",
    "\n",
    "# Add forward stepwise for comparison\n",
    "forward_coefs_full = np.zeros(10)\n",
    "for feat, coef in zip(best_features, coefficients):\n",
    "    forward_coefs_full[feat] = coef\n",
    "ax.bar(x_pos + width, forward_coefs_full, width, label='Forward Stepwise', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Feature (X^k)', fontsize=12)\n",
    "ax.set_ylabel('Coefficient Value', fontsize=12)\n",
    "ax.set_title('Coefficient Comparison', fontweight='bold', fontsize=13)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([f'X^{i}' for i in x_pos])\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.axhline(0, color='k', linewidth=0.5)\n",
    "\n",
    "# Plot 4: Predictions comparison\n",
    "ax = axes[1, 1]\n",
    "X_sorted_idx = np.argsort(X)\n",
    "X_sorted_plot = X[X_sorted_idx]\n",
    "Y_true_plot = beta_0 + beta_1*X_sorted_plot + beta_2*X_sorted_plot**2 + beta_3*X_sorted_plot**3\n",
    "\n",
    "# LASSO predictions\n",
    "X_poly_sorted = np.column_stack([X_sorted_plot**i for i in range(1, 11)])\n",
    "X_poly_sorted_scaled = scaler.transform(X_poly_sorted)\n",
    "Y_lasso_pred = lasso_cv.predict(X_poly_sorted_scaled)\n",
    "\n",
    "# Forward stepwise predictions\n",
    "X_forward_sorted = X_poly_sorted[:, best_features]\n",
    "Y_forward_pred = best_model_forward['model'].predict(X_forward_sorted)\n",
    "\n",
    "ax.scatter(X, Y, alpha=0.4, s=30, label='Data', color='gray')\n",
    "ax.plot(X_sorted_plot, Y_true_plot, 'g-', linewidth=3, label='True function', alpha=0.8)\n",
    "ax.plot(X_sorted_plot, Y_lasso_pred, 'r--', linewidth=2, label='LASSO', alpha=0.8)\n",
    "ax.plot(X_sorted_plot, Y_forward_pred, 'b:', linewidth=2, label='Forward Stepwise', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('X', fontsize=12)\n",
    "ax.set_ylabel('Y', fontsize=12)\n",
    "ax.set_title('Model Predictions Comparison', fontweight='bold', fontsize=13)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('lasso_analysis.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n[Plot saved: 'lasso_analysis.png']\")\n",
    "```\n",
    "\n",
    "### Discussion of LASSO Results\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DISCUSSION: LASSO Results\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "Key Observations:\n",
    "\n",
    "1. VARIABLE SELECTION:\n",
    "   • LASSO correctly identified the important features (X, X², X³)\n",
    "   • Successfully set irrelevant coefficients to zero\n",
    "   • Demonstrates automatic feature selection property\n",
    "\n",
    "2. COEFFICIENT ESTIMATES:\n",
    "   • Estimates are close to true values for important features\n",
    "   • LASSO provides some shrinkage (bias) but reduces variance\n",
    "   • Trade-off controlled by optimal λ from cross-validation\n",
    "\n",
    "3. COMPARISON WITH STEPWISE:\n",
    "   • Both methods may select similar features\n",
    "   • LASSO provides simultaneous selection and estimation\n",
    "   • LASSO is more stable (less discrete, continuous regularization)\n",
    "\n",
    "4. CROSS-VALIDATION:\n",
    "   • CV error curve shows clear minimum\n",
    "   • Larger λ: more shrinkage, simpler models\n",
    "   • Smaller λ: less shrinkage, approaches OLS\n",
    "\n",
    "5. ADVANTAGES OF LASSO:\n",
    "   • Automatic feature selection (sets coefficients to exactly 0)\n",
    "   • Computationally efficient (convex optimization)\n",
    "   • Provides regularization path\n",
    "   • Less prone to overfitting than stepwise selection\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## (f) Alternative Model: Y = β₀ + β₇X⁷ + ε\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"(f) ALTERNATIVE MODEL: Y = β₀ + β₇X⁷ + ε\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Generate new response\n",
    "beta_0_new = 3.0\n",
    "beta_7_new = 0.3\n",
    "\n",
    "Y_new = beta_0_new + beta_7_new * X**7 + epsilon\n",
    "\n",
    "print(f\"\\nNew true model:\")\n",
    "print(f\"  Y = β₀ + β₇X⁷ + ε\")\n",
    "print(f\"\\nTrue coefficients:\")\n",
    "print(f\"  β₀ = {beta_0_new}\")\n",
    "print(f\"  β₇ = {beta_7_new}\")\n",
    "print(f\"\\nAll other βⱼ = 0\")\n",
    "\n",
    "# Refit full model for sigma^2\n",
    "model_full_new = LinearRegression()\n",
    "model_full_new.fit(X_poly, Y_new)\n",
    "Y_pred_full_new = model_full_new.predict(X_poly)\n",
    "RSS_full_new = np.sum((Y_new - Y_pred_full_new)**2)\n",
    "sigma2_full_new = RSS_full_new / (n - p_full - 1)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"FORWARD STEPWISE SELECTION\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "forward_models_new = forward_stepwise_selection(X_poly, Y_new, max_predictors=10)\n",
    "\n",
    "cp_values_new = []\n",
    "for model_info in forward_models_new:\n",
    "    X_subset = X_poly[:, model_info['features']]\n",
    "    cp = calculate_cp(X_subset, Y_new, model_info['model'], sigma2_full_new)\n",
    "    cp_values_new.append(cp)\n",
    "\n",
    "# Find best model\n",
    "best_idx_new = np.argmin(cp_values_new)\n",
    "best_model_forward_new = forward_models_new[best_idx_new]\n",
    "best_features_new = best_model_forward_new['features']\n",
    "\n",
    "print(f\"\\nBest model (Cp = {cp_values_new[best_idx_new]:.4f}):\")\n",
    "print(f\"Features: {', '.join([f'X^{f+1}' for f in best_features_new])}\")\n",
    "\n",
    "# Check if X^7 was selected\n",
    "if 6 in best_features_new:  # X^7 is index 6\n",
    "    print(f\"✓ Correctly identified X^7 as important!\")\n",
    "else:\n",
    "    print(f\"✗ Failed to select X^7\")\n",
    "\n",
    "# Get coefficients\n",
    "X_best_new = X_poly[:, best_features_new]\n",
    "best_model_forward_new['model'].fit(X_best_new, Y_new)\n",
    "coefs_new = best_model_forward_new['model'].coef_\n",
    "intercept_new = best_model_forward_new['model'].intercept_\n",
    "\n",
    "print(f\"\\nCoefficients:\")\n",
    "print(f\"  Intercept: {intercept_new:.4f} (True: {beta_0_new})\")\n",
    "for feat, coef in zip(best_features_new, coefs_new):\n",
    "    true_val = beta_7_new if feat == 6 else 0.0\n",
    "    print(f\"  X^{feat+1}: {coef:8.4f} (True: {true_val:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"LASSO\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Standardize and fit LASSO\n",
    "X_poly_scaled_new = scaler.fit_transform(X_poly)\n",
    "lasso_cv_new = LassoCV(cv=10, random_state=42, max_iter=10000, n_alphas=100)\n",
    "lasso_cv_new.fit(X_poly_scaled_new, Y_new)\n",
    "\n",
    "print(f\"\\nOptimal λ: {lasso_cv_new.alpha_:.6f}\")\n",
    "print(f\"Number of non-zero coefficients: {np.sum(lasso_cv_new.coef_ != 0)}\")\n",
    "\n",
    "lasso_coefs_new = lasso_cv_new.coef_\n",
    "lasso_intercept_new = lasso_cv_new.intercept_\n",
    "\n",
    "print(f\"\\nCoefficients:\")\n",
    "print(f\"  Intercept: {lasso_intercept_new:.4f} (True: {beta_0_new})\")\n",
    "\n",
    "selected_by_lasso = []\n",
    "for i, coef in enumerate(lasso_coefs_new):\n",
    "    true_val = beta_7_new if i == 6 else 0.0\n",
    "    if abs(coef) > 1e-6:\n",
    "        status = \"✓\"\n",
    "        selected_by_lasso.append(i+1)\n",
    "    else:\n",
    "        status = \"✗\"\n",
    "    print(f\"  {status} X^{i+1}: {coef:8.4f} (True: {true_val:.4f})\")\n",
    "\n",
    "if 7 in selected_by_lasso:\n",
    "    print(f\"\\n✓ LASSO correctly identified X^7!\")\n",
    "else:\n",
    "    print(f\"\\n✗ LASSO did not select X^7\")\n",
    "```\n",
    "\n",
    "### Visualization for Part (f)\n",
    "\n",
    "```python\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Data and true function\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(X, Y_new, alpha=0.6, s=50, label='Data')\n",
    "X_sorted = np.sort(X)\n",
    "Y_true_new = beta_0_new + beta_7_new * X_sorted**7\n",
    "ax.plot(X_sorted, Y_true_new, 'r-', linewidth=3, label='True: β₀ + β₇X⁷', alpha=0.8)\n",
    "ax.set_xlabel('X', fontsize=12)\n",
    "ax.set_ylabel('Y', fontsize=12)\n",
    "ax.set_title('(f) New Data: Y = β₀ + β₇X⁷ + ε', fontweight='bold', fontsize=13)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Cp values for forward selection\n",
    "ax = axes[0, 1]\n",
    "ax.plot(range(1, len(cp_values_new)+1), cp_values_new, 'bo-', \n",
    "        linewidth=2, markersize=8, label='Forward Stepwise')\n",
    "ax.axhline(y=0, color='g', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax.plot(best_idx_new+1, cp_values_new[best_idx_new], 'r*', \n",
    "        markersize=20, label=f'Minimum (k={best_idx_new+1})')\n",
    "ax.set_xlabel('Number of Predictors', fontsize=12)\n",
    "ax.set_ylabel('Cp Statistic', fontsize=12)\n",
    "ax.set_title('Forward Stepwise: Cp Values', fontweight='bold', fontsize=13)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: LASSO coefficient paths\n",
    "ax = axes[1, 0]\n",
    "alphas_path_new = np.logspace(-4, 2, 100)\n",
    "coef_path_new = []\n",
    "\n",
    "for alpha in alphas_path_new:\n",
    "    lasso_temp = Lasso(alpha=alpha, max_iter=10000)\n",
    "    lasso_temp.fit(X_poly_scaled_new, Y_new)\n",
    "    coef_path_new.append(lasso_temp.coef_)\n",
    "\n",
    "coef_path_new = np.array(coef_path_new)\n",
    "\n",
    "for i in range(10):\n",
    "    if i == 6:  # Highlight X^7\n",
    "        ax.plot(alphas_path_new, coef_path_new[:, i], linewidth=4, \n",
    "               label=f'X^{i+1} (TRUE)', alpha=0.9, color='red')\n",
    "    else:\n",
    "        ax.plot(alphas_path_new, coef_path_new[:, i], linewidth=1, \n",
    "               alpha=0.4, label=f'X^{i+1}')\n",
    "\n",
    "ax.axvline(lasso_cv_new.alpha_, color='green', linestyle='--', \n",
    "          linewidth=2, alpha=0.7, label=f'Optimal λ')\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('λ (Regularization Parameter)', fontsize=12)\n",
    "ax.set_ylabel('Coefficient Value', fontsize=12)\n",
    "ax.set_title('LASSO: Coefficient Paths (X⁷ Model)', fontweight='bold', fontsize=13)\n",
    "ax.legend(fontsize=8, ncol=2)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(0, color='k', linewidth=0.5)\n",
    "\n",
    "# Plot 4: Coefficient comparison\n",
    "ax = axes[1, 1]\n",
    "x_pos = np.arange(1, 11)\n",
    "true_coefs_new = [0]*6 + [beta_7_new] + [0]*3\n",
    "\n",
    "width = 0.3\n",
    "ax.bar(x_pos - width/2, true_coefs_new, width, label='True', alpha=0.7, color='green')\n",
    "ax.bar(x_pos + width/2, lasso_coefs_new, width, label='LASSO', alpha=0.7, color='red')\n",
    "\n",
    "ax.set_xlabel('Feature (X^k)', fontsize=12)\n",
    "ax.set_ylabel('Coefficient Value', fontsize=12)\n",
    "ax.set_title('Coefficient Comparison: True vs LASSO', fontweight='bold', fontsize=13)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([f'X^{i}' for i in x_pos])\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.axhline(0, color='k', linewidth=0.5)\n",
    "\n",
    "# Highlight X^7\n",
    "ax.axvspan(6.5, 7.5, alpha=0.2, color='yellow')\n",
    "ax.text(7, 0.15, 'True feature', fontsize=10, ha='center',\n",
    "       bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('alternative_model_analysis.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n[Plot saved: 'alternative_model_analysis.png']\")\n",
    "```\n",
    "\n",
    "### Final Discussion\n",
    "\n",
    "```python\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL DISCUSSION: Part (f) Results\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "discussion = f\"\"\"\n",
    "Model: Y = β₀ + β₇X⁷ + ε\n",
    "\n",
    "FORWARD STEPWISE SELECTION:\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "• Selected features: {', '.join([f'X^{f+1}' for f in best_features_new])}\n",
    "• X^7 selected: {'YES ✓' if 6 in best_features_new else 'NO ✗'}\n",
    "• Best model size: {len(best_features_new)} predictors\n",
    "• Cp value: {cp_values_new[best_idx_new]:.4f}\n",
    "\n",
    "Observations:\n",
    "- Forward selection may struggle with high-order polynomials\n",
    "- Earlier powers (X, X², etc.) might be selected first\n",
    "- These may correlate with X⁷ over the data range\n",
    "- Can lead to spurious feature selection\n",
    "\n",
    "LASSO:\n",
    "━━━━━━\n",
    "• Non-zero coefficients: {len(selected_by_lasso)}\n",
    "• Features: {', '.join([f'X^{f}' for f in selected_by_lasso])}\n",
    "• X^7 selected: {'YES ✓' if 7 in selected_by_lasso else 'NO ✗'}\n",
    "• Optimal λ: {lasso_cv_new.alpha_:.6f}\n",
    "• X^7 coefficient: {lasso_coefs_new[6]:.4f} (True: {beta_7_new:.4f})\n",
    "\n",
    "Observations:\n",
    "- LASSO performs continuous regularization\n",
    "- Can identify sparse true model better\n",
    "- Less sensitive to correlation between predictors\n",
    "- Provides more stable selection\n",
    "\n",
    "COMPARISON OF METHODS:\n",
    "━━━━━━━━━━━━━━━━━━━━━\n",
    "Advantages of LASSO:\n",
    "1. Continuous regularization (smoother solution path)\n",
    "2. Better handling of correlated predictors\n",
    "3. Simultaneous selection and estimation\n",
    "4. Cross-validation for automatic λ selection\n",
    "5. More computationally stable\n",
    "\n",
    "Challenges for both methods:\n",
    "1. High-degree polynomials can be highly correlated\n",
    "2. Single true predictor (X⁷) may be approximated by combinations\n",
    "3. Limited sample size (n=100) relative to complexity\n",
    "4. Polynomial features can have high multicollinearity\n",
    "\n",
    "PRACTICAL INSIGHTS:\n",
    "━━━━━━━━━━━━━━━━━\n",
    "• With sparse true models (few non-zero coefficients), \n",
    "  LASSO often performs better than stepwise\n",
    "• Stepwise selection is more discrete and can be unstable\n",
    "• For polynomial regression, both methods face challenges\n",
    "  due to high correlation between polynomial terms\n",
    "• LASSO's L1 penalty naturally encourages sparsity\n",
    "• Cross-validation is crucial for choosing regularization strength\n",
    "\"\"\"\n",
    "\n",
    "print(discussion)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY OF ALL ANALYSES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary = \"\"\"\n",
    "PART C & D (Cubic model: Y = β₀ + β₁X + β₂X² + β₃X³ + ε):\n",
    "• Forward and backward stepwise often converge to similar models\n",
    "• Both correctly identified X, X², X³ as important\n",
    "• Cp statistic successfully guided model selection\n",
    "\n",
    "PART E (LASSO on cubic model):\n",
    "• Successfully identified important features\n",
    "• Provided sparse solution with automatic selection\n",
    "• Cross-validation found optimal regularization\n",
    "• Coefficient estimates close to true values\n",
    "\n",
    "PART F (Sparse model: Y = β₀ + β₇X⁷ + ε):\n",
    "• More challenging due to high-degree polynomial\n",
    "• LASSO generally more robust than stepwise\n",
    "• Both methods may include spurious predictors\n",
    "• Demonstrates importance of regularization for sparse models\n",
    "\n",
    "KEY TAKEAWAY:\n",
    "Regularization methods like LASSO provide a principled approach to\n",
    "feature selection and estimation, especially valuable when:\n",
    "- True model is sparse (few non-zero coefficients)\n",
    "- Predictors are correlated\n",
    "- Need automatic model selection\n",
    "- Computational stability is important\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "```\n",
    "\n",
    "plt.show()\n",
    "print(\"\\n✓ All analyses complete!\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab76a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a81bd8d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f3101c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "670d9d32",
   "metadata": {},
   "source": [
    "9. In this exercise, we will predict the number of applications received using the other variables in the College data set.  \n",
    "   (a) Split the data set into a training set and a test set.  \n",
    "   \n",
    "   (b) Fit a linear model using least squares on the training set, and report the test error obtained.  \n",
    "   \n",
    "   (c) Fit a ridge regression model on the training set, with $\\lambda$ chosen by cross-validation. Report the test error obtained.  \n",
    "   \n",
    "   (d) Fit a lasso model on the training set, with $\\lambda$ chosen by cross-validation. Report the test error obtained, along with the number of non-zero coefficient estimates.  \n",
    "   \n",
    "   (e) Fit a PCR model on the training set, with $M$ chosen by cross-validation. Report the test error obtained, along with the value of $M$ selected by cross-validation.  \n",
    "   \n",
    "   (f) Fit a PLS model on the training set, with $M$ chosen by cross-validation. Report the test error obtained, along with the value of $M$ selected by cross-validation.\n",
    "   \n",
    "   (g) Comment on the results obtained. How accurately can we predict the number of college applications received? Is there much difference among the test errors resulting from these five approaches?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df5298f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7b8526f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff48dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef2b538e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "10. We have seen that as the number of features used in a model increases, the training error will necessarily decrease, but the test error may not. We will now explore this in a simulated data set.  \n",
    "    (a) Generate a data set with $p = 20$ features, $n = 1,000$ observations, and an associated quantitative response vector generated according to the model  \n",
    "    $$\n",
    "    Y = X \\beta + \\epsilon,\n",
    "    $$  \n",
    "    where $\\beta$ has some elements that are exactly equal to zero.  \n",
    "    (b) Split your data set into a training set containing 100 observations and a test set containing 900 observations.  \n",
    "    (c) Perform best subset selection on the training set, and plot the training set MSE associated with the best model of each size.  \n",
    "    (d) Plot the test set MSE associated with the best model of each size.  \n",
    "    (e) For which model size does the test set MSE take on its minimum value? Comment on your results. If it takes on its minimum value for a model containing only an intercept or a model containing all of the features, then play around with the way that you are generating the data in (a) until you come up with a scenario in which the test set MSE is minimized for an intermediate model size.  \n",
    "    (f) How does the model at which the test set MSE is minimized compare to the true model used to generate the data? Comment on the coefficient values.  \n",
    "    (g) Create a plot displaying  \n",
    "    $$\n",
    "    \\sqrt{\\sum_{j=1}^{p} (\\beta_j - \\hat{\\beta}^r_j)^2}\n",
    "    $$  \n",
    "    for a range of values of $r$, where $\\hat{\\beta}^r_j$ is the $j$ th coefficient estimate for the best model containing $r$ coefficients. Comment on what you observe. How does this compare to the test MSE plot from (d)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac76d705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3046f2f",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "11. We will now try to predict per capita crime rate in the Boston data set.  \n",
    "    (a) Try out some of the regression methods explored in this chapter, such as best subset selection, the lasso, ridge regression, and PCR. Present and discuss results for the approaches that you consider.  \n",
    "    \n",
    "    (b) Propose a model (or set of models) that seem to perform well on this data set, and justify your answer. Make sure that you are evaluating model performance using validation set error, cross-validation, or some other reasonable alternative, as opposed to using training error.\n",
    "    \n",
    "    (c) Does your chosen model involve all of the features in the data set? Why or why not?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e477ecb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "islp_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
