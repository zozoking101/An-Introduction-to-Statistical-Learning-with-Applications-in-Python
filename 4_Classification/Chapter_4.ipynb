{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c645b505",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bb0214",
   "metadata": {},
   "source": [
    " The linear regression model discussed in Chapter 3 assumes that the re\n",
    "sponse variable Y is quantitative. But in many situations, the response\n",
    " variable is instead qualitative. For example, eye color is qualitative. Of- qualitative\n",
    " ten qualitative variables are referred to as categorical; we will use these\n",
    " terms interchangeably. In this chapter, we study approaches for predicting\n",
    " qualitative responses, a process that is known as classification. Predicting classification\n",
    " a qualitative response for an observation can be referred to as classifying\n",
    " that observation, since it involves assigning the observation to a category,\n",
    " or class. On the other hand, often the methods used for classification first\n",
    " predict the probability that the observation belongs to each of the cate\n",
    "gories of a qualitative variable, as the basis for making the classification.\n",
    " In this sense they also behave like regression methods.\n",
    " There are many possible classification techniques, or classifiers, that one classifier\n",
    " might use to predict a qualitative response. We touched on some of these\n",
    " in Sections 2.1.5 and 2.2.3. In this chapter we discuss some widely-used\n",
    " classifiers: logistic regression, linear discriminant analysis, quadratic dis- logistic\n",
    " criminant analysis, naive Bayes, and K-nearest neighbors. The discussion\n",
    " of logistic regression is used as a jumping-off point for a discussion of gen\n",
    "eralized linear models, and in particular, Poisson regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44eab83",
   "metadata": {},
   "source": [
    "#### An Overview of Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94704776",
   "metadata": {},
   "source": [
    " Classification problems occur often, perhaps even more so than regression problems. Some examples include:\n",
    "  1. A person arrives at the emergency room with a set of symptoms\n",
    " that could possibly be attributed to one of three medical conditions.\n",
    " Which of the three conditions does the individual have?\n",
    " 2. An online banking service must be able to determine whether or not\n",
    " a transaction being performed on the site is fraudulent, on the basis\n",
    " of the user’s IP address, past transaction history, and so forth.\n",
    " 3. On the basis of DNA sequence data for a number of patients with\n",
    " and without a given disease, a biologist would like to figure out which\n",
    " DNA mutations are deleterious (disease-causing) and which are not.\n",
    "\n",
    " Just as in the regression setting, in the classification setting we have a\n",
    " set of training observations (x1,y1),...,(xn,yn) that we can use to build\n",
    " a classifier. We want our classifier to perform well not only on the training\n",
    " data, but also on test observations that were not used to train the classifier.\n",
    " \n",
    " In this chapter, we will illustrate the concept of classification using the\n",
    " simulated Default data set. We are interested in predicting whether an\n",
    " individual will default on his or her credit card payment, on the basis of\n",
    " annual income and monthly credit card balance. The data set is displayed\n",
    " in Figure 4.1. In the left-hand panel of Figure 4.1, we have plotted annual\n",
    " income and monthly credit card balance for a subset of 10,000 individuals.\n",
    " The individuals who defaulted in a given month are shown in orange, and\n",
    " those who did not in blue. (The overall default rate is about 3%, so we\n",
    " have plotted only a fraction of the individuals who did not default.) It\n",
    " appears that individuals who defaulted tended to have higher credit card\n",
    " balances than those who did not. In the center and right-hand panels of\n",
    " Figure 4.1, two pairs of boxplots are shown. The first shows the distribution\n",
    " of balance split by the binary default variable; the second is a similar plot\n",
    " for income. In this chapter, we learn how to build a model to predict default\n",
    " (Y ) for any given value of balance (X1) and income (X2). Since Y is not\n",
    " quantitative, the simple linear regression model of Chapter 3 is not a good\n",
    " choice: we will elaborate on this further in Section 4.2.\n",
    " \n",
    " It is worth noting that Figure 4.1 displays a very pronounced relation\n",
    "ship between the predictor balance and the response default. In most real\n",
    " applications, the relationship between the predictor and the response will\n",
    " not be nearly so strong. However, for the sake of illustrating the classifica\n",
    "tion procedures discussed in this chapter, we use an example in which the\n",
    " relationship between the predictor and the response is somewhat exaggerated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5956a8",
   "metadata": {},
   "source": [
    "#### Why Not Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38612c",
   "metadata": {},
   "source": [
    " Suppose that we are trying to predict the medical condition of a patient\n",
    " in the emergency room on the basis of her symptoms. In this simplified\n",
    " example, there are three possible diagnoses: stroke, drug overdose, and epilepticseizure.Wecouldconsiderencodingthesevaluesasaquantita\n",
    "tiveresponsevariable,Y,asfollows:\n",
    " Y=\n",
    " 1 ifstroke;\n",
    " 2 ifdrugoverdose;\n",
    " 3 ifepilepticseizure.\n",
    " Usingthiscoding,leastsquarescouldbeusedtofitalinearregressionmodel\n",
    " topredictY onthebasisofasetofpredictorsX1,...,Xp.Unfortunately,\n",
    " thiscodingimpliesanorderingontheoutcomes,puttingdrug overdosein\n",
    " betweenstrokeandepilepticseizure, and insistingthat thedifference\n",
    " betweenstrokeanddrugoverdose is thesameas thedifferencebetween\n",
    " drugoverdoseandepilepticseizure. Inpractice there isnoparticular\n",
    " reasonthat thisneeds tobethecase.For instance, onecouldchoosean\n",
    " equallyreasonablecoding,\n",
    " Y=\n",
    " 1 ifepilepticseizure;\n",
    " 2 ifstroke;\n",
    " 3 ifdrugoverdose,\n",
    " whichwouldimplyatotallydifferentrelationshipamongthethreecondi\n",
    "tions.Eachof thesecodingswouldproducefundamentallydifferent linear\n",
    " modelsthatwouldultimatelyleadtodifferentsetsofpredictionsontest\n",
    " observations.\n",
    " If theresponsevariable’svaluesdidtakeonanaturalordering, suchas\n",
    " mild,moderate,andsevere,andwefeltthegapbetweenmildandmoderate\n",
    " wassimilartothegapbetweenmoderateandsevere,thena1,2,3coding\n",
    " wouldbereasonable.Unfortunately, ingeneral thereisnonaturalwayto\n",
    " convert a qualitative response variable with more than two levels into a\n",
    " quantitative response that is ready for linear regression.\n",
    " For a binary (two level) qualitative response, the situation is better. For binary\n",
    " instance, perhaps there are only two possibilities for the patient’s medical\n",
    " condition: stroke and drug overdose. We could then potentially use the\n",
    " dummyvariable approach from Section 3.3.1 to code the response as follows:\n",
    " Y = 0 ifstroke;\n",
    " 1 if drug overdose.\n",
    " We could then fit a linear regression to this binary response, and predict\n",
    " drug overdose if ˆY>0.5 and stroke otherwise. In the binary case it is not\n",
    " hard to show that even if we flip the above coding, linear regression will\n",
    " produce the same final predictions.\n",
    " For a binary response with a 0/1 coding as above, regression by least\n",
    " squares is not completely unreasonable: it can be shown that the X ˆob\n",
    "tained using linear regression is in fact an estimate of Pr(drug overdose|X)\n",
    " in this special case. However, if we use linear regression, some of our es\n",
    "timates might be outside the [0,1] interval (see Figure 4.2), making them\n",
    " hard to interpret as probabilities! Nevertheless, the predictions provide an\n",
    " ordering and can be interpreted as crude probability estimates. Curiously,\n",
    " it turns out that the classifications that we get if we use linear regression\n",
    " to predict a binary response will be the same as for the linear discriminant\n",
    " analysis (LDA) procedure we discuss in Section 4.4.\n",
    " To summarize, there are at least two reasons not to perform classifica\n",
    "tion using a regression method: (a) a regression method cannot accommo\n",
    "date a qualitative response with more than two classes; (b) a regression\n",
    " method will not provide meaningful estimates of Pr(Y |X), even with just\n",
    " two classes. Thus, it is preferable to use a classification method that is\n",
    " truly suited for qualitative response values. In the next section, we present\n",
    " logistic regression, which is well-suited for the case of a binary qualita\n",
    "tive response; in later sections we will cover classification methods that are\n",
    " appropriate when the qualitative response has two or more classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb3996a",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf416a40",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    " Consider again the Default data set, where the response default falls into\n",
    " one of two categories, Yes or No. Rather than modeling this response Y\n",
    " directly, logistic regression models the probability that Y belongs to a par\n",
    "ticular category.\n",
    " For the Default data, logistic regression models the probability of default.\n",
    " For example, the probability of default given balance can be written as\n",
    " Pr(default = Yes|balance).\n",
    " Thevalues of Pr(default = Yes|balance), which we abbreviate p(balance),\n",
    " will range between 0 and 1. Then for any given value of balance, a prediction\n",
    " can be made for default. For example, one might predict default = Yes\n",
    "  foranyindividual forwhomp(balance)>0.5.Alternatively, ifacompany\n",
    " wishestobeconservativeinpredictingindividualswhoareatriskforde\n",
    "fault,thentheymaychoosetousealowerthreshold,suchasp(balance)>\n",
    " 0.1.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955d644",
   "metadata": {},
   "source": [
    "##### The Logistic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c310444",
   "metadata": {},
   "source": [
    " Howshouldwemodel therelationshipbetweenp(X)=Pr(Y=1|X)and\n",
    " X?(Forconvenienceweareusingthegeneric0/1codingfortheresponse.)\n",
    " InSection4.2weconsideredusinga linearregressionmodel torepresent\n",
    " theseprobabilities:\n",
    " p(X)= 0+ 1X. (4.1)\n",
    " Ifweuse this approachtopredict default=Yesusingbalance, thenwe\n",
    " obtainthemodel showninthe left-handpanelofFigure4.2.Herewesee\n",
    " theproblemwiththisapproach: forbalances close tozerowepredict a\n",
    " negativeprobabilityofdefault;ifweweretopredictforverylargebalances,\n",
    " wewouldgetvaluesbiggerthan1.Thesepredictionsarenotsensible,since\n",
    " ofcoursethetrueprobabilityofdefault, regardlessofcreditcardbalance,\n",
    " mustfallbetween0and1.Thisproblemisnotuniquetothecreditdefault\n",
    " data.Anytimeastraight line isfittoabinaryresponsethat iscodedas\n",
    " 0or1, inprinciplewecanalwayspredictp(X)<0forsomevaluesofX\n",
    " andp(X)>1forothers(unlesstherangeofXislimited).\n",
    " Toavoidthisproblem,wemustmodelp(X)usingafunctionthatgives\n",
    " outputsbetween0and1 for all values ofX.Many functionsmeet this\n",
    " description. Inlogisticregression,weusethelogisticfunction, logistic\n",
    " function\n",
    " p(X)= e 0+1X\n",
    " 1+e 0+1X\n",
    " . (4.2)\n",
    " Tofitthemodel (4.2),weuseamethodcalledmaximumlikelihood,which maximum\n",
    " likelihood wediscussinthenextsection.Theright-handpanelofFigure4.2illustrates\n",
    " thefitofthelogisticregressionmodeltotheDefaultdata.Noticethatfor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cfde67",
   "metadata": {},
   "source": [
    " low balances we now predict the probability of default as close to, but never\n",
    " below, zero. Likewise, for high balances we predict a default probability\n",
    " close to, but never above, one. The logistic function will always produce\n",
    " an S-shaped curve of this form, and so regardless of the value of X,we\n",
    " will obtain a sensible prediction. We also see that the logistic model is\n",
    " better able to capture the range of probabilities than is the linear regression\n",
    " model in the left-hand plot. The average fitted probability in both cases is\n",
    " 0.0333 (averaged over the training data), which is the same as the overall\n",
    " proportion of defaulters in the data set.\n",
    " After a bit of manipulation of (4.2), we find that\n",
    " p(X)\n",
    " 1 p(X) =e 0+1X.\n",
    " (4.3)\n",
    " The quantity p(X)/[1 p(X)] is called the odds, and can take on any value odds\n",
    " between 0 and . Values of the odds close to 0 and indicate very low\n",
    " and very high probabilities of default, respectively. For example, on average\n",
    " 1 in 5 people with an odds of 1/4 will default, since p(X)=0.2 implies an\n",
    " odds of 0.2\n",
    " 1 0.2 =1/4. Likewise, on average nine out of every ten people with\n",
    " an odds of 9 will default, since p(X)=0.9 implies an odds of 0.9\n",
    " 1 0.9 =9.\n",
    " Odds are traditionally used instead of probabilities in horse-racing, since\n",
    " they relate more naturally to the correct betting strategy.\n",
    " By taking the logarithm of both sides of (4.3), we arrive at\n",
    " log\n",
    " p(X)\n",
    " 1 p(X) = 0+ 1X.\n",
    " (4.4)\n",
    " The left-hand side is called the log odds or logit. We see that the logistic log odds\n",
    " regression model (4.2) has a logit that is linear in X.\n",
    " Recall from Chapter 3 that in a linear regression model, 1 gives the\n",
    " average change in Y associated with a one-unit increase in X. By contrast,\n",
    " in a logistic regression model, increasing X by one unit changes the log\n",
    " odds by 1 (4.4). Equivalently, it multiplies the odds by e 1 (4.3). However,\n",
    " because the relationship between p(X) and X in (4.2) is not a straight line,\n",
    " 1 does not correspond to the change in p(X) associated with a one-unit\n",
    " increase in X. The amount that p(X) changes due to a one-unit change in\n",
    " X depends on the current value of X. But regardless of the value of X, if\n",
    " 1 is positive then increasing X will be associated with increasing p(X),\n",
    " and if 1 is negative then increasing X will be associated with decreasing\n",
    " p(X). The fact that there is not a straight-line relationship between p(X)\n",
    " and X, and the fact that the rate of change in p(X) per unit change in X\n",
    " depends on the current value of X, can also be seen by inspection of the\n",
    " right-hand panel of Figure 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cb6c35",
   "metadata": {},
   "source": [
    "##### Estimating the Regression Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e332f154",
   "metadata": {},
   "source": [
    " The coefficients 0 and 1 in (4.2) are unknown, and must be estimated\n",
    " based on the available training data. In Chapter 3, we used the least squares\n",
    " approach to estimate the unknown linear regression coefficients. Although\n",
    " we could use (non-linear) least squares to fit the model (4.4), the more\n",
    " general method of maximum likelihood is preferred, since it has better sta\n",
    "tistical properties. The basic intuition behind using maximum likelihood  to fit a logistic regression model is as follows: we seek estimates for 0 and\n",
    " 1 such that the predicted probability ˆp(xi) of default for each individual,\n",
    " using (4.2), corresponds as closely as possible to the individual’s observed\n",
    " default status. In other words, we try to find ˆ0 and ˆ1 such that plugging\n",
    " these estimates into the model for p(X), given in (4.2), yields a number\n",
    " close to one for all individuals who defaulted, and a number close to zero\n",
    " for all individuals who did not. This intuition can be formalized using a\n",
    " mathematical equation called a likelihood function:\n",
    " ( 0, 1)=\n",
    " p(xi)\n",
    " i:yi=1\n",
    " (1 p(xi)).\n",
    " i :yi=0\n",
    " (4.5)\n",
    " The estimates ˆ0 and ˆ1 are chosen to maximize this likelihood function.\n",
    " Maximum likelihood is a very general approach that is used to fit many\n",
    " of the non-linear models that we examine throughout this book. In the\n",
    " linear regression setting, the least squares approach is in fact a special case\n",
    " of maximum likelihood. The mathematical details of maximum likelihood\n",
    " are beyond the scope of this book. However, in general, logistic regression\n",
    " and other models can be easily fit using statistical software such as R, and\n",
    " so we do not need to concern ourselves with the details of the maximum\n",
    " likelihood fitting procedure.\n",
    " Table 4.1 shows the coefficient estimates and related information that\n",
    " result from fitting a logistic regression model on the Default data in order\n",
    " to predict the probability of default=Yes using balance. We see that ˆ1 =\n",
    " 0.0055; this indicates that an increase in balance is associated with an\n",
    " increase in the probability of default. To be precise, a one-unit increase in\n",
    " balance is associated with an increase in the log odds of default by 0.0055\n",
    " units.\n",
    " Many aspects of the logistic regression output shown in Table 4.1 are\n",
    " similar to the linear regression output of Chapter 3. For example, we can\n",
    " measure the accuracy of the coefficient estimates by computing their stan\n",
    "dard errors. The z-statistic in Table 4.1 plays the same role as the t-statistic\n",
    " in the linear regression output, for example in Table 3.1 on page 77. For\n",
    " instance, the z-statistic associated with 1 is equal to ˆ1/SE(ˆ1), and so a\n",
    " large (absolute) value of the z-statistic indicates evidence against the null\n",
    " hypothesis H0 : 1 =0. This null hypothesis implies that p(X)= e 0\n",
    " 1+e 0 \n",
    ": in\n",
    " other words, that the probability of default does not depend on balance.\n",
    " Since the p-value associated with balance in Table 4.1 is tiny, we can reject\n",
    " H0. In other words, we conclude that there is indeed an association between\n",
    " balance and probability of default. The estimated intercept in Table 4.1\n",
    " is typically not of interest; its main purpose is to adjust the average fitted\n",
    " probabilities to the proportion of ones in the data (in this case, the overall\n",
    " default rate)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f41578",
   "metadata": {},
   "source": [
    "##### Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c98477",
   "metadata": {},
   "source": [
    " Once the coefficients have been estimated, we can compute the probability\n",
    " of default for any given credit card balance. For example, using the coeffi\n",
    "cient estimates given in Table 4.1, we predict that the default probability  Classification\n",
    " Coefficient Std. error z-statistic\n",
    " p-value\n",
    " Intercept 10.6513\n",
    " balance 0.0055\n",
    " 0.3612\n",
    " 0.0002\n",
    " 29.5 <0.0001\n",
    " 24.9 <0.0001\n",
    " TABLE 4.1. For the Default data, estimated coefficients of the logistic regres\n",
    "sion model that predicts the probability of default using balance. A one-unit\n",
    " increase in balance is associated with an increase in the log odds of default by\n",
    " 0.0055 units.\n",
    " Coefficient Std. error z-statistic\n",
    " p-value\n",
    " Intercept\n",
    " student[Yes]\n",
    " 3.5041\n",
    " 0.4049\n",
    " 0.0707\n",
    " 0.1150\n",
    " 49.55 <0.0001\n",
    " 3.52\n",
    " 0.0004\n",
    " TABLE4.2.FortheDefault data, estimated coefficients of the logistic regression\n",
    " model that predicts the probability of default using student status. Student status\n",
    " is encoded as a dummy variable, with a value of 1 for a student and a value of 0\n",
    " for a non-student, and represented by the variable student[Yes] in the table.\n",
    " for an individual with a balance of $1,000 is\n",
    " ˆ\n",
    " p(X)= eˆ0+ˆ1X\n",
    " 1+eˆ0+ˆ1X \n",
    "= e 10.6513+0.0055 1,000\n",
    " 1+e 10.6513+0.0055 1,000 \n",
    "=0.00576,\n",
    " which is below 1%. In contrast, the predicted probability of default for an\n",
    " individual with a balance of $2,000 is much higher, and equals 0.586 or\n",
    " 58.6%.\n",
    " One can use qualitative predictors with the logistic regression model us\n",
    "ing the dummy variable approach from Section 3.3.1. As an example, the\n",
    " Default data set contains the qualitative variable student. To fit a model\n",
    " that uses student status as a predictor variable, we simply create a dummy\n",
    " variable that takes on a value of 1 for students and 0 for non-students. The\n",
    " logistic regression model that results from predicting probability of default\n",
    " from student status can be seen in Table 4.2. The coefficient associated\n",
    " with the dummy variable is positive, and the associated p-value is statisti\n",
    "cally significant. This indicates that students tend to have higher default\n",
    " probabilities than non-students:\n",
    " Pr(default=Yes|student=Yes)= e 3.5041+0.4049 1\n",
    " 1+e 3.5041+0.4049 1 \n",
    "=0.0431,\n",
    " Pr(default=Yes|student=No)= e 3.5041+0.4049 0\n",
    " 1+e 3.5041+0.4049 0 \n",
    "=0.0292.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a207b9a",
   "metadata": {},
   "source": [
    "##### Multiple Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129f13fb",
   "metadata": {},
   "source": [
    "Wenowconsider the problem of predicting a binary response using multiple\n",
    " predictors. By analogy with the extension from simple to multiple linear\n",
    " regression in Chapter 3, we can generalize (4.4) as follows:\n",
    " log\n",
    " p(X)\n",
    " 1 p(X) = 0+ 1X1+···+ pXp,\n",
    " (4.6)\n",
    " where X =(X1,...,Xp) are p predictors. Equation 4.6 can be rewritten as\n",
    " p(X)= e 0+1X1+···+pXp\n",
    " 1+e 0+1X1+···+pXp\n",
    " .\n",
    " (4.7)\n",
    "  Coefficient Std. error z-statistic\n",
    " p-value\n",
    " Intercept\n",
    " balance\n",
    " income\n",
    " student[Yes]\n",
    " 10.8690\n",
    " 0.0057\n",
    " 0.0030\n",
    " 0.6468\n",
    " 0.4923\n",
    " 0.0002\n",
    " 0.0082\n",
    " 0.2362\n",
    " 22.08 <0.0001\n",
    " 24.74 <0.0001\n",
    " 0.37\n",
    " 2.74\n",
    " 0.7115\n",
    " 0.0062\n",
    " TABLE4.3.FortheDefault data, estimated coefficients of the logistic regression\n",
    " model that predicts the probability of default using balance, income, and student\n",
    " status. Student status is encoded as a dummy variable student[Yes], with a value\n",
    " of 1 for a student and a value of 0 for a non-student. In fitting this model, income\n",
    " was measured in thousands of dollars.\n",
    " 0\n",
    " Just as in Section 4.3.2, we use the maximum likelihood method to estimate\n",
    " , 1,..., p.\n",
    " Table 4.3 shows the coefficient estimates for a logistic regression model\n",
    " that uses balance, income (in thousands of dollars), and student status to\n",
    " predict probability of default. There is a surprising result here. The p\n",
    "values associated with balance and the dummy variable for student status\n",
    " are very small, indicating that each of these variables is associated with\n",
    " the probability of default. However, the coefficient for the dummy variable\n",
    " is negative, indicating that students are less likely to default than non\n",
    "students. In contrast, the coefficient for the dummy variable is positive in\n",
    " Table 4.2. How is it possible for student status to be associated with an\n",
    " increase in probability of default in Table 4.2 and a decrease in probability\n",
    " of default in Table 4.3? The left-hand panel of Figure 4.3 provides a graph\n",
    "ical illustration of this apparent paradox. The orange and blue solid lines\n",
    " show the average default rates for students and non-students, respectively,\n",
    " as a function of credit card balance. The negative coefficient for student in\n",
    " the multiple logistic regression indicates that for a fixed value of balance\n",
    " and income, a student is less likely to default than a non-student. Indeed,\n",
    " we observe from the left-hand panel of Figure 4.3 that the student default\n",
    " rate is at or below that of the non-student default rate for every value of\n",
    " balance. But the horizontal broken lines near the base of the plot, which\n",
    " show the default rates for students and non-students averaged over all val\n",
    "ues of balance and income, suggest the opposite effect: the overall student\n",
    " default rate is higher than the non-student default rate. Consequently, there\n",
    " is a positive coefficient for student in the single variable logistic regression\n",
    " output shown in Table 4.2.\n",
    " The right-hand panel of Figure 4.3 provides an explanation for this dis\n",
    "crepancy. The variables student and balance are correlated. Students tend\n",
    " to hold higher levels of debt, which is in turn associated with higher prob\n",
    "ability of default. In other words, students are more likely to have large\n",
    " credit card balances, which, as we know from the left-hand panel of Fig\n",
    "ure 4.3, tend to be associated with high default rates. Thus, even though\n",
    " an individual student with a given credit card balance will tend to have a\n",
    " lower probability of default than a non-student with the same credit card\n",
    " balance, the fact that students on the whole tend to have higher credit card\n",
    " balances means that overall, students tend to default at a higher rate than\n",
    " non-students. This is an important distinction for a credit card company\n",
    " that is trying to determine to whom they should offer credit. A student is\n",
    " riskier than a non-student if no information about the student’s credit card  balance is available. However, that student is less risky than a non-student\n",
    " with the same credit card balance!\n",
    " This simple example illustrates the dangers and subtleties associated\n",
    " with performing regressions involving only a single predictor when other\n",
    " predictors may also be relevant. As in the linear regression setting, the\n",
    " results obtained using one predictor may be quite different from those ob\n",
    "tained using multiple predictors, especially when there is correlation among\n",
    " the predictors. In general, the phenomenon seen in Figure 4.3 is known as\n",
    " confounding.\n",
    " By substituting estimates for the regression coefficients from Table 4.3\n",
    " into (4.7), we can make predictions. For example, a student with a credit\n",
    " card balance of $1,500 and an income of $40,000 has an estimated proba\n",
    "bility of default of\n",
    " ˆ\n",
    " p(X)= e 10.869+0.00574 1,500+0.003 40 0.6468 1\n",
    " 1+e 10.869+0.00574 1,500+0.003 40 0.6468 1 \n",
    "=0.058.\n",
    " (4.8)\n",
    " A non-student with the same balance and income has an estimated prob\n",
    "ability of default of\n",
    " ˆ\n",
    " p(X)= e 10.869+0.00574 1,500+0.003 40 0.6468 0\n",
    " 1+e 10.869+0.00574 1,500+0.003 40 0.6468 0 \n",
    "=0.105.\n",
    " (4.9)\n",
    " (Here we multiply the income coefficient estimate from Table 4.3 by 40,\n",
    " rather than by 40,000, because in that table the model was fit with income\n",
    " measured in units of $1,000.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ec43d3",
   "metadata": {},
   "source": [
    "##### Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d467a26",
   "metadata": {},
   "source": [
    "We sometimes wish to classify a response variable that has more than two\n",
    " classes. For example, in Section 4.2 we had three categories of medical con\n",
    "dition in the emergency room: stroke, drug overdose, epileptic seizure.\n",
    " However, the logistic regression approach that we have seen in this section\n",
    " only allows for K =2classes for the response variable.\n",
    "  It turns out that it is possible to extend the two-class logistic regression\n",
    " approach to the setting of K>2 classes. This extension is sometimes\n",
    " known as multinomial logistic regression. To do this, we first select a single multinomial\n",
    " class to serve as the baseline; without loss of generality, we select the Kth\n",
    " class for this role. Then we replace the model (4.7) with the model\n",
    " e k0+k1x1+···+kpxp\n",
    " Pr(Y = k|X =x)=\n",
    " for k =1,...,K 1, and\n",
    " Pr(Y = K|X =x)=\n",
    " 1+ K 1\n",
    " l=1 e l0+ l1x1+···+ lpxp\n",
    " 1\n",
    " 1+ K1\n",
    " l=1 e l0+ l1x1+···+ lpxp \n",
    ".\n",
    " It is not hard to show that for k =1,...,K 1,\n",
    " log Pr(Y =k|X =x)\n",
    " Pr(Y = K|X =x) = k0+ k1x1+···+ kpxp.\n",
    " (4.10)\n",
    " (4.11)\n",
    " (4.12)\n",
    " Notice that (4.12) is quite similar to (4.6). Equation 4.12 indicates that once\n",
    " again, the log odds between any pair of classes is linear in the features.\n",
    " It turns out that in (4.10)–(4.12), the decision to treat the Kth class as\n",
    " the baseline is unimportant. For example, when classifying emergency room\n",
    " visits into stroke, drug overdose, and epileptic seizure, suppose that we\n",
    " f\n",
    " it two multinomial logistic regression models: one treating stroke as the\n",
    " baseline, another treating drug overdose as the baseline. The coefficient\n",
    " estimates will differ between the two fitted models due to the differing\n",
    " choice of baseline, but the fitted values (predictions), the log odds between\n",
    " any pair of classes, and the other key model outputs will remain the same.\n",
    " Nonetheless, interpretation of the coefficients in a multinomial logistic\n",
    " regression model must be done with care, since it is tied to the choice\n",
    " of baseline. For example, if we set epileptic seizure to be the baseline,\n",
    " then we can interpret stroke0 as the log odds of stroke versus epileptic\n",
    " seizure, given that x1 = ···= xp =0. Furthermore, a one-unit increase\n",
    " in Xj is associated with a strokej increase in the log odds of stroke over\n",
    " epileptic seizure. Stated another way, if Xj increases by one unit, then\n",
    " logistic\n",
    " regression\n",
    " Pr(Y = stroke|X = x)\n",
    " Pr(Y = epileptic seizure|X = x)\n",
    " increases by e strokej.\n",
    " We now briefly present an alternative coding for multinomial logistic\n",
    " regression, known as the softmax coding. The softmax coding is equivalent softmax\n",
    " to the coding just described in the sense that the fitted values, log odds\n",
    " between any pair of classes, and other key model outputs will remain the\n",
    " same, regardless of coding. But the softmax coding is used extensively in\n",
    " some areas of the machine learning literature (and will appear again in\n",
    " Chapter 10), so it is worth being aware of it. In the softmax coding, rather\n",
    " than selecting a baseline class, we treat all K classes symmetrically, and\n",
    " assume that for k =1,...,K,\n",
    " Pr(Y = k|X =x)= e k0+k1x1+···+kpxp\n",
    " l=1 e l0+ l1x1+···+ lpxp \n",
    ".\n",
    " K\n",
    " (4.13)\n",
    " Thus, rather than estimating coefficients for K 1 classes, we actually\n",
    " estimate coefficients for all K classes. It is not hard to see that as a result\n",
    " of (4.13), the log odds ratio between the kth and kth classes equals\n",
    " log Pr(Y =k|X =x)\n",
    " Pr(Y = k|X =x) =( k0 k0)+( k1 k1)x1+···+( kp kp)xp.\n",
    " (4.14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675766b7",
   "metadata": {},
   "source": [
    "#### Generative Models for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17be5b79",
   "metadata": {},
   "source": [
    " Logistic regression involves directly modeling Pr(Y = k|X = x) using the\n",
    " logistic function, given by (4.7) for the case of two response classes. In\n",
    " statistical jargon, we model the conditional distribution of the response Y ,\n",
    " given the predictor(s) X. We now consider an alternative and less direct\n",
    " approach to estimating these probabilities. In this new approach, we model\n",
    " the distribution of the predictors X separately in each of the response\n",
    " classes (i.e. for each value of Y ). We then use Bayes’ theorem to flip these\n",
    " around into estimates for Pr(Y = k|X = x). When the distribution of X\n",
    " within each class is assumed to be normal, it turns out that the model is\n",
    " very similar in form to logistic regression.\n",
    " Why do we need another method, when we have logistic regression?\n",
    " There are several reasons:\n",
    " • When there is substantial separation between the two classes, the\n",
    " parameter estimates for the logistic regression model are surprisingly\n",
    " unstable. The methods that we consider in this section do not suffer\n",
    " from this problem.\n",
    " • If the distribution of the predictors X is approximately normal in\n",
    " each of the classes and the sample size is small, then the approaches\n",
    " in this section may be more accurate than logistic regression.\n",
    " • The methods in this section can be naturally extended to the case\n",
    " of more than two response classes. (In the case of more than two\n",
    " response classes, we can also use multinomial logistic regression from\n",
    " Section 4.3.5.)\n",
    " Suppose that we wish to classify an observation into one of K classes,\n",
    " where K 2. In other words, the qualitative response variable Y can take\n",
    " on K possible distinct and unordered values. Let k represent the overall\n",
    " or prior probability that a randomly chosen observation comes from the prior\n",
    " kth class. Let fk(X) Pr(X|Y = k)1 denote the density function of X density\n",
    " for an observation that comes from the kth class. In other words, fk(x) is\n",
    " relatively large if there is a high probability that an observation in the kth\n",
    " class has X x, and fk(x) is small if it is very unlikely that an observation\n",
    " in the kth class has X x. Then Bayes’ theorem states that Pr(Y = k|X =x)= kfk(x)\n",
    "l=1 lfl(x)\n",
    ".\n",
    "K\n",
    "(4.15)\n",
    "In accordance with our earlier notation, we will use the abbreviation pk(x)=\n",
    "Pr(Y = k|X = x); this is the posterior probability that an observation posterior\n",
    "X = x belongs to the kth class. That is, it is the probability that the\n",
    "observation belongs to the kth class, given the predictor value for that\n",
    "observation.\n",
    "Equation 4.15 suggests that instead of directly computing the posterior\n",
    "probability pk(x) as in Section 4.3.1, we can simply plug in estimates of k\n",
    "and fk(x) into (4.15). In general, estimating k is easy if we have a random\n",
    "sample from the population: we simply compute the fraction of the training\n",
    "observations that belong to the kth class. However, estimating the density\n",
    "function fk(x) is much more challenging. As we will see, to estimate fk(x),\n",
    "we will typically have to make some simplifying assumptions.\n",
    "We know from Chapter 2 that the Bayes classifier, which classifies an\n",
    "observation x to the class for which pk(x) is largest, has the lowest possible\n",
    "error rate out of all classifiers. (Of course, this is only true if all of the\n",
    "terms in (4.15) are correctly specified.) Therefore, if we can find a way to\n",
    "estimate fk(x), then we can plug it into (4.15) in order to approximate the\n",
    "Bayes classifier.\n",
    "In the following sections, we discuss three classifiers that use different\n",
    "estimates of fk(x) in (4.15) to approximate the Bayes classifier: linear dis\n",
    "criminant analysis, quadratic discriminant analysis, and naive Bayes.\n",
    "4.4.1 Linear Discriminant Analysis for p =1\n",
    "For now, assume that p =1—that is, we have only one predictor. We would\n",
    "like to obtain an estimate for fk(x) that we can plug into (4.15) in order to\n",
    "estimate pk(x). We will then classify an observation to the class for which\n",
    "pk(x) is greatest. To estimate fk(x), we will first make some assumptions\n",
    "about its form.\n",
    "In particular, we assume that fk(x) is normal or Gaussian. In the one- normal\n",
    "dimensional setting, the normal density takes the form\n",
    "fk(x)= 1\n",
    "2 k\n",
    "exp 1\n",
    "2 2\n",
    "k\n",
    "(x µk)2 ,\n",
    "(4.16)\n",
    "where µk and 2\n",
    "k are the mean and variance parameters for the kth class.\n",
    "For now, let us further assume that 2\n",
    "1 = ···= 2\n",
    "K: that is, there is a shared\n",
    "variance term across all K classes, which for simplicity we can denote by\n",
    "2\n",
    ". Plugging (4.16) into (4.15), we find that\n",
    "pk(x)= k 1\n",
    "2\n",
    "exp 1\n",
    "2 2\n",
    "(x µk)2\n",
    "K\n",
    "l=1 l 1\n",
    "2\n",
    "exp 1\n",
    "2 2\n",
    "(x µl)2\n",
    ".\n",
    "(4.17)\n",
    "(Note that in (4.17), k denotes the prior probability that an observation\n",
    "belongs to the kth class, not to be confused with \n",
    "3.14159, the math\n",
    "ematical constant.) The Bayes classifier2 involves assigning an observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5fcfc6",
   "metadata": {},
   "source": [
    "X =xto the class for which (4.17) is largest. Taking the log of (4.17) and\n",
    "rearranging the terms, it is not hard to show3 that this is equivalent to\n",
    "assigning the observation to the class for which\n",
    "k(x)=x· µk\n",
    "2 \n",
    "µ2\n",
    "k\n",
    "2 2 \n",
    "+log( k)\n",
    "(4.18)\n",
    "is largest. For instance, if K =2and 1 = 2, then the Bayes classifier\n",
    "assigns an observation to class 1 if 2x(µ1 µ2) >µ2\n",
    "1 µ2\n",
    "2, and to class\n",
    "2 otherwise. The Bayes decision boundary is the point for which 1(x)=\n",
    "2(x); one can show that this amounts to\n",
    "x = µ2\n",
    "1 µ2\n",
    "2\n",
    "2(µ1 µ2) = µ1+µ2\n",
    "2 .\n",
    "(4.19)\n",
    "Anexample is shown in the left-hand panel of Figure 4.4. The two normal\n",
    "density functions that are displayed, f1(x) and f2(x), represent two distinct\n",
    "classes. The mean and variance parameters for the two density functions\n",
    "are µ1 = 1.25, µ2 =1.25, and 2\n",
    "1 = 2\n",
    "2 =1. The two densities overlap,\n",
    "and so given that X = x, there is some uncertainty about the class to which\n",
    "the observation belongs. If we assume that an observation is equally likely\n",
    "to come from either class—that is, 1 = 2 =0.5—then by inspection of\n",
    "(4.19), we see that the Bayes classifier assigns the observation to class 1\n",
    "if x<0 and class 2 otherwise. Note that in this case, we can compute\n",
    "the Bayes classifier because we know that X is drawn from a Gaussian\n",
    "distribution within each class, and we know all of the parameters involved.\n",
    "In a real-life situation, we are not able to calculate the Bayes classifier.\n",
    "In practice, even if we are quite certain of our assumption that X is\n",
    "drawn from a Gaussian distribution within each class, to apply the Bayes\n",
    "classifier we still have to estimate the parameters µ1,...,µK, 1,..., K,\n",
    "and 2. The linear discriminant analysis (LDA) method approximates the Bayes classifier by plugging estimates for k, µk, and 2 into (4.18)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d73ae7",
   "metadata": {},
   "source": [
    "particular, the following estimates are used:\n",
    "ˆ\n",
    "µk = 1\n",
    "nk i:yi=k \n",
    "xi\n",
    "ˆ2 = 1\n",
    "n K\n",
    "K\n",
    "k=1i:yi=k\n",
    "(xi \n",
    "ˆ\n",
    "µk)2\n",
    "(4.20)\n",
    "where n is the total number of training observations, and nk is the number\n",
    "of training observations in the kth class. The estimate for µk is simply the\n",
    "average of all the training observations from the kth class, while ˆ2 can\n",
    "be seen as a weighted average of the sample variances for each of the K\n",
    "classes. Sometimes we have knowledge of the class membership probabili\n",
    "ties 1,..., K, which can be used directly. In the absence of any additional\n",
    "information, LDA estimates k using the proportion of the training obser\n",
    "vations that belong to the kth class. In other words,\n",
    "ˆk = nk/n.\n",
    "(4.21)\n",
    "The LDAclassifier plugs the estimates given in (4.20) and (4.21) into (4.18),\n",
    "and assigns an observation X = x to the class for which\n",
    "ˆ\n",
    "k(x)=x· ˆµk\n",
    "ˆ2 \n",
    "ˆ\n",
    "µ2\n",
    "k\n",
    "2ˆ2 \n",
    "+log(ˆk)\n",
    "(4.22)\n",
    "is largest. The word linear in the classifier’s name stems from the fact\n",
    "that the discriminant functions ˆk(x) in (4.22) are linear functions of x (as discriminant\n",
    "opposed to a more complex function of x).\n",
    "The right-hand panel of Figure 4.4 displays a histogram of a random\n",
    "sample of 20 observations from each class. To implement LDA, we began\n",
    "by estimating k, µk, and 2 using (4.20) and (4.21). We then computed the\n",
    "decision boundary, shown as a black solid line, that results from assigning\n",
    "an observation to the class for which (4.22) is largest. All points to the left\n",
    "of this line will be assigned to the green class, while points to the right of\n",
    "this line are assigned to the purple class. In this case, since n1 = n2 = 20,\n",
    "we have ˆ1 =ˆ2. As a result, the decision boundary corresponds to the\n",
    "midpoint between the sample means for the two classes, (ˆµ1 +ˆ\n",
    "µ2)/2. The\n",
    "f\n",
    "igure indicates that the LDA decision boundary is slightly to the left of\n",
    "the optimal Bayes decision boundary, which instead equals (µ1 + µ2)/2=\n",
    "0. How well does the LDA classifier perform on this data? Since this is\n",
    "simulated data, we can generate a large number of test observations in order\n",
    "to compute the Bayes error rate and the LDA test error rate. These are\n",
    "10.6% and 11.1%, respectively. In other words, the LDA classifier’s error\n",
    "rate is only 0.5% above the smallest possible error rate! This indicates that\n",
    "LDA is performing pretty well on this data set.\n",
    "To reiterate, the LDA classifier results from assuming that the obser\n",
    "vations within each class come from a normal distribution with a class\n",
    "specific mean and a common variance 2, and plugging estimates for these\n",
    "parameters into the Bayes classifier. In Section 4.4.3, we will consider a less\n",
    "stringent set of assumptions, by allowing the observations in the kth class\n",
    "to have a class-specific variance, 2\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69a7361",
   "metadata": {},
   "source": [
    "#####  Linear Discriminant Analysis for p > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3b0496",
   "metadata": {},
   "source": [
    "WenowextendtheLDAclassifier tothecaseofmultiplepredictors.To\n",
    "dothis,wewillassumethatX=(X1,X2,...,Xp) isdrawnfromamulti\n",
    "variateGaussian(ormultivariatenormal)distribution,withaclass-specific multivariate\n",
    "Gaussian meanvectorandacommoncovariancematrix.Webeginwithabriefreview\n",
    "ofthisdistribution.\n",
    "ThemultivariateGaussiandistributionassumesthateachindividualpre\n",
    "dictorfollowsaone-dimensionalnormaldistribution,asin(4.16),withsome\n",
    "correlationbetweeneachpairofpredictors.Twoexamplesofmultivariate\n",
    "Gaussiandistributionswithp=2areshowninFigure4.5.Theheightof\n",
    "thesurfaceatanyparticularpointrepresentstheprobabilitythatbothX1\n",
    "andX2 fall inasmallregionaroundthatpoint.Ineitherpanel, ifthesur\n",
    "faceiscutalongtheX1axisoralongtheX2axis,theresultingcross-section\n",
    "willhavetheshapeofaone-dimensionalnormaldistribution.Theleft-hand\n",
    "panelofFigure4.5illustratesanexampleinwhichVar(X1)=Var(X2)and\n",
    "Cor(X1,X2)=0;thissurfacehasacharacteristicbell shape.However,the\n",
    "bellshapewillbedistortedifthepredictorsarecorrelatedorhaveunequal\n",
    "variances, as is illustrated inthe right-handpanel ofFigure4.5. Inthis\n",
    "situation, thebaseof thebellwillhaveanelliptical, ratherthancircular,\n",
    "shape.To indicatethatap-dimensional randomvariableXhasamulti\n",
    "variateGaussiandistribution,wewriteX N(µ, ).HereE(X)=µis\n",
    "themeanofX(avectorwithpcomponents), andCov(X)= is the\n",
    "p pcovariancematrixofX.Formally,themultivariateGaussiandensity\n",
    "isdefinedas\n",
    "f(x)= 1\n",
    "(2 )p/2| |1/2\n",
    "exp 1\n",
    "2 (x µ)T 1(x µ) . (4.23)\n",
    "Inthe caseof p>1predictors, theLDAclassifier assumes that the\n",
    "observations inthekthclassaredrawnfromamultivariateGaussiandis\n",
    "tributionN(µk, ),whereµk isaclass-specificmeanvector, and isa\n",
    "covariancematrixthat iscommontoallKclasses.Pluggingthedensity\n",
    "functionforthekthclass, fk(X=x), into(4.15)andperformingalittle\n",
    "bitofalgebrarevealsthattheBayesclassifierassignsanobservationX=x to the class for which\n",
    "k(x)=xT 1µk\n",
    "1\n",
    "2µT\n",
    "k\n",
    "1µk+log k\n",
    "is largest. This is the vector/matrix version of (4.18).\n",
    "(4.24)\n",
    "An example is shown in the left-hand panel of Figure 4.6. Three equally\n",
    "sized Gaussian classes are shown with class-specific mean vectors and a\n",
    "common covariance matrix. The three ellipses represent regions that con\n",
    "tain 95% of the probability for each of the three classes. The dashed lines\n",
    "are the Bayes decision boundaries. In other words, they represent the set\n",
    "of values x for which k(x)= (x); i.e.\n",
    "xT\n",
    "1µk \n",
    "1\n",
    "2µT\n",
    "k\n",
    "1µk =xT 1µl\n",
    "1\n",
    "2µT\n",
    "l\n",
    "1µl\n",
    "(4.25)\n",
    "for k= l. (The log k term from (4.24) has disappeared because each of\n",
    "the three classes has the same number of training observations; i.e. k is\n",
    "the same for each class.) Note that there are three lines representing the\n",
    "Bayes decision boundaries because there are three pairs of classes among\n",
    "the three classes. That is, one Bayes decision boundary separates class 1\n",
    "from class 2, one separates class 1 from class 3, and one separates class 2\n",
    "from class 3. These three Bayes decision boundaries divide the predictor\n",
    "space into three regions. The Bayes classifier will classify an observation\n",
    "according to the region in which it is located.\n",
    "Once again, we need to estimate the unknown parameters µ1,...,µK,\n",
    "1,..., K, and ; the formulas are similar to those used in the one\n",
    "dimensional case, given in (4.20). To assign a new observation X = x,\n",
    "LDA plugs these estimates into (4.24) to obtain quantities ˆk(x), and clas\n",
    "sifies to the class for which ˆk(x) is largest. Note that in (4.24) k(x) is\n",
    "a linear function of x; that is, the LDA decision rule depends on x only True default status\n",
    "No Yes Total\n",
    "Predicted No 9644 252 9896\n",
    "default status Yes 23 81 104\n",
    "Total 9667 333 10000\n",
    "TABLE 4.4. A confusion matrix compares the LDA predictions to the true\n",
    "default statuses for the 10,000 training observations in the Default data set.\n",
    "Elements on the diagonal of the matrix represent individuals whose default statuses\n",
    "were correctly predicted, while off-diagonal elements represent individuals that\n",
    "were misclassified. LDA made incorrect predictions for 23 individuals who did\n",
    "not default and for 252 individuals who did default.\n",
    "through a linear combination of its elements. As previously discussed, this\n",
    "is the reason for the word linear in LDA.\n",
    "In the right-hand panel of Figure 4.6, 20 observations drawn from each of\n",
    "the three classes are displayed, and the resulting LDA decision boundaries\n",
    "are shown as solid black lines. Overall, the LDA decision boundaries are\n",
    "pretty close to the Bayes decision boundaries, shown again as dashed lines.\n",
    "The test error rates for the Bayes and LDA classifiers are 0.0746 and 0.0770,\n",
    "respectively. This indicates that LDA is performing well on this data.\n",
    "We can perform LDA on the Default data in order to predict whether\n",
    "or not an individual will default on the basis of credit card balance and\n",
    "student status.4 The LDA model fit to the 10,000 training samples results\n",
    "in a training error rate of 2.75%. This sounds like a low error rate, but two\n",
    "caveats must be noted.\n",
    "• First of all, training error rates will usually be lower than test error\n",
    "rates, which are the real quantity of interest. In other words, we\n",
    "might expect this classifier to perform worse if we use it to predict\n",
    "whether or not a new set of individuals will default. The reason is\n",
    "that we specifically adjust the parameters of our model to do well on\n",
    "the training data. The higher the ratio of parameters p to number\n",
    "of samples n, the more we expect this overfitting to play a role. For overfitting\n",
    "these data we don’t expect this to be a problem, since p =2and\n",
    "n =10,000.\n",
    "• Second, since only 3.33% of the individuals in the training sample\n",
    "defaulted, a simple but useless classifier that always predicts that\n",
    "an individual will not default, regardless of his or her credit card\n",
    "balance and student status, will result in an error rate of 3.33%. In\n",
    "other words, the trivial null classifier will achieve an error rate that null\n",
    "is only a bit higher than the LDA training set error rate.\n",
    "In practice, a binary classifier such as this one can make two types of\n",
    "errors: it can incorrectly assign an individual who defaults to the no default\n",
    "category, or it can incorrectly assign an individual who does not default to the default category. It is often of interest to determine which of these two\n",
    "types of errors are being made. A confusion matrix, shown for the Default confusion\n",
    "data in Table 4.4, is a convenient way to display this information. The\n",
    "table reveals that LDA predicted that a total of 104 people would default.\n",
    "Of these people, 81 actually defaulted and 23 did not. Hence only 23 out\n",
    "of 9,667 of the individuals who did not default were incorrectly labeled.\n",
    "This looks like a pretty low error rate! However, of the 333 individuals who\n",
    "defaulted, 252 (or 75.7%) were missed by LDA. So while the overall error\n",
    "rate is low, the error rate among individuals who defaulted is very high.\n",
    "From the perspective of a credit card company that is trying to identify\n",
    "high-risk individuals, an error rate of 252/333 = 75.7% among individuals\n",
    "who default may well be unacceptable.\n",
    "matrix\n",
    "Class-specific performance is also important in medicine and biology,\n",
    "where the terms sensitivity and specificity characterize the performance of sensitivity\n",
    "a classifier or screening test. In this case the sensitivity is the percent\n",
    "age of true defaulters that are identified; it equals 24.3%. The specificity\n",
    "is the percentage of non-defaulters that are correctly identified; it equals\n",
    "(1 23/9667) = 99.8%.\n",
    "Why does LDA do such a poor job of classifying the customers who de\n",
    "fault? In other words, why does it have such low sensitivity? As we have\n",
    "seen, LDA is trying to approximate the Bayes classifier, which has the low\n",
    "est total error rate out of all classifiers. That is, the Bayes classifier will\n",
    "yield the smallest possible total number of misclassified observations, re\n",
    "gardless of the class from which the errors stem. Some misclassifications will\n",
    "result from incorrectly assigning a customer who does not default to the\n",
    "default class, and others will result from incorrectly assigning a customer\n",
    "who defaults to the non-default class. In contrast, a credit card company\n",
    "might particularly wish to avoid incorrectly classifying an individual who\n",
    "will default, whereas incorrectly classifying an individual who will not de\n",
    "fault, though still to be avoided, is less problematic. We will now see that it\n",
    "is possible to modify LDA in order to develop a classifier that better meets\n",
    "the credit card company’s needs.\n",
    "The Bayes classifier works by assigning an observation to the class for\n",
    "which the posterior probability pk(X) is greatest. In the two-class case, this\n",
    "amounts to assigning an observation to the default class if\n",
    "Pr(default = Yes|X = x) > 0.5.\n",
    "(4.26)\n",
    "Thus, the Bayes classifier, and by extension LDA, uses a threshold of 50%\n",
    "for the posterior probability of default in order to assign an observation\n",
    "to the default class. However, if we are concerned about incorrectly pre\n",
    "dicting the default status for individuals who default, then we can consider\n",
    "lowering this threshold. For instance, we might label any customer with a\n",
    "posterior probability of default above 20% to the default class. In other\n",
    "words, instead of assigning an observation to the default class if (4.26)\n",
    "holds, we could instead assign an observation to this class if\n",
    "Pr(default = Yes|X = x) > 0.2.\n",
    "(4.27)\n",
    "Theerror rates that result from taking this approach are shown in Table 4.5.\n",
    "Now LDA predicts that 430 individuals will default. Of the 333 individuals\n",
    "who default, LDA correctly predicts all but 138, or 41.4%. This is a vast threshold of 50%. However, this improvement comes at a cost: now 235\n",
    "individuals who do not default are incorrectly classified. As a result, the\n",
    "overall error rate has increased slightly to 3.73%. But a credit card company\n",
    "may consider this slight increase in the total error rate to be a small price to\n",
    "pay for more accurate identification of individuals who do indeed default.\n",
    "Figure 4.7 illustrates the trade-off that results from modifying the thresh\n",
    "old value for the posterior probability of default. Various error rates are\n",
    "shown as a function of the threshold value. Using a threshold of 0.5, as in\n",
    "(4.26), minimizes the overall error rate, shown as a black solid line. This\n",
    "is to be expected, since the Bayes classifier uses a threshold of 0.5 and is\n",
    "known to have the lowest overall error rate. But when a threshold of 0.5 is\n",
    "used, the error rate among the individuals who default is quite high (blue\n",
    "dashed line). As the threshold is reduced, the error rate among individuals\n",
    "who default decreases steadily, but the error rate among the individuals\n",
    "who do not default increases. How can we decide which threshold value is\n",
    "best? Such a decision must be based on domain knowledge, such as detailed\n",
    "information about the costs associated with default.\n",
    "The ROC curve is a popular graphic for simultaneously displaying the ROC curve\n",
    "two types of errors for all possible thresholds. The name “ROC” is historic,\n",
    "and comes from communications theory. It is an acronym for receiver op\n",
    "erating characteristics. Figure 4.8 displays the ROC curve for the LDA\n",
    "classifier on the training data. The overall performance of a classifier, sum marized over all possible thresholds, is given by the area under the (ROC)\n",
    "curve (AUC). An ideal ROC curve will hug the top left corner, so the larger area under\n",
    "the AUC the better the classifier. For this data the AUC is 0.95, which is\n",
    "close to the maximum of 1.0, so would be considered very good. We expect\n",
    "a classifier that performs no better than chance to have an AUC of 0.5\n",
    "(when evaluated on an independent test set not used in model training).\n",
    "ROC curves are useful for comparing different classifiers, since they take\n",
    "into account all possible thresholds. It turns out that the ROC curve for\n",
    "the logistic regression model of Section 4.3.4 fit to these data is virtually\n",
    "indistinguishable from this one for the LDA model, so we do not display it\n",
    "here.\n",
    "the (ROC)\n",
    "curve\n",
    "As we have seen above, varying the classifier threshold changes its true\n",
    "positive and false positive rate. These are also called the sensitivity and one sensitivity\n",
    "minus the specificity of our classifier. Since there is an almost bewildering specificity\n",
    "array of terms used in this context, we now give a summary. Table 4.6\n",
    "shows the possible results when applying a classifier (or diagnostic test)\n",
    "to a population. To make the connection with the epidemiology literature,\n",
    "we think of “+” as the “disease” that we are trying to detect, and “ ” as\n",
    "the “non-disease” state. To make the connection to the classical hypothesis\n",
    "testing literature, we think of “ ” as the null hypothesis and “+” as the alternative (non-null) hypothesis. In the context of the Default data, “+”\n",
    "indicates an individual who defaults, and “ ” indicates one who does not.\n",
    "Table 4.7 lists many of the popular performance measures that are used in\n",
    "this context. The denominators for the false positive and true positive rates\n",
    "are the actual population counts in each class. In contrast, the denominators\n",
    "for the positive predictive value and the negative predictive value are the\n",
    "total predicted counts for each class.\n",
    "4.4.3 Quadratic Discriminant Analysis\n",
    "As we have discussed, LDA assumes that the observations within each class\n",
    "are drawn from a multivariate Gaussian distribution with a class-specific\n",
    "mean vector and a covariance matrix that is common to all K classes.\n",
    "Quadratic discriminant analysis (QDA) provides an alternative approach. quadratic\n",
    "Like LDA, the QDA classifier results from assuming that the observations\n",
    "from each class are drawn from a Gaussian distribution, and plugging es\n",
    "timates for the parameters into Bayes’ theorem in order to perform pre\n",
    "diction. However, unlike LDA, QDA assumes that each class has its own\n",
    "covariance matrix. That is, it assumes that an observation from the kth\n",
    "class is of the form X N(µk, k), where k is a covariance matrix for\n",
    "the kth class. Under this assumption, the Bayes classifier assigns an obser\n",
    "vation X = x to the class for which\n",
    "k(x) = 1\n",
    "2 (x µk)T 1\n",
    "k (x µk) 1\n",
    "2 log| k|+log k\n",
    "= 1\n",
    "2xT 1\n",
    "k x+xT 1\n",
    "k µk\n",
    "1\n",
    "2µT\n",
    "k\n",
    "1\n",
    "k µk\n",
    "1\n",
    "2 log| k|+log k\n",
    "(4.28)\n",
    "is largest. So the QDA classifier involves plugging estimates for k, µk,\n",
    "and k into (4.28), and then assigning an observation X = x to the class\n",
    "for which this quantity is largest. Unlike in (4.24), the quantity x appears\n",
    "as a quadratic function in (4.28). This is where QDA gets its name.\n",
    "Whydoes it matter whether or not we assume that the K classes share a\n",
    "common covariance matrix? In other words, why would one prefer LDA to QDA, or vice-versa? The answer lies in the bias-variance trade-off. When\n",
    "there are p predictors, then estimating a covariance matrix requires esti\n",
    "mating p(p+1)/2 parameters. QDA estimates a separate covariance matrix\n",
    "for each class, for a total of Kp(p+1)/2 parameters. With 50 predictors this\n",
    "is some multiple of 1,275, which is a lot of parameters. By instead assum\n",
    "ing that the K classes share a common covariance matrix, the LDA model\n",
    "becomes linear in x, which means there are Kp linear coefficients to esti\n",
    "mate. Consequently, LDA is a much less flexible classifier than QDA, and\n",
    "so has substantially lower variance. This can potentially lead to improved\n",
    "prediction performance. But there is a trade-off: if LDA’s assumption that\n",
    "the K classes share a common covariance matrix is badly off, then LDA\n",
    "can suffer from high bias. Roughly speaking, LDA tends to be a better bet\n",
    "than QDA if there are relatively few training observations and so reducing\n",
    "variance is crucial. In contrast, QDA is recommended if the training set is\n",
    "very large, so that the variance of the classifier is not a major concern, or if\n",
    "the assumption of a common covariance matrix for the K classes is clearly\n",
    "untenable.\n",
    "Figure 4.9 illustrates the performances of LDA and QDA in two scenarios.\n",
    "In the left-hand panel, the two Gaussian classes have a common correla\n",
    "tion of 0.7 between X1 and X2. As a result, the Bayes decision boundary\n",
    "is linear and is accurately approximated by the LDA decision boundary.\n",
    "The QDA decision boundary is inferior, because it suffers from higher vari\n",
    "ance without a corresponding decrease in bias. In contrast, the right-hand\n",
    "panel displays a situation in which the orange class has a correlation of 0.7\n",
    "between the variables and the blue class has a correlation of 0.7. Now\n",
    "the Bayes decision boundary is quadratic, and so QDA more accurately\n",
    "approximates this boundary than does LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d10aa",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4ca58e",
   "metadata": {},
   "source": [
    "Recall that Bayes’ theorem (4.15) provides an expression for the pos\n",
    "terior probability pk(x) = Pr(Y = k|X = x) in terms of 1,..., K and\n",
    "f1(x),...,fK(x). To use (4.15) in practice, we need estimates for 1,..., K\n",
    "and f1(x),...,fK(x). As we saw in previous sections, estimating the prior\n",
    "probabilities 1,..., K is typically straightforward: for instance, we can\n",
    "estimate ˆk as the proportion of training observations belonging to the kth\n",
    "class, for k =1,...,K.\n",
    "However, estimating f1(x),...,fK(x) is more subtle. Recall that fk(x)\n",
    "is the p-dimensional density function for an observation in the kth class,\n",
    "for k =1,...,K. In general, estimating a p-dimensional density function is\n",
    "challenging. In LDA, we make a very strong assumption that greatly sim\n",
    "plifies the task: we assume that fk is the density function for a multivariate\n",
    "normal random variable with class-specific mean µk, and shared covariance\n",
    "matrix . By contrast, in QDA, we assume that fk is the density function\n",
    "for a multivariate normal random variable with class-specific mean µk, and\n",
    "class-specific covariance matrix k. By making these very strong assump\n",
    "tions, we are able to replace the very challenging problem of estimating K\n",
    "p-dimensional density functions with the much simpler problem of estimat\n",
    "ing Kp-dimensional mean vectors and one (in the case of LDA) or K (in\n",
    "the case of QDA) (p p)-dimensional covariance matrices.\n",
    "The naive Bayes classifier takes a different tack for estimating f1(x),...,\n",
    "fK(x). Instead of assuming that these functions belong to a particular\n",
    "family of distributions (e.g. multivariate normal), we instead make a single\n",
    "assumption:\n",
    "Within the kth class, the p predictors are independent.\n",
    "Stated mathematically, this assumption means that for k =1,...,K,\n",
    "fk(x)=fk1(x1) fk2(x2) ··· fkp(xp),\n",
    "(4.29)\n",
    "where fkj is the density function of the jth predictor among observations\n",
    "in the kth class.\n",
    "naive Bayes\n",
    "Why is this assumption so powerful? Essentially, estimating a p-dimen\n",
    "sional density function is challenging because we must consider not only\n",
    "the marginal distribution of each predictor — that is, the distribution of marginal\n",
    "each predictor on its own — but also the joint distribution of the predictors\n",
    "—that is, the association between the different predictors. In the case of\n",
    "a multivariate normal distribution, the association between the different\n",
    "predictors is summarized by the off-diagonal elements of the covariance\n",
    "matrix. However, in general, this association can be very hard to charac\n",
    "terize, and exceedingly challenging to estimate. But by assuming that the\n",
    "p covariates are independent within each class, we completely eliminate the\n",
    "need to worry about the association between the p predictors, because we\n",
    "have simply assumed that there is no association between the predictors!\n",
    "Do we really believe the naive Bayes assumption that the p covariates\n",
    "are independent within each class? In most settings, we do not. But even\n",
    "though this modeling assumption is made for convenience, it often leads to pretty decent results, especially in settings where n is not large enough rela\n",
    "tive to p for us to effectively estimate the joint distribution of the predictors\n",
    "within each class. In fact, since estimating a joint distribution requires such\n",
    "a huge amount of data, naive Bayes is a good choice in a wide range of set\n",
    "tings. Essentially, the naive Bayes assumption introduces some bias, but\n",
    "reduces variance, leading to a classifier that works quite well in practice as\n",
    "a result of the bias-variance trade-off.\n",
    "Once we have made the naive Bayes assumption, we can plug (4.29) into\n",
    "(4.15) to obtain an expression for the posterior probability,\n",
    "K\n",
    "Pr(Y = k|X =x)= k fk1(x1) fk2(x2) ··· fkp(xp)\n",
    "l=1 l fl1(x1) fl2(x2) ··· flp(xp) \n",
    "(4.30)\n",
    "for k =1,...,K.\n",
    "To estimate the one-dimensional density function fkj using training data\n",
    "x1j,...,xnj, we have a few options.\n",
    "• IfXj isquantitative, then we can assume that Xj|Y = k N(µjk, 2\n",
    "jk).\n",
    "In other words, we assume that within each class, the jth predictor is\n",
    "drawn from a (univariate) normal distribution. While this may sound\n",
    "a bit like QDA, there is one key difference, in that here we are assum\n",
    "ing that the predictors are independent; this amounts to QDA with\n",
    "an additional assumption that the class-specific covariance matrix is\n",
    "diagonal.\n",
    "• If Xj is quantitative, then another option is to use a non-parametric\n",
    "estimate for fkj. A very simple way to do this is by making a his\n",
    "togram for the observations of the jth predictor within each class.\n",
    "Then we can estimate fkj(xj) as the fraction of the training obser\n",
    "vations in the kth class that belong to the same histogram bin as\n",
    "xj. Alternatively, we can use a kernel density estimator, which is kernel\n",
    "essentially a smoothed version of a histogram.\n",
    "• If Xj is qualitative, then we can simply count the proportion of train\n",
    "ing observations for the jth predictor corresponding to each class. For\n",
    "instance, suppose that Xj {1,2,3}, and we have 100 observations\n",
    "in the kth class. Suppose that the jth predictor takes on values of 1,\n",
    "2, and 3 in 32, 55, and 13 of those observations, respectively. Then\n",
    "we can estimate fkj as\n",
    "ˆ\n",
    "fkj(xj)=\n",
    "0.32 if xj =1\n",
    "0.55 if xj =2\n",
    "0.13 if xj =3.\n",
    "We now consider the naive Bayes classifier in a toy example with p =3\n",
    "predictors and K =2classes. The first two predictors are quantitative,\n",
    "and the third predictor is qualitative with three levels. Suppose further\n",
    "that ˆ1 =ˆ2 =0.5. The estimated density functions ˆfkj for k =1,2\n",
    "and j =1,2,3 are displayed in Figure 4.10. Now suppose that we wish\n",
    "to classify a new observation, x = (0.4,1.5,1)T. It turns out that in this example, ˆf11(0.4)=0.368, ˆf12(1.5)=0.484, ˆf13(1)=0.226,and ˆf21(0.4)=\n",
    "0.030, ˆf22(1.5)=0.130, ˆf23(1)=0.616.Pluggingtheseestimatesinto(4.30)\n",
    "resultsinposteriorprobabilityestimatesofPr(Y=1|X=x)=0.944and\n",
    "Pr(Y=2|X=x)=0.056.\n",
    "Table4.8providestheconfusionmatrixresultingfromapplyingthenaive\n",
    "BayesclassifiertotheDefaultdataset,wherewepredictadefault if the\n",
    "posteriorprobabilityofadefault—thatis,P(Y=default|X=x)—ex\n",
    "ceeds0.5.ComparingthistotheresultsforLDAinTable4.4,ourfindings\n",
    "aremixed.WhileLDAhasaslightlyloweroverallerrorrate,naiveBaye tation of naive Bayes, we have assumed that each quantitative predictor is\n",
    "drawn from a Gaussian distribution (and, of course, that within each class,\n",
    "each predictor is independent).\n",
    "Just as with LDA, we can easily adjust the probability threshold for\n",
    "predicting a default. For example, Table 4.9 provides the confusion matrix\n",
    "resulting from predicting a default if P(Y = default|X = x) > 0.2. Again,\n",
    "the results are mixed relative to LDA with the same threshold (Table 4.5).\n",
    "Naive Bayes has a higher error rate, but correctly predicts almost two-thirds\n",
    "of the true defaults.\n",
    "In this example, it should not be too surprising that naive Bayes does\n",
    "not convincingly outperform LDA: this data set has n = 10,000 and p =2,\n",
    "and so the reduction in variance resulting from the naive Bayes assumption\n",
    "is not necessarily worthwhile. We expect to see a greater pay-off to using\n",
    "naive Bayes relative to LDA or QDA in instances where p is larger or n is\n",
    "smaller, so that reducing the variance is very important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30f313",
   "metadata": {},
   "source": [
    "####  A Comparison of Classification Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fc9f89",
   "metadata": {},
   "source": [
    "#####  An Analytical Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2525e05f",
   "metadata": {},
   "source": [
    "Wenowperformananalytical (or mathematical) comparison of LDA, QDA,\n",
    "naive Bayes, and logistic regression. We consider these approaches in a\n",
    "setting with K classes, so that we assign an observation to the class that\n",
    "maximizes Pr(Y = k|X = x). Equivalently, we can set K as the baseline\n",
    "class and assign an observation to the class that maximizes\n",
    "log Pr(Y =k|X =x)\n",
    "Pr(Y = K|X =x)\n",
    "(4.31)\n",
    "for k =1,...,K. Examining the specific form of (4.31) for each method\n",
    "provides a clear understanding of their similarities and differences.\n",
    "First, for LDA, we can make use of Bayes’ theorem (4.15) as well as\n",
    "the assumption that the predictors within each class are drawn from a\n",
    "multivariate normal density (4.23) with class-specific mean and shared co variancematrixinordertoshowthat\n",
    "log Pr(Y=k|X=x)\n",
    "Pr(Y=K|X=x) = log kfk(x)\n",
    "KfK(x)\n",
    "= log kexp 1\n",
    "2(x µk)T 1(x µk)\n",
    "Kexp 1\n",
    "2(x µK)T 1(x µK)\n",
    "= log k\n",
    "K\n",
    "1\n",
    "2 (x µk)T 1(x µk)\n",
    "+1\n",
    "2 (x µK)T 1(x µK)\n",
    "= log k\n",
    "K\n",
    "1\n",
    "2 (µk+µK)T 1(µk µK)\n",
    "+xT 1(µk µK)\n",
    "= ak+\n",
    "p\n",
    "j=1\n",
    "bkjxj, (4.32)\n",
    "whereak=log k\n",
    "K\n",
    "1\n",
    "2(µk+µK)T 1(µk µK) andbkj is the jth\n",
    "componentof 1(µk µK).HenceLDA, likelogisticregression,assumes\n",
    "thatthelogoddsoftheposteriorprobabilitiesislinearinx.\n",
    "Usingsimilarcalculations, intheQDAsetting(4.31)becomes\n",
    "log Pr(Y=k|X=x)\n",
    "Pr(Y=K|X=x) =ak+\n",
    "p\n",
    "j=1\n",
    "bkjxj+\n",
    "p\n",
    "j=1\n",
    "p\n",
    "l=1\n",
    "ckjlxjxl, (4.33)\n",
    "whereak,bkj,andckjl arefunctionsof k, K,µk,µK, kand K.Again,\n",
    "as thename suggests,QDAassumes that the logodds of theposterior\n",
    "probabilitiesisquadraticinx.\n",
    "Finally,we examine (4.31) in thenaiveBayes setting.Recall that in\n",
    "thissetting,fk(x) ismodeledasaproductofpone-dimensional functions\n",
    "fkj(xj)forj=1,...,p.Hence,\n",
    "log Pr(Y=k|X=x)\n",
    "Pr(Y=K|X=x) = log kfk(x)\n",
    "KfK(x)\n",
    "= log k\n",
    "p\n",
    "j=1fkj(xj)\n",
    "K\n",
    "p\n",
    "j=1fKj(xj)\n",
    "= log k\n",
    "K\n",
    "+\n",
    "p\n",
    "j=1\n",
    "log fkj(xj)\n",
    "fKj(xj)\n",
    "= ak+\n",
    "p\n",
    "j=1\n",
    "gkj(xj), (4.34)\n",
    "whereak=log k\n",
    "K\n",
    "andgkj(xj)=log fkj(xj)\n",
    "fKj(xj) .Hence, theright-hand\n",
    "sideof (4.34)takestheformofageneralizedadditivemodel,atopicthatis\n",
    "discussedfurtherinChapter7\n",
    "\n",
    "Inspection of (4.32), (4.33), and (4.34) yields the following observations\n",
    "about LDA, QDA, and naive Bayes:\n",
    "• LDA is a special case of QDA with ckjl =0 for all j =1,...,p,\n",
    "l =1,...,p, and k =1,...,K. (Of course, this is not surprising, since\n",
    "LDAissimply arestricted version of QDA with 1 = ···= K = .)\n",
    "• Anyclassifier with a linear decision boundary is a special case of naive\n",
    "Bayes with gkj(xj)=bkjxj. In particular, this means that LDA is\n",
    "a special case of naive Bayes! This is not at all obvious from the\n",
    "descriptions of LDA and naive Bayes earlier in this chapter, since\n",
    "each method makes very different assumptions: LDA assumes that\n",
    "the features are normally distributed with a common within-class\n",
    "covariance matrix, and naive Bayes instead assumes independence of\n",
    "the features.\n",
    "• Ifwemodel fkj(xj) in the naive Bayes classifier using a one-dimensio\n",
    "nal Gaussian distribution N(µkj, 2\n",
    "j), then we end up with gkj(xj)=\n",
    "bkjxj where bkj =(µkj µKj)/ 2\n",
    "j. In this case, naive Bayes is actually\n",
    "a special case of LDA with restricted to be a diagonal matrix with\n",
    "jth diagonal element equal to 2\n",
    "j.\n",
    "• Neither QDA nor naive Bayes is a special case of the other. Naive\n",
    "Bayes can produce a more flexible fit, since any choice can be made\n",
    "for gkj(xj). However, it is restricted to a purely additive fit, in the\n",
    "sense that in (4.34), a function of xj is added to a function of xl, for\n",
    "j= l; however, these terms are never multiplied. By contrast, QDA\n",
    "includes multiplicative terms of the form ckjlxjxl. Therefore, QDA\n",
    "has the potential to be more accurate in settings where interactions\n",
    "amongthe predictors are important in discriminating between classes.\n",
    "None of these methods uniformly dominates the others: in any setting, the\n",
    "choice of method will depend on the true distribution of the predictors in\n",
    "each of the K classes, as well as other considerations, such as the values of\n",
    "n and p. The latter ties into the bias-variance trade-off.\n",
    "How does logistic regression tie into this story? Recall from (4.12) that\n",
    "multinomial logistic regression takes the form\n",
    "log Pr(Y =k|X =x)\n",
    "Pr(Y = K|X =x) = k0+\n",
    "p\n",
    "j=1\n",
    "kjxj.\n",
    "This is identical to the linear form of LDA (4.32): in both cases,\n",
    "log Pr(Y=k|X=x)\n",
    "Pr(Y =K|X=x) is a linear function of the predictors. In LDA, the co\n",
    "efficients in this linear function are functions of estimates for k, K, µk,\n",
    "µK, and obtained by assuming that X1,...,Xp follow a normal distri\n",
    "bution within each class. By contrast, in logistic regression, the coefficients\n",
    "are chosen to maximize the likelihood function (4.5). Thus, we expect LDA\n",
    "to outperform logistic regression when the normality assumption (approxi\n",
    "mately) holds, and we expect logistic regression to perform better when it\n",
    "does not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed370d2b",
   "metadata": {},
   "source": [
    "We close with a brief discussion of K-nearest neighbors (KNN), intro\n",
    "duced in Chapter 2. Recall that KNN takes a completely different approach\n",
    "from the classifiers seen in this chapter. In order to make a prediction for\n",
    "an observation X = x, the training observations that are closest to x are\n",
    "identified. Then X is assigned to the class to which the plurality of these\n",
    "observations belong. Hence KNN is a completely non-parametric approach:\n",
    "no assumptions are made about the shape of the decision boundary. We\n",
    "make the following observations about KNN:\n",
    "• Because KNN is completely non-parametric, we can expect this ap\n",
    "proach to dominate LDA and logistic regression when the decision\n",
    "boundary is highly non-linear, provided that n is very large and p is\n",
    "small.\n",
    "• In order to provide accurate classification, KNN requires a lot of ob\n",
    "servations relative to the number of predictors—that is, n much larger\n",
    "than p. This has to do with the fact that KNN is non-parametric, and\n",
    "thus tends to reduce the bias while incurring a lot of variance.\n",
    "• In settings where the decision boundary is non-linear but n is only\n",
    "modest, or p is not very small, then QDA may be preferred to KNN.\n",
    "This is because QDA can provide a non-linear decision boundary\n",
    "while taking advantage of a parametric form, which means that it\n",
    "requires a smaller sample size for accurate classification, relative to\n",
    "KNN.\n",
    "• Unlike logistic regression, KNN does not tell us which predictors are\n",
    "important: we don’t get a table of coefficients as in Table 4.3.\n",
    "4.5.2 An Empirical Comparison\n",
    "We now compare the empirical (practical) performance of logistic regres\n",
    "sion, LDA, QDA, naive Bayes, and KNN. We generated data from six dif\n",
    "ferent scenarios, each of which involves a binary (two-class) classification\n",
    "problem. In three of the scenarios, the Bayes decision boundary is linear,\n",
    "and in the remaining scenarios it is non-linear. For each scenario, we pro\n",
    "duced 100 random training data sets. On each of these training sets, we\n",
    "f\n",
    "it each method to the data and computed the resulting test error rate on\n",
    "a large test set. Results for the linear scenarios are shown in Figure 4.11,\n",
    "and the results for the non-linear scenarios are in Figure 4.12. The KNN\n",
    "method requires selection of K, the number of neighbors (not to be con\n",
    "fused with the number of classes in earlier sections of this chapter). We\n",
    "performed KNN with two values of K: K =1, and a value of K that was\n",
    "chosen automatically using an approach called cross-validation, which we\n",
    "discuss further in Chapter 5. We applied naive Bayes assuming univariate\n",
    "Gaussian densities for the features within each class (and, of course — since\n",
    "this is the key characteristic of naive Bayes — assuming independence of\n",
    "the features).\n",
    "In each of the six scenarios, there were p =2quantitative predictors.\n",
    "The scenarios were as follows\n",
    "\n",
    "Scenario 1: There were 20 training observations in each of two classes. The\n",
    "observations within each class were uncorrelated random normal variables\n",
    "with a different mean in each class. The left-hand panel of Figure 4.11 shows\n",
    "that LDA performed well in this setting, as one would expect since this is\n",
    "the model assumed by LDA. Logistic regression also performed quite well,\n",
    "since it assumes a linear decision boundary. KNN performed poorly because\n",
    "it paid a price in terms of variance that was not offset by a reduction in bias.\n",
    "QDA also performed worse than LDA, since it fit a more flexible classifier\n",
    "than necessary. The performance of naive Bayes was slightly better than\n",
    "QDA, because the naive Bayes assumption of independent predictors is\n",
    "correct.\n",
    "\n",
    "Scenario 2: Details are as in Scenario 1, except that within each class, the\n",
    "two predictors had a correlation of 0.5. The center panel of Figure 4.11\n",
    "indicates that the performance of most methods is similar to the previ\n",
    "ous scenario. The notable exception is naive Bayes, which performs very\n",
    "poorly here, since the naive Bayes assumption of independent predictors is\n",
    "violated.\n",
    "\n",
    "Scenario 3: As in the previous scenario, there is substantial negative cor\n",
    "relation between the predictors within each class. However, this time we\n",
    "generated X1 and X2 from the t-distribution, with 50 observations per class.\n",
    "\n",
    "The t-distribution has a similar shape to the normal distribution, but it\n",
    "has a tendency to yield more extreme points—that is, more points that are\n",
    "far from the mean. In this setting, the decision boundary was still linear,\n",
    "and so fit into the logistic regression framework. The set-up violated the\n",
    "assumptions of LDA, since the observations were not drawn from a normal\n",
    "distribution. The right-hand panel of Figure 4.11 shows that logistic regres\n",
    "sion outperformed LDA, though both methods were superior to the other\n",
    "approaches. In particular, the QDA results deteriorated considerably as a\n",
    "consequence of non-normality. Naive Bayes performed very poorly because\n",
    "the independence assumption is violated.\n",
    "\n",
    "Scenario 4: The data were generated from a normal distribution, with a\n",
    "correlation of 0.5 between the predictors in the first class, and correlation of\n",
    "0.5 between the predictors in the second class. This setup corresponded to\n",
    "the QDA assumption, and resulted in quadratic decision boundaries. The\n",
    "left-hand panel of Figure 4.12 shows that QDA outperformed all of the other approaches. The naive Bayes assumption of independent predictors\n",
    "is violated, so naive Bayes performs poorly.\n",
    "\n",
    "Scenario 5: The data were generated from a normal distribution with un\n",
    "correlated predictors. Then the responses were sampled from the logistic\n",
    "function applied to a complicated non-linear function of the predictors. The\n",
    "center panel of Figure 4.12 shows that both QDA and naive Bayes gave\n",
    "slightly better results than the linear methods, while the much more flexi\n",
    "ble KNN-CV method gave the best results. But KNN with K =1gave the\n",
    "worst results out of all methods. This highlights the fact that even when the\n",
    "data exhibits a complex non-linear relationship, a non-parametric method\n",
    "such as KNN can still give poor results if the level of smoothness is not\n",
    "chosen correctly.\n",
    "\n",
    "Scenario 6: The observations were generated from a normal distribution\n",
    "with a different diagonal covariance matrix for each class. However, the\n",
    "sample size was very small: just n =6in each class. Naive Bayes performed\n",
    "very well, because its assumptions are met. LDA and logistic regression\n",
    "performed poorly because the true decision boundary is non-linear, due to\n",
    "the unequal covariance matrices. QDA performed a bit worse than naive\n",
    "Bayes, because given the very small sample size, the former incurred too\n",
    "much variance in estimating the correlation between the predictors within\n",
    "each class. KNN’s performance also suffered due to the very small sample\n",
    "size.\n",
    "\n",
    "These six examples illustrate that no one method will dominate the oth\n",
    "ers in every situation. When the true decision boundaries are linear, then\n",
    "the LDAandlogistic regression approaches will tend to perform well. When\n",
    "the boundaries are moderately non-linear, QDA or naive Bayes may give\n",
    "better results. Finally, for much more complicated decision boundaries, a\n",
    "non-parametric approach such as KNN can be superior. But the level of\n",
    "smoothness for a non-parametric approach must be chosen carefully. In the\n",
    "next chapter we examine a number of approaches for choosing the correct\n",
    "level of smoothness and, in general, for selecting the best overall method.\n",
    "\n",
    "Finally, recall from Chapter 3 that in the regression setting we can accom\n",
    "modate a non-linear relationship between the predictors and the response\n",
    "by performing regression using transformations of the predictors. A similar\n",
    "approach could be taken in the classification setting. For instance, we could and even X4 as predictors. This may or may not improve logistic regres\n",
    "sion’s performance, depending on whether the increase in variance due to\n",
    "the added flexibility is offset by a sufficiently large reduction in bias. We\n",
    "could do the same for LDA. If we added all possible quadratic terms and\n",
    "cross-products to LDA, the form of the model would be the same as the\n",
    "QDA model, although the parameter estimates would be different. This\n",
    "device allows us to move somewhere between an LDA and a QDA model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b324e8a1",
   "metadata": {},
   "source": [
    "#### Generalized Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3483332",
   "metadata": {},
   "source": [
    "In Chapter 3, we assumed that the response Y is quantitative, and ex\n",
    "plored the use of least squares linear regression to predict Y . Thus far in\n",
    "this chapter, we have instead assumed that Y is qualitative. However, we\n",
    "may sometimes be faced with situations in which Y is neither qualitative\n",
    "nor quantitative, and so neither linear regression from Chapter 3 nor the\n",
    "classification approaches covered in this chapter is applicable.\n",
    "As a concrete example, we consider the Bikeshare data set. The response\n",
    "is bikers, the number of hourly users of a bike sharing program in Wash\n",
    "ington, DC. This response value is neither qualitative nor quantitative:\n",
    "instead, it takes on non-negative integer values, or counts. We will consider counts\n",
    "predicting bikers using the covariates mnth (month of the year), hr (hour\n",
    "of the day, from 0 to 23), workingday (an indicator variable that equals 1 if\n",
    "it is neither a weekend nor a holiday), temp (the normalized temperature,\n",
    "in Celsius), and weathersit (a qualitative variable that takes on one of four\n",
    "possible values: clear; misty or cloudy; light rain or light snow; or heavy\n",
    "rain or heavy snow.)\n",
    "In the analyses that follow, we will treat mnth, hr, and weathersit as\n",
    "qualitative variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca11ad",
   "metadata": {},
   "source": [
    "##### Linear Regression on the Bikeshare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e51f9a0",
   "metadata": {},
   "source": [
    "To begin, we consider predicting bikers using linear regression. The results\n",
    "are shown in Table 4.10.\n",
    "We see, for example, that a progression of weather from clear to cloudy\n",
    "results in, on average, 12.89 fewer bikers per hour; however, if the weather\n",
    "progresses further to rain or snow, then this further results in 53.60 fewer\n",
    "bikers per hour. Figure 4.13 displays the coefficients associated with mnth and the coefficients associated with hr. We see that bike usage is highest in\n",
    "the spring and fall, and lowest during the winter months. Furthermore, bike\n",
    "usage is greatest around rush hour (9 AM and 6 PM), and lowest overnight.\n",
    "Thus, at first glance, fitting a linear regression model to the Bikeshare data\n",
    "set seems to provide reasonable and intuitive results.\n",
    "But upon more careful inspection, some issues become apparent. For\n",
    "example, 9.6% of the fitted values in the Bikeshare data set are negative:\n",
    "that is, the linear regression model predicts a negative number of users\n",
    "during 9.6% of the hours in the data set. This calls into question our ability\n",
    "to perform meaningful predictions on the data, and it also raises concerns\n",
    "about the accuracy of the coefficient estimates, confidence intervals, and\n",
    "other outputs of the regression model.\n",
    "Furthermore, it is reasonable to suspect that when the expected value\n",
    "of bikers is small, the variance of bikers should be small as well. For\n",
    "instance, at 2 AM during a heavy December snow storm, we expect that\n",
    "extremely few people will use a bike, and moreover that there should be\n",
    "little variance associated with the number of users during those conditions.\n",
    "This is borne out in the data: between 1 AM and 4 AM, in December,\n",
    "January, and February, when it is raining, there are 5.05 users, on average,\n",
    "with a standard deviation of 3.73. By contrast, between 7 AM and 10 AM,\n",
    "in April, May, and June, when skies are clear, there are 243.59 users, on\n",
    "average, with a standard deviation of 131.7. The mean-variance relationship\n",
    "is displayed in the left-hand panel of Figure 4.14. This is a major violation\n",
    "of the assumptions of a linear model, which state that Y = p\n",
    "j=1Xj j + ,\n",
    "where is a mean-zero error term with variance 2 that is constant, and\n",
    "not a function of the covariates. Therefore, the heteroscedasticity of the\n",
    "data calls into question the suitability of a linear regression model.\n",
    "Finally, the response bikers is integer-valued. But under a linear model,\n",
    "Y = 0+ p\n",
    "j=1Xj j+ , where is a continuous-valued error term. This\n",
    "means that in a linear model, the response Y is necessarily continuous\n",
    "valued (quantitative). Thus, the integer nature of the response bikers sug\n",
    "gests that a linear regression model is not entirely satisfactory for this data\n",
    "set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef672fa",
   "metadata": {},
   "source": [
    "Someof theproblemsthatarisewhenfittingalinearregressionmodel\n",
    "totheBikesharedatacanbeovercomebytransformingtheresponse; for\n",
    "instance,wecanfitthemodel\n",
    "log(Y)=\n",
    "p\n",
    "j=1\n",
    "Xj j+ .\n",
    "Transformingthe responseavoids thepossibilityof negativepredictions,\n",
    "anditovercomesmuchoftheheteroscedasticityintheuntransformeddata,\n",
    "asisshownintheright-handpanelofFigure4.14.However, itisnotquite\n",
    "asatisfactorysolution,sincepredictionsandinferencearemadeintermsof\n",
    "thelogoftheresponse, ratherthantheresponse.This leadstochallenges\n",
    "in interpretation, e.g. “a one-unit increase inXj is associatedwith an\n",
    "increase in themeanof the logof Y byanamount j”.Furthermore, a\n",
    "logtransformationoftheresponsecannotbeappliedinsettingswherethe\n",
    "responsecantakeonavalueof 0.Thus,whilefittinga linearmodel to\n",
    "atransformationof theresponsemaybeanadequateapproachfor some\n",
    "count-valueddatasets, itoftenleavessomethingtobedesired.Wewillsee\n",
    "inthenextsectionthataPoissonregressionmodelprovidesamuchmore\n",
    "naturalandelegantapproachforthistask.\n",
    "4.6.2 PoissonRegressionontheBikeshareData\n",
    "ToovercometheinadequaciesoflinearregressionforanalyzingtheBikeshare\n",
    "data set, wewillmake use of an alternative approach, calledPoisson\n",
    "regression.BeforewecantalkaboutPoissonregression,wemustfirst in-Poisson\n",
    "regression troducethePoissondistribution.\n",
    "Poisson\n",
    "distribution\n",
    "SupposethatarandomvariableY takesonnonnegativeintegervalues,\n",
    "i.e.Y {0,1,2,...}. IfY followsthePoissondistribution,then\n",
    "Pr(Y=k)=e k\n",
    "k! fork=0,1,2,.... (4.35)\n",
    "Here, > 0 is the expected value of Y, i.e. E(Y). It turns out that also\n",
    "equals the variance of Y , i.e. = E(Y) = Var(Y). This means that if Y\n",
    "follows the Poisson distribution, then the larger the mean of Y , the larger\n",
    "its variance. (In (4.35), the notation k!, pronounced “k factorial”, is defined\n",
    "as k!=k (k 1) (k 2) ... 3 2 1.)\n",
    "The Poisson distribution is typically used to model counts; this is a nat\n",
    "ural choice for a number of reasons, including the fact that counts, like\n",
    "the Poisson distribution, take on nonnegative integer values. To see how\n",
    "we might use the Poisson distribution in practice, let Y denote the num\n",
    "ber of users of the bike sharing program during a particular hour of the\n",
    "day, under a particular set of weather conditions, and during a particu\n",
    "lar month of the year. We might model Y as a Poisson distribution with\n",
    "mean E(Y)= =5.This means that the probability of no users dur\n",
    "ing this particular hour is Pr(Y = 0) = e 550\n",
    "0!\n",
    "= e 5 =0.0067 (where\n",
    "0! = 1 by convention). The probability that there is exactly one user\n",
    "is Pr(Y = 1) = e 551\n",
    "1!\n",
    "Pr(Y = 2) = e 552\n",
    "2!\n",
    "=5e 5 =0.034, the probability of two users is\n",
    "=0.084, and so on.\n",
    "Of course, in reality, we expect the mean number of users of the bike\n",
    "sharing program, = E(Y), to vary as a function of the hour of the day,\n",
    "the month of the year, the weather conditions, and so forth. So rather\n",
    "than modeling the number of bikers, Y, as a Poisson distribution with a\n",
    "f\n",
    "ixed mean value like =5, we would like to allow the mean to vary as a\n",
    "function of the covariates. In particular, we consider the following model\n",
    "for the mean = E(Y), which we now write as (X1,...,Xp) to emphasize\n",
    "that it is a function of the covariates X1,...,Xp:\n",
    "log( (X1,...,Xp)) = 0 + 1X1 +···+ pXp\n",
    "or equivalently\n",
    "(X1,...,Xp)=e 0+1X1+···+pXp.\n",
    "(4.36)\n",
    "(4.37)\n",
    "Here, 0, 1,..., p are parameters to be estimated. Together, (4.35) and\n",
    "(4.36) define the Poisson regression model. Notice that in (4.36), we take\n",
    "the log of (X1,...,Xp) to be linear in X1,...,Xp, rather than having\n",
    "(X1,...,Xp) itself be linear in X1,...,Xp; this ensures that (X1,...,Xp)\n",
    "takes on nonnegative values for all values of the covariates.\n",
    "To estimate the coefficients 0, 1,..., p, we use the same maximum\n",
    "likelihood approach that we adopted for logistic regression in Section 4.3.2.\n",
    "Specifically, given n independent observations from the Poisson regression\n",
    "model, the likelihood takes the form\n",
    "n\n",
    "( 0, 1,..., p)=\n",
    "i=1\n",
    "e (xi) (xi)yi\n",
    "yi!\n",
    ",\n",
    "(4.38)\n",
    "where (xi)=e 0+1xi1+···+pxip, due to (4.37). We estimate the coef\n",
    "f\n",
    "icients that maximize the likelihood ( 0, 1,..., p), i.e. that make the\n",
    "observed data as likely as possible.\n",
    "We now fit a Poisson regression model to the Bikeshare data set. The\n",
    "results are shown in Table 4.11 and Figure 4.15. Qualitatively, the results\n",
    "are similar to those from linear regression in Section 4.6.1. We again see\n",
    "that bike usage is highest in the spring and fall and during rush hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d9d6d0",
   "metadata": {},
   "source": [
    "and lowest during the winter and in the early morning hours. Moreover,\n",
    "bike usage increases as the temperature increases, and decreases as the\n",
    "weather worsens. Interestingly, the coefficient associated with workingday\n",
    "is statistically significant under the Poisson regression model, but not under\n",
    "the linear regression model.\n",
    "Some important distinctions between the Poisson regression model and\n",
    "the linear regression model are as follows:\n",
    "• Interpretation: To interpret the coefficients in the Poisson regression\n",
    "model, we must pay close attention to (4.37), which states that an\n",
    "increase in Xj by one unit is associated with a change in E(Y )=\n",
    "by a factor of exp( j). For example, a change in weather from clear\n",
    "to cloudy skies is associated with a change in mean bike usage by a\n",
    "factor of exp( 0.08) = 0.923, i.e. on average, only 92.3% as many\n",
    "people will use bikes when it is cloudy relative to when it is clear.\n",
    "If the weather worsens further and it begins to rain, then the mean\n",
    "bike usage will further change by a factor of exp( 0.5) = 0.607, i.e.\n",
    "on average only 60.7% as many people will use bikes when it is rainy\n",
    "relative to when it is cloudy\n",
    "\n",
    "• Mean-variance relationship: As mentioned earlier, under the Poisson\n",
    "model, = E(Y) = Var(Y). Thus, by modeling bike usage with a\n",
    "Poisson regression, we implicitly assume that mean bike usage in a\n",
    "given hour equals the variance of bike usage during that hour. By\n",
    "contrast, under a linear regression model, the variance of bike usage\n",
    "always takes on a constant value. Recall from Figure 4.14 that in the\n",
    "Bikeshare data, when biking conditions are favorable, both the mean\n",
    "and the variance in bike usage are much higher than when conditions\n",
    "are unfavorable. Thus, the Poisson regression model is able to handle\n",
    "the mean-variance relationship seen in the Bikeshare data in a way\n",
    "that the linear regression model is not.5\n",
    "• nonnegative fitted values: There are no negative predictions using the\n",
    "Poisson regression model. This is because the Poisson model itself\n",
    "only allows for nonnegative values; see (4.35). By contrast, when we\n",
    "f\n",
    "it a linear regression model to the Bikeshare data set, almost 10% of\n",
    "the predictions were negative.\n",
    "4.6.3 Generalized Linear Models in Greater Generality\n",
    "Wehave now discussed three types of regression models: linear, logistic and\n",
    "Poisson. These approaches share some common characteristics:\n",
    "1. Each approach uses predictors X1,...,Xp to predict a response Y .\n",
    "We assume that, conditional on X1,...,Xp, Y belongs to a certain\n",
    "family of distributions. For linear regression, we typically assume that\n",
    "Y follows a Gaussian or normal distribution. For logistic regression,\n",
    "we assume that Y follows a Bernoulli distribution. Finally, for Poisson\n",
    "regression, we assume that Y follows a Poisson distribution.\n",
    "2. Each approach models the mean of Y as a function of the predictors.\n",
    "In linear regression, the mean of Y takes the form\n",
    "E(Y |X1,...,Xp)= 0 + 1X1 +···+ pXp,\n",
    "(4.39)\n",
    "i.e. it is a linear function of the predictors. For logistic regression, the\n",
    "mean instead takes the form\n",
    "E(Y |X1,...,Xp) = Pr(Y =1|X1,...,Xp)\n",
    "= e 0+1X1+···+pXp\n",
    "1+e 0+1X1+···+pXp\n",
    ",\n",
    "while for Poisson regression it takes the form\n",
    "(4.40)\n",
    "E(Y |X1,...,Xp)= (X1,...,Xp)=e 0+1X1+···+pXp. (4.41)\n",
    "overdispersion\n",
    "Equations (4.39)–(4.41) can be expressed using a link function, , which applies a transformation to E(Y |X1,...,Xp) so that the transformed mean\n",
    "is a linear function of the predictors. That is,\n",
    "(E(Y |X1,...,Xp)) = 0 + 1X1 +···+ pXp.\n",
    "(4.42)\n",
    "The link functions for linear, logistic and Poisson regression are (µ)=µ,\n",
    "(µ) = log(µ/(1 µ)), and (µ) = log(µ), respectively.\n",
    "The Gaussian, Bernoulli and Poisson distributions are all members of a\n",
    "wider class of distributions, known as the exponential family. Other well- exponential\n",
    "known members of this family are the exponential distribution, the Gamma\n",
    "distribution, and the negative binomial distribution. In general, we can per\n",
    "form a regression by modeling the response Y as coming from a particular\n",
    "member of the exponential family, and then transforming the mean of the\n",
    "response so that the transformed mean is a linear function of the predictors\n",
    "via (4.42). Any regression approach that follows this very general recipe is\n",
    "family\n",
    "exponential\n",
    "Gamma\n",
    "negative\n",
    "binomial\n",
    "known as a generalized linear model (GLM). Thus, linear regression, logistic generalized\n",
    "regression, and Poisson regression are three examples of GLMs. Other ex\n",
    "amples not covered here include Gamma regression and negative binomial\n",
    "regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4654c2b4",
   "metadata": {},
   "source": [
    "####  Lab: Logistic Regression, LDA, QDA, and KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdea757",
   "metadata": {},
   "source": [
    "##### The Stock Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f4fdf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b072280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f78d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aad5030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42808938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e38713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc05f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP.models import (ModelSpec as MS, summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d6a9cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP import confusion_table\n",
    "from ISLP.models import contrast\n",
    "from sklearn.discriminant_analysis import \\\n",
    "    (LinearDiscriminantAnalysis as LDA, \n",
    "     QuadraticDiscriminantAnalysis as QDA)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d94c6f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b6cada2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lag2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lag3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lag4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lag5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Today",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Direction",
         "rawType": "category",
         "type": "unknown"
        }
       ],
       "ref": "44129e44-6727-46ad-a770-9d8c369d0301",
       "rows": [
        [
         "0",
         "2001",
         "0.381",
         "-0.192",
         "-2.624",
         "-1.055",
         "5.01",
         "1.1913",
         "0.959",
         "Up"
        ],
        [
         "1",
         "2001",
         "0.959",
         "0.381",
         "-0.192",
         "-2.624",
         "-1.055",
         "1.2965",
         "1.032",
         "Up"
        ],
        [
         "2",
         "2001",
         "1.032",
         "0.959",
         "0.381",
         "-0.192",
         "-2.624",
         "1.4112",
         "-0.623",
         "Down"
        ],
        [
         "3",
         "2001",
         "-0.623",
         "1.032",
         "0.959",
         "0.381",
         "-0.192",
         "1.276",
         "0.614",
         "Up"
        ],
        [
         "4",
         "2001",
         "0.614",
         "-0.623",
         "1.032",
         "0.959",
         "0.381",
         "1.2057",
         "0.213",
         "Up"
        ],
        [
         "5",
         "2001",
         "0.213",
         "0.614",
         "-0.623",
         "1.032",
         "0.959",
         "1.3491",
         "1.392",
         "Up"
        ],
        [
         "6",
         "2001",
         "1.392",
         "0.213",
         "0.614",
         "-0.623",
         "1.032",
         "1.445",
         "-0.4029999999999999",
         "Down"
        ],
        [
         "7",
         "2001",
         "-0.4029999999999999",
         "1.392",
         "0.213",
         "0.614",
         "-0.623",
         "1.4078",
         "0.027",
         "Up"
        ],
        [
         "8",
         "2001",
         "0.027",
         "-0.4029999999999999",
         "1.392",
         "0.213",
         "0.614",
         "1.164",
         "1.3030000000000002",
         "Up"
        ],
        [
         "9",
         "2001",
         "1.3030000000000002",
         "0.027",
         "-0.4029999999999999",
         "1.392",
         "0.213",
         "1.2326",
         "0.287",
         "Up"
        ],
        [
         "10",
         "2001",
         "0.287",
         "1.3030000000000002",
         "0.027",
         "-0.4029999999999999",
         "1.392",
         "1.3090000000000002",
         "-0.498",
         "Down"
        ],
        [
         "11",
         "2001",
         "-0.498",
         "0.287",
         "1.3030000000000002",
         "0.027",
         "-0.4029999999999999",
         "1.258",
         "-0.1889999999999999",
         "Down"
        ],
        [
         "12",
         "2001",
         "-0.1889999999999999",
         "-0.498",
         "0.287",
         "1.3030000000000002",
         "0.027",
         "1.098",
         "0.68",
         "Up"
        ],
        [
         "13",
         "2001",
         "0.68",
         "-0.1889999999999999",
         "-0.498",
         "0.287",
         "1.3030000000000002",
         "1.0531",
         "0.701",
         "Up"
        ],
        [
         "14",
         "2001",
         "0.701",
         "0.68",
         "-0.1889999999999999",
         "-0.498",
         "0.287",
         "1.1498",
         "-0.562",
         "Down"
        ],
        [
         "15",
         "2001",
         "-0.562",
         "0.701",
         "0.68",
         "-0.1889999999999999",
         "-0.498",
         "1.2953",
         "0.546",
         "Up"
        ],
        [
         "16",
         "2001",
         "0.546",
         "-0.562",
         "0.701",
         "0.68",
         "-0.1889999999999999",
         "1.1188",
         "-1.747",
         "Down"
        ],
        [
         "17",
         "2001",
         "-1.747",
         "0.546",
         "-0.562",
         "0.701",
         "0.68",
         "1.0484",
         "0.359",
         "Up"
        ],
        [
         "18",
         "2001",
         "0.359",
         "-1.747",
         "0.546",
         "-0.562",
         "0.701",
         "1.013",
         "-0.151",
         "Down"
        ],
        [
         "19",
         "2001",
         "-0.151",
         "0.359",
         "-1.747",
         "0.546",
         "-0.562",
         "1.0596",
         "-0.841",
         "Down"
        ],
        [
         "20",
         "2001",
         "-0.841",
         "-0.151",
         "0.359",
         "-1.747",
         "0.546",
         "1.1583",
         "-0.623",
         "Down"
        ],
        [
         "21",
         "2001",
         "-0.623",
         "-0.841",
         "-0.151",
         "0.359",
         "-1.747",
         "1.1072",
         "-1.334",
         "Down"
        ],
        [
         "22",
         "2001",
         "-1.334",
         "-0.623",
         "-0.841",
         "-0.151",
         "0.359",
         "1.0755",
         "1.183",
         "Up"
        ],
        [
         "23",
         "2001",
         "1.183",
         "-1.334",
         "-0.623",
         "-0.841",
         "-0.151",
         "1.0391",
         "-0.865",
         "Down"
        ],
        [
         "24",
         "2001",
         "-0.865",
         "1.183",
         "-1.334",
         "-0.623",
         "-0.841",
         "1.0752",
         "-0.218",
         "Down"
        ],
        [
         "25",
         "2001",
         "-0.218",
         "-0.865",
         "1.183",
         "-1.334",
         "-0.623",
         "1.1503",
         "0.812",
         "Up"
        ],
        [
         "26",
         "2001",
         "0.812",
         "-0.218",
         "-0.865",
         "1.183",
         "-1.334",
         "1.1537",
         "-1.891",
         "Down"
        ],
        [
         "27",
         "2001",
         "-1.891",
         "0.812",
         "-0.218",
         "-0.865",
         "1.183",
         "1.2572",
         "-1.736",
         "Down"
        ],
        [
         "28",
         "2001",
         "-1.736",
         "-1.891",
         "0.812",
         "-0.218",
         "-0.865",
         "1.1122",
         "-1.851",
         "Down"
        ],
        [
         "29",
         "2001",
         "-1.851",
         "-1.736",
         "-1.891",
         "0.812",
         "-0.218",
         "1.2085",
         "-0.195",
         "Down"
        ],
        [
         "30",
         "2001",
         "-0.195",
         "-1.851",
         "-1.736",
         "-1.891",
         "0.812",
         "1.3659",
         "-0.556",
         "Down"
        ],
        [
         "31",
         "2001",
         "-0.556",
         "-0.195",
         "-1.851",
         "-1.736",
         "-1.891",
         "1.2313",
         "1.749",
         "Up"
        ],
        [
         "32",
         "2001",
         "1.749",
         "-0.556",
         "-0.195",
         "-1.851",
         "-1.736",
         "1.1308",
         "-0.7659999999999999",
         "Down"
        ],
        [
         "33",
         "2001",
         "-0.7659999999999999",
         "1.749",
         "-0.556",
         "-0.195",
         "-1.851",
         "1.1141",
         "-1.431",
         "Down"
        ],
        [
         "34",
         "2001",
         "-1.431",
         "-0.7659999999999999",
         "1.749",
         "-0.556",
         "-0.195",
         "1.2253",
         "0.104",
         "Up"
        ],
        [
         "35",
         "2001",
         "0.104",
         "-1.431",
         "-0.7659999999999999",
         "1.749",
         "-0.556",
         "1.2949",
         "-0.568",
         "Down"
        ],
        [
         "36",
         "2001",
         "-0.568",
         "0.104",
         "-1.431",
         "-0.7659999999999999",
         "1.749",
         "1.294",
         "0.586",
         "Up"
        ],
        [
         "37",
         "2001",
         "0.586",
         "-0.568",
         "0.104",
         "-1.431",
         "-0.7659999999999999",
         "0.9292",
         "0.998",
         "Up"
        ],
        [
         "38",
         "2001",
         "0.998",
         "0.586",
         "-0.568",
         "0.104",
         "-1.431",
         "1.0918",
         "0.645",
         "Up"
        ],
        [
         "39",
         "2001",
         "0.645",
         "0.998",
         "0.586",
         "-0.568",
         "0.104",
         "1.1322",
         "0.226",
         "Up"
        ],
        [
         "40",
         "2001",
         "0.226",
         "0.645",
         "0.998",
         "0.586",
         "-0.568",
         "1.1141",
         "-2.476",
         "Down"
        ],
        [
         "41",
         "2001",
         "-2.476",
         "0.226",
         "0.645",
         "0.998",
         "0.586",
         "1.0859",
         "-4.3180000000000005",
         "Down"
        ],
        [
         "42",
         "2001",
         "-4.3180000000000005",
         "-2.476",
         "0.226",
         "0.645",
         "0.998",
         "1.229",
         "1.483",
         "Up"
        ],
        [
         "43",
         "2001",
         "1.483",
         "-4.3180000000000005",
         "-2.476",
         "0.226",
         "0.645",
         "1.3609",
         "-2.584",
         "Down"
        ],
        [
         "44",
         "2001",
         "-2.584",
         "1.483",
         "-4.3180000000000005",
         "-2.476",
         "0.226",
         "1.3974",
         "0.5870000000000001",
         "Up"
        ],
        [
         "45",
         "2001",
         "0.5870000000000001",
         "-2.584",
         "1.483",
         "-4.3180000000000005",
         "-2.476",
         "1.2595",
         "-1.962",
         "Down"
        ],
        [
         "46",
         "2001",
         "-1.962",
         "0.5870000000000001",
         "-2.584",
         "1.483",
         "-4.3180000000000005",
         "1.54356",
         "1.763",
         "Up"
        ],
        [
         "47",
         "2001",
         "1.763",
         "-1.962",
         "0.5870000000000001",
         "-2.584",
         "1.483",
         "1.1262",
         "-2.408",
         "Down"
        ],
        [
         "48",
         "2001",
         "-2.408",
         "1.763",
         "-1.962",
         "0.5870000000000001",
         "-2.584",
         "1.2359",
         "-1.7919999999999998",
         "Down"
        ],
        [
         "49",
         "2001",
         "-1.7919999999999998",
         "-2.408",
         "1.763",
         "-1.962",
         "0.5870000000000001",
         "1.3463",
         "-0.406",
         "Down"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 1250
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>5.010</td>\n",
       "      <td>1.19130</td>\n",
       "      <td>0.959</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>1.29650</td>\n",
       "      <td>1.032</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>1.41120</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>1.27600</td>\n",
       "      <td>0.614</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.20570</td>\n",
       "      <td>0.213</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>2005</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>1.88850</td>\n",
       "      <td>0.043</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>2005</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>1.28581</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>2005</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>1.54047</td>\n",
       "      <td>0.130</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>2005</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.252</td>\n",
       "      <td>1.42236</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>2005</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1.38254</td>\n",
       "      <td>-0.489</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year   Lag1   Lag2   Lag3   Lag4   Lag5   Volume  Today Direction\n",
       "0     2001  0.381 -0.192 -2.624 -1.055  5.010  1.19130  0.959        Up\n",
       "1     2001  0.959  0.381 -0.192 -2.624 -1.055  1.29650  1.032        Up\n",
       "2     2001  1.032  0.959  0.381 -0.192 -2.624  1.41120 -0.623      Down\n",
       "3     2001 -0.623  1.032  0.959  0.381 -0.192  1.27600  0.614        Up\n",
       "4     2001  0.614 -0.623  1.032  0.959  0.381  1.20570  0.213        Up\n",
       "...    ...    ...    ...    ...    ...    ...      ...    ...       ...\n",
       "1245  2005  0.422  0.252 -0.024 -0.584 -0.285  1.88850  0.043        Up\n",
       "1246  2005  0.043  0.422  0.252 -0.024 -0.584  1.28581 -0.955      Down\n",
       "1247  2005 -0.955  0.043  0.422  0.252 -0.024  1.54047  0.130        Up\n",
       "1248  2005  0.130 -0.955  0.043  0.422  0.252  1.42236 -0.298      Down\n",
       "1249  2005 -0.298  0.130 -0.955  0.043  0.422  1.38254 -0.489      Down\n",
       "\n",
       "[1250 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Smarket = load_data('Smarket')\n",
    "Smarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1271d3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume', 'Today',\n",
       "       'Direction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Smarket.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7a7b7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lag2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lag3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lag4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lag5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Today",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "af8a78ca-b62e-48b0-a432-c767995dca37",
       "rows": [
        [
         "Year",
         "1.0",
         "0.02969964893366154",
         "0.030596421946722827",
         "0.03319458113126754",
         "0.03568871750417519",
         "0.029787994691551026",
         "0.5390064661397674",
         "0.03009522892855877"
        ],
        [
         "Lag1",
         "0.02969964893366154",
         "1.0",
         "-0.026294328149736822",
         "-0.010803401704898335",
         "-0.0029859106997225256",
         "-0.005674606238866534",
         "0.04090990806740808",
         "-0.02615504543244527"
        ],
        [
         "Lag2",
         "0.030596421946722827",
         "-0.026294328149736822",
         "1.0",
         "-0.025896669813363752",
         "-0.010853533001405208",
         "-0.0035579494775570502",
         "-0.043383214641792386",
         "-0.010250033403228408"
        ],
        [
         "Lag3",
         "0.03319458113126754",
         "-0.010803401704898335",
         "-0.025896669813363752",
         "1.0",
         "-0.024051036377459766",
         "-0.01880833758214213",
         "-0.04182368627531741",
         "-0.002447647116524297"
        ],
        [
         "Lag4",
         "0.03568871750417519",
         "-0.0029859106997225256",
         "-0.010853533001405208",
         "-0.024051036377459766",
         "1.0",
         "-0.027083640769007516",
         "-0.048414246239615454",
         "-0.006899526938247343"
        ],
        [
         "Lag5",
         "0.029787994691551026",
         "-0.005674606238866534",
         "-0.0035579494775570502",
         "-0.01880833758214213",
         "-0.027083640769007516",
         "1.0",
         "-0.022002314871805748",
         "-0.03486008278727016"
        ],
        [
         "Volume",
         "0.5390064661397674",
         "0.04090990806740808",
         "-0.043383214641792386",
         "-0.04182368627531741",
         "-0.048414246239615454",
         "-0.022002314871805748",
         "1.0",
         "0.0145918232591566"
        ],
        [
         "Today",
         "0.03009522892855877",
         "-0.02615504543244527",
         "-0.010250033403228408",
         "-0.002447647116524297",
         "-0.006899526938247343",
         "-0.03486008278727016",
         "0.0145918232591566",
         "1.0"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.030596</td>\n",
       "      <td>0.033195</td>\n",
       "      <td>0.035689</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.539006</td>\n",
       "      <td>0.030095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag1</th>\n",
       "      <td>0.029700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026294</td>\n",
       "      <td>-0.010803</td>\n",
       "      <td>-0.002986</td>\n",
       "      <td>-0.005675</td>\n",
       "      <td>0.040910</td>\n",
       "      <td>-0.026155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag2</th>\n",
       "      <td>0.030596</td>\n",
       "      <td>-0.026294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025897</td>\n",
       "      <td>-0.010854</td>\n",
       "      <td>-0.003558</td>\n",
       "      <td>-0.043383</td>\n",
       "      <td>-0.010250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag3</th>\n",
       "      <td>0.033195</td>\n",
       "      <td>-0.010803</td>\n",
       "      <td>-0.025897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.024051</td>\n",
       "      <td>-0.018808</td>\n",
       "      <td>-0.041824</td>\n",
       "      <td>-0.002448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag4</th>\n",
       "      <td>0.035689</td>\n",
       "      <td>-0.002986</td>\n",
       "      <td>-0.010854</td>\n",
       "      <td>-0.024051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.027084</td>\n",
       "      <td>-0.048414</td>\n",
       "      <td>-0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag5</th>\n",
       "      <td>0.029788</td>\n",
       "      <td>-0.005675</td>\n",
       "      <td>-0.003558</td>\n",
       "      <td>-0.018808</td>\n",
       "      <td>-0.027084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.022002</td>\n",
       "      <td>-0.034860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>0.539006</td>\n",
       "      <td>0.040910</td>\n",
       "      <td>-0.043383</td>\n",
       "      <td>-0.041824</td>\n",
       "      <td>-0.048414</td>\n",
       "      <td>-0.022002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Today</th>\n",
       "      <td>0.030095</td>\n",
       "      <td>-0.026155</td>\n",
       "      <td>-0.010250</td>\n",
       "      <td>-0.002448</td>\n",
       "      <td>-0.006900</td>\n",
       "      <td>-0.034860</td>\n",
       "      <td>0.014592</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Year      Lag1      Lag2      Lag3      Lag4      Lag5    Volume  \\\n",
       "Year    1.000000  0.029700  0.030596  0.033195  0.035689  0.029788  0.539006   \n",
       "Lag1    0.029700  1.000000 -0.026294 -0.010803 -0.002986 -0.005675  0.040910   \n",
       "Lag2    0.030596 -0.026294  1.000000 -0.025897 -0.010854 -0.003558 -0.043383   \n",
       "Lag3    0.033195 -0.010803 -0.025897  1.000000 -0.024051 -0.018808 -0.041824   \n",
       "Lag4    0.035689 -0.002986 -0.010854 -0.024051  1.000000 -0.027084 -0.048414   \n",
       "Lag5    0.029788 -0.005675 -0.003558 -0.018808 -0.027084  1.000000 -0.022002   \n",
       "Volume  0.539006  0.040910 -0.043383 -0.041824 -0.048414 -0.022002  1.000000   \n",
       "Today   0.030095 -0.026155 -0.010250 -0.002448 -0.006900 -0.034860  0.014592   \n",
       "\n",
       "           Today  \n",
       "Year    0.030095  \n",
       "Lag1   -0.026155  \n",
       "Lag2   -0.010250  \n",
       "Lag3   -0.002448  \n",
       "Lag4   -0.006900  \n",
       "Lag5   -0.034860  \n",
       "Volume  0.014592  \n",
       "Today   1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Smarket.select_dtypes(include=[np.number]).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07d0ae01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Smarket.plot(y='Volume');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b15e9",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5d792f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "coef",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "std err",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "z",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "P>|z|",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "53656ea3-a20f-40ba-81fa-38eb1a33edb5",
       "rows": [
        [
         "intercept",
         "-0.126",
         "0.241",
         "-0.523",
         "0.601"
        ],
        [
         "Lag1",
         "-0.0731",
         "0.05",
         "-1.457",
         "0.145"
        ],
        [
         "Lag2",
         "-0.0423",
         "0.05",
         "-0.845",
         "0.398"
        ],
        [
         "Lag3",
         "0.0111",
         "0.05",
         "0.222",
         "0.824"
        ],
        [
         "Lag4",
         "0.0094",
         "0.05",
         "0.187",
         "0.851"
        ],
        [
         "Lag5",
         "0.0103",
         "0.05",
         "0.208",
         "0.835"
        ],
        [
         "Volume",
         "0.1354",
         "0.158",
         "0.855",
         "0.392"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>-0.1260</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag1</th>\n",
       "      <td>-0.0731</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-1.457</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag2</th>\n",
       "      <td>-0.0423</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag3</th>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag4</th>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag5</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef  std err      z  P>|z|\n",
       "intercept -0.1260    0.241 -0.523  0.601\n",
       "Lag1      -0.0731    0.050 -1.457  0.145\n",
       "Lag2      -0.0423    0.050 -0.845  0.398\n",
       "Lag3       0.0111    0.050  0.222  0.824\n",
       "Lag4       0.0094    0.050  0.187  0.851\n",
       "Lag5       0.0103    0.050  0.208  0.835\n",
       "Volume     0.1354    0.158  0.855  0.392"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allvars = Smarket.columns.drop(['Today', 'Direction', 'Year'])\n",
    "design = MS(allvars)\n",
    "X = design.fit_transform(Smarket)\n",
    "y = Smarket.Direction == 'Up'\n",
    "glm = sm.GLM(y,\n",
    "             X,\n",
    "             family=sm.families.Binomial())\n",
    "results = glm.fit()\n",
    "summarize(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a26c6a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "e92a8fd0-f8fe-4f76-a111-e3b56b4e9831",
       "rows": [
        [
         "intercept",
         "-0.12600025890602876"
        ],
        [
         "Lag1",
         "-0.07307374700210044"
        ],
        [
         "Lag2",
         "-0.04230134472928433"
        ],
        [
         "Lag3",
         "0.011085108239685193"
        ],
        [
         "Lag4",
         "0.009358938342130984"
        ],
        [
         "Lag5",
         "0.010313068515485972"
        ],
        [
         "Volume",
         "0.13544066079529946"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 7
       }
      },
      "text/plain": [
       "intercept   -0.126000\n",
       "Lag1        -0.073074\n",
       "Lag2        -0.042301\n",
       "Lag3         0.011085\n",
       "Lag4         0.009359\n",
       "Lag5         0.010313\n",
       "Volume       0.135441\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e5cddb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "52fcefa6-01d4-4d81-96f9-0d6c78080762",
       "rows": [
        [
         "intercept",
         "0.6007003960493587"
        ],
        [
         "Lag1",
         "0.14523155718601138"
        ],
        [
         "Lag2",
         "0.39835233468292164"
        ],
        [
         "Lag3",
         "0.824334203796644"
        ],
        [
         "Lag4",
         "0.8514454089899393"
        ],
        [
         "Lag5",
         "0.8349982312925964"
        ],
        [
         "Volume",
         "0.3924037071231441"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 7
       }
      },
      "text/plain": [
       "intercept    0.600700\n",
       "Lag1         0.145232\n",
       "Lag2         0.398352\n",
       "Lag3         0.824334\n",
       "Lag4         0.851445\n",
       "Lag5         0.834998\n",
       "Volume       0.392404\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ea68cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50708413, 0.48146788, 0.48113883, 0.51522236, 0.51078116,\n",
       "       0.50695646, 0.49265087, 0.50922916, 0.51761353, 0.48883778])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = results.predict()\n",
    "probs[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04edd99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(['Down']*1250)\n",
    "labels[probs>0.5] = \"Up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e614e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Predicted",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Down",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Up",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "c77fe219-891e-4fc3-b7c9-5affc9dfffe0",
       "rows": [
        [
         "Down",
         "145",
         "141"
        ],
        [
         "Up",
         "457",
         "507"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>Down</th>\n",
       "      <th>Up</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Down</th>\n",
       "      <td>145</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Up</th>\n",
       "      <td>457</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth      Down   Up\n",
       "Predicted           \n",
       "Down        145  141\n",
       "Up          457  507"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_table(labels, Smarket.Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "851caaad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5216, 0.5216)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(507+145)/1250, np.mean(labels == Smarket.Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7b30984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = (Smarket.Year < 2005)\n",
    "Smarket_train = Smarket.loc[train]\n",
    "Smarket_test = Smarket.loc[ train]\n",
    "Smarket_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed94df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X.loc[train], X.loc[ train]\n",
    "y_train, y_test = y.loc[train], y.loc[ train]\n",
    "\n",
    "glm_train = sm.GLM(y_train,\n",
    "                   X_train,\n",
    "                   family=sm.families.Binomial())\n",
    "results = glm_train.fit()\n",
    "probs = results.predict(exog=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3273285",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Smarket.Direction\n",
    "L_train, L_test = D.loc[train], D.loc[ train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2827680e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Predicted",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Down",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Up",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2301b179-a39b-4d94-baf2-4919fb3de54e",
       "rows": [
        [
         "Down",
         "175",
         "156"
        ],
        [
         "Up",
         "316",
         "351"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>Down</th>\n",
       "      <th>Up</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Down</th>\n",
       "      <td>175</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Up</th>\n",
       "      <td>316</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth      Down   Up\n",
       "Predicted           \n",
       "Down        175  156\n",
       "Up          316  351"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array(['Down']*998)\n",
    "labels[probs>0.5] = 'Up'\n",
    "confusion_table(labels, L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43b2d3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5270541082164328, 0.4729458917835671)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(labels == L_test), np.mean(labels != L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4df22d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Predicted",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Down",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Up",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "a15bd309-e4f8-4aec-a6b7-7edd1ecfcc2e",
       "rows": [
        [
         "Down",
         "168",
         "160"
        ],
        [
         "Up",
         "323",
         "347"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>Down</th>\n",
       "      <th>Up</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Down</th>\n",
       "      <td>168</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Up</th>\n",
       "      <td>323</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth      Down   Up\n",
       "Predicted           \n",
       "Down        168  160\n",
       "Up          323  347"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MS(['Lag1', 'Lag2']).fit(Smarket)\n",
    "X = model.transform(Smarket)\n",
    "X_train, X_test = X.loc[train], X.loc[ train]\n",
    "glm_train = sm.GLM(y_train,\n",
    "                   X_train,\n",
    "                   family=sm.families.Binomial())\n",
    "results = glm_train.fit()\n",
    "probs = results.predict(exog=X_test)\n",
    "labels = np.array(['Down']*998)\n",
    "labels[probs>0.5] = 'Up'\n",
    "confusion_table(labels, L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad7b9f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5595238095238095, 0.5824175824175825)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(35+106)/252,106/(106+76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e68067a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c711a47d-22f7-409f-b4ba-7149fd7b6531",
       "rows": [
        [
         "0",
         "0.47914623911039295"
        ],
        [
         "1",
         "0.4960938729355764"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "0    0.479146\n",
       "1    0.496094\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata = pd.DataFrame({'Lag1':[1.2, 1.5],\n",
    "                        'Lag2':[1.1,-0.8]});\n",
    "newX = model.transform(newdata)\n",
    "results.predict(newX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88400bd9",
   "metadata": {},
   "source": [
    "#####  Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd90eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(store_covariance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48941d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis(store_covariance=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearDiscriminantAnalysis</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html\">?<span>Documentation for LinearDiscriminantAnalysis</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#:~:text=solver,-%7B%27svd%27%2C%20%27lsqr%27%2C%20%27eigen%27%7D%2C%20default%3D%27svd%27\">\n",
       "            solver\n",
       "            <span class=\"param-doc-description\">solver: {'svd', 'lsqr', 'eigen'}, default='svd'<br><br>Solver to use, possible values:<br>  - 'svd': Singular value decomposition (default).<br>    Does not compute the covariance matrix, therefore this solver is<br>    recommended for data with a large number of features.<br>  - 'lsqr': Least squares solution.<br>    Can be combined with shrinkage or custom covariance estimator.<br>  - 'eigen': Eigenvalue decomposition.<br>    Can be combined with shrinkage or custom covariance estimator.<br><br>.. versionchanged:: 1.2<br>    `solver=\"svd\"` now has experimental Array API support. See the<br>    :ref:`Array API User Guide <array_api>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;svd&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('shrinkage',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#:~:text=shrinkage,-%27auto%27%20or%20float%2C%20default%3DNone\">\n",
       "            shrinkage\n",
       "            <span class=\"param-doc-description\">shrinkage: 'auto' or float, default=None<br><br>Shrinkage parameter, possible values:<br>  - None: no shrinkage (default).<br>  - 'auto': automatic shrinkage using the Ledoit-Wolf lemma.<br>  - float between 0 and 1: fixed shrinkage parameter.<br><br>This should be left to None if `covariance_estimator` is used.<br>Note that shrinkage works only with 'lsqr' and 'eigen' solvers.<br><br>For a usage example, see<br>:ref:`sphx_glr_auto_examples_classification_plot_lda.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('priors',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#:~:text=priors,-array-like%20of%20shape%20%28n_classes%2C%29%2C%20default%3DNone\">\n",
       "            priors\n",
       "            <span class=\"param-doc-description\">priors: array-like of shape (n_classes,), default=None<br><br>The class prior probabilities. By default, the class proportions are<br>inferred from the training data.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_components',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#:~:text=n_components,-int%2C%20default%3DNone\">\n",
       "            n_components\n",
       "            <span class=\"param-doc-description\">n_components: int, default=None<br><br>Number of components (<= min(n_classes - 1, n_features)) for<br>dimensionality reduction. If None, will be set to<br>min(n_classes - 1, n_features). This parameter only affects the<br>`transform` method.<br><br>For a usage example, see<br>:ref:`sphx_glr_auto_examples_decomposition_plot_pca_vs_lda.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('store_covariance',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#:~:text=store_covariance,-bool%2C%20default%3DFalse\">\n",
       "            store_covariance\n",
       "            <span class=\"param-doc-description\">store_covariance: bool, default=False<br><br>If True, explicitly compute the weighted within-class covariance<br>matrix when solver is 'svd'. The matrix is always computed<br>and stored for the other solvers.<br><br>.. versionadded:: 0.17</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#:~:text=tol,-float%2C%20default%3D1.0e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1.0e-4<br><br>Absolute threshold for a singular value of X to be considered<br>significant, used to estimate the rank of X. Dimensions whose<br>singular values are non-significant are discarded. Only used if<br>solver is 'svd'.<br><br>.. versionadded:: 0.17</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('covariance_estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#:~:text=covariance_estimator,-covariance%20estimator%2C%20default%3DNone\">\n",
       "            covariance_estimator\n",
       "            <span class=\"param-doc-description\">covariance_estimator: covariance estimator, default=None<br><br>If not None, `covariance_estimator` is used to estimate<br>the covariance matrices instead of relying on the empirical<br>covariance estimator (with potential shrinkage).<br>The object should have a fit method and a ``covariance_`` attribute<br>like the estimators in :mod:`sklearn.covariance`.<br>if None the shrinkage parameter drives the estimate.<br><br>This should be left to None if `shrinkage` is used.<br>Note that `covariance_estimator` works only with 'lsqr' and 'eigen'<br>solvers.<br><br>.. versionadded:: 0.24</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ],
      "text/plain": [
       "LinearDiscriminantAnalysis(store_covariance=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = [M.drop(columns=['intercept'])\n",
    "                   for M in [X_train, X_test]]\n",
    "lda.fit(X_train, L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c5098b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04279022,  0.03389409],\n",
       "       [-0.03954635, -0.03132544]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de886816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Down', 'Up'], dtype='<U4')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66492dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49198397, 0.50801603])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.priors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35e11bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.64201904],\n",
       "       [-0.51352928]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.scalings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac142df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_pred = lda.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6aaa6935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Predicted",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Down",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Up",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "9d90b9f0-b07e-43ac-8ad3-79ee4285effe",
       "rows": [
        [
         "Down",
         "168",
         "160"
        ],
        [
         "Up",
         "323",
         "347"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>Down</th>\n",
       "      <th>Up</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Down</th>\n",
       "      <td>168</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Up</th>\n",
       "      <td>323</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth      Down   Up\n",
       "Predicted           \n",
       "Down        168  160\n",
       "Up          323  347"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_table(lda_pred, L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70ba996a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_prob = lda.predict_proba(X_test)\n",
    "np.all(\n",
    "    np.where(lda_prob[:,1] >= 0.5, 'Up','Down') == lda_pred\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "636a5c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(\n",
    "    [lda.classes_[i] for i in np.argmax(lda_prob, 1)] == \n",
    "    lda_pred\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "385494ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(lda_prob[:,0] > 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae58d81a",
   "metadata": {},
   "source": [
    "##### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea55a6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>QuadraticDiscriminantAnalysis(store_covariance=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>QuadraticDiscriminantAnalysis</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html\">?<span>Documentation for QuadraticDiscriminantAnalysis</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#:~:text=solver,-%7B%27svd%27%2C%20%27eigen%27%7D%2C%20default%3D%27svd%27\">\n",
       "            solver\n",
       "            <span class=\"param-doc-description\">solver: {'svd', 'eigen'}, default='svd'<br><br>Solver to use, possible values:<br>  - 'svd': Singular value decomposition (default).<br>    Does not compute the covariance matrix, therefore this solver is<br>    recommended for data with a large number of features.<br>  - 'eigen': Eigenvalue decomposition.<br>    Can be combined with shrinkage or custom covariance estimator.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;svd&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('shrinkage',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#:~:text=shrinkage,-%27auto%27%20or%20float%2C%20default%3DNone\">\n",
       "            shrinkage\n",
       "            <span class=\"param-doc-description\">shrinkage: 'auto' or float, default=None<br><br>Shrinkage parameter, possible values:<br>  - None: no shrinkage (default).<br>  - 'auto': automatic shrinkage using the Ledoit-Wolf lemma.<br>  - float between 0 and 1: fixed shrinkage parameter.<br><br>  Enabling shrinkage is expected to improve the model when some<br>  classes have a relatively small number of training data points<br>  compared to the number of features by mitigating overfitting during<br>  the covariance estimation step.<br><br>This should be left to `None` if `covariance_estimator` is used.<br>Note that shrinkage works only with 'eigen' solver.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('priors',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#:~:text=priors,-array-like%20of%20shape%20%28n_classes%2C%29%2C%20default%3DNone\">\n",
       "            priors\n",
       "            <span class=\"param-doc-description\">priors: array-like of shape (n_classes,), default=None<br><br>Class priors. By default, the class proportions are inferred from the<br>training data.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_param',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#:~:text=reg_param,-float%2C%20default%3D0.0\">\n",
       "            reg_param\n",
       "            <span class=\"param-doc-description\">reg_param: float, default=0.0<br><br>Regularizes the per-class covariance estimates by transforming S2 as<br>``S2 = (1 - reg_param) * S2 + reg_param * np.eye(n_features)``,<br>where S2 corresponds to the `scaling_` attribute of a given class.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('store_covariance',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#:~:text=store_covariance,-bool%2C%20default%3DFalse\">\n",
       "            store_covariance\n",
       "            <span class=\"param-doc-description\">store_covariance: bool, default=False<br><br>If True, the class covariance matrices are explicitly computed and<br>stored in the `self.covariance_` attribute.<br><br>.. versionadded:: 0.17</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#:~:text=tol,-float%2C%20default%3D1.0e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1.0e-4<br><br>Absolute threshold for the covariance matrix to be considered rank<br>deficient after applying some regularization (see `reg_param`) to each<br>`Sk` where `Sk` represents covariance matrix for k-th class. This<br>parameter does not affect the predictions. It controls when a warning<br>is raised if the covariance matrix is not full rank.<br><br>.. versionadded:: 0.17</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('covariance_estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#:~:text=covariance_estimator,-covariance%20estimator%2C%20default%3DNone\">\n",
       "            covariance_estimator\n",
       "            <span class=\"param-doc-description\">covariance_estimator: covariance estimator, default=None<br><br>If not None, `covariance_estimator` is used to estimate the covariance<br>matrices instead of relying on the empirical covariance estimator<br>(with potential shrinkage).  The object should have a fit method and<br>a ``covariance_`` attribute like the estimators in<br>:mod:`sklearn.covariance`. If None the shrinkage parameter drives the<br>estimate.<br><br>This should be left to `None` if `shrinkage` is used.<br>Note that `covariance_estimator` works only with the 'eigen' solver.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-2');</script></body>"
      ],
      "text/plain": [
       "QuadraticDiscriminantAnalysis(store_covariance=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda = QDA(store_covariance=True)\n",
    "qda.fit(X_train, L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5922a0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.04279022,  0.03389409],\n",
       "        [-0.03954635, -0.03132544]]),\n",
       " array([0.49198397, 0.50801603]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda.means_, qda.priors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d58b4d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.50662277, -0.03924806],\n",
       "       [-0.03924806,  1.53559498]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda.covariance_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f20d34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Predicted",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Down",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Up",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "93715d68-e99f-42e8-96ee-af6917b9b848",
       "rows": [
        [
         "Down",
         "162",
         "156"
        ],
        [
         "Up",
         "329",
         "351"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>Down</th>\n",
       "      <th>Up</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Down</th>\n",
       "      <td>162</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Up</th>\n",
       "      <td>329</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth      Down   Up\n",
       "Predicted           \n",
       "Down        162  156\n",
       "Up          329  351"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda_pred = qda.predict(X_test)\n",
    "confusion_table(qda_pred, L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "199fc7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5140280561122245"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(qda_pred == L_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40218683",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02e4aeff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-3.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-3.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GaussianNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('priors',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.GaussianNB.html#:~:text=priors,-array-like%20of%20shape%20%28n_classes%2C%29%2C%20default%3DNone\">\n",
       "            priors\n",
       "            <span class=\"param-doc-description\">priors: array-like of shape (n_classes,), default=None<br><br>Prior probabilities of the classes. If specified, the priors are not<br>adjusted according to the data.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('var_smoothing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.GaussianNB.html#:~:text=var_smoothing,-float%2C%20default%3D1e-9\">\n",
       "            var_smoothing\n",
       "            <span class=\"param-doc-description\">var_smoothing: float, default=1e-9<br><br>Portion of the largest variance of all features that is added to<br>variances for calculation stability.<br><br>.. versionadded:: 0.20</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1e-09</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-3');</script></body>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB = GaussianNB()\n",
    "NB.fit(X_train, L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "787ff8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Down', 'Up'], dtype='<U4')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0abda505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49198397, 0.50801603])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB.class_prior_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "73753289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04279022,  0.03389409],\n",
       "       [-0.03954635, -0.03132544]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB.theta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "244583b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.50355429, 1.53246749],\n",
       "       [1.51401364, 1.48732877]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB.var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5406e925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "faf4c0ed-572b-4afb-a726-28ce98364e17",
       "rows": [
        [
         "Lag1",
         "0.04279022403258654"
        ],
        [
         "Lag2",
         "0.03389409368635437"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "Lag1    0.042790\n",
       "Lag2    0.033894\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[L_train == 'Down'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f7eb544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2cb99477-8065-40b4-9011-6e3141cad8d3",
       "rows": [
        [
         "Lag1",
         "1.5035542920429221"
        ],
        [
         "Lag2",
         "1.5324674918388417"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "Lag1    1.503554\n",
       "Lag2    1.532467\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[L_train == 'Down'].var(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "477c8172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Predicted",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Down",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Up",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "6976d319-db1f-4afc-bbbd-44d184b33e20",
       "rows": [
        [
         "Down",
         "154",
         "147"
        ],
        [
         "Up",
         "337",
         "360"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>Down</th>\n",
       "      <th>Up</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Down</th>\n",
       "      <td>154</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Up</th>\n",
       "      <td>337</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth      Down   Up\n",
       "Predicted           \n",
       "Down        154  147\n",
       "Up          337  360"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_labels = NB.predict(X_test)\n",
    "confusion_table(nb_labels, L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b5f8b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49221294, 0.50778706],\n",
       "       [0.50610738, 0.49389262],\n",
       "       [0.51517229, 0.48482771],\n",
       "       [0.49413149, 0.50586851],\n",
       "       [0.49147627, 0.50852373]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB.predict_proba(X_test)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157447f1",
   "metadata": {},
   "source": [
    "#####  K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f353736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Predicted",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Down",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Up",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "e5ab19ac-742c-457d-8d68-7746f35876bd",
       "rows": [
        [
         "Down",
         "491",
         "0"
        ],
        [
         "Up",
         "0",
         "507"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>Down</th>\n",
       "      <th>Up</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Down</th>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Up</th>\n",
       "      <td>0</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth      Down   Up\n",
       "Predicted           \n",
       "Down        491    0\n",
       "Up            0  507"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn1 = KNeighborsClassifier(n_neighbors=1)\n",
    "knn1.fit(X_train, L_train)\n",
    "knn1_pred = knn1.predict(X_test)\n",
    "confusion_table(knn1_pred, L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9ac44138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 1.0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(83+43)/252, np.mean(knn1_pred == L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45ed611d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7545090180360722"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn3_pred = knn3.fit(X_train, L_train).predict(X_test)\n",
    "np.mean(knn3_pred == L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fe311982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Purchase",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "cee6f625-f1c5-4852-ae16-573b547614d6",
       "rows": [
        [
         "No",
         "5474"
        ],
        [
         "Yes",
         "348"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "Purchase\n",
       "No     5474\n",
       "Yes     348\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Caravan = load_data('Caravan')\n",
    "Purchase = Caravan.Purchase\n",
    "Purchase.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8943c783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05977327378907592"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "348 / 5822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d6d3773",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = Caravan.drop(columns=['Purchase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "65df2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=True,\n",
    "                        with_std=True,\n",
    "                        copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fcce32e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(feature_df)\n",
    "X_std = scaler.transform(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c74a2623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "471caeb6-3453-4e4a-a692-b6942b522158",
       "rows": [
        [
         "MOSTYPE",
         "1.0000858922054408"
        ],
        [
         "MAANTHUI",
         "1.0000858922054023"
        ],
        [
         "MGEMOMV",
         "1.0000858922054434"
        ],
        [
         "MGEMLEEF",
         "1.0000858922054865"
        ],
        [
         "MOSHOOFD",
         "1.0000858922054296"
        ],
        [
         "MGODRK",
         "1.0000858922054159"
        ],
        [
         "MGODPR",
         "1.0000858922054487"
        ],
        [
         "MGODOV",
         "1.000085892205457"
        ],
        [
         "MGODGE",
         "1.000085892205433"
        ],
        [
         "MRELGE",
         "1.0000858922054672"
        ],
        [
         "MRELSA",
         "1.000085892205441"
        ],
        [
         "MRELOV",
         "1.0000858922054556"
        ],
        [
         "MFALLEEN",
         "1.0000858922054428"
        ],
        [
         "MFGEKIND",
         "1.0000858922054656"
        ],
        [
         "MFWEKIND",
         "1.0000858922054272"
        ],
        [
         "MOPLHOOG",
         "1.0000858922054534"
        ],
        [
         "MOPLMIDD",
         "1.0000858922054319"
        ],
        [
         "MOPLLAAG",
         "1.000085892205438"
        ],
        [
         "MBERHOOG",
         "1.0000858922054305"
        ],
        [
         "MBERZELF",
         "1.0000858922054041"
        ],
        [
         "MBERBOER",
         "1.0000858922054003"
        ],
        [
         "MBERMIDD",
         "1.000085892205415"
        ],
        [
         "MBERARBG",
         "1.0000858922054605"
        ],
        [
         "MBERARBO",
         "1.0000858922054214"
        ],
        [
         "MSKA",
         "1.0000858922054452"
        ],
        [
         "MSKB1",
         "1.0000858922054405"
        ],
        [
         "MSKB2",
         "1.0000858922054554"
        ],
        [
         "MSKC",
         "1.000085892205443"
        ],
        [
         "MSKD",
         "1.0000858922054467"
        ],
        [
         "MHHUUR",
         "1.0000858922054563"
        ],
        [
         "MHKOOP",
         "1.0000858922054512"
        ],
        [
         "MAUT1",
         "1.0000858922054152"
        ],
        [
         "MAUT2",
         "1.0000858922054354"
        ],
        [
         "MAUT0",
         "1.000085892205439"
        ],
        [
         "MZFONDS",
         "1.0000858922054083"
        ],
        [
         "MZPART",
         "1.0000858922054405"
        ],
        [
         "MINKM30",
         "1.0000858922054359"
        ],
        [
         "MINK3045",
         "1.000085892205425"
        ],
        [
         "MINK4575",
         "1.0000858922054512"
        ],
        [
         "MINK7512",
         "1.0000858922054712"
        ],
        [
         "MINK123M",
         "1.0000858922054323"
        ],
        [
         "MINKGEM",
         "1.000085892205418"
        ],
        [
         "MKOOPKLA",
         "1.0000858922054356"
        ],
        [
         "PWAPART",
         "1.0000858922054054"
        ],
        [
         "PWABEDR",
         "1.000085892205432"
        ],
        [
         "PWALAND",
         "1.0000858922053948"
        ],
        [
         "PPERSAUT",
         "1.000085892205422"
        ],
        [
         "PBESAUT",
         "1.0000858922054476"
        ],
        [
         "PMOTSCO",
         "1.0000858922054998"
        ],
        [
         "PVRAAUT",
         "1.0000858922054006"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 85
       }
      },
      "text/plain": [
       "MOSTYPE     1.000086\n",
       "MAANTHUI    1.000086\n",
       "MGEMOMV     1.000086\n",
       "MGEMLEEF    1.000086\n",
       "MOSHOOFD    1.000086\n",
       "              ...   \n",
       "AZEILPL     1.000086\n",
       "APLEZIER    1.000086\n",
       "AFIETS      1.000086\n",
       "AINBOED     1.000086\n",
       "ABYSTAND    1.000086\n",
       "Length: 85, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_std = pd.DataFrame(X_std,\n",
    "                           columns=feature_df.columns);\n",
    "feature_std.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a61ca470",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,\n",
    " X_test,\n",
    " y_train,\n",
    " y_test) = train_test_split(feature_std,\n",
    "                            Purchase,\n",
    "                            test_size=1000,\n",
    "                            random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0dcfca45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.111, 0.067)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn1 = KNeighborsClassifier(n_neighbors=1)\n",
    "knn1_pred = knn1.fit(X_train, y_train).predict(X_test)\n",
    "np.mean(y_test != knn1_pred), np.mean(y_test != \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "00287ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Predicted",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Yes",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "edff6cef-7670-46d9-b190-5c5a5b62dced",
       "rows": [
        [
         "No",
         "880",
         "58"
        ],
        [
         "Yes",
         "53",
         "9"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>880</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth       No  Yes\n",
       "Predicted          \n",
       "No         880   58\n",
       "Yes         53    9"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_table(knn1_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "408bd784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14516129032258066"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9/(53+9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68205014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1: # predicted to rent: 62, # who did rent 9, accuracy 14.5%\n",
      "K=2: # predicted to rent:  6, # who did rent 1, accuracy 16.7%\n",
      "K=3: # predicted to rent: 20, # who did rent 3, accuracy 15.0%\n",
      "K=4: # predicted to rent:  4, # who did rent 0, accuracy 0.0%\n",
      "K=5: # predicted to rent:  7, # who did rent 1, accuracy 14.3%\n"
     ]
    }
   ],
   "source": [
    "for K in range(1,6):\n",
    "    knn = KNeighborsClassifier(n_neighbors=K)\n",
    "    knn_pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "    C = confusion_table(knn_pred, y_test)\n",
    "    templ = ('K={0:d}: # predicted to rent: {1:>2},' +\n",
    "             ' # who did rent {2:d}, accuracy {3:.1%}')\n",
    "    pred = C.loc['Yes'].sum()\n",
    "    did_rent = C.loc['Yes','Yes']\n",
    "    print(templ.format(\n",
    "        K,\n",
    "        pred,\n",
    "        did_rent,\n",
    "        did_rent / pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5604a6d0",
   "metadata": {},
   "source": [
    "Comparison to Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "da10c759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Predicted",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Yes",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "9cca8c7c-4b4a-4de0-90c1-d0c28e4a7096",
       "rows": [
        [
         "No",
         "933",
         "67"
        ],
        [
         "Yes",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>933</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth       No  Yes\n",
       "Predicted          \n",
       "No         933   67\n",
       "Yes          0    0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression(C=1e10, solver='liblinear')\n",
    "logit.fit(X_train, y_train)\n",
    "logit_pred = logit.predict_proba(X_test)\n",
    "logit_labels = np.where(logit_pred[:,1] > 5, 'Yes', 'No')\n",
    "confusion_table(logit_labels, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94fa6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "islp_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
