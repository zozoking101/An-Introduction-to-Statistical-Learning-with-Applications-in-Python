{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428d309b",
   "metadata": {},
   "source": [
    "### Resampling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea98acc",
   "metadata": {},
   "source": [
    "Resampling methods are an indispensable tool in modern statistics. They\n",
    "involve repeatedly drawing samples from a training set and refitting a model\n",
    "of interest on each sample in order to obtain additional information about\n",
    "the fitted model. For example, in order to estimate the variability of a linear\n",
    "regression fit, we can repeatedly draw different samples from the training\n",
    "data, fit a linear regression to each new sample, and then examine the\n",
    "extent to which the resulting fits differ. Such an approach may allow us to\n",
    "obtain information that would not be available from fitting the model only\n",
    "once using the original training sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdab74e1",
   "metadata": {},
   "source": [
    "Cross-validation can be used to estimate the test error associated with a given statistical learning method in order to evaluate\n",
    "its performance, or to select the appropriate level of flexibility. \n",
    "\n",
    "The process of evaluating a model’s performance is known as model assessment, whereas model\n",
    "the process of selecting the proper level of flexibility for a model is known as\n",
    "model selection. \n",
    "\n",
    "The bootstrap is used in several contexts, most commonly model\n",
    "to provide a measure of accuracy of a parameter estimate or of a given statistical learning method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4f7ef6",
   "metadata": {},
   "source": [
    "#### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e4390d",
   "metadata": {},
   "source": [
    "The test error is the average error that results from using\n",
    "a statistical learning method to predict the response on a new observation—\n",
    "that is, a measurement that was not used in training the method. Given\n",
    "a data set, the use of a particular statistical learning method is warranted\n",
    "if it results in a low test error. The test error can be easily calculated if a\n",
    "designated test set is available. Unfortunately, this is usually not the case.\n",
    "In contrast, the training error can be easily calculated by applying the\n",
    "statistical learning method to the observations used in its training. But as\n",
    "we saw in Chapter 2, the training error rate often is quite different from the\n",
    "test error rate, and in particular the former can dramatically underestimate\n",
    "the latter.\n",
    "\n",
    "In the absence of a very large designated test set that can be used to\n",
    "directly estimate the test error rate, a number of techniques can be used\n",
    "to estimate this quantity using the available training data. Some methods\n",
    "make a mathematical adjustment to the training error rate in order to\n",
    "estimate the test error rate. Such approaches are discussed.\n",
    "In this section, we instead consider a class of methods that estimate the\n",
    "test error rate by holding out a subset of the training observations from the\n",
    "fitting process, and then applying the statistical learning method to those\n",
    "held out observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40baa390",
   "metadata": {},
   "source": [
    "#####  The Validation Set Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaeafb5",
   "metadata": {},
   "source": [
    "Suppose that we would like to estimate the test error associated with fit\n",
    "ting a particular statistical learning method on a set of observations. The\n",
    "validation set approach, displayed in Figure 5.1, is a very simple strategy validation\n",
    "for this task. It involves randomly dividing the available set of observa\n",
    "tions into two parts, a training set and a validation set or hold-out set. The validation\n",
    "model is fit on the training set, and the fitted model is used to predict the\n",
    "responses for the observations in the validation set. The resulting validation\n",
    "set error rate—typically assessed using MSE in the case of a quantitative\n",
    "response—provides an estimate of the test error rate.\n",
    "Weillustrate the validation set approach on the Auto data set. Recall from\n",
    "Chapter 3 that there appears to be a non-linear relationship between mpg\n",
    "and horsepower, and that a model that predicts mpg using horsepower and\n",
    "horsepower2 gives better results than a model that uses only a linear term.\n",
    "It is natural to wonder whether a cubic or higher-order fit might provide\n",
    "even better results. We answer this question in Chapter 3 by looking at\n",
    "the p-values associated with a cubic term and higher-order polynomial\n",
    "terms in a linear regression. But we could also answer this question using\n",
    "the validation method. We randomly split the 392 observations into two sets, a training set containing 196 of the data points, and a validation set\n",
    "containing the remaining 196 observations. The validation set error rates\n",
    "that result from fitting various regression models on the training sample\n",
    "and evaluating their performance on the validation sample, using MSE\n",
    "as a measure of validation set error, are shown in the left-hand panel of\n",
    "Figure 5.2. The validation set MSE for the quadratic fit is considerably\n",
    "smaller than for the linear fit. However, the validation set MSE for the cubic\n",
    "f\n",
    "it is actually slightly larger than for the quadratic fit. This implies that\n",
    "including a cubic term in the regression does not lead to better prediction\n",
    "than simply using a quadratic term.\n",
    "Recall that in order to create the left-hand panel of Figure 5.2, we ran\n",
    "domly divided the data set into two parts, a training set and a validation\n",
    "set. If we repeat the process of randomly splitting the sample set into two\n",
    "parts, we will get a somewhat different estimate for the test MSE. As an\n",
    "illustration, the right-hand panel of Figure 5.2 displays ten different vali\n",
    "dation set MSE curves from the Auto data set, produced using ten different\n",
    "random splits of the observations into training and validation sets. All ten\n",
    "curves indicate that the model with a quadratic term has a dramatically\n",
    "smaller validation set MSE than the model with only a linear term. Fur\n",
    "thermore, all ten curves indicate that there is not much benefit in including\n",
    "cubic or higher-order polynomial terms in the model. But it is worth noting\n",
    "that each of the ten curves results in a different test MSE estimate for each\n",
    "of the ten regression models considered. And there is no consensus among\n",
    "the curves as to which model results in the smallest validation set MSE.\n",
    "Based on the variability among these curves, all that we can conclude with\n",
    "any confidence is that the linear fit is not adequate for this data.\n",
    "The validation set approach is conceptually simple and is easy to imple\n",
    "ment. But it has two potential drawbacks:\n",
    "1. As is shown in the right-hand panel of Figure 5.2, the validation esti\n",
    "mate of the test error rate can be highly variable, depending on pre\n",
    "cisely which observations are included in the training set and which\n",
    "observations are included in the validation set.\n",
    "2. In the validation approach, only a subset of the observations—those\n",
    "that are included in the training set rather than in the validation\n",
    "set—are used to fit the model. Since statistical methods tend to per\n",
    "form worse when trained on fewer observations, this suggests that the validation set error rate may tend to overestimate the test error rate\n",
    "for the model fit on the entire data set.\n",
    "In the coming subsections, we will present cross-validation, a refinement of\n",
    "the validation set approach that addresses these two issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7af9682",
   "metadata": {},
   "source": [
    "##### Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6d07f2",
   "metadata": {},
   "source": [
    "5.1.2 Leave-One-Out Cross-Validation\n",
    "Leave-one-out cross-validation (LOOCV) is closely related to the validation leave-one\n",
    "set approach of Section 5.1.1, but it attempts to address that method’s\n",
    "drawbacks.\n",
    "Like the validation set approach, LOOCV involves splitting the set of\n",
    "observations into two parts. However, instead of creating two subsets of\n",
    "comparable size, a single observation (x1,y1) is used for the validation\n",
    "set, and the remaining observations {(x2,y2),...,(xn,yn)} make up the\n",
    "training set. The statistical learning method is fit on the n 1 training\n",
    "observations, and a prediction ˆy1 is made for the excluded observation,\n",
    "using its value x1. Since (x1,y1) was not used in the fitting process, MSE1 =\n",
    "(y1 \n",
    "ˆ\n",
    "y1)2 provides an approximately unbiased estimate for the test error.\n",
    "But even though MSE1 is unbiased for the test error, it is a poor estimate\n",
    "because it is highly variable, since it is based upon a single observation\n",
    "(x1,y1).\n",
    "We can repeat the procedure by selecting (x2,y2) for the validation\n",
    "data, training the statistical learning procedure on the n 1 observations\n",
    "{(x1,y1),(x3,y3),...,(xn,yn)}, and computing MSE2 =(y2 ˆy2)2. Repeat\n",
    "ing this approach n times produces n squared errors, MSE1,..., MSEn.\n",
    "The LOOC proach n times produces n squared errors, MSE1,..., MSEn.\n",
    "The LOOCV estimate for the test MSE is the average of these n test error\n",
    "estimates:\n",
    "CV(n) = 1\n",
    "n \n",
    "n\n",
    "i=1 \n",
    "MSEi.\n",
    "(5.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9516b37",
   "metadata": {},
   "source": [
    "LOOCV has a couple of major advantages over the validation set ap\n",
    "proach. First, it has far less bias. In LOOCV, we repeatedly fit the sta\n",
    "tistical learning method using training sets that contain n 1 observa\n",
    "tions, almost as many as are in the entire data set. This is in contrast to\n",
    "the validation set approach, in which the training set is typically around\n",
    "half the size of the original data set. Consequently, the LOOCV approach\n",
    "tends not to overestimate the test error rate as much as the validation\n",
    "set approach does. Second, in contrast to the validation approach which\n",
    "will yield different results when applied repeatedly due to randomness in\n",
    "the training/validation set splits, performing LOOCV multiple times will\n",
    "always yield the same results: there is no randomness in the training/vali\n",
    "dation set splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d943ddfb",
   "metadata": {},
   "source": [
    "LOOCVhas the potential to be expensive to implement, since the model\n",
    "has to be fit n times. This can be very time consuming if n is large, and if\n",
    "each individual model is slow to fit. With least squares linear or polynomial\n",
    "regression, an amazing shortcut makes the cost of LOOCV the same as that\n",
    "of a single model fit! The following formula holds:\n",
    "CV(n) = 1\n",
    "n \n",
    "n\n",
    "i=1 \n",
    "yi ˆyi\n",
    "2\n",
    ",\n",
    "(5.2)\n",
    "\n",
    "where ˆyi is the ith fitted value from the original least squares fit, and hi is\n",
    "the leverage defined in (3.37) on page 105.1 This is like the ordinary MSE,\n",
    "except the ith residual is divided by 1 hi. The leverage lies between 1/n\n",
    "and 1, and reflects the amount that an observation influences its own fit.\n",
    "Hence the residuals for high-leverage points are inflated in this formula by\n",
    "exactly the right amount for this equality to hold.\n",
    "LOOCV is a very general method, and can be used with any kind of\n",
    "predictive modeling. For example we could use it with logistic regression\n",
    "or linear discriminant analysis, or any of the methods discussed in later\n",
    "chapters. The magic formula (5.2) does not hold in general, in which case\n",
    "the model has to be refit n times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc2e9b4",
   "metadata": {},
   "source": [
    "#####  k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48748614",
   "metadata": {},
   "source": [
    "An alternative to LOOCV is k-fold CV. This approach involves randomly k-fold CV\n",
    "dividing the set of observations into k groups, or folds, of approximately\n",
    "equal size. The first fold is treated as a validation set, and the method\n",
    "is fit on the remaining k 1 folds. The mean squared error, MSE1, is\n",
    "then computed on the observations in the held-out fold. This procedure is\n",
    "repeated k times; each time, a different group of observations is treated\n",
    "as a validation set. This process results in k estimates of the test error,\n",
    "MSE1,MSE2,...,MSEk. The k-fold CV estimate is computed by averaging\n",
    "these values,\n",
    "CV(k) = 1\n",
    "k \n",
    "k\n",
    "i=1 \n",
    "MSEi.\n",
    "Figure 5.5 illustrates the k-fold CV approach.\n",
    "(5.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a77df72",
   "metadata": {},
   "source": [
    "It is not hard to see that LOOCV is a special case of k-fold CV in which k\n",
    "is set to equal n. In practice, one typically performs k-fold CV using k =5\n",
    "or k = 10. What is the advantage of using k =5or k = 10 rather than\n",
    "k = n? The most obvious advantage is computational. LOOCV requires\n",
    "f\n",
    "itting the statistical learning method n times. This has the potential to be\n",
    "computationally expensive (except for linear models fit by least squares,\n",
    "in which case formula (5.2) can be used). But cross-validation is a very\n",
    "general approach that can be applied to almost any statistical learning\n",
    "method. Some statistical learning methods have computationally intensive\n",
    "f\n",
    "itting procedures, and so performing LOOCV may pose computational\n",
    "problems, especially if n is extremely large. In contrast, performing 10-fold\n",
    "CV requires fitting the learning procedure only ten times, which may be\n",
    "much more feasible. As we see in Section 5.1.4, there also can be other\n",
    "non-computational advantages to performing 5-fold or 10-fold CV, which\n",
    "involve the bias-variance trade-off.\n",
    "The right-hand panel of Figure 5.4 displays nine different 10-fold CV\n",
    "estimates for the Auto data set, each resulting from a different random split\n",
    "of the observations into ten folds. As we can see from the figure, there is\n",
    "some variability in the CV estimates as a result of the variability in how\n",
    "the observations are divided into ten folds. But this variability is typically\n",
    "much lower than the variability in the test error estimates that results from\n",
    "the validation set approach (right-hand panel of Figure 5.2).\n",
    "When we examine real data, we do not know the true test MSE, and\n",
    "so it is difficult to determine the accuracy of the cross-validation estimate.\n",
    "However, if we examine simulated data, then we can compute the true\n",
    "test MSE, and can thereby evaluate the accuracy of our cross-validation\n",
    "results. In Figure 5.6, we plot the cross-validation estimates and true test\n",
    "error rates that result from applying smoothing splines to the simulated\n",
    "data sets illustrated in Figures 2.9–2.11 of Chapter 2. The true test MSE\n",
    "is displayed in blue. The black dashed and orange solid lines respectively\n",
    "show the estimated LOOCV and 10-fold CV estimates. In all three plots,\n",
    "the two cross-validation estimates are very similar.\n",
    "\n",
    "rue test MSE.\n",
    "When we perform cross-validation, our goal might be to determine how\n",
    "well a given statistical learning procedure can be expected to perform on\n",
    "independent data; in this case, the actual estimate of the test MSE is\n",
    "of interest. But at other times we are interested only in the location of\n",
    "the minimum point in the estimated test MSE curve. This is because we\n",
    "might be performing cross-validation on a number of statistical learning\n",
    "methods, or on a single method using different levels of flexibility, in order\n",
    "to identify the method that results in the lowest test error. For this purpose,\n",
    "the location of the minimum point in the estimated test MSE curve is\n",
    "important, but the actual value of the estimated test MSE is not. We find\n",
    "in Figure 5.6 that despite the fact that they sometimes underestimate the\n",
    "true test MSE, all of the CV curves come close to identifying the correct\n",
    "level of flexibility—that is, the flexibility level corresponding to the smallest\n",
    "test MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108f0357",
   "metadata": {},
   "source": [
    "##### Bias-Variance Trade-Off for k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790de511",
   "metadata": {},
   "source": [
    " k-fold CV with k<nhas a compu\n",
    "tational advantage to LOOCV. But putting computational issues aside,\n",
    "a less obvious but potentially more important advantage of k-fold CV is\n",
    "that it often gives more accurate estimates of the test error rate than does\n",
    "LOOCV. This has to do with a bias-variance trade-off.\n",
    "It was mentioned in Section 5.1.1 that the validation set approach can\n",
    "lead to overestimates of the test error rate, since in this approach the\n",
    "training set used to fit the statistical learning method contains only half\n",
    "the observations of the entire data set. Using this logic, it is not hard to see that LOOCV will give approximately unbiased estimates of the test error,\n",
    "since each training set contains n 1 observations, which is almost as many\n",
    "as the number of observations in the full data set. And performing k-fold\n",
    "CV for, say, k =5or k = 10 will lead to an intermediate level of bias,\n",
    "since each training set contains approximately (k 1)n/k observations—\n",
    "fewer than in the LOOCV approach, but substantially more than in the\n",
    "validation set approach. Therefore, from the perspective of bias reduction,\n",
    "it is clear that LOOCV is to be preferred to k-fold CV.\n",
    "However, we know that bias is not the only source for concern in an esti\n",
    "mating procedure; we must also consider the procedure’s variance. It turns\n",
    "out that LOOCV has higher variance than does k-fold CV with k<n.Why\n",
    "is this the case? When we perform LOOCV, we are in effect averaging the\n",
    "outputs of n fitted models, each of which is trained on an almost identical\n",
    "set of observations; therefore, these outputs are highly (positively) corre\n",
    "lated with each other. In contrast, when we perform k-fold CV with k<n,\n",
    "we are averaging the outputs of k fitted models that are somewhat less\n",
    "correlated with each other, since the overlap between the training sets in\n",
    "each model is smaller. Since the mean of many highly correlated quantities\n",
    "has higher variance than does the mean of many quantities that are not\n",
    "as highly correlated, the test error estimate resulting from LOOCV tends\n",
    "to have higher variance than does the test error estimate resulting from\n",
    "k-fold CV.\n",
    "To summarize, there is a bias-variance trade-off associated with the\n",
    "choice of k in k-fold cross-validation. Typically, given these considerations,\n",
    "one performs k-fold cross-validation using k =5or k = 10, as these values\n",
    "have been shown empirically to yield test error rate estimates that suffer\n",
    "neither from excessively high bias nor from very high variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa5a826",
   "metadata": {},
   "source": [
    "#####  Cross-Validation on Classification Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e369b",
   "metadata": {},
   "source": [
    "Cross-validation can also be a very useful\n",
    "approach in the classification setting when Y is qualitative. In this setting,\n",
    "cross-validation works just as described earlier in this chapter, except that\n",
    "rather than using MSE to quantify test error, we instead use the number\n",
    "of misclassified observations. For instance, in the classification setting, the\n",
    "LOOCV error rate takes the form\n",
    "CV(n) = 1\n",
    "n \n",
    "n\n",
    "i=1 \n",
    "Erri,\n",
    "where Erri = I(yi=ˆ\n",
    "(5.4)\n",
    "yi). The k-fold CV error rate and validation set error\n",
    "rates are defined analogously.\n",
    "As an example, we fit various logistic regression models on the two\n",
    "dimensional classification data displayed in Figure 2.13. In the top-left\n",
    "panel of Figure 5.7, the black solid line shows the estimated decision bound\n",
    "ary resulting from fitting a standard logistic regression model to this data\n",
    "set. Since this is simulated data, we can compute the true test error rate,\n",
    "which takes a value of 0.201 and so is substantially larger than the Bayes errorrateof0.133.Clearlylogisticregressiondoesnothaveenoughflexi\n",
    "bilitytomodel theBayesdecisionboundaryinthissetting.Wecaneasily\n",
    "extendlogisticregressiontoobtainanon-lineardecisionboundarybyusing\n",
    "polynomialfunctionsofthepredictors,aswedidintheregressionsettingin\n",
    "Section3.3.2.Forexample,wecanfitaquadraticlogisticregressionmodel,\n",
    "givenby\n",
    "log p\n",
    "1 p = 0+ 1X1+ 2X2\n",
    "1+ 3X2+ 4X2\n",
    "2. (5.5)\n",
    "Thetop-rightpanelofFigure5.7displaystheresultingdecisionboundary,\n",
    "whichisnowcurved.However,thetesterrorratehasimprovedonlyslightly,\n",
    "to0.197.Amuchlargerimprovementisapparentinthebottom-leftpanel of Figure 5.7, in which we have fit a logistic regression model involving\n",
    "cubic polynomials of the predictors. Now the test error rate has decreased\n",
    "to 0.160. Going to a quartic polynomial (bottom-right) slightly increases\n",
    "the test error.\n",
    "In practice, for real data, the Bayes decision boundary and the test er\n",
    "ror rates are unknown. So how might we decide between the four logistic\n",
    "regression models displayed in Figure 5.7? We can use cross-validation in\n",
    "order to make this decision. The left-hand panel of Figure 5.8 displays in\n",
    "black the 10-fold CV error rates that result from fitting ten logistic regres\n",
    "sion models to the data, using polynomial functions of the predictors up\n",
    "to tenth order. The true test errors are shown in brown, and the training\n",
    "errors are shown in blue. As we have seen previously, the training error\n",
    "tends to decrease as the flexibility of the fit increases. (The figure indicates\n",
    "that though the training error rate doesn’t quite decrease monotonically,\n",
    "it tends to decrease on the whole as the model complexity increases.) In\n",
    "contrast, the test error displays a characteristic U-shape. The 10-fold CV\n",
    "error rate provides a pretty good approximation to the test error rate.\n",
    "While it somewhat underestimates the error rate, it reaches a minimum\n",
    "when fourth-order polynomials are used, which is very close to the min\n",
    "imum of the test curve, which occurs when third-order polynomials are\n",
    "used. In fact, using fourth-order polynomials would likely lead to good test\n",
    "set performance, as the true test error rate is approximately the same for\n",
    "third, fourth, fifth, and sixth-order polynomials.\n",
    "The right-hand panel of Figure 5.8 displays the same three curves us\n",
    "ing the KNN approach for classification, as a function of the value of K\n",
    "(which in this context indicates the number of neighbors used in the KNN\n",
    "classifier, rather than the number of CV folds used). Again the training\n",
    "error rate declines as the method becomes more flexible, and so we see that\n",
    "the training error rate cannot be used to select the optimal value for K.\n",
    "Though the cross-validation error curve slightly underestimates the test error rate, it takes on a minimum very close to the best value for K."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f409f0b5",
   "metadata": {},
   "source": [
    "####  The Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f469a",
   "metadata": {},
   "source": [
    "The bootstrap is a widely applicable and extremely powerful statistical tool bootstrap\n",
    "that can be used to quantify the uncertainty associated with a given esti\n",
    "mator or statistical learning method. As a simple example, the bootstrap\n",
    "can be used to estimate the standard errors of the coefficients from a linear\n",
    "regression fit. In the specific case of linear regression, this is not particularly\n",
    "useful, since we saw in Chapter 3 that standard statistical software such as\n",
    "R outputs such standard errors automatically. However, the power of the\n",
    "bootstrap lies in the fact that it can be easily applied to a wide range of\n",
    "statistical learning methods, including some for which a measure of vari\n",
    "ability is otherwise difficult to obtain and is not automatically output by\n",
    "statistical software.\n",
    "In this section we illustrate the bootstrap on a toy example in which we\n",
    "wish to determine the best investment allocation under a simple model.\n",
    "In Section 5.3 we explore the use of the bootstrap to assess the variability\n",
    "associated with the regression coefficients in a linear model fit.\n",
    "Suppose that we wish to invest a fixed sum of money in two financial\n",
    "assets that yield returns of X and Y, respectively, where X and Y are\n",
    "random quantities. We will invest a fraction of our money in X, and will\n",
    "invest the remaining 1 \n",
    "in Y. Since there is variability associated with\n",
    "the returns on these two assets, we wish to choose to minimize the total\n",
    "risk, or variance, of our investment. In other words, we want to minimize\n",
    "Var( X+(1 )Y). One can show that the value that minimizes the risk\n",
    "is given by\n",
    "\n",
    "2=\n",
    "Y \n",
    "XY\n",
    "2\n",
    "X + 2\n",
    "Y 2XY\n",
    "\n",
    "(5.6)\n",
    "\n",
    "where 2\n",
    "X = Var(X), 2\n",
    "Y = Var(Y), and XY = Cov(X,Y).\n",
    "In reality, the quantities 2\n",
    "X, 2\n",
    "Y , and XY are unknown. We can compute\n",
    "estimates for these quantities, ˆ2\n",
    "X, ˆ2\n",
    "Y , and ˆXY, using a data set that\n",
    "contains past measurements for X and Y . We can then estimate the value\n",
    "of \n",
    "that minimizes the variance of our investment using\n",
    "\n",
    "ˆ= ˆ2\n",
    "Y ˆXY\n",
    "ˆ2\n",
    "X +ˆ2\n",
    "Y 2ˆXY \n",
    ".\n",
    "(5.7)\n",
    "\n",
    "Figure 5.9 illustrates this approach for estimating on a simulated data\n",
    "set. In each panel, we simulated 100 pairs of returns for the investments\n",
    "X and Y. We used these returns to estimate 2\n",
    "X, 2\n",
    "Y, and XY, which we\n",
    "then substituted into (5.7) in order to obtain estimates for . The value of\n",
    "ˆresulting from each simulated data set ranges from 0.532 to 0.657.\n",
    "It is natural to wish to quantify the accuracy of our estimate of .To\n",
    "estimate the standard deviation of ˆ, we repeated the process of simu\n",
    "lating 100 paired observations of X and Y , and estimating using (5.7),\n",
    "1,000 times. We thereby obtained 1,000 estimates for , which we can call\n",
    "ˆ1, ˆ2,...,ˆ1,000. The left-hand panel of Figure 5.10 displays a histogram\n",
    "of the resulting estimates. For these simulations the parameters were set to\n",
    "2\n",
    "X =1, 2\n",
    "Y =1.25, and XY =0.5, and so we know that the true value of\n",
    "is 0.6. We indicated this value using a solid vertical line on the histogram.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85509ae",
   "metadata": {},
   "source": [
    "Themeanoverall1,000estimatesfor is\n",
    "¯= 1\n",
    "1000\n",
    "1000\n",
    "r=1\n",
    "ˆr=0.5996,\n",
    "verycloseto =0.6,andthestandarddeviationoftheestimatesis\n",
    "1\n",
    "1000 1\n",
    "1000\n",
    "r=1\n",
    "(ˆr ¯)2=0.083.\n",
    "Thisgivesusaverygood ideaof theaccuracyof ˆ: SE(ˆ) 0.083. So\n",
    "roughly speaking, for a randomsample fromthepopulation,wewould\n",
    "expectˆtodifferfrom byapproximately0.08,onaverage.\n",
    "Inpractice,however,theprocedureforestimatingSE(ˆ)outlinedabove\n",
    "cannotbeapplied,becauseforrealdatawecannotgeneratenewsamples\n",
    "fromtheoriginalpopulation.However, thebootstrapapproachallowsus\n",
    "touseacomputer toemulate theprocessof obtainingnewsample sets,\n",
    "sothatwecanestimatethevariabilityof ˆwithoutgeneratingadditional\n",
    "samples.Ratherthanrepeatedlyobtainingindependentdatasetsfromthe\n",
    "population,we insteadobtaindistinctdata setsbyrepeatedlysampling\n",
    "observationsfromtheoriginaldataset.\n",
    "Thisapproachis illustratedinFigure5.11onasimpledataset,which\n",
    "wecallZ, thatcontainsonlyn=3observations.Werandomlyselectn\n",
    "observations fromthedataset inorder toproduceabootstrapdataset, Z1. The sampling is performed with replacement, which means that the with\n",
    "same observation can occur more than once in the bootstrap data set. In\n",
    "this example, Z1 contains the third observation twice, the first observation\n",
    "once, and no instances of the second observation. Note that if an observation\n",
    "is contained in Z1, then both its X and Y values are included. We can use\n",
    "Z1 to produce a new bootstrap estimate for , which we call ˆ 1. This\n",
    "procedure is repeated B times for some large value of B, in order to produce\n",
    "B different bootstrap data sets, Z1,Z2,...,ZB, and B corresponding \n",
    "estimates, ˆ 1, ˆ 2,...,ˆB. We can compute the standard error of these\n",
    "bootstrap estimates using the formula\n",
    "B\n",
    "SEB(ˆ)=\n",
    "1\n",
    "B 1\n",
    "r=1\n",
    "ˆ r \n",
    "1\n",
    "B \n",
    "B\n",
    "r=1\n",
    "ˆ r\n",
    "2\n",
    ".\n",
    "(5.8)\n",
    "This serves as an estimate of the standard error of ˆestimated from the\n",
    "original data set.\n",
    "The bootstrap approach is illustrated in the center panel of Figure 5.10,\n",
    "which displays a histogram of 1,000 bootstrap estimates of , each com\n",
    "puted using a distinct bootstrap data set. This panel was constructed on\n",
    "the basis of a single data set, and hence could be created using real data.\n",
    "Note that the histogram looks very similar to the left-hand panel, which\n",
    "displays the idealized histogram of the estimates of obtained by generat\n",
    "ing 1,000 simulated data sets from the true population. In particular the\n",
    "bootstrap estimate SE(ˆ) from (5.8) is 0.087, very close to the estimate of\n",
    "0.083 obtained using 1,000 simulated data sets. The right-hand panel dis\n",
    "plays the information in the center and left panels in a different way, via\n",
    "boxplots of the estimates for obtained by generating 1,000 simulated data\n",
    "sets from the true population and using the bootstrap approach. Again, the\n",
    "boxplots have similar spreads, indicating that the bootstrap approach can\n",
    "be used to effectively estimate the variability associated with ˆ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc71b94",
   "metadata": {},
   "source": [
    "####  Lab:Cross-Validation and the Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d69b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                            summarize,\n",
    "                            poly)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc9227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import \\\n",
    "    (cross_validate,\n",
    "     KFold,\n",
    "     ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d4b49c",
   "metadata": {},
   "source": [
    "##### The Validation Set Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c78cc1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto = load_data('Auto')\n",
    "Auto_train, Auto_valid = train_test_split(Auto,\n",
    "                                          test_size=196,\n",
    "                                          random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "847b972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_mm = MS(['horsepower'])\n",
    "X_train = hp_mm.fit_transform(Auto_train)\n",
    "y_train = Auto_train['mpg']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b72dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.616617069669882"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = hp_mm.transform(Auto_valid)\n",
    "y_valid = Auto_valid['mpg']\n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid- valid_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dd097eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalMSE(terms,\n",
    "            response,\n",
    "            train,\n",
    "            test):\n",
    "        \n",
    "        mm = MS(terms)\n",
    "        X_train = mm.fit_transform(train)\n",
    "        y_train = train[response]\n",
    "        \n",
    "        X_test = mm.transform(test)\n",
    "        y_test = test[response]\n",
    "        results = sm.OLS(y_train, X_train).fit()\n",
    "        test_pred = results.predict(X_test)\n",
    "        return np.mean((y_test- test_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd5455c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707, 18.76303135, 18.79694163])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = np.zeros(3)\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                       'mpg',\n",
    "                       Auto_train,\n",
    "                       Auto_valid)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f0ce87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.75540796, 16.94510676, 16.97437833])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auto_train, Auto_valid = train_test_split(Auto,\n",
    "                                          test_size=196,\n",
    "                                          random_state=3)\n",
    "MSE = np.zeros(3)\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                       'mpg',\n",
    "                       Auto_train,\n",
    "                       Auto_valid)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ab9132",
   "metadata": {},
   "source": [
    "##### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f06abfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.231513517929226"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model = sklearn_sm(sm.OLS,\n",
    "                      MS(['horsepower']))\n",
    "X, Y = Auto.drop(columns=['mpg']), Auto['mpg']\n",
    "cv_results = cross_validate(hp_model,\n",
    "                            X,\n",
    "                            Y,\n",
    "                            cv=Auto.shape[0])\n",
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a986acd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.23151352, 19.24821312, 19.33498406, 19.4244303 , 19.03322447])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "H = np.array(Auto['horsepower'])\n",
    "M = sklearn_sm(sm.OLS)\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=Auto.shape[0])\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e22a9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  7],\n",
       "       [ 7,  9],\n",
       "       [11, 13]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([3, 5, 9])\n",
    "B = np.array([2, 4])\n",
    "np.add.outer(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbcd3e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.20766449, 19.18533142, 19.27626666, 19.47848402, 19.13718691])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "cv = KFold(n_splits=10,\n",
    "           shuffle=True,\n",
    "           random_state=0) # use same splits for each degree\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=cv)\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44c5cef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = ShuffleSplit(n_splits=1,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=validation);\n",
    "results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8219ef92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.802232661034164, 1.4218450941091882)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = ShuffleSplit(n_splits=10,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=validation)\n",
    "results['test_score'].mean(), results['test_score'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49365985",
   "metadata": {},
   "source": [
    "##### The Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1911cf",
   "metadata": {},
   "source": [
    "Estimating the Accuracy of a Statistic of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b8f3187",
   "metadata": {},
   "outputs": [],
   "source": [
    "Portfolio = load_data('Portfolio')\n",
    "def alpha_func(D, idx):\n",
    "    cov_ = np.cov(D[['X','Y']].loc[idx], rowvar=False)\n",
    "    return ((cov_[1,1]- cov_[0,1]) /\n",
    "            (cov_[0,0]+cov_[1,1]-2*cov_[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "598ed6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57583207459283"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_func(Portfolio, range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0bb397a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6074452469619004"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "alpha_func(Portfolio,\n",
    "           rng.choice(100,\n",
    "                      100,\n",
    "                      replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41794c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_SE(func,\n",
    "            D,\n",
    "            n=None,\n",
    "            B=1000,\n",
    "            seed=0):\n",
    "        rng = np.random.default_rng(seed)\n",
    "        first_, second_ = 0, 0\n",
    "        n = n or D.shape[0]\n",
    "        for _ in range(B):\n",
    "            idx = rng.choice(len(D), \n",
    "                             n, \n",
    "                             replace=True)\n",
    "\n",
    "            value = func(D, idx)\n",
    "            first_ += value\n",
    "            second_ += value**2\n",
    "        return np.sqrt(second_ / B- (first_ / B)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80319b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09118176521277699"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_SE = boot_SE(alpha_func,\n",
    "                   Portfolio,\n",
    "                   B=1000,\n",
    "                   seed=0)\n",
    "alpha_SE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3cc353",
   "metadata": {},
   "source": [
    "Estimating the Accuracy of a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a364764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_OLS(model_matrix, response, D, idx):\n",
    "    D_ = D.iloc[idx]\n",
    "    Y_ = D_[response]\n",
    "    X_ = clone(model_matrix).fit_transform(D_)\n",
    "    return sm.OLS(Y_, X_).fit().params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5af0f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_func = partial(boot_OLS, MS(['horsepower']), 'mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "beade960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.88064456, -0.1567849 ],\n",
       "       [38.73298691, -0.14699495],\n",
       "       [38.31734657, -0.14442683],\n",
       "       [39.91446826, -0.15782234],\n",
       "       [39.43349349, -0.15072702],\n",
       "       [40.36629857, -0.15912217],\n",
       "       [39.62334517, -0.15449117],\n",
       "       [39.0580588 , -0.14952908],\n",
       "       [38.66688437, -0.14521037],\n",
       "       [39.64280792, -0.15555698]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "np.array([hp_func(Auto,\n",
    "                  rng.choice(392,\n",
    "                             392,\n",
    "                             replace=True)) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e267217b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "5a6b0739-48db-48dd-9cca-dd4753fe2839",
       "rows": [
        [
         "intercept",
         "0.848807486625101"
        ],
        [
         "horsepower",
         "0.007351532719270423"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "intercept     0.848807\n",
       "horsepower    0.007352\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_se = boot_SE(hp_func,\n",
    "                Auto,\n",
    "                B=1000,\n",
    "                seed=10)\n",
    "hp_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "848dcf28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "std err",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "dcd081cb-4cfe-491c-a9c7-e2911949077e",
       "rows": [
        [
         "intercept",
         "0.717"
        ],
        [
         "horsepower",
         "0.006"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "intercept     0.717\n",
       "horsepower    0.006\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model.fit(Auto, Auto['mpg'])\n",
    "model_se = summarize(hp_model.results_)['std err']\n",
    "model_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd83efc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "4fd39361-20e8-4d8b-86bc-83f0020b5879",
       "rows": [
        [
         "intercept",
         "2.0678395776921237"
        ],
        [
         "poly(horsepower, degree=2, raw=True)[0]",
         "0.03301887735583843"
        ],
        [
         "poly(horsepower, degree=2, raw=True)[1]",
         "0.00011971222618619913"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/plain": [
       "intercept                                  2.067840\n",
       "poly(horsepower, degree=2, raw=True)[0]    0.033019\n",
       "poly(horsepower, degree=2, raw=True)[1]    0.000120\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quad_model = MS([poly('horsepower', 2, raw=True)])\n",
    "quad_func = partial(boot_OLS,\n",
    "                    quad_model,\n",
    "                    'mpg')\n",
    "boot_SE(quad_func, Auto, B=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3059865c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "std err",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "289aaa11-1613-4003-adab-f140103e952a",
       "rows": [
        [
         "intercept",
         "1.8"
        ],
        [
         "poly(horsepower, degree=2, raw=True)[0]",
         "0.031"
        ],
        [
         "poly(horsepower, degree=2, raw=True)[1]",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/plain": [
       "intercept                                  1.800\n",
       "poly(horsepower, degree=2, raw=True)[0]    0.031\n",
       "poly(horsepower, degree=2, raw=True)[1]    0.000\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = sm.OLS(Auto['mpg'],\n",
    "           quad_model.fit_transform(Auto))\n",
    "summarize(M.fit())['std err']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075147e",
   "metadata": {},
   "source": [
    "####  Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ec3eba",
   "metadata": {},
   "source": [
    "Conceptual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ebe985",
   "metadata": {},
   "source": [
    "1. Using basic statistical properties of the variance, as well as single-variable calculus, derive $$\n",
    "\\alpha = \\frac{\\sigma^2_Y - \\sigma_{XY}}{\\sigma^2_X + \\sigma^2_Y - 2\\sigma_{XY}}\n",
    " (5.6).$$ In other words, prove that $ \\alpha $ given by (5.6) does indeed minimize $ \\text{Var}(\\alpha X + (1 - \\alpha) Y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57d695",
   "metadata": {},
   "source": [
    "We want to minimize the variance of a portfolio $\\alpha X + (1-\\alpha)Y$ with respect to $\\alpha$.\n",
    "\n",
    "##### Step 1: Express the variance\n",
    "\n",
    "Using the basic properties of variance:\n",
    "\n",
    "$$\\text{Var}(\\alpha X + (1-\\alpha)Y) = \\text{Var}(\\alpha X) + \\text{Var}((1-\\alpha)Y) + 2\\text{Cov}(\\alpha X, (1-\\alpha)Y)$$\n",
    "\n",
    "##### Step 2: Apply variance properties\n",
    "\n",
    "For constants $a$ and $b$:\n",
    "- $\\text{Var}(aX) = a^2\\text{Var}(X)$\n",
    "- $\\text{Cov}(aX, bY) = ab\\text{Cov}(X,Y)$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$\\text{Var}(\\alpha X + (1-\\alpha)Y) = \\alpha^2\\sigma^2_X + (1-\\alpha)^2\\sigma^2_Y + 2\\alpha(1-\\alpha)\\sigma_{XY}$$\n",
    "\n",
    "##### Step 3: Expand the expression\n",
    "\n",
    "$$f(\\alpha) = \\alpha^2\\sigma^2_X + (1-2\\alpha + \\alpha^2)\\sigma^2_Y + 2\\alpha(1-\\alpha)\\sigma_{XY}$$\n",
    "\n",
    "$$= \\alpha^2\\sigma^2_X + \\sigma^2_Y - 2\\alpha\\sigma^2_Y + \\alpha^2\\sigma^2_Y + 2\\alpha\\sigma_{XY} - 2\\alpha^2\\sigma_{XY}$$\n",
    "\n",
    "$$= \\alpha^2(\\sigma^2_X + \\sigma^2_Y - 2\\sigma_{XY}) + \\alpha(2\\sigma_{XY} - 2\\sigma^2_Y) + \\sigma^2_Y$$\n",
    "\n",
    "##### Step 4: Find the minimum using calculus\n",
    "\n",
    "To minimize, take the derivative with respect to $\\alpha$ and set it equal to zero:\n",
    "\n",
    "$$\\frac{df}{d\\alpha} = 2\\alpha(\\sigma^2_X + \\sigma^2_Y - 2\\sigma_{XY}) + 2\\sigma_{XY} - 2\\sigma^2_Y = 0$$\n",
    "\n",
    "##### Step 5: Solve for α\n",
    "\n",
    "$$2\\alpha(\\sigma^2_X + \\sigma^2_Y - 2\\sigma_{XY}) = 2\\sigma^2_Y - 2\\sigma_{XY}$$\n",
    "\n",
    "$$\\alpha(\\sigma^2_X + \\sigma^2_Y - 2\\sigma_{XY}) = \\sigma^2_Y - \\sigma_{XY}$$\n",
    "\n",
    "$$\\boxed{\\alpha = \\frac{\\sigma^2_Y - \\sigma_{XY}}{\\sigma^2_X + \\sigma^2_Y - 2\\sigma_{XY}}}$$\n",
    "\n",
    "##### Step 6: Verify this is a minimum\n",
    "\n",
    "The second derivative is:\n",
    "\n",
    "$$\\frac{d^2f}{d\\alpha^2} = 2(\\sigma^2_X + \\sigma^2_Y - 2\\sigma_{XY})$$\n",
    "\n",
    "For this to be a minimum, we need $\\frac{d^2f}{d\\alpha^2} > 0$, which requires:\n",
    "\n",
    "$$\\sigma^2_X + \\sigma^2_Y - 2\\sigma_{XY} > 0$$\n",
    "\n",
    "This is guaranteed to be true because $\\sigma^2_X + \\sigma^2_Y - 2\\sigma_{XY} = \\text{Var}(X - Y) \\geq 0$, with equality only when $X = Y$ almost surely.\n",
    "\n",
    "**Therefore, the formula (5.6) is proven.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87411358",
   "metadata": {},
   "source": [
    "2. We will now derive the probability that a given observation is part of a bootstrap sample. Suppose that we obtain a bootstrap sample from a set of $ n $ observations.\n",
    "\n",
    "   (a) What is the probability that the first bootstrap observation is **not** the $ j $ th observation from the original sample? Justify your answer.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5982d2ee",
   "metadata": {},
   "source": [
    "\n",
    "In bootstrap sampling, we sample **with replacement** from n observations. Each draw is independent and uniform.\n",
    "\n",
    "For any single draw, the probability of selecting the jth observation is $\\frac{1}{n}$.\n",
    "\n",
    "Therefore, the probability that the first bootstrap observation is **NOT** the jth observation is:\n",
    "\n",
    "$$P(\\text{first obs} \\neq j) = 1 - \\frac{1}{n}$$\n",
    "\n",
    "**Justification:** Since we sample uniformly at random from n observations, each observation has equal probability $\\frac{1}{n}$ of being selected. The complement gives us the probability of not selecting observation j."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774e371c",
   "metadata": {},
   "source": [
    "(b) What is the probability that the second bootstrap observation is **not** the $ j $ th observation from the original sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f04672",
   "metadata": {},
   "source": [
    "Since bootstrap sampling is done **with replacement**, each draw is independent of all previous draws.\n",
    "\n",
    "Therefore, the probability that the second bootstrap observation is **NOT** the jth observation is:\n",
    "\n",
    "$$P(\\text{second obs} \\neq j) = 1 - \\frac{1}{n}$$\n",
    "\n",
    "This is the same as part (a) because of independence and the fact that we're sampling with replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e636df",
   "metadata": {},
   "source": [
    "(c) Argue that the probability that the $ j $ th observation is **not** in the bootstrap sample is $ (1 - \\frac{1}{n})^n $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee075e6",
   "metadata": {},
   "source": [
    "Since we draw n observations with replacement, and each draw is independent, the jth observation is NOT in the bootstrap sample if and only if it is not selected in ANY of the n draws.\n",
    "\n",
    "Using independence:\n",
    "\n",
    "$$P(j \\text{ not in bootstrap sample}) = P(\\text{draw 1} \\neq j) \\times P(\\text{draw 2} \\neq j) \\times \\cdots \\times P(\\text{draw n} \\neq j)$$\n",
    "\n",
    "$$= \\left(1 - \\frac{1}{n}\\right) \\times \\left(1 - \\frac{1}{n}\\right) \\times \\cdots \\times \\left(1 - \\frac{1}{n}\\right)$$\n",
    "\n",
    "$$= \\left(1 - \\frac{1}{n}\\right)^n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492b4a94",
   "metadata": {},
   "source": [
    "(d) When $n = 5$, what is the probability that the $j$ th observation is in the bootstrap sample?\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8649aa5b",
   "metadata": {},
   "source": [
    "The probability that the jth observation **IS** in the bootstrap sample is the complement:\n",
    "\n",
    "$$P(j \\text{ in bootstrap sample}) = 1 - P(j \\text{ not in bootstrap sample}) = 1 - \\left(1 - \\frac{1}{n}\\right)^n$$\n",
    "\n",
    "For n = 5:\n",
    "\n",
    "```python\n",
    "n = 5\n",
    "prob_not_in = (1 - 1/n)**n\n",
    "prob_in = 1 - prob_not_in\n",
    "print(f\"When n = {n}:\")\n",
    "print(f\"Probability j is NOT in bootstrap sample: {prob_not_in:.6f}\")\n",
    "print(f\"Probability j IS in bootstrap sample: {prob_in:.6f}\")\n",
    "```\n",
    "\n",
    "When n = 5:\n",
    "Probability j is NOT in bootstrap sample: 0.327680\n",
    "Probability j IS in bootstrap sample: 0.672320\n",
    "\n",
    "**Answer: 0.6723 or approximately 67.23%**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e313c3",
   "metadata": {},
   "source": [
    "(e) When $n = 100$, what is the probability that the $j$ th observation is in the bootstrap sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0032101b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When n = 100:\n",
      "Probability j is NOT in bootstrap sample: 0.366032\n",
      "Probability j IS in bootstrap sample: 0.633968\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "prob_not_in = (1 - 1/n)**n\n",
    "prob_in = 1 - prob_not_in\n",
    "print(f\"When n = {n}:\")\n",
    "print(f\"Probability j is NOT in bootstrap sample: {prob_not_in:.6f}\")\n",
    "print(f\"Probability j IS in bootstrap sample: {prob_in:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a28b8c0",
   "metadata": {},
   "source": [
    "When $n$ = 100:\n",
    "\n",
    "Probability $j$ is NOT in bootstrap sample: 0.366032\n",
    "\n",
    "Probability $j$ IS in bootstrap sample: 0.633968\n",
    "\n",
    "**Answer: 0.6340 or approximately 63.40%**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ae96e5",
   "metadata": {},
   "source": [
    "(f) When $n = 10,000$, what is the probability that the $j$ th observation is in the bootstrap sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f177ca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When n = 10000:\n",
      "Probability j is NOT in bootstrap sample: 0.367861\n",
      "Probability j IS in bootstrap sample: 0.632139\n"
     ]
    }
   ],
   "source": [
    "n = 10000\n",
    "prob_not_in = (1 - 1/n)**n\n",
    "prob_in = 1 - prob_not_in\n",
    "print(f\"When n = {n}:\")\n",
    "print(f\"Probability j is NOT in bootstrap sample: {prob_not_in:.6f}\")\n",
    "print(f\"Probability j IS in bootstrap sample: {prob_in:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a5a3a",
   "metadata": {},
   "source": [
    "\n",
    "When $n$ = 10000:\n",
    "\n",
    "Probability $j$ is NOT in bootstrap sample: 0.367861\n",
    "\n",
    "Probability $j$ IS in bootstrap sample: 0.632139\n",
    "\n",
    "**Answer: 0.6321 or approximately 63.21%**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d707d0f6",
   "metadata": {},
   "source": [
    "(g) Create a plot that displays, for each integer value of $n$ from 1 to 100,000, the probability that the $j$ th observation is in the bootstrap sample. Comment on what you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b8cd03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "As n → ∞, the probability converges to: 1 - 1/e = 0.632121\n",
      "This is approximately 63.21%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create array of n values from 1 to 100,000\n",
    "n_values = np.arange(1, 100001)\n",
    "\n",
    "# Calculate probability that jth observation IS in bootstrap sample\n",
    "prob_in_sample = 1 - (1 - 1/n_values)**n_values\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_values, prob_in_sample, linewidth=1.5)\n",
    "plt.axhline(y=1 - 1/np.e, color='r', linestyle='--', linewidth=2, \n",
    "            label=f'Limit: 1 - 1/e ≈ {1 - 1/np.e:.6f}')\n",
    "plt.xlabel('n (sample size)', fontsize=12)\n",
    "plt.ylabel('Probability jth observation is in bootstrap sample', fontsize=12)\n",
    "plt.title('Probability of Observation Being in Bootstrap Sample vs. Sample Size', \n",
    "          fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=11)\n",
    "plt.ylim([0.6, 0.7])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the limiting value\n",
    "print(f\"\\nAs n → ∞, the probability converges to: 1 - 1/e = {1 - 1/np.e:.6f}\")\n",
    "print(f\"This is approximately {100*(1 - 1/np.e):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f755f0",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "1. **Rapid convergence:** The probability quickly converges to a limiting value as n increases. Even by n = 20-30, the probability is very close to its asymptotic limit.\n",
    "\n",
    "2. **Limiting value:** As $n \\to \\infty$, the probability converges to $1 - \\frac{1}{e} \\approx 0.6321$ (approximately 63.21%). This follows from the well-known limit:\n",
    "   $$\\lim_{n \\to \\infty} \\left(1 - \\frac{1}{n}\\right)^n = \\frac{1}{e}$$\n",
    "\n",
    "3. **Practical implication:** Regardless of how large the original dataset is, any given observation has roughly a 63.2% chance of appearing in a bootstrap sample. This means approximately 36.8% of the original observations are **not** included in any given bootstrap sample.\n",
    "\n",
    "4. **Monotonic increase:** The probability increases monotonically with n, starting at 0 when n=1 (since we can only select that one observation) and approaching the limit from below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e9c8e7",
   "metadata": {},
   "source": [
    "(h) We will now investigate numerically the probability that a bootstrap sample of size $n = 100$ contains the $j$ th observation. Here $j = 4$. We first create an array structure that will subsequently be overwritten using the function `np.empty()`. We then repeatedly create bootstrap samples, and each time we record whether or not the first observation is contained in the bootstrap sample.\n",
    "   \n",
    "   ```python\n",
    "    rng = np.random.default_rng(0)\n",
    "     = np.empty(10000)\n",
    "    for i in range(10000):\n",
    "        store[i] = np.sum(np.random.choice(100, replace=True) == 4)\n",
    "    np.mean(store)\n",
    "```\n",
    "    \n",
    "Comment on the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d49a8e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical probability (from simulation): 0.641300\n",
      "Theoretical probability: 0.633968\n",
      "Difference: 0.007332\n",
      "\n",
      "Number of simulations where j=4 was in sample: 6413/10000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "store = np.empty(10000)\n",
    "\n",
    "for i in range(10000):\n",
    "    # Create bootstrap sample of size 100 from observations 0 to 99\n",
    "    bootstrap_sample = rng.choice(100, size=100, replace=True)\n",
    "    # Check if observation 4 is in the bootstrap sample\n",
    "    store[i] = np.sum(bootstrap_sample == 4) > 0  # True if 4 appears at least once\n",
    "\n",
    "empirical_prob = np.mean(store)\n",
    "theoretical_prob = 1 - (1 - 1/100)**100\n",
    "\n",
    "print(f\"Empirical probability (from simulation): {empirical_prob:.6f}\")\n",
    "print(f\"Theoretical probability: {theoretical_prob:.6f}\")\n",
    "print(f\"Difference: {abs(empirical_prob - theoretical_prob):.6f}\")\n",
    "print(f\"\\nNumber of simulations where j=4 was in sample: {int(np.sum(store))}/10000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f299ad",
   "metadata": {},
   "source": [
    "**Comments on the results:**\n",
    "\n",
    "1. **Close agreement:** The empirical probability from the simulation closely matches the theoretical probability of approximately 0.634. With 10,000 simulations, we expect good convergence to the true value.\n",
    "\n",
    "2. **Law of Large Numbers:** The simulation demonstrates the law of large numbers - as we increase the number of bootstrap replications, the empirical frequency converges to the theoretical probability.\n",
    "\n",
    "3. **Code note:** The original code had `np.random.choice(100, replace=True)` which would only draw a single value. It should be `np.random.choice(100, size=100, replace=True)` to create a bootstrap sample of size 100.\n",
    "\n",
    "4. **Interpretation:** Out of 10,000 bootstrap samples, observation j=4 appeared in approximately 6,340 of them, confirming our theoretical calculation that any given observation has about a 63.4% chance of being included in a bootstrap sample when n=100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de70f0b6",
   "metadata": {},
   "source": [
    "3. We now review **k-fold cross-validation**.\n",
    "\n",
    "   (a) Explain how k-fold cross-validation is implemented.\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e98a1c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3702e422",
   "metadata": {},
   "source": [
    "(b) What are the advantages and disadvantages of k-fold cross-validation relative to:\n",
    "   \n",
    "i. The validation set approach?\n",
    "\n",
    "ii. LOOCV?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb87a91",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c20e1f66",
   "metadata": {},
   "source": [
    "4. Suppose that we use some statistical learning method to make a prediction for the response $Y$ for a particular value of the predictor $X$. Carefully describe how we might estimate the standard deviation of our prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87587cbb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10e2b0eb",
   "metadata": {},
   "source": [
    "Applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c747dac",
   "metadata": {},
   "source": [
    "5. In Chapter 4, we used logistic regression to predict the probability of\n",
    "default using income and balance on the Default data set. We will\n",
    "now estimate the test error of this logistic regression model using the\n",
    "validation set approach. Do not forget to set a random seed before\n",
    "beginning your analysis.\n",
    "(a) Fit a logistic regression model that uses `income` and `balance` to\n",
    "predict `default`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f0a33c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7b08fa5",
   "metadata": {},
   "source": [
    "(b) Using the validation set approach, estimate the test error of this\n",
    "model. In order to do this, you must perform the following steps:\n",
    "\n",
    "i. Split the sample set into a training set and a validation set.\n",
    "\n",
    "ii. Fit a multiple logistic regression model using only the train\n",
    "ing observations.\n",
    "\n",
    "iii. Obtain a prediction of default status for each individual in\n",
    "the validation set by computing the posterior probability of\n",
    "default for that individual, and classifying the individual to\n",
    "the default category if the posterior probability is greater\n",
    "than 0.5.\n",
    "\n",
    "iv. Compute the validation set error, which is the fraction of\n",
    "the observations in the validation set that are misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4e539f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d49a4a30",
   "metadata": {},
   "source": [
    "(c) Repeat the process in (b) three times, using three different splits\n",
    "of the observations into a training set and a validation set. Com\n",
    "ment on the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95851014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21cb3bdc",
   "metadata": {},
   "source": [
    "(d) Now consider a logistic regression model that predicts the prob\n",
    "ability of default using income, balance, and a dummy variable\n",
    "for student. Estimate the test error for this model using the val\n",
    "idation set approach. Comment on whether or not including a\n",
    "dummyvariable for student leads to a reduction in the test error\n",
    "rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af59b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab978490",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a45e52c7",
   "metadata": {},
   "source": [
    "6. We continue to consider the use of a logistic regression model to\n",
    "predict the probability of default using `income` and `balance` on the\n",
    "`Default` data set. In particular, we will now compute estimates for the\n",
    "standard errors of the income and balance logistic regression coeffi\n",
    "cients in two different ways: (1) using the **bootstrap**, and (2) using the\n",
    "standard formula for computing the standard errors in the `sm.GLM()`\n",
    "function. Do not forget to set a random seed before beginning your\n",
    "analysis.\n",
    "\n",
    "(a) Using the summarize() and sm.GLM() functions, determine the\n",
    "estimated standard errors for the coefficients associated with\n",
    "income and balance in a multiple logistic regression model that\n",
    "uses both predictors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5e943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaeeede3",
   "metadata": {},
   "source": [
    "(b) Write a function, `boot_fn()`, that takes as input the `Default` data\n",
    "set as well as an index of the observations, and that outputs\n",
    "the coefficient estimates for income and balance in the multiple\n",
    "logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c884f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9979c738",
   "metadata": {},
   "source": [
    "(c) Following the bootstrap example in the lab, use your `boot_fn()`\n",
    "function to estimate the standard errors of the logistic regression\n",
    "coefficients for `income` and `balance`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c5ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60322539",
   "metadata": {},
   "source": [
    "(d) Comment on the estimated standard errors obtained using the\n",
    "`sm.GLM()` function and using the bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c43d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bc3525f",
   "metadata": {},
   "source": [
    "7. In Sections 5.1.2 and 5.1.3, we saw that the `cross_validate()` function\n",
    "can be used in order to compute the LOOCV test error estimate.\n",
    "Alternatively, one could compute those quantities using just `sm.GLM()`\n",
    "and the `predict()` method of the fitted model within a for loop. You\n",
    "will now take this approach in order to compute the LOOCV error\n",
    "for a simple logistic regression model on the Weekly data set. Recall\n",
    "that in the context of classification problems, the LOOCV error is\n",
    "given in $CV_{(n)} = \\frac{1}{n} \\sum_{i=1}^{n} Err_i\n",
    "$ (5.4).\n",
    "\n",
    "(a) Fit a logistic regression model that predicts `Direction` using `Lag1`\n",
    "and `Lag2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b7b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "413c7bf7",
   "metadata": {},
   "source": [
    "\n",
    "(b) Fit a logistic regression model that predicts `Direction` using `Lag1`\n",
    "and `Lag2` *using all but the first observation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866549df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a36db15",
   "metadata": {},
   "source": [
    "(c) Use the model from (b) to predict the direction of the first obser\n",
    "vation. You can do this by predicting that the first observation\n",
    "will go up if *P*(`Direction = \"Up\"|Lag1, Lag2`) > 0.5. Was this\n",
    "observation correctly classified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5140558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21c0a42f",
   "metadata": {},
   "source": [
    "(d) Write a for loop from $i =1$ to $i = n$, where $n$ is the number of\n",
    "observations in the data set, that performs each of the following\n",
    "steps:\n",
    "\n",
    "i. Fit a logistic regression model using all but the ith obser\n",
    "vation to predict Direction using `Lag1` and `Lag2`.\n",
    "\n",
    "ii. Compute the posterior probability of the market moving up\n",
    "for the ith observation.\n",
    "\n",
    "iii. Use the posterior probability for the ith observation in order\n",
    "to predict whether or not the market moves up.\n",
    "\n",
    "iv. Determine whether or not an error was made in predicting\n",
    "the direction for the ith observation. If an error was made,\n",
    "then indicate this as a 1, and otherwise indicate it as a 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44656558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f995f6c",
   "metadata": {},
   "source": [
    "(e) Take the average of the $n$ numbers obtained in (d)iv in order to\n",
    "obtain the LOOCV estimate for the test error. Comment on the\n",
    "results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10808bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e6731a0",
   "metadata": {},
   "source": [
    "8. We will now perform cross-validation on a simulated data set.\n",
    "\n",
    "   (a) Generate a simulated data set as follows:\n",
    "\n",
    "   ```python\n",
    "   rng = np.random.default_rng(1)\n",
    "   x = rng.normal(size=100)\n",
    "   y = x**2 + rng.normal(size=100)\n",
    "   ```\n",
    "\n",
    "   In this data set, what is $ n $ and what is $ p $? Write out the model used to generate the data in equation form.\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e288bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd627209",
   "metadata": {},
   "source": [
    "(b) Create a scatterplot of $ X $ against $ Y $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638b7d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10281c50",
   "metadata": {},
   "source": [
    "(c) Create a linear model and then compute the LOOCV errors that result from fitting the following four models using least squares:\n",
    "\n",
    "   i. $ Y = \\beta_0 + \\beta_1 X $\n",
    "\n",
    "   ii. $ Y = \\beta_0 + \\beta_1 X^2 $\n",
    "\n",
    "   iii. $ Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 $\n",
    "\n",
    "   iv. $ Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 $\n",
    "\n",
    "   Note: You may find it helpful to use the `data.frame()` function to create a single data set containing both $ X $ and $ Y $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190bf761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8cac928",
   "metadata": {},
   "source": [
    "(d) Repeat (c) using another random seed, and report your results.\n",
    "Are your results the same as what you got in (c)? Why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2be2ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeb96bc2",
   "metadata": {},
   "source": [
    "(e) Which of the models in (c) had the smallest LOOCV error? Is\n",
    "this what you expected? Explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5316f6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c66b916",
   "metadata": {},
   "source": [
    "(f) Comment on the statistical significance of the coefficient estimates that results from fitting each of the models in (c) using\n",
    "least squares. Do these results agree with the conclusions drawn\n",
    "based on the cross-validation results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d324f954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3199ac8",
   "metadata": {},
   "source": [
    "9. We will now consider the `Boston` housing data set, from the `ISLP`\n",
    "library.\n",
    "\n",
    "(a) Based on this data set, provide an estimate for the population\n",
    "mean of `medv`. Call this estimate $ \\hat{\\mu} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab328976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1703957c",
   "metadata": {},
   "source": [
    "(b) Provide an estimate of the standard error of $ \\hat{\\mu} $. \n",
    "\n",
    "*Hint: We can compute the standard error of the sample mean by dividing the sample standard deviation by the square root of the number of observations.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770f1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c7490fd",
   "metadata": {},
   "source": [
    "(c) Now estimate the standard error of $ \\hat{\\mu} $ using the bootstrap. How does this compare to your answer from (b)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad579f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69ee1953",
   "metadata": {},
   "source": [
    "(d) Based on your bootstrap estimate from (c), provide a 95% confidence interval for the mean of `medv`. Compare it to the results obtained by using `Boston['medv'].std()` and the two standard error rule $\n",
    "\\hat{\\beta}_1 \\pm 2 \\cdot SE(\\hat{\\beta}_1)\n",
    "$ (3.9).\n",
    "\n",
    "*Hint: You can approximate a 95% confidence interval using the\n",
    "formula* $ \\text{CI} = [\\hat{\\mu} - 2\\text{SE}(\\hat{\\mu}) , \\hat{\\mu} + 2\\text{SE}(\\hat{\\mu})] $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dec680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40b2054e",
   "metadata": {},
   "source": [
    "(e) Based on this data set, provide an estimate, $ \\hat{\\mu}_{med} $, for the median value of `medv` in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f5695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f50dacb7",
   "metadata": {},
   "source": [
    "(f) Now we would like to estimate the standard error of $ \\hat{\\mu}_{med} $. There is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440dfdb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "058e6df7",
   "metadata": {},
   "source": [
    "(g) Based on this data set, estimate for the tenth percentile of medv in Boston census tracts. Call this quantity $ \\hat{\\mu}_{1} $. (You can use the `np.percentile()` function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e97d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01ce7836",
   "metadata": {},
   "source": [
    "(h) Use the bootstrap to estimate the standard error of $ \\hat{\\mu}_{0.1} $. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5078c786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "islp_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
